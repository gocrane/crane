{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 The goal of Crane is to provide a one-stop-shop project to help Kubernetes users to save cloud resource usage with a rich set of functionalities: Time Series Prediction based on monitoring data Usage and Cost visibility Usage & Cost Optimization including: R2 (Resource Re-allocation) R3 (Request & Replicas Recommendation) Effective Pod Autoscaling (Effective Horizontal & Vertical Pod Autoscaling) Cost Optimization Enhanced QoS based on Pod PriorityClass Load-aware Scheduling Features \u00b6 Time Series Prediction \u00b6 TimeSeriesPrediction defines metric spec to predict kubernetes resources like Pod or Node. The prediction module is the core component that other crane components relied on, like EHPA and Analytics . Please see this document to learn more. Effective HorizontalPodAutoscaler \u00b6 EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with native HorizontalPodAutoscaler but extends more features like prediction-driven autoscaling. Please see this document to learn more. Analytics \u00b6 Analytics model analyzes the workload and provide recommendations about resource optimize. Two Recommendations are currently supported: ResourceRecommend : Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. HPARecommend : Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster. Please see this document to learn more. QoS Ensurance \u00b6 Kubernetes is capable of starting multiple pods on same node, and as a result, some of the user applications may be impacted when there are resources(e.g. cpu) consumption competition. To mitigate this, Crane allows users defining PrioirtyClass for the pods and QoSEnsurancePolicy, and then detects disruption and ensure the high priority pods not being impacted by resource competition. Avoidance Actions: Disable Schedule : disable scheduling by setting node taint and condition Throttle : throttle the low priority pods by squeezing cgroup settings Evict : evict low priority pods Please see this document to learn more. Load-aware Scheduling \u00b6 Native scheduler of kubernetes can only schedule pods by resource request, which can easily cause a series of load uneven problems. In contrast, Crane-scheduler can get the actual load of kubernetes nodes from Prometheus, and achieve more efficient scheduling. Please see this document to learn more. Repositories \u00b6 Crane is composed of the following components: craned - main crane control plane. Predictor - Predicts resources metrics trends based on historical data. AnalyticsController - Analyzes resources and generate related recommendations. RecommendationController - Recommend Pod resource requests and autoscaler. ClusterNodePredictionController - Create Predictor for nodes. EffectiveHPAController - Effective HPA for horizontal scaling. EffectiveVPAController - Effective VPA for vertical scaling. metric-adaptor - Metric server for driving the scaling. crane-agent - Ensure critical workloads SLO based on abnormally detection. gocrane/api - This repository defines component-level APIs for the Crane platform. gocrane/fadvisor - Financial advisor which collect resource prices from cloud API. gocrane/crane-scheduler - A Kubernetes scheduler which can schedule pod based on actual node load.","title":"Introduction"},{"location":"#introduction","text":"The goal of Crane is to provide a one-stop-shop project to help Kubernetes users to save cloud resource usage with a rich set of functionalities: Time Series Prediction based on monitoring data Usage and Cost visibility Usage & Cost Optimization including: R2 (Resource Re-allocation) R3 (Request & Replicas Recommendation) Effective Pod Autoscaling (Effective Horizontal & Vertical Pod Autoscaling) Cost Optimization Enhanced QoS based on Pod PriorityClass Load-aware Scheduling","title":"Introduction"},{"location":"#features","text":"","title":"Features"},{"location":"#time-series-prediction","text":"TimeSeriesPrediction defines metric spec to predict kubernetes resources like Pod or Node. The prediction module is the core component that other crane components relied on, like EHPA and Analytics . Please see this document to learn more.","title":"Time Series Prediction"},{"location":"#effective-horizontalpodautoscaler","text":"EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with native HorizontalPodAutoscaler but extends more features like prediction-driven autoscaling. Please see this document to learn more.","title":"Effective HorizontalPodAutoscaler"},{"location":"#analytics","text":"Analytics model analyzes the workload and provide recommendations about resource optimize. Two Recommendations are currently supported: ResourceRecommend : Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. HPARecommend : Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster. Please see this document to learn more.","title":"Analytics"},{"location":"#qos-ensurance","text":"Kubernetes is capable of starting multiple pods on same node, and as a result, some of the user applications may be impacted when there are resources(e.g. cpu) consumption competition. To mitigate this, Crane allows users defining PrioirtyClass for the pods and QoSEnsurancePolicy, and then detects disruption and ensure the high priority pods not being impacted by resource competition. Avoidance Actions: Disable Schedule : disable scheduling by setting node taint and condition Throttle : throttle the low priority pods by squeezing cgroup settings Evict : evict low priority pods Please see this document to learn more.","title":"QoS Ensurance"},{"location":"#load-aware-scheduling","text":"Native scheduler of kubernetes can only schedule pods by resource request, which can easily cause a series of load uneven problems. In contrast, Crane-scheduler can get the actual load of kubernetes nodes from Prometheus, and achieve more efficient scheduling. Please see this document to learn more.","title":"Load-aware Scheduling"},{"location":"#repositories","text":"Crane is composed of the following components: craned - main crane control plane. Predictor - Predicts resources metrics trends based on historical data. AnalyticsController - Analyzes resources and generate related recommendations. RecommendationController - Recommend Pod resource requests and autoscaler. ClusterNodePredictionController - Create Predictor for nodes. EffectiveHPAController - Effective HPA for horizontal scaling. EffectiveVPAController - Effective VPA for vertical scaling. metric-adaptor - Metric server for driving the scaling. crane-agent - Ensure critical workloads SLO based on abnormally detection. gocrane/api - This repository defines component-level APIs for the Crane platform. gocrane/fadvisor - Financial advisor which collect resource prices from cloud API. gocrane/crane-scheduler - A Kubernetes scheduler which can schedule pod based on actual node load.","title":"Repositories"},{"location":"CONTRIBUTING/","text":"Contributing to Crane \u00b6 Welcome to Crane! This document is a guideline about how to contribute to Crane. Become a contributor \u00b6 You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides . Report bugs \u00b6 Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug. Suggest enhancements \u00b6 If you have an idea to improve Crane, submit an feature request .","title":"Contributing"},{"location":"CONTRIBUTING/#contributing-to-crane","text":"Welcome to Crane! This document is a guideline about how to contribute to Crane.","title":"Contributing to Crane"},{"location":"CONTRIBUTING/#become-a-contributor","text":"You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides .","title":"Become a contributor"},{"location":"CONTRIBUTING/#report-bugs","text":"Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug.","title":"Report bugs"},{"location":"CONTRIBUTING/#suggest-enhancements","text":"If you have an idea to improve Crane, submit an feature request .","title":"Suggest enhancements"},{"location":"code-standards/","text":"Code standards \u00b6 This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project import need to be organized \u00b6 import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" ) logs standard \u00b6 logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err )) event is needed for critical reconcile loop \u00b6 event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ()) comment \u00b6 every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) } functions \u00b6 function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils variable \u00b6 variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop folder and file \u00b6 folder name should be letter with lower case and number file name should be letter and number and _ unit test \u00b6 Test-driven developing Complex function that include condition decide should add unit test for it don't forget to run make fmt before you submit code \u00b6","title":"Code Standard"},{"location":"code-standards/#code-standards","text":"This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project","title":"Code standards"},{"location":"code-standards/#import-need-to-be-organized","text":"import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" )","title":"import need to be organized"},{"location":"code-standards/#logs-standard","text":"logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err ))","title":"logs standard"},{"location":"code-standards/#event-is-needed-for-critical-reconcile-loop","text":"event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ())","title":"event is needed for critical reconcile loop"},{"location":"code-standards/#comment","text":"every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) }","title":"comment"},{"location":"code-standards/#functions","text":"function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils","title":"functions"},{"location":"code-standards/#variable","text":"variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop","title":"variable"},{"location":"code-standards/#folder-and-file","text":"folder name should be letter with lower case and number file name should be letter and number and _","title":"folder and file"},{"location":"code-standards/#unit-test","text":"Test-driven developing Complex function that include condition decide should add unit test for it","title":"unit test"},{"location":"code-standards/#dont-forget-to-run-make-fmt-before-you-submit-code","text":"","title":"don't forget to run make fmt before you submit code"},{"location":"developer-guide/","text":"First, please make sure you've got a working Go environment and Docker environment . Clone crane \u00b6 Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane Building Binaries \u00b6 Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder. Building Docker Images \u00b6 You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"Developer Guide"},{"location":"developer-guide/#clone-crane","text":"Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane","title":"Clone crane"},{"location":"developer-guide/#building-binaries","text":"Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder.","title":"Building Binaries"},{"location":"developer-guide/#building-docker-images","text":"You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"Building Docker Images"},{"location":"installation/","text":"Installation \u00b6 Prerequisites \u00b6 Kubernetes 1.18+ Helm 3.1.0 Steps \u00b6 Helm Installation \u00b6 Please refer to Helm's documentation for installation. Installing prometheus and grafana with helm chart \u00b6 Note If you already deployed prometheus, grafana in your environment, then skip this step. Network Problems If your network is hard to connect GitHub resources, you can try the mirror repo. Like GitHub Release, GitHub Raw Content raw.githubusercontent.com . But mirror repo has a certain latency . Mirror Repo Crane use prometheus to be the default metric provider. Using following command to install prometheus components: prometheus-server, node-exporter, kube-state-metrics. Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus Fadvisor use grafana to present cost estimates. Using following command to install a grafana. Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana Deploying Crane and Fadvisor \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor Deploying Crane-scheduler(optional) \u00b6 helm install scheduler -n crane-system --create-namespace crane/scheduler Verify Installation \u00b6 Check deployments are all available by running: kubectl get deploy -n crane-system The output is similar to: NAME READY STATUS RESTARTS AGE crane-agent-8h7df 1 /1 Running 0 119m crane-agent-8qf5n 1 /1 Running 0 119m crane-agent-h9h5d 1 /1 Running 0 119m craned-5c69c684d8-dxmhw 2 /2 Running 0 20m grafana-7fddd867b4-kdxv2 1 /1 Running 0 41m metric-adapter-94b6f75b-k8h7z 1 /1 Running 0 119m prometheus-kube-state-metrics-6dbc9cd6c9-dfmkw 1 /1 Running 0 45m prometheus-node-exporter-bfv74 1 /1 Running 0 45m prometheus-node-exporter-s6zps 1 /1 Running 0 45m prometheus-node-exporter-x5rnm 1 /1 Running 0 45m prometheus-server-5966b646fd-g9vxl 2 /2 Running 0 45m you can see this to learn more. Customize Installation \u00b6 Deploy Crane by apply YAML declaration. Main Mirror git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter git clone https://e.coding.net/finops/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter The following command will configure prometheus http address for crane if you want to customize it. Specify CUSTOMIZE_PROMETHEUS if you have existing prometheus server. export CUSTOMIZE_PROMETHEUS = if [ $CUSTOMIZE_PROMETHEUS ] ; then sed -i '' \"s/http:\\/\\/prometheus-server.crane-system.svc.cluster.local:8080/ ${ CUSTOMIZE_PROMETHEUS } /\" deploy/craned/deployment.yaml ; fi Access Dashboard \u00b6 You can use the dashboard to view and manage crane manifests. Port Forward \u00b6 Easy access to the dashboard through kubectl port-forward . kubectl -n crane-system port-forward service/craned 9090 :9090 NodePort \u00b6 # Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"NodePort\"}}' # Get Dashboard link base on your cluster configuration PORT = $( kubectl get svc -n crane-system craned -o jsonpath = '{.spec.ports[?(@.name == \"dashboard-service\")].nodePort}' ) NODE_IP = $( kubectl get node -ojsonpath = '{.items[].status.addresses[?(@.type == \"InternalIP\")].address}' ) echo \"Dashboard link: http:// ${ NODE_IP } : ${ PORT } \" LoadBalancer \u00b6 Quick Start \u00b6 # Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' Example \u00b6 $ kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' service/craned patched $ kubectl get svc -n crane-system craned NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE craned LoadBalancer 10.101.123.74 10.200.0.4 443:30908/TCP,8082:32426/TCP,9090:31331/TCP,8080:31072/TCP 57m # Access dashboard via 10.200.0.4:9090 Ingress \u00b6 kubernetes/ingress-nginx \u00b6 If the cluster version is < 1.19, you can create the ingress resources like this: apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : ingressClassName : nginx rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / backend : serviceName : craned servicePort : 9090 If the cluster uses Kubernetes version >= 1.19.x, then its suggested to create the second ingress resources, using yaml examples shown below. These examples are in conformity with the networking.kubernetes.io/v1 api. apiVersion : networking.k8s.io/v1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / pathType : Prefix backend : service : name : craned port : number : 9090 ingressClassName : nginx Example: $ kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.102.235.229 10.200.0.5 80:32568/TCP,443:30144/TCP 91m ingress-nginx-controller-admission ClusterIP 10.102.49.240 <none> 443/TCP 91m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.5 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................ Traefik \u00b6 apiVersion : traefik.containo.us/v1alpha1 kind : IngressRoute metadata : name : dashboard-crane-ingress namespace : crane-system spec : entryPoints : - web routes : - kind : Rule match : Host(`dashboard.gocrane.io`) services : - name : craned port : 9090 $ kubectl get svc -n traefik-v2 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE traefik LoadBalancer 10.107.109.44 10.200.0.6 80:30102/TCP,443:30139/TCP 16m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................ Get your Kubernetes Cost Report \u00b6 Get the Grafana URL to visit by running these commands in the same shell: export POD_NAME = $( kubectl get pods --namespace crane-system -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana\" -o jsonpath = \"{.items[0].metadata.name}\" ) kubectl --namespace crane-system port-forward $POD_NAME 3000 visit Cost Report here with account(admin:admin).","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#prerequisites","text":"Kubernetes 1.18+ Helm 3.1.0","title":"Prerequisites"},{"location":"installation/#steps","text":"","title":"Steps"},{"location":"installation/#helm-installation","text":"Please refer to Helm's documentation for installation.","title":"Helm Installation"},{"location":"installation/#installing-prometheus-and-grafana-with-helm-chart","text":"Note If you already deployed prometheus, grafana in your environment, then skip this step. Network Problems If your network is hard to connect GitHub resources, you can try the mirror repo. Like GitHub Release, GitHub Raw Content raw.githubusercontent.com . But mirror repo has a certain latency . Mirror Repo Crane use prometheus to be the default metric provider. Using following command to install prometheus components: prometheus-server, node-exporter, kube-state-metrics. Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus Fadvisor use grafana to present cost estimates. Using following command to install a grafana. Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana","title":"Installing prometheus and grafana with helm chart"},{"location":"installation/#deploying-crane-and-fadvisor","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor","title":"Deploying Crane and Fadvisor"},{"location":"installation/#deploying-crane-scheduleroptional","text":"helm install scheduler -n crane-system --create-namespace crane/scheduler","title":"Deploying Crane-scheduler(optional)"},{"location":"installation/#verify-installation","text":"Check deployments are all available by running: kubectl get deploy -n crane-system The output is similar to: NAME READY STATUS RESTARTS AGE crane-agent-8h7df 1 /1 Running 0 119m crane-agent-8qf5n 1 /1 Running 0 119m crane-agent-h9h5d 1 /1 Running 0 119m craned-5c69c684d8-dxmhw 2 /2 Running 0 20m grafana-7fddd867b4-kdxv2 1 /1 Running 0 41m metric-adapter-94b6f75b-k8h7z 1 /1 Running 0 119m prometheus-kube-state-metrics-6dbc9cd6c9-dfmkw 1 /1 Running 0 45m prometheus-node-exporter-bfv74 1 /1 Running 0 45m prometheus-node-exporter-s6zps 1 /1 Running 0 45m prometheus-node-exporter-x5rnm 1 /1 Running 0 45m prometheus-server-5966b646fd-g9vxl 2 /2 Running 0 45m you can see this to learn more.","title":"Verify Installation"},{"location":"installation/#customize-installation","text":"Deploy Crane by apply YAML declaration. Main Mirror git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter git clone https://e.coding.net/finops/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter The following command will configure prometheus http address for crane if you want to customize it. Specify CUSTOMIZE_PROMETHEUS if you have existing prometheus server. export CUSTOMIZE_PROMETHEUS = if [ $CUSTOMIZE_PROMETHEUS ] ; then sed -i '' \"s/http:\\/\\/prometheus-server.crane-system.svc.cluster.local:8080/ ${ CUSTOMIZE_PROMETHEUS } /\" deploy/craned/deployment.yaml ; fi","title":"Customize Installation"},{"location":"installation/#access-dashboard","text":"You can use the dashboard to view and manage crane manifests.","title":"Access Dashboard"},{"location":"installation/#port-forward","text":"Easy access to the dashboard through kubectl port-forward . kubectl -n crane-system port-forward service/craned 9090 :9090","title":"Port Forward"},{"location":"installation/#nodeport","text":"# Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"NodePort\"}}' # Get Dashboard link base on your cluster configuration PORT = $( kubectl get svc -n crane-system craned -o jsonpath = '{.spec.ports[?(@.name == \"dashboard-service\")].nodePort}' ) NODE_IP = $( kubectl get node -ojsonpath = '{.items[].status.addresses[?(@.type == \"InternalIP\")].address}' ) echo \"Dashboard link: http:// ${ NODE_IP } : ${ PORT } \"","title":"NodePort"},{"location":"installation/#loadbalancer","text":"","title":"LoadBalancer"},{"location":"installation/#quick-start","text":"# Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}'","title":"Quick Start"},{"location":"installation/#example","text":"$ kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' service/craned patched $ kubectl get svc -n crane-system craned NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE craned LoadBalancer 10.101.123.74 10.200.0.4 443:30908/TCP,8082:32426/TCP,9090:31331/TCP,8080:31072/TCP 57m # Access dashboard via 10.200.0.4:9090","title":"Example"},{"location":"installation/#ingress","text":"","title":"Ingress"},{"location":"installation/#kubernetesingress-nginx","text":"If the cluster version is < 1.19, you can create the ingress resources like this: apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : ingressClassName : nginx rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / backend : serviceName : craned servicePort : 9090 If the cluster uses Kubernetes version >= 1.19.x, then its suggested to create the second ingress resources, using yaml examples shown below. These examples are in conformity with the networking.kubernetes.io/v1 api. apiVersion : networking.k8s.io/v1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / pathType : Prefix backend : service : name : craned port : number : 9090 ingressClassName : nginx Example: $ kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.102.235.229 10.200.0.5 80:32568/TCP,443:30144/TCP 91m ingress-nginx-controller-admission ClusterIP 10.102.49.240 <none> 443/TCP 91m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.5 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................","title":"kubernetes/ingress-nginx"},{"location":"installation/#traefik","text":"apiVersion : traefik.containo.us/v1alpha1 kind : IngressRoute metadata : name : dashboard-crane-ingress namespace : crane-system spec : entryPoints : - web routes : - kind : Rule match : Host(`dashboard.gocrane.io`) services : - name : craned port : 9090 $ kubectl get svc -n traefik-v2 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE traefik LoadBalancer 10.107.109.44 10.200.0.6 80:30102/TCP,443:30139/TCP 16m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................","title":"Traefik"},{"location":"installation/#get-your-kubernetes-cost-report","text":"Get the Grafana URL to visit by running these commands in the same shell: export POD_NAME = $( kubectl get pods --namespace crane-system -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana\" -o jsonpath = \"{.items[0].metadata.name}\" ) kubectl --namespace crane-system port-forward $POD_NAME 3000 visit Cost Report here with account(admin:admin).","title":"Get your Kubernetes Cost Report"},{"location":"mirror/","text":"Mirror Resources \u00b6 About mirror resources \u00b6 Because of various network issues, it is difficult to access GitHub resources such as GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com in some regions. For a better experience, GoCrane offers several additional mirror repositories for you, but with some latency. Image Registry \u00b6 GoCrane provides a friendly way to use images to deploy and test. GoCrane builds images based on the CI(GitHub Action). Platforms \u00b6 GoCrane now supports linux/amd64 and linux/arm64. GoCrane still cares about arm users, like apple m1/m2. Repo \u00b6 Because of the network problems, GoCrane pushes the images to three different repo at the same time. Tips Click these links to see details. DockerHub Coding GitHub Container Registry If you locate in China, we recommend using the Coding repo. It's fast than other registry repo. If you locate outside of China, we recommend using DockerHub and GitHub Container Registry. However, if you use Coding, the Registry may be slow. Build logic \u00b6 Each branch You can try the new features based on the branch images. In addition, we still reserve the early images. Each pull request When you make a pull request to the crane repo, that will trigger CI to build images. In addition, a comment will include image info to the pull request when CI completes. How to use the images? \u00b6 Here use the main branch as an example. The git commit hash is abc123. Base on the branch name \u00b6 Tips The branch name still points to the last commit. Don't forget to re-pull the images when you want to try the new features. DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main docker pull ghcr.io/gocrane/crane/craned:main Base on the branch name and the specific commit hash \u00b6 DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main-abc123 docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main-abc123 docker pull ghcr.io/gocrane/crane/craned:main-abc123 Helm Resources \u00b6 Tips Sync the latest version of upstream every six hours Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public Git Resources \u00b6 Tips Sync upstream repository every day Coding \u00b6 Warning Now Coding is not support to fetch raw contents directly. You must be get token first. Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public Gitee \u00b6 Origin Mirror Type Public https://github.com/gocrane/crane.git https://gitee.com/finops/crane Git Public https://github.com/gocrane/helm-charts.git https://gitee.com/finops/helm-charts Git Public https://github.com/gocrane/crane-scheduler.git https://gitee.com/finops/crane-scheduler Git Public Get the raw file contents of the Coding repo \u00b6 Warning Now Coding is not support to fetch raw contents directly. You must be get token first. Here you'll find out how to get the contents of a source file directly from the Coding Git repository via an HTTP request. Coding Git Repo - Key Params \u00b6 Similar to regular API requests, the Coding Git repository provides a corresponding API interface. The following is an overview of the related parameters. Example Using https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml as an example. Click Here Params Description example team Name of the team finops project Name of the project gocrane repo Name of the Git Repo helm-charts branch Name of the branch main file path The path to the file in the repo /integration/grafana/override_values.yaml Constructing HTTP requests \u00b6 By filling in the following URL construction rules according to the properties mentioned above, you can obtain a URL that can directly access the content of the source file. https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips Try this command. curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"Mirror Resource"},{"location":"mirror/#mirror-resources","text":"","title":"Mirror Resources"},{"location":"mirror/#about-mirror-resources","text":"Because of various network issues, it is difficult to access GitHub resources such as GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com in some regions. For a better experience, GoCrane offers several additional mirror repositories for you, but with some latency.","title":"About mirror resources"},{"location":"mirror/#image-registry","text":"GoCrane provides a friendly way to use images to deploy and test. GoCrane builds images based on the CI(GitHub Action).","title":"Image Registry"},{"location":"mirror/#platforms","text":"GoCrane now supports linux/amd64 and linux/arm64. GoCrane still cares about arm users, like apple m1/m2.","title":"Platforms"},{"location":"mirror/#repo","text":"Because of the network problems, GoCrane pushes the images to three different repo at the same time. Tips Click these links to see details. DockerHub Coding GitHub Container Registry If you locate in China, we recommend using the Coding repo. It's fast than other registry repo. If you locate outside of China, we recommend using DockerHub and GitHub Container Registry. However, if you use Coding, the Registry may be slow.","title":"Repo"},{"location":"mirror/#build-logic","text":"Each branch You can try the new features based on the branch images. In addition, we still reserve the early images. Each pull request When you make a pull request to the crane repo, that will trigger CI to build images. In addition, a comment will include image info to the pull request when CI completes.","title":"Build logic"},{"location":"mirror/#how-to-use-the-images","text":"Here use the main branch as an example. The git commit hash is abc123.","title":"How to use the images?"},{"location":"mirror/#base-on-the-branch-name","text":"Tips The branch name still points to the last commit. Don't forget to re-pull the images when you want to try the new features. DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main docker pull ghcr.io/gocrane/crane/craned:main","title":"Base on the branch name"},{"location":"mirror/#base-on-the-branch-name-and-the-specific-commit-hash","text":"DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main-abc123 docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main-abc123 docker pull ghcr.io/gocrane/crane/craned:main-abc123","title":"Base on the branch name and the specific commit hash"},{"location":"mirror/#helm-resources","text":"Tips Sync the latest version of upstream every six hours Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public","title":"Helm Resources"},{"location":"mirror/#git-resources","text":"Tips Sync upstream repository every day","title":"Git Resources"},{"location":"mirror/#coding","text":"Warning Now Coding is not support to fetch raw contents directly. You must be get token first. Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public","title":"Coding"},{"location":"mirror/#gitee","text":"Origin Mirror Type Public https://github.com/gocrane/crane.git https://gitee.com/finops/crane Git Public https://github.com/gocrane/helm-charts.git https://gitee.com/finops/helm-charts Git Public https://github.com/gocrane/crane-scheduler.git https://gitee.com/finops/crane-scheduler Git Public","title":"Gitee"},{"location":"mirror/#get-the-raw-file-contents-of-the-coding-repo","text":"Warning Now Coding is not support to fetch raw contents directly. You must be get token first. Here you'll find out how to get the contents of a source file directly from the Coding Git repository via an HTTP request.","title":"Get the raw file contents of the Coding repo"},{"location":"mirror/#coding-git-repo-key-params","text":"Similar to regular API requests, the Coding Git repository provides a corresponding API interface. The following is an overview of the related parameters. Example Using https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml as an example. Click Here Params Description example team Name of the team finops project Name of the project gocrane repo Name of the Git Repo helm-charts branch Name of the branch main file path The path to the file in the repo /integration/grafana/override_values.yaml","title":"Coding Git Repo - Key Params"},{"location":"mirror/#constructing-http-requests","text":"By filling in the following URL construction rules according to the properties mentioned above, you can obtain a URL that can directly access the content of the source file. https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips Try this command. curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"Constructing HTTP requests"},{"location":"proposals/20220228-advanced-cpuset-manger/","text":"Advanced CPUSet Manager \u00b6 Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet. Table of Contents \u00b6 Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations Motivation \u00b6 Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service. Goals \u00b6 Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus Non-Goals/Future Work \u00b6 Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered Proposal \u00b6 Relax restrictions of cpuset allocation \u00b6 Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2 Add new annotation to describe the requirement of cpuset contorl manger \u00b6 apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use. Advanced CPU Manager component \u00b6 Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet User Stories \u00b6 Users can update pod annotaion to control cpuset policy flexibly Story 1 \u00b6 make pod from none to share without recreating pod Story 2 \u00b6 make pod from exclusive to share, so offline process can use these CPUs Risks and Mitigations \u00b6 kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Advanced CpuSet Manager"},{"location":"proposals/20220228-advanced-cpuset-manger/#advanced-cpuset-manager","text":"Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet.","title":"Advanced CPUSet Manager"},{"location":"proposals/20220228-advanced-cpuset-manger/#table-of-contents","text":"Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations","title":"Table of Contents"},{"location":"proposals/20220228-advanced-cpuset-manger/#motivation","text":"Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service.","title":"Motivation"},{"location":"proposals/20220228-advanced-cpuset-manger/#goals","text":"Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus","title":"Goals"},{"location":"proposals/20220228-advanced-cpuset-manger/#non-goalsfuture-work","text":"Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered","title":"Non-Goals/Future Work"},{"location":"proposals/20220228-advanced-cpuset-manger/#proposal","text":"","title":"Proposal"},{"location":"proposals/20220228-advanced-cpuset-manger/#relax-restrictions-of-cpuset-allocation","text":"Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2","title":"Relax restrictions of cpuset allocation"},{"location":"proposals/20220228-advanced-cpuset-manger/#add-new-annotation-to-describe-the-requirement-of-cpuset-contorl-manger","text":"apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use.","title":"Add new annotation to describe the  requirement of cpuset contorl manger"},{"location":"proposals/20220228-advanced-cpuset-manger/#advanced-cpu-manager-component","text":"Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet","title":"Advanced CPU Manager component"},{"location":"proposals/20220228-advanced-cpuset-manger/#user-stories","text":"Users can update pod annotaion to control cpuset policy flexibly","title":"User Stories"},{"location":"proposals/20220228-advanced-cpuset-manger/#story-1","text":"make pod from none to share without recreating pod","title":"Story 1"},{"location":"proposals/20220228-advanced-cpuset-manger/#story-2","text":"make pod from exclusive to share, so offline process can use these CPUs","title":"Story 2"},{"location":"proposals/20220228-advanced-cpuset-manger/#risks-and-mitigations","text":"kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Risks and Mitigations"},{"location":"proposals/20220402-policy-based-abnomal-detection/","text":"Provide a policy-based abnormal detection mechanism in crane-agent \u00b6 Table of Contents \u00b6 Summary \u00b6 Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine. Motivation \u00b6 The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance. Goals \u00b6 Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code. Non-Goals \u00b6 How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope. Proposal \u00b6 User Stories \u00b6 Story 1 \u00b6 A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status. Story 2 \u00b6 The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly. Story 3 \u00b6 The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night. Functional Requirements \u00b6 Implementation Details \u00b6 API \u00b6 NodeQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 } PodQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future. Metrics \u00b6 Built-in metrics \u00b6 Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine. External metrics (New) \u00b6 Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node. Embedded metrics TSDB \u00b6 In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from. Policy \u00b6 The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"proposals/20220402-policy-based-abnomal-detection/#provide-a-policy-based-abnormal-detection-mechanism-in-crane-agent","text":"","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"proposals/20220402-policy-based-abnomal-detection/#table-of-contents","text":"","title":"Table of Contents"},{"location":"proposals/20220402-policy-based-abnomal-detection/#summary","text":"Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine.","title":"Summary"},{"location":"proposals/20220402-policy-based-abnomal-detection/#motivation","text":"The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance.","title":"Motivation"},{"location":"proposals/20220402-policy-based-abnomal-detection/#goals","text":"Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code.","title":"Goals"},{"location":"proposals/20220402-policy-based-abnomal-detection/#non-goals","text":"How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope.","title":"Non-Goals"},{"location":"proposals/20220402-policy-based-abnomal-detection/#proposal","text":"","title":"Proposal"},{"location":"proposals/20220402-policy-based-abnomal-detection/#user-stories","text":"","title":"User Stories"},{"location":"proposals/20220402-policy-based-abnomal-detection/#story-1","text":"A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status.","title":"Story 1"},{"location":"proposals/20220402-policy-based-abnomal-detection/#story-2","text":"The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly.","title":"Story 2"},{"location":"proposals/20220402-policy-based-abnomal-detection/#story-3","text":"The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night.","title":"Story 3"},{"location":"proposals/20220402-policy-based-abnomal-detection/#functional-requirements","text":"","title":"Functional Requirements"},{"location":"proposals/20220402-policy-based-abnomal-detection/#implementation-details","text":"","title":"Implementation Details"},{"location":"proposals/20220402-policy-based-abnomal-detection/#api","text":"","title":"API"},{"location":"proposals/20220402-policy-based-abnomal-detection/#nodeqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 }","title":"NodeQOSEnsurancePolicy"},{"location":"proposals/20220402-policy-based-abnomal-detection/#podqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future.","title":"PodQOSEnsurancePolicy"},{"location":"proposals/20220402-policy-based-abnomal-detection/#metrics","text":"","title":"Metrics"},{"location":"proposals/20220402-policy-based-abnomal-detection/#built-in-metrics","text":"Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine.","title":"Built-in metrics"},{"location":"proposals/20220402-policy-based-abnomal-detection/#external-metrics-new","text":"Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node.","title":"External metrics (New)"},{"location":"proposals/20220402-policy-based-abnomal-detection/#embedded-metrics-tsdb","text":"In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from.","title":"Embedded metrics TSDB"},{"location":"proposals/20220402-policy-based-abnomal-detection/#policy","text":"The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Policy"},{"location":"proposals/20220706-recommendation-definition/","text":"Recommendation Definition \u00b6 This proposal aims at definition for universal resource optimization. Table of Contents \u00b6 Motivation \u00b6 Proposal \u00b6 Api Definition \u00b6 RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` } Recommendation Configuration \u00b6 Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Definition"},{"location":"proposals/20220706-recommendation-definition/#recommendation-definition","text":"This proposal aims at definition for universal resource optimization.","title":"Recommendation Definition"},{"location":"proposals/20220706-recommendation-definition/#table-of-contents","text":"","title":"Table of Contents"},{"location":"proposals/20220706-recommendation-definition/#motivation","text":"","title":"Motivation"},{"location":"proposals/20220706-recommendation-definition/#proposal","text":"","title":"Proposal"},{"location":"proposals/20220706-recommendation-definition/#api-definition","text":"RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` }","title":"Api Definition"},{"location":"proposals/20220706-recommendation-definition/#recommendation-configuration","text":"Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Configuration"},{"location":"proposals/20220706-universal-resource-optimization/","text":"Universal Resource Optimization \u00b6 Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud. Table of Contents \u00b6 Motivation \u00b6 Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds. Goals \u00b6 Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud Non-Goals \u00b6 Cloud Resources that not included in kubernetes Proposal \u00b6 Recommendation Definition Recommendation Framework User Stories \u00b6 Story 1 \u00b6 As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production. Story 2 \u00b6 As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists. Story 3 \u00b6 As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Universal Resource Optimization"},{"location":"proposals/20220706-universal-resource-optimization/#universal-resource-optimization","text":"Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud.","title":"Universal Resource Optimization"},{"location":"proposals/20220706-universal-resource-optimization/#table-of-contents","text":"","title":"Table of Contents"},{"location":"proposals/20220706-universal-resource-optimization/#motivation","text":"Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds.","title":"Motivation"},{"location":"proposals/20220706-universal-resource-optimization/#goals","text":"Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud","title":"Goals"},{"location":"proposals/20220706-universal-resource-optimization/#non-goals","text":"Cloud Resources that not included in kubernetes","title":"Non-Goals"},{"location":"proposals/20220706-universal-resource-optimization/#proposal","text":"Recommendation Definition Recommendation Framework","title":"Proposal"},{"location":"proposals/20220706-universal-resource-optimization/#user-stories","text":"","title":"User Stories"},{"location":"proposals/20220706-universal-resource-optimization/#story-1","text":"As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production.","title":"Story 1"},{"location":"proposals/20220706-universal-resource-optimization/#story-2","text":"As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists.","title":"Story 2"},{"location":"proposals/20220706-universal-resource-optimization/#story-3","text":"As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Story 3"},{"location":"proposals/20220712-recommendation-framework-internal/","text":"Recommendation Framework Internal \u00b6 Summary \u00b6 This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly. Motivation \u00b6 At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type. Goals \u00b6 Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules. Non-Goals \u00b6 Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework. Proposal \u00b6 Architecture \u00b6 Phases \u00b6 We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework. Fliter \u00b6 The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it. Prepare \u00b6 Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic. Recommend \u00b6 The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it. Observe \u00b6 Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Recommendation Framework Internal"},{"location":"proposals/20220712-recommendation-framework-internal/#recommendation-framework-internal","text":"","title":"Recommendation Framework Internal"},{"location":"proposals/20220712-recommendation-framework-internal/#summary","text":"This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly.","title":"Summary"},{"location":"proposals/20220712-recommendation-framework-internal/#motivation","text":"At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type.","title":"Motivation"},{"location":"proposals/20220712-recommendation-framework-internal/#goals","text":"Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules.","title":"Goals"},{"location":"proposals/20220712-recommendation-framework-internal/#non-goals","text":"Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework.","title":"Non-Goals"},{"location":"proposals/20220712-recommendation-framework-internal/#proposal","text":"","title":"Proposal"},{"location":"proposals/20220712-recommendation-framework-internal/#architecture","text":"","title":"Architecture"},{"location":"proposals/20220712-recommendation-framework-internal/#phases","text":"We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework.","title":"Phases"},{"location":"proposals/20220712-recommendation-framework-internal/#fliter","text":"The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it.","title":"Fliter"},{"location":"proposals/20220712-recommendation-framework-internal/#prepare","text":"Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic.","title":"Prepare"},{"location":"proposals/20220712-recommendation-framework-internal/#recommend","text":"The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it.","title":"Recommend"},{"location":"proposals/20220712-recommendation-framework-internal/#observe","text":"Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Observe"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/","text":"Pod Sorting And Precise Execution For Crane Agent \u00b6 The proposal enriches the sorting strategy of the crane agent and perfects the general sorting. In addition, a framework of precise operation (throttle/eviction) is implemented. When performing throttle, eviction and other operations, the precise operation logic of operating to the water level specified by the user, i.e. stopping, avoids excessive operation of low optimal pod; Specifically: Enriches the sorting strategy of crane agent, and perfects the general sorting and CPU dimension sorting with CPU usage as the main reference; For CPU usage, the precise operation logic that stops when operating to the water level specified by the user when throttle/eviction is implemented, which avoids the excessive operation of low optimal pod; A framework of precise operation (throttle/eviction) is implemented. By improving some column attributes and implementation of user-defined indicators, it can also have the same precise operation ability as CPU usage without caring about specific details, and has certain universality and scalability. Table of Contents \u00b6 Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal Enrich the sorting strategy of pod Definition of metric attribute How to control accurately according to the water level Precise operation of pod based on water level Analyzer phase Executor phase Non-Goals/Future Work User Stories Motivation \u00b6 Currently, in the crane agent, when the water level specified in the NodeQosEnsurancePolicy is exceeded, perform throttle, eviction and other operations to sort the low priority pods first. The current sorting is based on the prority class of the pod, and then perform throttle or eviction on the sorted pods; The existing problems are: sorting only refers to prority class, which cannot meet the sorting based on other features; At the same time, it can not meet the requirements of flexible sequencing according to the precise operation of the water level line, and can not meet the requirements of making the nodes reach the specified water level as soon as possible. For example, when we want to reduce the CPU usage of low priority services as soon as possible, we should select the pod with more CPU usage, which can reduce the CPU usage faster and ensure that high-quality services are not affected. after triggering the watermark specified in NodeQosEnsurancePolicy, all pods on the node that are lower than the specified prolityclass will be operated; For example, there are 10 pods on the current node that are lower than the specified prority class. After the water level is triggered, operations will be performed on all 10 pods. However, in fact, after the operation on the first pod is completed, it may be lower than the index value in NodeQosEnsurancePolicy. The operation on the remaining pods is excessive and can be avoided. If the index value in NodeQosEnsurancePolicy can be used as the watermark to accurately operate the pod, it is more appropriate to operate it just below the watermark, so as to avoid excessive impact on low priority services. Goals \u00b6 Enriches the sorting strategy of crane agent, including the sorting with pod CPU consumption as the main reference, the sorting with pod memory consumption as the main reference, the sorting based on runtime, and the sorting based on extended resource utilization. Implement a framework including sorting and a precise operation, support to enrich sorting rules for different indicators, and realize precise operation. To achieve a precise operation for CPU usage and memory usage, when the machine load exceeds the water level specified in NodeQosEnsurancePolicy, the low priority pods will be sorted first, and then the operation will be carried out in order until it is just below the water level. Proposal \u00b6 Enrich the sorting strategy of pod \u00b6 The proposal implements some general sorting methods (which will be improved later): classAndPriority\uff1a Compare the Qos class and class value of two pods. Compare Qos class first and then class value; Those with high priority are ranked later and have higher priority runningTime\uff1aCompare the running time of two pods. The one with a long running time is ranked later and has a higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the usage of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } Sorting of CPU usage The priority of two pods will be compared in turn. If the priority is the same, then compare the CPU usage. If the CPU usage is also the same, continue to compare the EXT CPU resource usage (this is a special point of the CPU attribute). Finally, compare the running time of the pod. When there is a difference in a certain index, the comparison result can be returned ``` go func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ) . Sort ( pods ) } ``` Sorting of ext CPU usage First, it will compare whether the extended CPU resources are used by two pods. If both are used, it will compare the ratio of the extended CPU resource usage / the extended CPU resource limit For the indicators that need to be customized, the following methods can be implemented, and the flexible and customized sorting of pods can be easily realized by freely matching the general sorting methods. The represents the customized metric indicators, and the represents the customized sorting strategy for func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } The only needs to implement the following sorting methods func ( p1 , p2 podinfo . PodContext ) int32 Definition of metric attribute \u00b6 In order to better sort and precisely control metrics configured based on NodeQosEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metrics include the following: Name indicates the name of the metric, which should be consistent with the indicator name collected in the collector module ActionPriority indicates the priority of the indicator. 0 is the lowest and 10 is the highest SortAble indicates whether the indicator can be sorted Sorting methods corresponding to SortFunc. Sorting methods can be arranged and combined with some general methods, and then combined with the sorting of indicators, which will be introduced in detail below ThrottleAble indicates whether pod can be suppressed for this indicator. For example, for the metric of CPU usage, there are corresponding suppression methods. However, for the indicator of memory usage, the pod can only be expelled, and effective suppression cannot be carried out ThrottleQuantified indicates whether the corresponding metric resources released after the suppression can be accurately calculated after a pod is restored. We call the indicators that can be accurately quantified quantifiable, otherwise, they are not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; For example, memory usage does not belong to the suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc, the specific method to execute the throttle action. If throttling is not available, the returned released is null RestoreFunc: after being throttled, the specific method to execute the recovery action. If throttling is not allowed, the returned released is null Relevant definitions of evicting actions by evictable, evictquantified, and evictfunc are similar to those of throttle actions type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } You can define your own metric. After the construction is completed, you can register it through registermetricmap() How to control accurately according to the water level \u00b6 Build multiple waterlines according to multiple nodeqosensurancepolicies and objectiveinsurances: Classified according to the actions corresponding to objectiveinsurances, the crane agent currently has three operations to guarantee node QoS, namely, evict, thtottledown (to suppress pod usage when the current usage is higher than the value in objectiveinsurances) and throttleup (to relax and recover pod usage when the current usage is lower than the value in objectiveinsurances). Therefore, there will be three waterline sets, namely, throttledownwaterline, Throttleupwaterline and evictwaterline Then classify the waterlines in the same operation category according to their metric rules (metric A and metric Z are used as schematic in the figure), and record the value of each objectiveinsurances water level line, which is recorded as waterline; The structures of throttledownwaterline, throttleupwaterline and evictwaterline are as follows: type WaterLines map[WaterLineMetric]*WaterLine Where waterlinemetric is the name field of the above metric, and waterline of value is the resource value type WaterLine resource.Quantity Finally, a data store similar to the following figure is formed: Construct the difference between real-time consumption and waterline: The following data structure is constructed by combining the difference between the real-time consumption of the indicator at the current node and the minimum value in the waterline corresponding to the indicator in waterlines, representing the difference between the current consumption and the waterline type GapToWaterLines map[WaterLineMetric]float64 Where the key value is the name field of metric, and the value is the difference between the consumption and the waterline; It should be noted that for throttleup, the minimum waterline - current usage is used as the gap value. For the other two, the minimum waterline - current usage is used as the gap value, that is, the gap value is always kept positive The following three data represent the indicators that need to perform evict, thatttledown and throttleup operations and their corresponding differences to the lowest waterline EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] Taking the metric CpuUsage as an example, the process and data structure of constructing the waterline related to node CPU usage are as follows: Precise operation of pod based on water level \u00b6 In order to realize the precise operation of pod based on the water level, the proposal will modify the analyzer and executor. The general process is as follows: In the analyzer phase, construct waterlines for different operations (eviction, throttle, etc.) and different metrics, delete the original sorting logic, and move it to the executor phase where formal operations are required, and multiple rounds of sorting may be required; In the executor stage, the corresponding sorting is carried out according to the indicators involved in the waterline, the latest consumption is obtained, gaptowaterlines is constructed, and precise operations are carried out Analyzer phase \u00b6 At this stage, the NodeQosEnsurancePolicy is converted to waterlines, and the rules of the same actionname and metricreule are merged. The details have been described above Executor phase \u00b6 Throttle: Firstly, analyze the metrics involved in the ThrottoleDownGapToWaterLines, and divide these metrics into two parts according to their quantized attribute. If there is a metric that cannot be quantized, get the metric of a throttleable (with a throttlefunc) with the highest action priority through gethighstprioritythottleablemetric to suppress all the selected pods, because if there is a metric that cannot be quantized, It is impossible to carry out a precise operation Get the latest usage of the current node and workload through getstatefunc(), Construct the gaptowaterline according to the ThrottoleDownGapToWaterLines and real-time usage (note that when constructing the gaptowaterline, it will traverse with the registered metric, so the finally constructed metric in the gaptowaterline will be the metric registered in the ThrottoleDownGapToWaterLines, avoiding the situation that the configuration error does not exist or the metric is not registered in the nodeqosensancepolicy) If there is a metric in the gaptowaterline whose real-time usage cannot be obtained (hasusagemissedmetric), obtain the metric of a throttleable (with throttlefunc) with the highest action priority through GetHighestPriorityThrottleAbleMetric to suppress all the selected pods, because if there is a metric whose real-time usage cannot be obtained, the gap with the waterline cannot be known, and precise operations cannot be performed If the situation in 3 does not exist, traverse the quantifiable metrics in the ThrottoleDownGapToWaterLines: if the metric has a sorting method, it directly uses its sortfunc to sort the pods. If not, it uses generalsorter to sort the pods, and then uses its corresponding throttlefunc to suppress the pods, and calculate the released resources of the corresponding metric, Until the gap corresponding to this metric in ThrottoleDownGapToWaterLines no longer exists metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } Eviction\uff1a The process of eviction and throttle is the same, except that it is necessary to judge whether the pod has been expelled when operating the pod; Take out a pod that has not been executed, execute the eviction operation, calculate the released metric resources, and subtract the released value from the corresponding water level until the current metric waterline requirements are met metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } } Non-Goals/Future Work \u00b6 Currently, only the precise operation of CPU usage is supported, but the framework can be reused. In the future, the framework based on precise control can achieve precise control of more dimensional indicators. In the process of precise control, only the release of metric is considered at present, and the interaction between different metrics is not considered. For example, when pressing CPU usage, memory usage will also be affected. If there are many indicators, the relationship between different indicators will be very complex, so the direct interaction of different metrics will not be considered for the time being. User Stories \u00b6 Users can use crane agent for better QoS guarantees. Support faster node load reduction to ensure that high priority services are not affected. At the same time, the throttle/eviction of low priority services is precisely controlled to avoid excessive operation. With the help of the framework of precise operation (throttle/eviction), users can easily realize the QoS function with precise operation and sorting capability based on the user-defined metric without paying attention to details by implementing the attributes and methods related to the user-defined metric.","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#pod-sorting-and-precise-execution-for-crane-agent","text":"The proposal enriches the sorting strategy of the crane agent and perfects the general sorting. In addition, a framework of precise operation (throttle/eviction) is implemented. When performing throttle, eviction and other operations, the precise operation logic of operating to the water level specified by the user, i.e. stopping, avoids excessive operation of low optimal pod; Specifically: Enriches the sorting strategy of crane agent, and perfects the general sorting and CPU dimension sorting with CPU usage as the main reference; For CPU usage, the precise operation logic that stops when operating to the water level specified by the user when throttle/eviction is implemented, which avoids the excessive operation of low optimal pod; A framework of precise operation (throttle/eviction) is implemented. By improving some column attributes and implementation of user-defined indicators, it can also have the same precise operation ability as CPU usage without caring about specific details, and has certain universality and scalability.","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#table-of-contents","text":"Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal Enrich the sorting strategy of pod Definition of metric attribute How to control accurately according to the water level Precise operation of pod based on water level Analyzer phase Executor phase Non-Goals/Future Work User Stories","title":"Table of Contents"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#motivation","text":"Currently, in the crane agent, when the water level specified in the NodeQosEnsurancePolicy is exceeded, perform throttle, eviction and other operations to sort the low priority pods first. The current sorting is based on the prority class of the pod, and then perform throttle or eviction on the sorted pods; The existing problems are: sorting only refers to prority class, which cannot meet the sorting based on other features; At the same time, it can not meet the requirements of flexible sequencing according to the precise operation of the water level line, and can not meet the requirements of making the nodes reach the specified water level as soon as possible. For example, when we want to reduce the CPU usage of low priority services as soon as possible, we should select the pod with more CPU usage, which can reduce the CPU usage faster and ensure that high-quality services are not affected. after triggering the watermark specified in NodeQosEnsurancePolicy, all pods on the node that are lower than the specified prolityclass will be operated; For example, there are 10 pods on the current node that are lower than the specified prority class. After the water level is triggered, operations will be performed on all 10 pods. However, in fact, after the operation on the first pod is completed, it may be lower than the index value in NodeQosEnsurancePolicy. The operation on the remaining pods is excessive and can be avoided. If the index value in NodeQosEnsurancePolicy can be used as the watermark to accurately operate the pod, it is more appropriate to operate it just below the watermark, so as to avoid excessive impact on low priority services.","title":"Motivation"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#goals","text":"Enriches the sorting strategy of crane agent, including the sorting with pod CPU consumption as the main reference, the sorting with pod memory consumption as the main reference, the sorting based on runtime, and the sorting based on extended resource utilization. Implement a framework including sorting and a precise operation, support to enrich sorting rules for different indicators, and realize precise operation. To achieve a precise operation for CPU usage and memory usage, when the machine load exceeds the water level specified in NodeQosEnsurancePolicy, the low priority pods will be sorted first, and then the operation will be carried out in order until it is just below the water level.","title":"Goals"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#proposal","text":"","title":"Proposal"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#enrich-the-sorting-strategy-of-pod","text":"The proposal implements some general sorting methods (which will be improved later): classAndPriority\uff1a Compare the Qos class and class value of two pods. Compare Qos class first and then class value; Those with high priority are ranked later and have higher priority runningTime\uff1aCompare the running time of two pods. The one with a long running time is ranked later and has a higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the usage of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } Sorting of CPU usage The priority of two pods will be compared in turn. If the priority is the same, then compare the CPU usage. If the CPU usage is also the same, continue to compare the EXT CPU resource usage (this is a special point of the CPU attribute). Finally, compare the running time of the pod. When there is a difference in a certain index, the comparison result can be returned ``` go func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ) . Sort ( pods ) } ``` Sorting of ext CPU usage First, it will compare whether the extended CPU resources are used by two pods. If both are used, it will compare the ratio of the extended CPU resource usage / the extended CPU resource limit For the indicators that need to be customized, the following methods can be implemented, and the flexible and customized sorting of pods can be easily realized by freely matching the general sorting methods. The represents the customized metric indicators, and the represents the customized sorting strategy for func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } The only needs to implement the following sorting methods func ( p1 , p2 podinfo . PodContext ) int32","title":"Enrich the sorting strategy of pod"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#definition-of-metric-attribute","text":"In order to better sort and precisely control metrics configured based on NodeQosEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metrics include the following: Name indicates the name of the metric, which should be consistent with the indicator name collected in the collector module ActionPriority indicates the priority of the indicator. 0 is the lowest and 10 is the highest SortAble indicates whether the indicator can be sorted Sorting methods corresponding to SortFunc. Sorting methods can be arranged and combined with some general methods, and then combined with the sorting of indicators, which will be introduced in detail below ThrottleAble indicates whether pod can be suppressed for this indicator. For example, for the metric of CPU usage, there are corresponding suppression methods. However, for the indicator of memory usage, the pod can only be expelled, and effective suppression cannot be carried out ThrottleQuantified indicates whether the corresponding metric resources released after the suppression can be accurately calculated after a pod is restored. We call the indicators that can be accurately quantified quantifiable, otherwise, they are not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; For example, memory usage does not belong to the suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc, the specific method to execute the throttle action. If throttling is not available, the returned released is null RestoreFunc: after being throttled, the specific method to execute the recovery action. If throttling is not allowed, the returned released is null Relevant definitions of evicting actions by evictable, evictquantified, and evictfunc are similar to those of throttle actions type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } You can define your own metric. After the construction is completed, you can register it through registermetricmap()","title":"Definition of metric attribute"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#how-to-control-accurately-according-to-the-water-level","text":"Build multiple waterlines according to multiple nodeqosensurancepolicies and objectiveinsurances: Classified according to the actions corresponding to objectiveinsurances, the crane agent currently has three operations to guarantee node QoS, namely, evict, thtottledown (to suppress pod usage when the current usage is higher than the value in objectiveinsurances) and throttleup (to relax and recover pod usage when the current usage is lower than the value in objectiveinsurances). Therefore, there will be three waterline sets, namely, throttledownwaterline, Throttleupwaterline and evictwaterline Then classify the waterlines in the same operation category according to their metric rules (metric A and metric Z are used as schematic in the figure), and record the value of each objectiveinsurances water level line, which is recorded as waterline; The structures of throttledownwaterline, throttleupwaterline and evictwaterline are as follows: type WaterLines map[WaterLineMetric]*WaterLine Where waterlinemetric is the name field of the above metric, and waterline of value is the resource value type WaterLine resource.Quantity Finally, a data store similar to the following figure is formed: Construct the difference between real-time consumption and waterline: The following data structure is constructed by combining the difference between the real-time consumption of the indicator at the current node and the minimum value in the waterline corresponding to the indicator in waterlines, representing the difference between the current consumption and the waterline type GapToWaterLines map[WaterLineMetric]float64 Where the key value is the name field of metric, and the value is the difference between the consumption and the waterline; It should be noted that for throttleup, the minimum waterline - current usage is used as the gap value. For the other two, the minimum waterline - current usage is used as the gap value, that is, the gap value is always kept positive The following three data represent the indicators that need to perform evict, thatttledown and throttleup operations and their corresponding differences to the lowest waterline EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] Taking the metric CpuUsage as an example, the process and data structure of constructing the waterline related to node CPU usage are as follows:","title":"How to control accurately according to the water level"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#precise-operation-of-pod-based-on-water-level","text":"In order to realize the precise operation of pod based on the water level, the proposal will modify the analyzer and executor. The general process is as follows: In the analyzer phase, construct waterlines for different operations (eviction, throttle, etc.) and different metrics, delete the original sorting logic, and move it to the executor phase where formal operations are required, and multiple rounds of sorting may be required; In the executor stage, the corresponding sorting is carried out according to the indicators involved in the waterline, the latest consumption is obtained, gaptowaterlines is constructed, and precise operations are carried out","title":"Precise operation of pod based on water level"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#analyzer-phase","text":"At this stage, the NodeQosEnsurancePolicy is converted to waterlines, and the rules of the same actionname and metricreule are merged. The details have been described above","title":"Analyzer phase"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#executor-phase","text":"Throttle: Firstly, analyze the metrics involved in the ThrottoleDownGapToWaterLines, and divide these metrics into two parts according to their quantized attribute. If there is a metric that cannot be quantized, get the metric of a throttleable (with a throttlefunc) with the highest action priority through gethighstprioritythottleablemetric to suppress all the selected pods, because if there is a metric that cannot be quantized, It is impossible to carry out a precise operation Get the latest usage of the current node and workload through getstatefunc(), Construct the gaptowaterline according to the ThrottoleDownGapToWaterLines and real-time usage (note that when constructing the gaptowaterline, it will traverse with the registered metric, so the finally constructed metric in the gaptowaterline will be the metric registered in the ThrottoleDownGapToWaterLines, avoiding the situation that the configuration error does not exist or the metric is not registered in the nodeqosensancepolicy) If there is a metric in the gaptowaterline whose real-time usage cannot be obtained (hasusagemissedmetric), obtain the metric of a throttleable (with throttlefunc) with the highest action priority through GetHighestPriorityThrottleAbleMetric to suppress all the selected pods, because if there is a metric whose real-time usage cannot be obtained, the gap with the waterline cannot be known, and precise operations cannot be performed If the situation in 3 does not exist, traverse the quantifiable metrics in the ThrottoleDownGapToWaterLines: if the metric has a sorting method, it directly uses its sortfunc to sort the pods. If not, it uses generalsorter to sort the pods, and then uses its corresponding throttlefunc to suppress the pods, and calculate the released resources of the corresponding metric, Until the gap corresponding to this metric in ThrottoleDownGapToWaterLines no longer exists metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } Eviction\uff1a The process of eviction and throttle is the same, except that it is necessary to judge whether the pod has been expelled when operating the pod; Take out a pod that has not been executed, execute the eviction operation, calculate the released metric resources, and subtract the released value from the corresponding water level until the current metric waterline requirements are met metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } }","title":"Executor phase"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#non-goalsfuture-work","text":"Currently, only the precise operation of CPU usage is supported, but the framework can be reused. In the future, the framework based on precise control can achieve precise control of more dimensional indicators. In the process of precise control, only the release of metric is considered at present, and the interaction between different metrics is not considered. For example, when pressing CPU usage, memory usage will also be affected. If there are many indicators, the relationship between different indicators will be very complex, so the direct interaction of different metrics will not be considered for the time being.","title":"Non-Goals/Future Work"},{"location":"proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#user-stories","text":"Users can use crane agent for better QoS guarantees. Support faster node load reduction to ensure that high priority services are not affected. At the same time, the throttle/eviction of low priority services is precisely controlled to avoid excessive operation. With the help of the framework of precise operation (throttle/eviction), users can easily realize the QoS function with precise operation and sorting capability based on the user-defined metric without paying attention to details by implementing the attributes and methods related to the user-defined metric.","title":"User Stories"},{"location":"roadmaps/roadmap-2022/","text":"Crane Roadmap for 2022 \u00b6 Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan. 0.1.0 [released] \u00b6 Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing 0.2.0\uff1a[released] \u00b6 Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio 0.3.0 [released] \u00b6 UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA 0.4.0 [released] \u00b6 UI to support EPA. 0.5.0 [released] \u00b6 Resource and Replicas Recommendation Load-aware Scheduler 0.6.0 [released] \u00b6 Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics 0.7.0 [July] \u00b6 Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator 0.8.0 [August] \u00b6 External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization 0.9.0 [September] \u00b6 Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard 0.10.0 [October] \u00b6 Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison 0.11.0 [November] \u00b6 Multi-cluster cost dashboard 0.12.0 [December] \u00b6 Multi-cluster cost optimization","title":2022},{"location":"roadmaps/roadmap-2022/#crane-roadmap-for-2022","text":"Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan.","title":"Crane Roadmap for 2022"},{"location":"roadmaps/roadmap-2022/#010-released","text":"Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing","title":"0.1.0 [released]"},{"location":"roadmaps/roadmap-2022/#020released","text":"Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio","title":"0.2.0\uff1a[released]"},{"location":"roadmaps/roadmap-2022/#030-released","text":"UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA","title":"0.3.0 [released]"},{"location":"roadmaps/roadmap-2022/#040-released","text":"UI to support EPA.","title":"0.4.0 [released]"},{"location":"roadmaps/roadmap-2022/#050-released","text":"Resource and Replicas Recommendation Load-aware Scheduler","title":"0.5.0 [released]"},{"location":"roadmaps/roadmap-2022/#060-released","text":"Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics","title":"0.6.0 [released]"},{"location":"roadmaps/roadmap-2022/#070-july","text":"Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator","title":"0.7.0 [July]"},{"location":"roadmaps/roadmap-2022/#080-august","text":"External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization","title":"0.8.0 [August]"},{"location":"roadmaps/roadmap-2022/#090-september","text":"Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard","title":"0.9.0 [September]"},{"location":"roadmaps/roadmap-2022/#0100-october","text":"Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison","title":"0.10.0 [October]"},{"location":"roadmaps/roadmap-2022/#0110-november","text":"Multi-cluster cost dashboard","title":"0.11.0 [November]"},{"location":"roadmaps/roadmap-2022/#0120-december","text":"Multi-cluster cost optimization","title":"0.12.0 [December]"},{"location":"tutorials/analytics-and-recommendation/","text":"Analytics and Recommendation \u00b6 Analytics and Recommendation provide capacity that analyzes the workload in k8s cluster and provide recommendations about resource optimize. Two Recommendations are currently supported: ResourceRecommend : Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. HPARecommend : Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster. Architecture \u00b6 An analytical process \u00b6 Users create Analytics object and config ResourceSelector to select resources to be analyzed. Multiple types of resource selection (based on Group,Kind, and Version) are supported. Analyze each selected resource in parallel and try to execute analysis and give recommendation. Each analysis process is divided into two stages: inspecting and advising: Inspecting: Filter resources that don't match the recommended conditions. For example, for hpa recommendation, the workload that has many not running pod is excluded Advising: Analysis and calculation based on algorithm model then provide the recommendation result. If you paas the above two stages, it will create Recommendation object and display the result in recommendation.Status You can find the failure reasons from analytics.status.recommendations Wait for the next analytics based on the interval Core concept \u00b6 Analytics \u00b6 Analysis defines a scanning analysis task. Two task types are supported: resource recommendation and hpa recommendation. Crane regularly runs analysis tasks and produces recommended results. Recommendation \u00b6 The recommendation shows the results of an Analytics . The recommended result is a YAML configuration that allows users to take appropriate optimization actions, such as adjusting the resource configuration of the application. Configuration \u00b6 Different analytics uses different computing models. Crane provides a default computing model and a corresponding configuration that users can modify to customize the recommended effect. You can modify the default configuration globally or modify the configuration of a single analytics task.","title":"Analytics Overview"},{"location":"tutorials/analytics-and-recommendation/#analytics-and-recommendation","text":"Analytics and Recommendation provide capacity that analyzes the workload in k8s cluster and provide recommendations about resource optimize. Two Recommendations are currently supported: ResourceRecommend : Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. HPARecommend : Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster.","title":"Analytics and Recommendation"},{"location":"tutorials/analytics-and-recommendation/#architecture","text":"","title":"Architecture"},{"location":"tutorials/analytics-and-recommendation/#an-analytical-process","text":"Users create Analytics object and config ResourceSelector to select resources to be analyzed. Multiple types of resource selection (based on Group,Kind, and Version) are supported. Analyze each selected resource in parallel and try to execute analysis and give recommendation. Each analysis process is divided into two stages: inspecting and advising: Inspecting: Filter resources that don't match the recommended conditions. For example, for hpa recommendation, the workload that has many not running pod is excluded Advising: Analysis and calculation based on algorithm model then provide the recommendation result. If you paas the above two stages, it will create Recommendation object and display the result in recommendation.Status You can find the failure reasons from analytics.status.recommendations Wait for the next analytics based on the interval","title":"An analytical process"},{"location":"tutorials/analytics-and-recommendation/#core-concept","text":"","title":"Core concept"},{"location":"tutorials/analytics-and-recommendation/#analytics","text":"Analysis defines a scanning analysis task. Two task types are supported: resource recommendation and hpa recommendation. Crane regularly runs analysis tasks and produces recommended results.","title":"Analytics"},{"location":"tutorials/analytics-and-recommendation/#recommendation","text":"The recommendation shows the results of an Analytics . The recommended result is a YAML configuration that allows users to take appropriate optimization actions, such as adjusting the resource configuration of the application.","title":"Recommendation"},{"location":"tutorials/analytics-and-recommendation/#configuration","text":"Different analytics uses different computing models. Crane provides a default computing model and a corresponding configuration that users can modify to customize the recommended effect. You can modify the default configuration globally or modify the configuration of a single analytics task.","title":"Configuration"},{"location":"tutorials/dynamic-scheduler-plugin/","text":"Dynamic-scheduler: a load-aware scheduler plugin \u00b6 Introduction \u00b6 Native scheduler of kubernetes can only schedule pods by resource request, which can easily cause a series of load uneven problems: for some nodes, the actual load is not much different from the resource request, which will lead to a very high probability of stability problems. for others, the actual load is much smaller than the resource request, which will lead to a huge waste of resources. To solve these problems, Dynamic scheduler builds a simple but efficient model based on actual node utilization data\uff0cand filters out those nodes with high load to balance the cluster. Design Details \u00b6 Architecture \u00b6 As shown above, Dynamic scheduler relies on Prometheus and Node-exporter to collect and aggregate metrics data, and it consists of two components: Note Node-annotator is currently a module of Crane-scheduler-controller . Node-annotator periodically pulls data from Prometheus and marks them with timestamp on the node in the form of annotations. Dynamic plugin reads the load data directly from the node's annotation, filters and scores candidates based on a simple algorithm. Scheduler Policy \u00b6 Dynamic provides a default scheduler policy and supports user-defined policies. The default policy reies on following metrics: cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d At the scheduling Filter stage, the node will be filtered if the actual usage rate of this node is greater than the threshold of any of the above metrics. And at the Score stage, the final score is the weighted sum of these metrics' values. Hot Value \u00b6 In the production cluster, scheduling hotspots may occur frequently because the load of the nodes can not increase immediately after the pod is created. Therefore, we define an extra metrics named Hot Value , which represents the scheduling frequency of the node in recent times. And the final priority of the node is the final score minus the Hot Value .","title":"Load-aware Scheduling"},{"location":"tutorials/dynamic-scheduler-plugin/#dynamic-scheduler-a-load-aware-scheduler-plugin","text":"","title":"Dynamic-scheduler: a load-aware scheduler plugin"},{"location":"tutorials/dynamic-scheduler-plugin/#introduction","text":"Native scheduler of kubernetes can only schedule pods by resource request, which can easily cause a series of load uneven problems: for some nodes, the actual load is not much different from the resource request, which will lead to a very high probability of stability problems. for others, the actual load is much smaller than the resource request, which will lead to a huge waste of resources. To solve these problems, Dynamic scheduler builds a simple but efficient model based on actual node utilization data\uff0cand filters out those nodes with high load to balance the cluster.","title":"Introduction"},{"location":"tutorials/dynamic-scheduler-plugin/#design-details","text":"","title":"Design Details"},{"location":"tutorials/dynamic-scheduler-plugin/#architecture","text":"As shown above, Dynamic scheduler relies on Prometheus and Node-exporter to collect and aggregate metrics data, and it consists of two components: Note Node-annotator is currently a module of Crane-scheduler-controller . Node-annotator periodically pulls data from Prometheus and marks them with timestamp on the node in the form of annotations. Dynamic plugin reads the load data directly from the node's annotation, filters and scores candidates based on a simple algorithm.","title":"Architecture"},{"location":"tutorials/dynamic-scheduler-plugin/#scheduler-policy","text":"Dynamic provides a default scheduler policy and supports user-defined policies. The default policy reies on following metrics: cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d At the scheduling Filter stage, the node will be filtered if the actual usage rate of this node is greater than the threshold of any of the above metrics. And at the Score stage, the final score is the weighted sum of these metrics' values.","title":"Scheduler Policy"},{"location":"tutorials/dynamic-scheduler-plugin/#hot-value","text":"In the production cluster, scheduling hotspots may occur frequently because the load of the nodes can not increase immediately after the pod is created. Therefore, we define an extra metrics named Hot Value , which represents the scheduling frequency of the node in recent times. And the final priority of the node is the final score minus the Hot Value .","title":"Hot Value"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/","text":"Intelligent Autoscaling Practices Based on Effective HPA for Custom Metrics \u00b6 The Kubernetes HPA supports rich elasticity scaling capabilities, with Kubernetes platform developers deploying services to implement custom Metric services and Kubernetes users configuring multiple built-in resource metrics or custom Metric metrics to achieve custom horizontal elasticity. Effective HPA is compatible with the community's Kubernetes HPA capabilities, providing smarter autoscaling policies such as prediction-based autoscaling and Cron-cycle-based autoscaling. Prometheus is a popular open source monitoring system today, through which user-defined metrics configurations are accessible. In this article, we present an example of how to implement intelligent resilience of custom metrics based on Effective HPA. Some configurations are taken from official documentation Environment Requirements \u00b6 Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus Refer to installation documentation to install Crane in the cluster, Prometheus can be used either from the installation documentation or from the deployed Prometheus. Environment build \u00b6 Installing PrometheusAdapter \u00b6 The Crane components Metric-Adapter and PrometheusAdapter are both based on custom-metric-apiserver which implements When installing Crane, the corresponding ApiService will be installed as the Metric-Adapter of Crane, so you need to remove the ApiService before installing PrometheusAdapter to ensure that Helm is installed successfully. # View the current ApiService kubectl get apiservice Since Crane is installed, the result is as follows. NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d Remove the installed ApiService by crane kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io Install PrometheusAdapter via Helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter Then change the ApiService back to Crane's Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml Configure Metric-Adapter to enable RemoteAdapter functionality \u00b6 The installation of PrometheusAdapter did not point the ApiService to PrometheusAdapter, so in order to allow PrometheusAdapter to provide custom Metric as well, the RemoteAdapter function of Crane Metric Adapter is used to forward requests to PrometheusAdapter. Modify the Metric-Adapter configuration to configure PrometheusAdapter's Service as Crane Metric Adapter's RemoteAdapter # View the current ApiService kubectl edit deploy metric-adapter -n crane-system Make the following changes based on the PrometheusAdapter configuration. apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #Add external Adapter configuration - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443 RemoteAdapter Capabilities \u00b6 Kubernetes restricts an ApiService to configure only one backend service, so in order to use the Metric provided by Crane and the Metric provided by PrometheusAdapter within a cluster, Crane supports a RemoteAdapter to solve this problem Crane Metric-Adapter supports the configuration of a Kubernetes Service as a Remote Adapter The Crane Metric-Adapter will first check if the request is a Crane provided Local Metric, and if not, forward it to the Remote Adapter Run the example \u00b6 Preparing the application \u00b6 Deploy the following application to the cluster, which exposes the Metric to show the number of http requests received per second. sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml When the application is deployed, you can check the http_requests_total Metric with the command curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics Configure collection rules \u00b6 Configure Prometheus' ScrapeConfig to collect the application's Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server Add the following configuration - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod At this point, you can use psql to query Prometheus: sum(rate(http_requests_total[5m])) by (pod) Verify PrometheusAdapter \u00b6 The default rule configuration of PrometheusAdapter supports converting http_requests_total to a custom metric of type Pods, verified by the command kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . The result should include pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } This indicates that the HPA can now be configured via Pod Metric. Configuring autoscaling \u00b6 We can now create the Effective HPA. at this point the Effective HPA can be resilient via Pod Metric http_requests : How to define a custom metric to enable prediction \u00b6 Annotation in the Effective HPA adds the configuration according to the following rules: annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml Check the TimeSeriesPrediction status, which may be unpredictable if the app has been running for a short time: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests Looking at the HPA object created by Effective HPA, you can observe that a Metric has been created based on custom metrics predictions: crane_custom.pods_http_requests . apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app Summary \u00b6 Due to the complexity of production environments, multi-metric-based autoscaling (CPU/Memory/custom metrics) is often a common choice for production applications, so Effective HPA achieves the effectiveness of helping more businesses land horizontal autoscaling in production environments by covering multi-metric autoscaling with predictive algorithms.","title":"Custom Metric Prediction With Prometheus"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#intelligent-autoscaling-practices-based-on-effective-hpa-for-custom-metrics","text":"The Kubernetes HPA supports rich elasticity scaling capabilities, with Kubernetes platform developers deploying services to implement custom Metric services and Kubernetes users configuring multiple built-in resource metrics or custom Metric metrics to achieve custom horizontal elasticity. Effective HPA is compatible with the community's Kubernetes HPA capabilities, providing smarter autoscaling policies such as prediction-based autoscaling and Cron-cycle-based autoscaling. Prometheus is a popular open source monitoring system today, through which user-defined metrics configurations are accessible. In this article, we present an example of how to implement intelligent resilience of custom metrics based on Effective HPA. Some configurations are taken from official documentation","title":"Intelligent Autoscaling Practices Based on Effective HPA for Custom Metrics"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#environment-requirements","text":"Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus Refer to installation documentation to install Crane in the cluster, Prometheus can be used either from the installation documentation or from the deployed Prometheus.","title":"Environment Requirements"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#environment-build","text":"","title":"Environment build"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#installing-prometheusadapter","text":"The Crane components Metric-Adapter and PrometheusAdapter are both based on custom-metric-apiserver which implements When installing Crane, the corresponding ApiService will be installed as the Metric-Adapter of Crane, so you need to remove the ApiService before installing PrometheusAdapter to ensure that Helm is installed successfully. # View the current ApiService kubectl get apiservice Since Crane is installed, the result is as follows. NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d Remove the installed ApiService by crane kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io Install PrometheusAdapter via Helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter Then change the ApiService back to Crane's Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml","title":"Installing PrometheusAdapter"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#configure-metric-adapter-to-enable-remoteadapter-functionality","text":"The installation of PrometheusAdapter did not point the ApiService to PrometheusAdapter, so in order to allow PrometheusAdapter to provide custom Metric as well, the RemoteAdapter function of Crane Metric Adapter is used to forward requests to PrometheusAdapter. Modify the Metric-Adapter configuration to configure PrometheusAdapter's Service as Crane Metric Adapter's RemoteAdapter # View the current ApiService kubectl edit deploy metric-adapter -n crane-system Make the following changes based on the PrometheusAdapter configuration. apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #Add external Adapter configuration - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443","title":"Configure Metric-Adapter to enable RemoteAdapter functionality"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#remoteadapter-capabilities","text":"Kubernetes restricts an ApiService to configure only one backend service, so in order to use the Metric provided by Crane and the Metric provided by PrometheusAdapter within a cluster, Crane supports a RemoteAdapter to solve this problem Crane Metric-Adapter supports the configuration of a Kubernetes Service as a Remote Adapter The Crane Metric-Adapter will first check if the request is a Crane provided Local Metric, and if not, forward it to the Remote Adapter","title":"RemoteAdapter Capabilities"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#run-the-example","text":"","title":"Run the example"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#preparing-the-application","text":"Deploy the following application to the cluster, which exposes the Metric to show the number of http requests received per second. sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml When the application is deployed, you can check the http_requests_total Metric with the command curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics","title":"Preparing the application"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#configure-collection-rules","text":"Configure Prometheus' ScrapeConfig to collect the application's Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server Add the following configuration - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod At this point, you can use psql to query Prometheus: sum(rate(http_requests_total[5m])) by (pod)","title":"Configure collection rules"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#verify-prometheusadapter","text":"The default rule configuration of PrometheusAdapter supports converting http_requests_total to a custom metric of type Pods, verified by the command kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . The result should include pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } This indicates that the HPA can now be configured via Pod Metric.","title":"Verify PrometheusAdapter"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#configuring-autoscaling","text":"We can now create the Effective HPA. at this point the Effective HPA can be resilient via Pod Metric http_requests :","title":"Configuring autoscaling"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#how-to-define-a-custom-metric-to-enable-prediction","text":"Annotation in the Effective HPA adds the configuration according to the following rules: annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml Check the TimeSeriesPrediction status, which may be unpredictable if the app has been running for a short time: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests Looking at the HPA object created by Effective HPA, you can observe that a Metric has been created based on custom metrics predictions: crane_custom.pods_http_requests . apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app","title":"How to define a custom metric to enable prediction"},{"location":"tutorials/effective-hpa-with-prometheus-adapter/#summary","text":"Due to the complexity of production environments, multi-metric-based autoscaling (CPU/Memory/custom metrics) is often a common choice for production applications, so Effective HPA achieves the effectiveness of helping more businesses land horizontal autoscaling in production environments by covering multi-metric autoscaling with predictive algorithms.","title":"Summary"},{"location":"tutorials/replicas-recommendation/","text":"Replicas Recommendation \u00b6 Kubernetes' users often set the replicas of workload or HPA configurations based on empirical values. Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. You can refer to and adopt it for your workloads to improve cluster resource utilization. Features \u00b6 Algorithm: The algorithm for calculating the replicas refers to HPA, and supports to customization algo args HPA recommendations: Scan for applications that suitable for configuring horizontal elasticity (EHPA), And give advice for configuration of EHPA, EHPA is a smart horizontal elastic product provided by Crane Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads Create HPA Analytics \u00b6 Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-replicas.yaml The created Analytics yaml is following: analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-hpa spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics ehpa.deployment-min-replicas : \"1\" ehpa.fluctuation-threshold : \"0\" ehpa.min-cpu-usage-threshold : \"0\" You can get created recommendations from analytics status: kubectl get analytics nginx-replicas -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-02T09:44:54Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-02T09:44:54Z\" recommendations : - lastStartTime : \"2022-06-02T09:44:54Z\" message : Success name : nginx-replicas-replicas-7qspm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : c853043c-5ff6-4ee0-a941-e04c8ec3093b Recommendation: Analytics result \u00b6 Use label selector to get related recommendations owns by Analytics . kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-02T09:44:54Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : e9168c6e-329f-40e9-8d0f-a1ddc35b0d47 app : nginx name : nginx-replicas-replicas-7qspm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : e9168c6e-329f-40e9-8d0f-a1ddc35b0d47 resourceVersion : \"818959913\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-7qspm uid : c853043c-5ff6-4ee0-a941-e04c8ec3093b spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-02T09:44:54Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-02T09:44:54Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\" Batch recommendation \u00b6 Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource HPA Recommendation Algorithm model \u00b6 Inspecting \u00b6 Workload with low replicas: If the replicas is too low, may not be suitable for hpa recommendation. Associated configuration: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas Workload with a certain percentage of not running pods: if the workload of Pod mostly can't run normally, may not be suitable for flexibility. Associated configuration: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio Workload with low CPU usage: The low CPU usage workload means that there is no load pressure. In this case, we can't estimate it. Associated configuration: ehpa.min-cpu-usage-threshold Workload with low fluctuation of CPU usage: dividing of the maximum and minimum usage is defined as the fluctuation rate. If the fluctuation rate is too low, the workload will not benefit much from hpa. Associated configuration: ehpa.fluctuation-threshold Advising \u00b6 In the advising phase, one EffectiveHPA Spec is recommended using the following Algorithm model. The recommended logic for each field is as follows: Recommend TargetUtilization Principle: Use Pod P99 resource utilization to recommend hpa. Because if the application can accept this utilization over P99 time, it can be inferred as a target for elasticity. Get the Pod P99 usage of the past seven days by Percentile algorithm: \\(pod\\_cpu\\_usage\\_p99\\) Corresponding utilization: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) To prevent over-utilization or under-utilization, target_pod_cpu_utilization needs to be less than ehpa.min-cpu-target-utilization and greater than ehpa. max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) Recommend minReplicas Principle: MinReplicas are recommended for the lowest hourly workload utilization for the past seven days. Calculate the lowest median workload cpu usage of the past seven days: \\(workload\\_cpu\\_usage\\_medium\\_min\\) Corresponding replicas: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) To prevent the minReplicas being too small, the minReplicas must be greater than or equal to ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) Recommend maxReplicas Principle: Use workload's past and future seven days load to recommend maximum replicas. Calculate P95 workload CPU usage for the past seven days and the next seven days: \\(workload\\_cpu\\_usage\\_p95\\) Corresponding replicas: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) To handle with the peak traffic, Magnify by a certain factor: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) Recommend MetricSpec(except CpuUtilization) If HPA is configured for workload, MetricSpecs other than CpuUtilization are inherited Recommend Behavior If HPA is configured for workload, the corresponding Behavior configuration is inherited Recommend Prediction Try to predict the CPU usage of the workload in the next seven days using DSP If the prediction is successful, add the prediction configuration If the workload is not predictable, do not add the prediction configuration. Configurations for HPA Recommendation \u00b6 Configuration Default Value Description ehpa.deployment-min-replicas 1 hpa recommendations are not made for workloads smaller than this value. ehpa.statefulset-min-replicas 1 hpa recommendations are not made for workloads smaller than this value. ehpa.workload-min-replicas 1 Workload replicas smaller than this value are not recommended for hpa. ehpa.pod-min-ready-seconds 30 specifies the number of seconds in decide whether a POD is ready. ehpa.pod-available-ratio 0.5 Workloads whose Ready pod ratio is smaller than this value are not recommended for hpa. ehpa.default-min-replicas 2 the default minimum minReplicas. ehpa.max-replicas-factor 3 the factor for calculate maxReplicas. ehpa.min-cpu-usage-threshold 10 hpa recommendations are not made for workloads smaller than this value. ehpa.fluctuation-threshold 1.5 hpa recommendations are not made for workloads smaller than this value. ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true inherits the existing HPA configuration","title":"Replicas Recommendation"},{"location":"tutorials/replicas-recommendation/#replicas-recommendation","text":"Kubernetes' users often set the replicas of workload or HPA configurations based on empirical values. Replicas recommendation analyze the actual application usage and give advice for replicas and HPA configurations. You can refer to and adopt it for your workloads to improve cluster resource utilization.","title":"Replicas Recommendation"},{"location":"tutorials/replicas-recommendation/#features","text":"Algorithm: The algorithm for calculating the replicas refers to HPA, and supports to customization algo args HPA recommendations: Scan for applications that suitable for configuring horizontal elasticity (EHPA), And give advice for configuration of EHPA, EHPA is a smart horizontal elastic product provided by Crane Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads","title":"Features"},{"location":"tutorials/replicas-recommendation/#create-hpa-analytics","text":"Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-replicas.yaml The created Analytics yaml is following: analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-hpa spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics ehpa.deployment-min-replicas : \"1\" ehpa.fluctuation-threshold : \"0\" ehpa.min-cpu-usage-threshold : \"0\" You can get created recommendations from analytics status: kubectl get analytics nginx-replicas -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-02T09:44:54Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-02T09:44:54Z\" recommendations : - lastStartTime : \"2022-06-02T09:44:54Z\" message : Success name : nginx-replicas-replicas-7qspm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : c853043c-5ff6-4ee0-a941-e04c8ec3093b","title":"Create HPA Analytics"},{"location":"tutorials/replicas-recommendation/#recommendation-analytics-result","text":"Use label selector to get related recommendations owns by Analytics . kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-02T09:44:54Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : e9168c6e-329f-40e9-8d0f-a1ddc35b0d47 app : nginx name : nginx-replicas-replicas-7qspm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : e9168c6e-329f-40e9-8d0f-a1ddc35b0d47 resourceVersion : \"818959913\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-7qspm uid : c853043c-5ff6-4ee0-a941-e04c8ec3093b spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-02T09:44:54Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-02T09:44:54Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\"","title":"Recommendation: Analytics result"},{"location":"tutorials/replicas-recommendation/#batch-recommendation","text":"Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource","title":"Batch recommendation"},{"location":"tutorials/replicas-recommendation/#hpa-recommendation-algorithm-model","text":"","title":"HPA Recommendation Algorithm model"},{"location":"tutorials/replicas-recommendation/#inspecting","text":"Workload with low replicas: If the replicas is too low, may not be suitable for hpa recommendation. Associated configuration: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas Workload with a certain percentage of not running pods: if the workload of Pod mostly can't run normally, may not be suitable for flexibility. Associated configuration: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio Workload with low CPU usage: The low CPU usage workload means that there is no load pressure. In this case, we can't estimate it. Associated configuration: ehpa.min-cpu-usage-threshold Workload with low fluctuation of CPU usage: dividing of the maximum and minimum usage is defined as the fluctuation rate. If the fluctuation rate is too low, the workload will not benefit much from hpa. Associated configuration: ehpa.fluctuation-threshold","title":"Inspecting"},{"location":"tutorials/replicas-recommendation/#advising","text":"In the advising phase, one EffectiveHPA Spec is recommended using the following Algorithm model. The recommended logic for each field is as follows: Recommend TargetUtilization Principle: Use Pod P99 resource utilization to recommend hpa. Because if the application can accept this utilization over P99 time, it can be inferred as a target for elasticity. Get the Pod P99 usage of the past seven days by Percentile algorithm: \\(pod\\_cpu\\_usage\\_p99\\) Corresponding utilization: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) To prevent over-utilization or under-utilization, target_pod_cpu_utilization needs to be less than ehpa.min-cpu-target-utilization and greater than ehpa. max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) Recommend minReplicas Principle: MinReplicas are recommended for the lowest hourly workload utilization for the past seven days. Calculate the lowest median workload cpu usage of the past seven days: \\(workload\\_cpu\\_usage\\_medium\\_min\\) Corresponding replicas: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) To prevent the minReplicas being too small, the minReplicas must be greater than or equal to ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) Recommend maxReplicas Principle: Use workload's past and future seven days load to recommend maximum replicas. Calculate P95 workload CPU usage for the past seven days and the next seven days: \\(workload\\_cpu\\_usage\\_p95\\) Corresponding replicas: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) To handle with the peak traffic, Magnify by a certain factor: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) Recommend MetricSpec(except CpuUtilization) If HPA is configured for workload, MetricSpecs other than CpuUtilization are inherited Recommend Behavior If HPA is configured for workload, the corresponding Behavior configuration is inherited Recommend Prediction Try to predict the CPU usage of the workload in the next seven days using DSP If the prediction is successful, add the prediction configuration If the workload is not predictable, do not add the prediction configuration.","title":"Advising"},{"location":"tutorials/replicas-recommendation/#configurations-for-hpa-recommendation","text":"Configuration Default Value Description ehpa.deployment-min-replicas 1 hpa recommendations are not made for workloads smaller than this value. ehpa.statefulset-min-replicas 1 hpa recommendations are not made for workloads smaller than this value. ehpa.workload-min-replicas 1 Workload replicas smaller than this value are not recommended for hpa. ehpa.pod-min-ready-seconds 30 specifies the number of seconds in decide whether a POD is ready. ehpa.pod-available-ratio 0.5 Workloads whose Ready pod ratio is smaller than this value are not recommended for hpa. ehpa.default-min-replicas 2 the default minimum minReplicas. ehpa.max-replicas-factor 3 the factor for calculate maxReplicas. ehpa.min-cpu-usage-threshold 10 hpa recommendations are not made for workloads smaller than this value. ehpa.fluctuation-threshold 1.5 hpa recommendations are not made for workloads smaller than this value. ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true inherits the existing HPA configuration","title":"Configurations for HPA Recommendation"},{"location":"tutorials/resource-recommendation/","text":"Resource Recommendation \u00b6 Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster. Difference between VPA \u00b6 Resource recommendations are a lightweight implementation of VPA and are more flexible. Algorithm: The algorithm model adopts the Moving Window algorithm of VPA, and supports to customization algo args , providing higher flexibility Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads without creating VPA objects one by one More portable: It is difficult to use VPA's Auto mode in production because it will cause container reconstruction when updating container resource configuration. Resource recommendation provides suggestions to users and leaves the decision of change to users Create Resource Analytics \u00b6 Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics The created Analytics yaml is following: analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment The output is: NAME AGE nginx-resource 16m You can get view analytics status by running: kubectl get analytics nginx-resource -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e Recommendation: Analytics result \u00b6 You can get recommendations that created by above Analytics by running. kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\" The status.recommendedValue.ResourceRequest is recommended by crane's recommendation engine. Batch recommendation \u00b6 Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource Resource Recommendation Algorithm model \u00b6 Inspecting \u00b6 Workload with not pods: if the workload has no pods exist means that it's not a available workload. Advising \u00b6 VPA's Moving Window algorithm was used to calculate the CPU and Memory of each container and give the corresponding recommended values","title":"Resource Recommendation"},{"location":"tutorials/resource-recommendation/#resource-recommendation","text":"Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster.","title":"Resource Recommendation"},{"location":"tutorials/resource-recommendation/#difference-between-vpa","text":"Resource recommendations are a lightweight implementation of VPA and are more flexible. Algorithm: The algorithm model adopts the Moving Window algorithm of VPA, and supports to customization algo args , providing higher flexibility Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads without creating VPA objects one by one More portable: It is difficult to use VPA's Auto mode in production because it will cause container reconstruction when updating container resource configuration. Resource recommendation provides suggestions to users and leaves the decision of change to users","title":"Difference between VPA"},{"location":"tutorials/resource-recommendation/#create-resource-analytics","text":"Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics The created Analytics yaml is following: analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment The output is: NAME AGE nginx-resource 16m You can get view analytics status by running: kubectl get analytics nginx-resource -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e","title":"Create Resource Analytics"},{"location":"tutorials/resource-recommendation/#recommendation-analytics-result","text":"You can get recommendations that created by above Analytics by running. kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\" The status.recommendedValue.ResourceRequest is recommended by crane's recommendation engine.","title":"Recommendation: Analytics result"},{"location":"tutorials/resource-recommendation/#batch-recommendation","text":"Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource","title":"Batch recommendation"},{"location":"tutorials/resource-recommendation/#resource-recommendation-algorithm-model","text":"","title":"Resource Recommendation Algorithm model"},{"location":"tutorials/resource-recommendation/#inspecting","text":"Workload with not pods: if the workload has no pods exist means that it's not a available workload.","title":"Inspecting"},{"location":"tutorials/resource-recommendation/#advising","text":"VPA's Moving Window algorithm was used to calculate the CPU and Memory of each container and give the corresponding recommended values","title":"Advising"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/","text":"Crane-scheduler \u00b6 Overview \u00b6 Crane-scheduler is a collection of scheduler plugins based on scheduler framework , including: Dynamic scheduler: a load-aware scheduler plugin Get Started \u00b6 Install Prometheus \u00b6 Make sure your kubernetes cluster has Prometheus installed. If not, please refer to Install Prometheus . Configure Prometheus Rules \u00b6 Configure the rules of Prometheus to get expected aggregated data: apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting The sampling interval of Prometheus must be less than 30 seconds, otherwise the above rules(such as cpu_usage_active) may not take effect. Install Crane-scheduler \u00b6 There are two options: Install Crane-scheduler as a second scheduler Replace native Kube-scheduler with Crane-scheduler Install Crane-scheduler as a second scheduler \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler Replace native Kube-scheduler with Crane-scheduler \u00b6 Backup /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ Modify configfile of kube-scheduler( scheduler-config.yaml ) to enable Dynamic scheduler plugin and configure plugin args: scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... Create /etc/kubernetes/policy.yaml , using as scheduler policy of Dynamic plugin: /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 Modify kube-scheduler.yaml and replace kube-scheduler image with Crane-scheduler\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... Install crane-scheduler-controller : Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml Schedule Pods With Crane-scheduler \u00b6 Test Crane-scheduler with following example: apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note Change crane-scheduler to default-scheduler if crane-scheduler is used as default. There will be the following event if the test pod is successfully scheduled: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"Overview"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler","text":"","title":"Crane-scheduler"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#overview","text":"Crane-scheduler is a collection of scheduler plugins based on scheduler framework , including: Dynamic scheduler: a load-aware scheduler plugin","title":"Overview"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#get-started","text":"","title":"Get Started"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#install-prometheus","text":"Make sure your kubernetes cluster has Prometheus installed. If not, please refer to Install Prometheus .","title":"Install Prometheus"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#configure-prometheus-rules","text":"Configure the rules of Prometheus to get expected aggregated data: apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting The sampling interval of Prometheus must be less than 30 seconds, otherwise the above rules(such as cpu_usage_active) may not take effect.","title":"Configure Prometheus Rules"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#install-crane-scheduler","text":"There are two options: Install Crane-scheduler as a second scheduler Replace native Kube-scheduler with Crane-scheduler","title":"Install Crane-scheduler"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#install-crane-scheduler-as-a-second-scheduler","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler","title":"Install Crane-scheduler as a second scheduler"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#replace-native-kube-scheduler-with-crane-scheduler","text":"Backup /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ Modify configfile of kube-scheduler( scheduler-config.yaml ) to enable Dynamic scheduler plugin and configure plugin args: scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... Create /etc/kubernetes/policy.yaml , using as scheduler policy of Dynamic plugin: /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 Modify kube-scheduler.yaml and replace kube-scheduler image with Crane-scheduler\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... Install crane-scheduler-controller : Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml","title":"Replace native Kube-scheduler with Crane-scheduler"},{"location":"tutorials/scheduling-pods-based-on-actual-node-load/#schedule-pods-with-crane-scheduler","text":"Test Crane-scheduler with following example: apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note Change crane-scheduler to default-scheduler if crane-scheduler is used as default. There will be the following event if the test pod is successfully scheduled: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"Schedule Pods With Crane-scheduler"},{"location":"tutorials/timeseriees-forecasting-by-dsp/","text":"DSP\u9884\u6d4b\u7b97\u6cd5 \u00b6 Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09 \u6d41\u7a0b \u00b6 \u9884\u5904\u7406 \u00b6 \u586b\u5145\u7f3a\u5931\u6570\u636e \u00b6 \u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\) \u53bb\u9664\u5f02\u5e38\u70b9 \u00b6 \u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u00b6 \u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002 \u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570 \u00b6 \u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002 \u9884\u6d4b \u00b6 \u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002 \u5e94\u7528 \u00b6 Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#dsp","text":"Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_1","text":"","title":"\u6d41\u7a0b"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_2","text":"","title":"\u9884\u5904\u7406"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_3","text":"\u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\)","title":"\u586b\u5145\u7f3a\u5931\u6570\u636e"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_4","text":"\u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002","title":"\u53bb\u9664\u5f02\u5e38\u70b9"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_5","text":"\u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002","title":"\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_6","text":"\u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002","title":"\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_7","text":"\u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002","title":"\u9884\u6d4b"},{"location":"tutorials/timeseriees-forecasting-by-dsp/#_8","text":"Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"\u5e94\u7528"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/","text":"EffectiveHorizontalPodAutoscaler \u00b6 EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with HorizontalPodAutoscaler but extends more features. EffectiveHorizontalPodAutoscaler supports prediction-driven autoscaling. With this capability, user can forecast the incoming peak flow and scale up their application ahead, also user can know when the peak flow will end and scale down their application gracefully. Besides that, EffectiveHorizontalPodAutoscaler also defines several scale strategies to support different scaling scenarios. Features \u00b6 A EffectiveHorizontalPodAutoscaler sample yaml looks like below: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef is the reference to the workload that should be scaled. MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. ScaleStrategy indicates the strategy to scaling target, value can be \"Auto\" and \"Preview\". Metrics contains the specifications for which to use to calculate the desired replica count. Prediction defines configurations for predict resources.If unspecified, defaults don't enable prediction. PredictionWindowSeconds is the time window to predict metrics in the future. Prediction-driven autoscaling \u00b6 Most of online applications follow regular pattern. We can predict future trend of hours or days. DSP is a time series prediction algorithm that applicable for application metrics prediction. The following shows a sample EffectiveHorizontalPodAutoscaler yaml with prediction enabled. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" Metric conversion \u00b6 When user defines spec.metrics in EffectiveHorizontalPodAutoscaler and prediction configuration is enabled, EffectiveHPAController will convert it to a new metric and configure the background HorizontalPodAutoscaler. This is a source EffectiveHorizontalPodAutoscaler yaml for metric definition. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 It's converted to underlying HorizontalPodAutoscaler metrics yaml. apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource In this sample, the resource metric defined by user is converted into two metrics: prediction metric and origin metric. prediction metric is custom metrics that provided by component MetricAdapter. Since custom metric doesn't support targetAverageUtilization , it's converted to targetAverageValue based on target pod cpu request. origin metric is equivalent to user defined metrics in EffectiveHorizontalPodAutoscaler, to fall back to baseline user defined in case of some unexpected situation e.g. business traffic sudden growth. HorizontalPodAutoscaler will calculate on each metric, and propose new replicas based on that. The largest one will be picked as the new scale. Horizontal scaling process \u00b6 There are six steps of prediction and scaling process: EffectiveHPAController create HorizontalPodAutoscaler and TimeSeriesPrediction instance PredictionCore get historic metric from prometheus and persist into TimeSeriesPrediction HPAController read metrics from KubeApiServer KubeApiServer forward requests to MetricAdapter and MetricServer HPAController calculate all metric results and propose a new scale replicas for target HPAController scale target with Scale Api Below is the process flow. Use case \u00b6 Let's take one use case that using EffectiveHorizontalPodAutoscaler in production cluster. We did a profiling on the load history of one application in production and replayed it in staging environment. With the same application, we leverage both EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler to manage the scale and compare the result. From the red line in below chart, we can see its actual total cpu usage is high at ~8am, ~12pm, ~8pm and low in midnight. The green line shows the prediction cpu usage trend. Below is the comparison result between EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler. The red line is the replica number generated by HorizontalPodAutoscaler and the green line is the result from EffectiveHorizontalPodAutoscaler. We can see significant improvement with EffectiveHorizontalPodAutoscaler: Scale up in advance before peek flow Scale down gracefully after peek flow Fewer replicas changes than HorizontalPodAutoscaler ScaleStrategy \u00b6 EffectiveHorizontalPodAutoscaler provides two strategies for scaling: Auto and Preview . User can change the strategy at runtime, and it will take effect on the fly. Auto \u00b6 Auto strategy achieves automatic scaling based on metrics. It is the default strategy. With this strategy, EffectiveHorizontalPodAutoscaler will create and control a HorizontalPodAutoscaler instance in backend. We don't recommend explicit configuration on the underlying HorizontalPodAutoscaler because it will be overridden by EffectiveHPAController. If user delete EffectiveHorizontalPodAutoscaler, HorizontalPodAutoscaler will be cleaned up too. Preview \u00b6 Preview strategy means EffectiveHorizontalPodAutoscaler won't change target's replicas automatically, so you can preview the calculated replicas and control target's replicas by themselves. User can switch from default strategy to this one by applying spec.scaleStrategy to Preview . It will take effect immediately, During the switch, EffectiveHPAController will disable HorizontalPodAutoscaler if exists and scale the target to the value spec.specificReplicas , if user not set spec.specificReplicas , when ScaleStrategy is change to Preview, it will just stop scaling. A sample preview configuration looks like following: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target HorizontalPodAutoscaler compatible \u00b6 EffectiveHorizontalPodAutoscaler is designed to be compatible with k8s native HorizontalPodAutoscaler, because we don't reinvent the autoscaling part but take advantage of the extension from HorizontalPodAutoscaler and build a high level autoscaling CRD. EffectiveHorizontalPodAutoscaler support all abilities from HorizontalPodAutoscaler like metricSpec and behavior. EffectiveHorizontalPodAutoscaler will continue support incoming new feature from HorizontalPodAutoscaler. EffectiveHorizontalPodAutoscaler status \u00b6 This is a yaml from EffectiveHorizontalPodAutoscaler.Status apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0 Cron-based autoscaling \u00b6 EffectiveHorizontalPodAutoscaler supports cron based autoscaling. Besides based on monitoring metrics, sometimes there are differences between holiday and weekdays in workload traffic, and a simple prediction algorithm may not work relatively well. Then you can make up for the lack of prediction by setting the weekend cron to have a larger number of replicas. For some non-web traffic applications, for example, some applications do not need to work on weekends, and then want to reduce the workload replicas to 1, you can also configure cron to reduce the cost for your service. Following are cron main fields in the ehpa spec: CronSpec: You can set multiple cron autoscaling configurations, cron cycle can set the start time and end time of the cycle, and the number of replicas of the workload can be continuously guaranteed to the set target value within the time range. Name: cron identifier TargetReplicas: the target number of replicas of the workload in this cron time range. Start: The start time of the cron, in the standard linux crontab format End: the end time of the cron, in the standard linux crontab format Current cron autoscaling capabilities from some manufacturers and communities have some shortcomings. The cron capability is provided separately, has no global view of autoscaling, poor compatibility with HPA, and conflicts with other scale trigger. The semantics and behavior of cron do not match very well, and are even very difficult to understand when used, which can easily mislead users and lead to autoscaling failures. The following figure shows the comparison between the current EHPA cron autoscaling implementation and other cron capabilities. To address the above issues, the cron autoscaling implemented by EHPA is designed on the basis of compatibility with HPA, and cron, as an indicator of HPA, acts on the workload object together with other indicators. In addition, the setting of cron is also very simple. When cron is configured separately, the default scaling of the workload will not be performed when it is not in the active time range. Cron working without other metrics \u00b6 You can just configure cron itself to work, assume you have no other metrics configured. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Better to setting cron to fill the one complete time period such as one day, one week # Below is one day cron scheduling, it #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Local timezone means you use the server's(or maybe is a container's) timezone which the craned running in. for example, if your craned started as utc timezone, then it is utc. if it started as Asia/Shanghai, then it is Asia/Shanghai. crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec has following fields. name defines the name of the cron, cron name must be unique in the same ehpa description defines the details description of the cron. it can be empty. timezone defines the timezone of the cron which the crane to schedule in. If unspecified, default use UTC timezone. you can set it to Local which means you use timezone of the container of crane service running in. Also, America/Los_Angeles is ok. start defines the cron start time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron end defines the cron end time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron targetReplicas defines the target replicas the workload to scale when the cron is active, which means current time is between start and end. Above means each day, the workload needs to keep the replicas hourly. #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Remember not to set start time is after end . For example, when you set following: crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 Above is not valid because the start will be always later than end. The hpa controller will always get the workload's desired replica to scale, which means keep the original replicas. Horizontal scaling process \u00b6 There are six steps of cron-driven and scaling process: EffectiveHPAController creates HorizontalPodAutoscaler which is injected to external cron metrics in spec. HPAController reads cron external metrics from KubeApiServer KubeApiServer forwards requests to MetricAdapter and MetricServer The MetricAdapter finds the cron scaler for target hpa, and detect if the cron scaler is active, which means the current time is between the cron start and end schedule time. It will return the TargetReplicas specified in the CronSpec . HPAController calculates all metric results and propose a new scale replicas for target by selecting the largest one. HPAController scales target with Scale Api When use ehpa, users can configure only cron metric, let the ehpa to be used as cron hpa. Multiple crons of one ehpa will be transformed to one external metric. HPA will fetch this external cron metric and calculates target replicas when reconcile. HPA will select the largest proposal replicas to scale the workload from multiple metrics. Cron working with other metrics together \u00b6 EffectiveHorizontalPodAutoscaler is compatible with HorizontalPodAutoscaler(Which is kubernetes built in). So if you configured metrics for HPA such as cpu or memory, then the HPA will scale by the real time metric it observed. With EHPA, users can configure CronMetric\u3001PredictionMetric\u3001OriginalMetric at the same time. We highly recomend you configure metrics of all dimensions. They are represtenting the cron replicas, prior predicted replicas, posterior observed replicas. This is a powerful feature. Because HPA always pick the largest replicas calculated by all dimensional metrics to scale. Which will gurantee your workload's QoS, when you configure three types of autoscaling at the same time, the replicas caculated by real metric observed is largest, then it will use the max one. Although the replicas caculated by prediction metric is smaller for some unexpected reason. So you don't be worried about the QoS. Mechanism \u00b6 When metrics adapter deal with the external cron metric requests, metrics adapter will do following steps. graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; No active cron now, there are two cases: no other hpa metrics work with cron together, then return current workload replicas to keep the original desired replicas other hpa metrics work with cron together, then return min value to remove the cron impact for other metrics. when cron is working with other metrics together, it should not return workload's original desired replicas, because there maybe other metrics want to trigger the workload to scale in. hpa controller select max replicas computed by all metrics(this is hpa default policy in hard code), cron will impact the hpa. so we should remove the cron effect when cron is not active, it should return min value. Has active ones. we use the largest targetReplicas specified in cron spec. Basically, there should not be more then one active cron at the same time period, it is not a best practice. HPA will get the cron external metric value, then it will compute the replicas by itself. Use Case \u00b6 When you need to keep the workload replicas to minimum at midnight, you configured cron. And you need the HPA to get the real metric observed by metrics server to do scale based on real time observed metric. At last you configure a prediction-driven metric to do scale up early and scale down lately by predicting way. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100 FAQ \u00b6 error: unable to get metric crane_pod_cpu_usage \u00b6 When checking the status for EffectiveHorizontalPodAutoscaler, you may see this error: - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive reason: Not all workload's cpu metric are predictable, if predict your workload failed, it will show above errors. solution: Just waiting. the Prediction algorithm need more time, you can see DSP section to know more about this algorithm. EffectiveHorizontalPodAutoscaler have a protection mechanism when prediction failed, it will use the actual cpu utilization to do autoscaling.","title":"Effective HPA"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler","text":"EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with HorizontalPodAutoscaler but extends more features. EffectiveHorizontalPodAutoscaler supports prediction-driven autoscaling. With this capability, user can forecast the incoming peak flow and scale up their application ahead, also user can know when the peak flow will end and scale down their application gracefully. Besides that, EffectiveHorizontalPodAutoscaler also defines several scale strategies to support different scaling scenarios.","title":"EffectiveHorizontalPodAutoscaler"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#features","text":"A EffectiveHorizontalPodAutoscaler sample yaml looks like below: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef is the reference to the workload that should be scaled. MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. ScaleStrategy indicates the strategy to scaling target, value can be \"Auto\" and \"Preview\". Metrics contains the specifications for which to use to calculate the desired replica count. Prediction defines configurations for predict resources.If unspecified, defaults don't enable prediction. PredictionWindowSeconds is the time window to predict metrics in the future.","title":"Features"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#prediction-driven-autoscaling","text":"Most of online applications follow regular pattern. We can predict future trend of hours or days. DSP is a time series prediction algorithm that applicable for application metrics prediction. The following shows a sample EffectiveHorizontalPodAutoscaler yaml with prediction enabled. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\"","title":"Prediction-driven autoscaling"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#metric-conversion","text":"When user defines spec.metrics in EffectiveHorizontalPodAutoscaler and prediction configuration is enabled, EffectiveHPAController will convert it to a new metric and configure the background HorizontalPodAutoscaler. This is a source EffectiveHorizontalPodAutoscaler yaml for metric definition. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 It's converted to underlying HorizontalPodAutoscaler metrics yaml. apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource In this sample, the resource metric defined by user is converted into two metrics: prediction metric and origin metric. prediction metric is custom metrics that provided by component MetricAdapter. Since custom metric doesn't support targetAverageUtilization , it's converted to targetAverageValue based on target pod cpu request. origin metric is equivalent to user defined metrics in EffectiveHorizontalPodAutoscaler, to fall back to baseline user defined in case of some unexpected situation e.g. business traffic sudden growth. HorizontalPodAutoscaler will calculate on each metric, and propose new replicas based on that. The largest one will be picked as the new scale.","title":"Metric conversion"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontal-scaling-process","text":"There are six steps of prediction and scaling process: EffectiveHPAController create HorizontalPodAutoscaler and TimeSeriesPrediction instance PredictionCore get historic metric from prometheus and persist into TimeSeriesPrediction HPAController read metrics from KubeApiServer KubeApiServer forward requests to MetricAdapter and MetricServer HPAController calculate all metric results and propose a new scale replicas for target HPAController scale target with Scale Api Below is the process flow.","title":"Horizontal scaling process"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#use-case","text":"Let's take one use case that using EffectiveHorizontalPodAutoscaler in production cluster. We did a profiling on the load history of one application in production and replayed it in staging environment. With the same application, we leverage both EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler to manage the scale and compare the result. From the red line in below chart, we can see its actual total cpu usage is high at ~8am, ~12pm, ~8pm and low in midnight. The green line shows the prediction cpu usage trend. Below is the comparison result between EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler. The red line is the replica number generated by HorizontalPodAutoscaler and the green line is the result from EffectiveHorizontalPodAutoscaler. We can see significant improvement with EffectiveHorizontalPodAutoscaler: Scale up in advance before peek flow Scale down gracefully after peek flow Fewer replicas changes than HorizontalPodAutoscaler","title":"Use case"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#scalestrategy","text":"EffectiveHorizontalPodAutoscaler provides two strategies for scaling: Auto and Preview . User can change the strategy at runtime, and it will take effect on the fly.","title":"ScaleStrategy"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#auto","text":"Auto strategy achieves automatic scaling based on metrics. It is the default strategy. With this strategy, EffectiveHorizontalPodAutoscaler will create and control a HorizontalPodAutoscaler instance in backend. We don't recommend explicit configuration on the underlying HorizontalPodAutoscaler because it will be overridden by EffectiveHPAController. If user delete EffectiveHorizontalPodAutoscaler, HorizontalPodAutoscaler will be cleaned up too.","title":"Auto"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#preview","text":"Preview strategy means EffectiveHorizontalPodAutoscaler won't change target's replicas automatically, so you can preview the calculated replicas and control target's replicas by themselves. User can switch from default strategy to this one by applying spec.scaleStrategy to Preview . It will take effect immediately, During the switch, EffectiveHPAController will disable HorizontalPodAutoscaler if exists and scale the target to the value spec.specificReplicas , if user not set spec.specificReplicas , when ScaleStrategy is change to Preview, it will just stop scaling. A sample preview configuration looks like following: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target","title":"Preview"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontalpodautoscaler-compatible","text":"EffectiveHorizontalPodAutoscaler is designed to be compatible with k8s native HorizontalPodAutoscaler, because we don't reinvent the autoscaling part but take advantage of the extension from HorizontalPodAutoscaler and build a high level autoscaling CRD. EffectiveHorizontalPodAutoscaler support all abilities from HorizontalPodAutoscaler like metricSpec and behavior. EffectiveHorizontalPodAutoscaler will continue support incoming new feature from HorizontalPodAutoscaler.","title":"HorizontalPodAutoscaler compatible"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler-status","text":"This is a yaml from EffectiveHorizontalPodAutoscaler.Status apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0","title":"EffectiveHorizontalPodAutoscaler status"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-based-autoscaling","text":"EffectiveHorizontalPodAutoscaler supports cron based autoscaling. Besides based on monitoring metrics, sometimes there are differences between holiday and weekdays in workload traffic, and a simple prediction algorithm may not work relatively well. Then you can make up for the lack of prediction by setting the weekend cron to have a larger number of replicas. For some non-web traffic applications, for example, some applications do not need to work on weekends, and then want to reduce the workload replicas to 1, you can also configure cron to reduce the cost for your service. Following are cron main fields in the ehpa spec: CronSpec: You can set multiple cron autoscaling configurations, cron cycle can set the start time and end time of the cycle, and the number of replicas of the workload can be continuously guaranteed to the set target value within the time range. Name: cron identifier TargetReplicas: the target number of replicas of the workload in this cron time range. Start: The start time of the cron, in the standard linux crontab format End: the end time of the cron, in the standard linux crontab format Current cron autoscaling capabilities from some manufacturers and communities have some shortcomings. The cron capability is provided separately, has no global view of autoscaling, poor compatibility with HPA, and conflicts with other scale trigger. The semantics and behavior of cron do not match very well, and are even very difficult to understand when used, which can easily mislead users and lead to autoscaling failures. The following figure shows the comparison between the current EHPA cron autoscaling implementation and other cron capabilities. To address the above issues, the cron autoscaling implemented by EHPA is designed on the basis of compatibility with HPA, and cron, as an indicator of HPA, acts on the workload object together with other indicators. In addition, the setting of cron is also very simple. When cron is configured separately, the default scaling of the workload will not be performed when it is not in the active time range.","title":"Cron-based autoscaling"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-without-other-metrics","text":"You can just configure cron itself to work, assume you have no other metrics configured. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Better to setting cron to fill the one complete time period such as one day, one week # Below is one day cron scheduling, it #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Local timezone means you use the server's(or maybe is a container's) timezone which the craned running in. for example, if your craned started as utc timezone, then it is utc. if it started as Asia/Shanghai, then it is Asia/Shanghai. crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec has following fields. name defines the name of the cron, cron name must be unique in the same ehpa description defines the details description of the cron. it can be empty. timezone defines the timezone of the cron which the crane to schedule in. If unspecified, default use UTC timezone. you can set it to Local which means you use timezone of the container of crane service running in. Also, America/Los_Angeles is ok. start defines the cron start time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron end defines the cron end time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron targetReplicas defines the target replicas the workload to scale when the cron is active, which means current time is between start and end. Above means each day, the workload needs to keep the replicas hourly. #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Remember not to set start time is after end . For example, when you set following: crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 Above is not valid because the start will be always later than end. The hpa controller will always get the workload's desired replica to scale, which means keep the original replicas.","title":"Cron working without other metrics"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontal-scaling-process_1","text":"There are six steps of cron-driven and scaling process: EffectiveHPAController creates HorizontalPodAutoscaler which is injected to external cron metrics in spec. HPAController reads cron external metrics from KubeApiServer KubeApiServer forwards requests to MetricAdapter and MetricServer The MetricAdapter finds the cron scaler for target hpa, and detect if the cron scaler is active, which means the current time is between the cron start and end schedule time. It will return the TargetReplicas specified in the CronSpec . HPAController calculates all metric results and propose a new scale replicas for target by selecting the largest one. HPAController scales target with Scale Api When use ehpa, users can configure only cron metric, let the ehpa to be used as cron hpa. Multiple crons of one ehpa will be transformed to one external metric. HPA will fetch this external cron metric and calculates target replicas when reconcile. HPA will select the largest proposal replicas to scale the workload from multiple metrics.","title":"Horizontal scaling process"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-with-other-metrics-together","text":"EffectiveHorizontalPodAutoscaler is compatible with HorizontalPodAutoscaler(Which is kubernetes built in). So if you configured metrics for HPA such as cpu or memory, then the HPA will scale by the real time metric it observed. With EHPA, users can configure CronMetric\u3001PredictionMetric\u3001OriginalMetric at the same time. We highly recomend you configure metrics of all dimensions. They are represtenting the cron replicas, prior predicted replicas, posterior observed replicas. This is a powerful feature. Because HPA always pick the largest replicas calculated by all dimensional metrics to scale. Which will gurantee your workload's QoS, when you configure three types of autoscaling at the same time, the replicas caculated by real metric observed is largest, then it will use the max one. Although the replicas caculated by prediction metric is smaller for some unexpected reason. So you don't be worried about the QoS.","title":"Cron working with other metrics together"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#mechanism","text":"When metrics adapter deal with the external cron metric requests, metrics adapter will do following steps. graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; No active cron now, there are two cases: no other hpa metrics work with cron together, then return current workload replicas to keep the original desired replicas other hpa metrics work with cron together, then return min value to remove the cron impact for other metrics. when cron is working with other metrics together, it should not return workload's original desired replicas, because there maybe other metrics want to trigger the workload to scale in. hpa controller select max replicas computed by all metrics(this is hpa default policy in hard code), cron will impact the hpa. so we should remove the cron effect when cron is not active, it should return min value. Has active ones. we use the largest targetReplicas specified in cron spec. Basically, there should not be more then one active cron at the same time period, it is not a best practice. HPA will get the cron external metric value, then it will compute the replicas by itself.","title":"Mechanism"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#use-case_1","text":"When you need to keep the workload replicas to minimum at midnight, you configured cron. And you need the HPA to get the real metric observed by metrics server to do scale based on real time observed metric. At last you configure a prediction-driven metric to do scale up early and scale down lately by predicting way. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100","title":"Use Case"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#faq","text":"","title":"FAQ"},{"location":"tutorials/using-effective-hpa-to-scaling-with-effectiveness/#error-unable-to-get-metric-crane_pod_cpu_usage","text":"When checking the status for EffectiveHorizontalPodAutoscaler, you may see this error: - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive reason: Not all workload's cpu metric are predictable, if predict your workload failed, it will show above errors. solution: Just waiting. the Prediction algorithm need more time, you can see DSP section to know more about this algorithm. EffectiveHorizontalPodAutoscaler have a protection mechanism when prediction failed, it will use the actual cpu utilization to do autoscaling.","title":"error: unable to get metric crane_pod_cpu_usage"},{"location":"tutorials/using-qos-ensurance/","text":"Qos Ensurance \u00b6 QoS ensurance guarantees the stability of the pods running on Kubernetes. It has the ability of interference detection and active avoidance. When pod with higher priority is affected by resource competition, disable schedule, throttle and evict will be applied to pod with lower priority to support interference detection and user-defined operation of user-defined indicators; At the same time, it has enhanced bypass cpuset management capability to improve resource utilization efficiency while binding cores. It has the dynamic resource oversold ability enhanced by the prediction algorithm, and reuses the idle resources. At the same time, it combines the prediction ability of the crane to better reuse the idle resources. At the same time, it has the elastic resource limitation function to limit the workload of reusing idle resources. Qos Ensurance Architecture \u00b6 Qos ensurance's architecture is shown as below. It contains three modules. state collector: collect metrics periodically anomaly analyzer: analyze the node triggered anomaly used collected metrics action executor: execute avoidance actions, include disable scheduling, throttle and eviction. The main process: State collector synchronizes policies from kube-apiserver. If the policies are changed, the state collector updates the collectors. State collector collects metrics periodically. State collector transmits metrics to anomaly analyzer. Anomaly analyzer ranges all rules to analyze the avoidance threshold or the restored threshold reached. Anomaly analyzer merges the analyzed results and notices the avoidance actions. Action executor executes actions based on the analyzed results. Interference Detection and Active Avoidance \u00b6 Disable Scheduling \u00b6 The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, disable schedule action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 # The minimum wait time of the node from scheduling disable status to normal status apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) We consider the rule is triggered, when the threshold reached continued so many times We consider the rule is restored, when the threshold not reached continued so many times Name of AvoidanceAction which be associated Strategy for the action, you can set it \"Preview\" to not perform actually Name of metric Threshold of metric Please check the video to learn more about the scheduling disable actions. Throttle \u00b6 The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, throttle action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" The minimal ratio of the CPU quota, if the pod is throttled lower than this ratio, it will be set to this. The step for throttle action. It will reduce this percentage of CPU quota in each avoidance triggered.It will increase this percentage of CPU quota in each restored. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000 Eviction \u00b6 The following YAML is another case, low priority pods on the node will be evicted, when the node CPU usage trigger the threshold. apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" Duration in seconds the pod needs to terminate gracefully. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 Strategy for the action, \"Preview\" to not perform actually Supported Metrics \u00b6 Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization Accurately Perform Avoidance Actions \u00b6 Through the following two points, the excessive operation of low-quality pod can be avoided, and the gap between the metrics and the specified waterline can be reduced faster, so as to ensure that the high-priority service is not affected 1. Sort pod Crane implements some general sorting methods (which will be improved later): ClassAndPriority: compare the QOSClass and class value of two pods, compare QOSClass first, and then class value; Those with high priority are ranked later and have higher priority runningTime: compare the running time of two pods. The one with long running time is ranked later and has higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the consumption of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod Taking the ranking of CPU usage metric as an example, it also extends some ranking strategies related to its own metric, such as the ranking of CPU usage, which will compare the priority of two pods in turn. If the priority is the same, then compare the CPU consumption. If the CPU consumption is also the same, continue to compare the extended CPU resource consumption, and finally compare the running time of pod, when there is a difference in an indicator, the comparison result can be returned: orderedby (classandpriority, CpuUsage, extcpuusage, runningtime) Sort(pods) Refer to the waterline and pod usage to perform avoidance action //Divide all the metrics that trigger the waterline threshold into two parts according to their quantified attribute metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // If there is a metric that cannot be quantified, obtain the metric of a throttleable with the highest actionpriority to operate on all selected pods if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //Get the latest usage, get the gap to waterline ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //If the real-time consumption of metric in the trigger waterline threshold cannot be obtained, chose the metric which is throttleable with the highest actionpriority to suppress all selected pods if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //Traverse the quantifiable metrics in the metrics that trigger the waterline: if the metric has a sorting method, use its sortfunc to sort the pod directly, //otherwise use generalsorter to sort; Then use its corresponding operation method to operate the pod, and calculate the amount of resources released from the corresponding metric until the gap between the corresponding metric and the waterline no longer exists for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } About extending user-defined metrics and sorting, it is introduced in \"User-defined metrics interference detection avoidance and user-defined sorting\". Enhanced bypass cpuset management capability \u00b6 Kubelet supports the static CPU manager strategy. When the guaranteed pod runs on the node, kebelet will allocate the specified dedicated CPU for the pod, which cannot be occupied by other processes. This ensures the CPU monopoly of the guaranteed pod, but also causes the low utilization of CPU and nodes, resulting in a certain waste. Crane agent provides a new strategy for cpuset management, allowing pod and other pod to share CPU. When it specifies CPU binding core, it can make use of the advantages of less context switching and higher cache affinity of binding core, and also allow other workload to deploy and share, so as to improve resource utilization. Three types of pod cpuset are provided: Exclusive: after binding the core, other containers can no longer use the CPU and monopolize the CPU Share: other containers can use the CPU after binding the core None: select the CPU that is not occupied by the container of exclusive pod, can use the binding core of share type Share type binding strategy can make use of the advantages of less context switching and higher cache affinity, and can also be shared by other workload deployments to improve resource utilization Relax the restrictions on binding cores in kubelet Originally, it was required that the CPU limit of all containers be equal to the CPU request. Here, it is only required that the CPU limit of any container be greater than or equal to 1 and equal to the CPU request to set the binding core for the container Support modifying the cpuset policy of pod during the running of pod, which will take effect immediately The CPU manager policy of pod is converted from none to share and from exclusive to share without restart How to use: 1. Set the cpuset manager of kubelet to \"None\" 2. Set CPU manager policy through pod annotation qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Dynamic resource oversold enhanced by prediction algorithm \u00b6 In order to improve the stability, users usually set the request value higher than the actual usage when deploying applications, resulting in a waste of resources. In order to improve the resource utilization of nodes, users will deploy some besteffort applications in combination, using idle resources to realize oversold; However, due to the lack of resource limit and request constraints and related information in these applications, scheduler may still schedule these pods to nodes with high load, which is inconsistent with our original intention, so it is best to schedule based on the free resources of nodes. Crane collects the idle resources of nodes in the following two ways, and takes them as the idle resources of nodes after synthesis, which enhances the accuracy of resource evaluation: CPU usage information collected locally nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal ExclusiveCPUIdle refers to the idle amount of CPU occupied by the pod whose CPU manager policy is exclusive. Although this part of resources is idle, it cannot be reused because of monopoly, so it is counted as used ExtResContainerCpuUsageTotal refers to the CPU consumption used as dynamic resources, which needs to be subtracted to avoid secondary calculation Create a TSP of node CPU usage, which is automatically created by default, and will predict node CPU usage based on history apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default Combine the prediction algorithm with the current actual consumption to calculate the remaining available resources of the node, and give it to the node as an extended resource. Pod can indicate that the extended resource is used as an offline job to use the idle resources, so as to improve the resource utilization rate of the node; How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> , as follows spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\" Elastic resource restriction function \u00b6 The native besteffort application lacks a fair guarantee of resource usage. Crane guarantees that the CPU usage of the besteffort pod using dynamic resources is limited within the reasonable range of its allowable use. The agent guarantees that the actual consumption of the pod using extended resources will not exceed its stated limit. At the same time, when the CPU competes, it can also compete fairly according to its stated amount; At the same time, pod using elastic resources will also be managed by the waterline function. How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> User-defined metrics interference detection avoidance and user-defined sorting \u00b6 The use of user-defined metrics interference detection avoidance and user-defined sorting is the same as the process described in the \"Accurately Perform Avoidance Actions\". Here is how to customize your own metrics to participate in the interference detection avoidance process In order to better sort and accurately control metrics configured based on NodeQoSEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metric include the following, and these fields can be realized by customized indicators: Name Indicates the name of metric, which should be consistent with the metric name collected in the collector module ActionPriority Indicates the priority of the metric. 0 is the lowest and 10 is the highest SortAble Indicates whether the metric can be sorted. If it is true, the corresponding SortFunc needs to be implemented SortFunc The corresponding sorting method. The sorting method can be arranged and combined with some general methods, and then combined with the sorting of the metric itself, which will be introduced in detail below ThrottleAble Indicates whether pod can be suppressed for this metric. For example, for the metric of CPU usage, there are corresponding suppression methods, but for the metric of memory usage, pod can only be evicted, and effective suppression cannot be carried out ThrottleQuantified Indicates whether the amount of resources corresponding to metric released after suppressing (restoring) a pod can be accurately calculated. We call the metric that can be accurately quantified as quantifiable, otherwise it is not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; Memory usage does not belong to suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc The specific method of executing throttle action. If throttle is not available, the returned released is null RestoreFunc After being throttled, the specific method of performing the recovery action. If restore is not allowed, the returned released is null Evictable, EvictQuantified and EvictFunc The relevant definitions of evict action are similar to those of throttle action type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } After the construction is completed, register the metric through registerMetricMap() For the metrics that need to be customized, you can easily realize the flexible customized sorting of pod by combining the following methods with general sorting methods to represent the customized metric indicators, represents the customized sorting strategy func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } Among them, the following sorting method <metric-sort-func> needs to be implemented func (p1, p2 podinfo.PodContext) int32","title":"Qos Ensurance"},{"location":"tutorials/using-qos-ensurance/#qos-ensurance","text":"QoS ensurance guarantees the stability of the pods running on Kubernetes. It has the ability of interference detection and active avoidance. When pod with higher priority is affected by resource competition, disable schedule, throttle and evict will be applied to pod with lower priority to support interference detection and user-defined operation of user-defined indicators; At the same time, it has enhanced bypass cpuset management capability to improve resource utilization efficiency while binding cores. It has the dynamic resource oversold ability enhanced by the prediction algorithm, and reuses the idle resources. At the same time, it combines the prediction ability of the crane to better reuse the idle resources. At the same time, it has the elastic resource limitation function to limit the workload of reusing idle resources.","title":"Qos Ensurance"},{"location":"tutorials/using-qos-ensurance/#qos-ensurance-architecture","text":"Qos ensurance's architecture is shown as below. It contains three modules. state collector: collect metrics periodically anomaly analyzer: analyze the node triggered anomaly used collected metrics action executor: execute avoidance actions, include disable scheduling, throttle and eviction. The main process: State collector synchronizes policies from kube-apiserver. If the policies are changed, the state collector updates the collectors. State collector collects metrics periodically. State collector transmits metrics to anomaly analyzer. Anomaly analyzer ranges all rules to analyze the avoidance threshold or the restored threshold reached. Anomaly analyzer merges the analyzed results and notices the avoidance actions. Action executor executes actions based on the analyzed results.","title":"Qos Ensurance Architecture"},{"location":"tutorials/using-qos-ensurance/#interference-detection-and-active-avoidance","text":"","title":"Interference Detection and Active Avoidance"},{"location":"tutorials/using-qos-ensurance/#disable-scheduling","text":"The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, disable schedule action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 # The minimum wait time of the node from scheduling disable status to normal status apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) We consider the rule is triggered, when the threshold reached continued so many times We consider the rule is restored, when the threshold not reached continued so many times Name of AvoidanceAction which be associated Strategy for the action, you can set it \"Preview\" to not perform actually Name of metric Threshold of metric Please check the video to learn more about the scheduling disable actions.","title":"Disable Scheduling"},{"location":"tutorials/using-qos-ensurance/#throttle","text":"The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, throttle action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" The minimal ratio of the CPU quota, if the pod is throttled lower than this ratio, it will be set to this. The step for throttle action. It will reduce this percentage of CPU quota in each avoidance triggered.It will increase this percentage of CPU quota in each restored. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000","title":"Throttle"},{"location":"tutorials/using-qos-ensurance/#eviction","text":"The following YAML is another case, low priority pods on the node will be evicted, when the node CPU usage trigger the threshold. apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" Duration in seconds the pod needs to terminate gracefully. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 Strategy for the action, \"Preview\" to not perform actually","title":"Eviction"},{"location":"tutorials/using-qos-ensurance/#supported-metrics","text":"Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization","title":"Supported Metrics"},{"location":"tutorials/using-qos-ensurance/#accurately-perform-avoidance-actions","text":"Through the following two points, the excessive operation of low-quality pod can be avoided, and the gap between the metrics and the specified waterline can be reduced faster, so as to ensure that the high-priority service is not affected 1. Sort pod Crane implements some general sorting methods (which will be improved later): ClassAndPriority: compare the QOSClass and class value of two pods, compare QOSClass first, and then class value; Those with high priority are ranked later and have higher priority runningTime: compare the running time of two pods. The one with long running time is ranked later and has higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the consumption of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod Taking the ranking of CPU usage metric as an example, it also extends some ranking strategies related to its own metric, such as the ranking of CPU usage, which will compare the priority of two pods in turn. If the priority is the same, then compare the CPU consumption. If the CPU consumption is also the same, continue to compare the extended CPU resource consumption, and finally compare the running time of pod, when there is a difference in an indicator, the comparison result can be returned: orderedby (classandpriority, CpuUsage, extcpuusage, runningtime) Sort(pods) Refer to the waterline and pod usage to perform avoidance action //Divide all the metrics that trigger the waterline threshold into two parts according to their quantified attribute metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // If there is a metric that cannot be quantified, obtain the metric of a throttleable with the highest actionpriority to operate on all selected pods if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //Get the latest usage, get the gap to waterline ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //If the real-time consumption of metric in the trigger waterline threshold cannot be obtained, chose the metric which is throttleable with the highest actionpriority to suppress all selected pods if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //Traverse the quantifiable metrics in the metrics that trigger the waterline: if the metric has a sorting method, use its sortfunc to sort the pod directly, //otherwise use generalsorter to sort; Then use its corresponding operation method to operate the pod, and calculate the amount of resources released from the corresponding metric until the gap between the corresponding metric and the waterline no longer exists for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } About extending user-defined metrics and sorting, it is introduced in \"User-defined metrics interference detection avoidance and user-defined sorting\".","title":"Accurately Perform Avoidance Actions"},{"location":"tutorials/using-qos-ensurance/#enhanced-bypass-cpuset-management-capability","text":"Kubelet supports the static CPU manager strategy. When the guaranteed pod runs on the node, kebelet will allocate the specified dedicated CPU for the pod, which cannot be occupied by other processes. This ensures the CPU monopoly of the guaranteed pod, but also causes the low utilization of CPU and nodes, resulting in a certain waste. Crane agent provides a new strategy for cpuset management, allowing pod and other pod to share CPU. When it specifies CPU binding core, it can make use of the advantages of less context switching and higher cache affinity of binding core, and also allow other workload to deploy and share, so as to improve resource utilization. Three types of pod cpuset are provided: Exclusive: after binding the core, other containers can no longer use the CPU and monopolize the CPU Share: other containers can use the CPU after binding the core None: select the CPU that is not occupied by the container of exclusive pod, can use the binding core of share type Share type binding strategy can make use of the advantages of less context switching and higher cache affinity, and can also be shared by other workload deployments to improve resource utilization Relax the restrictions on binding cores in kubelet Originally, it was required that the CPU limit of all containers be equal to the CPU request. Here, it is only required that the CPU limit of any container be greater than or equal to 1 and equal to the CPU request to set the binding core for the container Support modifying the cpuset policy of pod during the running of pod, which will take effect immediately The CPU manager policy of pod is converted from none to share and from exclusive to share without restart How to use: 1. Set the cpuset manager of kubelet to \"None\" 2. Set CPU manager policy through pod annotation qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share","title":"Enhanced bypass cpuset management capability"},{"location":"tutorials/using-qos-ensurance/#dynamic-resource-oversold-enhanced-by-prediction-algorithm","text":"In order to improve the stability, users usually set the request value higher than the actual usage when deploying applications, resulting in a waste of resources. In order to improve the resource utilization of nodes, users will deploy some besteffort applications in combination, using idle resources to realize oversold; However, due to the lack of resource limit and request constraints and related information in these applications, scheduler may still schedule these pods to nodes with high load, which is inconsistent with our original intention, so it is best to schedule based on the free resources of nodes. Crane collects the idle resources of nodes in the following two ways, and takes them as the idle resources of nodes after synthesis, which enhances the accuracy of resource evaluation: CPU usage information collected locally nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal ExclusiveCPUIdle refers to the idle amount of CPU occupied by the pod whose CPU manager policy is exclusive. Although this part of resources is idle, it cannot be reused because of monopoly, so it is counted as used ExtResContainerCpuUsageTotal refers to the CPU consumption used as dynamic resources, which needs to be subtracted to avoid secondary calculation Create a TSP of node CPU usage, which is automatically created by default, and will predict node CPU usage based on history apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default Combine the prediction algorithm with the current actual consumption to calculate the remaining available resources of the node, and give it to the node as an extended resource. Pod can indicate that the extended resource is used as an offline job to use the idle resources, so as to improve the resource utilization rate of the node; How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> , as follows spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\"","title":"Dynamic resource oversold enhanced by prediction algorithm"},{"location":"tutorials/using-qos-ensurance/#elastic-resource-restriction-function","text":"The native besteffort application lacks a fair guarantee of resource usage. Crane guarantees that the CPU usage of the besteffort pod using dynamic resources is limited within the reasonable range of its allowable use. The agent guarantees that the actual consumption of the pod using extended resources will not exceed its stated limit. At the same time, when the CPU competes, it can also compete fairly according to its stated amount; At the same time, pod using elastic resources will also be managed by the waterline function. How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value>","title":"Elastic resource restriction function"},{"location":"tutorials/using-qos-ensurance/#user-defined-metrics-interference-detection-avoidance-and-user-defined-sorting","text":"The use of user-defined metrics interference detection avoidance and user-defined sorting is the same as the process described in the \"Accurately Perform Avoidance Actions\". Here is how to customize your own metrics to participate in the interference detection avoidance process In order to better sort and accurately control metrics configured based on NodeQoSEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metric include the following, and these fields can be realized by customized indicators: Name Indicates the name of metric, which should be consistent with the metric name collected in the collector module ActionPriority Indicates the priority of the metric. 0 is the lowest and 10 is the highest SortAble Indicates whether the metric can be sorted. If it is true, the corresponding SortFunc needs to be implemented SortFunc The corresponding sorting method. The sorting method can be arranged and combined with some general methods, and then combined with the sorting of the metric itself, which will be introduced in detail below ThrottleAble Indicates whether pod can be suppressed for this metric. For example, for the metric of CPU usage, there are corresponding suppression methods, but for the metric of memory usage, pod can only be evicted, and effective suppression cannot be carried out ThrottleQuantified Indicates whether the amount of resources corresponding to metric released after suppressing (restoring) a pod can be accurately calculated. We call the metric that can be accurately quantified as quantifiable, otherwise it is not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; Memory usage does not belong to suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc The specific method of executing throttle action. If throttle is not available, the returned released is null RestoreFunc After being throttled, the specific method of performing the recovery action. If restore is not allowed, the returned released is null Evictable, EvictQuantified and EvictFunc The relevant definitions of evict action are similar to those of throttle action type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } After the construction is completed, register the metric through registerMetricMap() For the metrics that need to be customized, you can easily realize the flexible customized sorting of pod by combining the following methods with general sorting methods to represent the customized metric indicators, represents the customized sorting strategy func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } Among them, the following sorting method <metric-sort-func> needs to be implemented func (p1, p2 podinfo.PodContext) int32","title":"User-defined metrics interference detection avoidance and user-defined sorting"},{"location":"tutorials/using-time-series-prediction/","text":"TimeSeriesPrediction \u00b6 Knowing the future makes things easier for us. Many businesses are naturally cyclical in time series, especially for those that directly or indirectly serve \"people\". This periodicity is determined by the regularity of people\u2019s daily activities. For example, people are accustomed to ordering take-out at noon and in the evenings; there are always traffic peaks in the morning and evening; even for services that don't have such obvious patterns, such as searching, the amount of requests at night is much lower than that during business hours. For applications related to this kind of business, it is a natural idea to infer the next day's metrics from the historical data of the past few days, or to infer the coming Monday's access traffic from the data of last Monday. With predicted metrics or traffic patterns in the next 24 hours, we can better manage our application instances, stabilize our system, and meanwhile, reduce the cost. TimeSeriesPrediction is used to forecast the kubernetes object metric. It is based on PredictionCore to do forecast. Features \u00b6 A TimeSeriesPrediction sample yaml looks like below: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef defines the reference to the kubernetes object including Node or other workload such as Deployment. spec.predictionMetrics defines the metrics about the spec.targetRef. spec.predictionWindowSeconds is a prediction time series duration. the TimeSeriesPredictionController will rotate the predicted data in spec.Status for consumer to consume the predicted time series data. PredictionMetrics \u00b6 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" MetricType \u00b6 There are three types of the metric query: ResourceQuery is a kubernetes built-in resource metric such as cpu or memory. crane supports only cpu and memory now. RawQuery is a query by DSL, such as prometheus query language. now support prometheus. ExpressionQuery is a query by Expression selector. Now we only support prometheus as data source. We define the MetricType to orthogonal with the datasource. but now maybe some datasources do not support the metricType. Algorithm \u00b6 Algorithm define the algorithm type and params to do predict for the metric. Now there are two kinds of algorithms: dsp is an algorithm to forcasting a time series, it is based on FFT(Fast Fourier Transform), it is good at predicting some time series with seasonality and periods. percentile is an algorithm to estimate a time series, and find a recommended value to represent the past time series, it is based on exponentially-decaying weights historgram statistics. it is used to estimate a time series, it is not good at to predict a time sequences, although the percentile can output a time series predicted data, but it is all the same value. so if you want to predict a time sequences, dsp is a better choice. dsp params \u00b6 percentile params \u00b6","title":"Time Series Prediction"},{"location":"tutorials/using-time-series-prediction/#timeseriesprediction","text":"Knowing the future makes things easier for us. Many businesses are naturally cyclical in time series, especially for those that directly or indirectly serve \"people\". This periodicity is determined by the regularity of people\u2019s daily activities. For example, people are accustomed to ordering take-out at noon and in the evenings; there are always traffic peaks in the morning and evening; even for services that don't have such obvious patterns, such as searching, the amount of requests at night is much lower than that during business hours. For applications related to this kind of business, it is a natural idea to infer the next day's metrics from the historical data of the past few days, or to infer the coming Monday's access traffic from the data of last Monday. With predicted metrics or traffic patterns in the next 24 hours, we can better manage our application instances, stabilize our system, and meanwhile, reduce the cost. TimeSeriesPrediction is used to forecast the kubernetes object metric. It is based on PredictionCore to do forecast.","title":"TimeSeriesPrediction"},{"location":"tutorials/using-time-series-prediction/#features","text":"A TimeSeriesPrediction sample yaml looks like below: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef defines the reference to the kubernetes object including Node or other workload such as Deployment. spec.predictionMetrics defines the metrics about the spec.targetRef. spec.predictionWindowSeconds is a prediction time series duration. the TimeSeriesPredictionController will rotate the predicted data in spec.Status for consumer to consume the predicted time series data.","title":"Features"},{"location":"tutorials/using-time-series-prediction/#predictionmetrics","text":"apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\"","title":"PredictionMetrics"},{"location":"tutorials/using-time-series-prediction/#metrictype","text":"There are three types of the metric query: ResourceQuery is a kubernetes built-in resource metric such as cpu or memory. crane supports only cpu and memory now. RawQuery is a query by DSL, such as prometheus query language. now support prometheus. ExpressionQuery is a query by Expression selector. Now we only support prometheus as data source. We define the MetricType to orthogonal with the datasource. but now maybe some datasources do not support the metricType.","title":"MetricType"},{"location":"tutorials/using-time-series-prediction/#algorithm","text":"Algorithm define the algorithm type and params to do predict for the metric. Now there are two kinds of algorithms: dsp is an algorithm to forcasting a time series, it is based on FFT(Fast Fourier Transform), it is good at predicting some time series with seasonality and periods. percentile is an algorithm to estimate a time series, and find a recommended value to represent the past time series, it is based on exponentially-decaying weights historgram statistics. it is used to estimate a time series, it is not good at to predict a time sequences, although the percentile can output a time series predicted data, but it is all the same value. so if you want to predict a time sequences, dsp is a better choice.","title":"Algorithm"},{"location":"tutorials/using-time-series-prediction/#dsp-params","text":"","title":"dsp params"},{"location":"tutorials/using-time-series-prediction/#percentile-params","text":"","title":"percentile params"},{"location":"zh/","text":"\u4ecb\u7ecd \u00b6 The goal of Crane is to provide a one-stop-shop project to help Kubernetes users to save cloud resource usage with a rich set of functionalities: Time Series Prediction based on monitoring data Usage and Cost visibility Usage & Cost Optimization including: R2 (Resource Re-allocation) R3 (Request & Replicas Recommendation) Effective Pod Autoscaling (Effective Horizontal & Vertical Pod Autoscaling) Cost Optimization Enhanced QoS based on Pod PriorityClass Load-aware Scheduling Features \u00b6 Time Series Prediction \u00b6 TimeSeriesPrediction defines metric spec to predict kubernetes resources like Pod or Node. The prediction module is the core component that other crane components relied on, like EHPA and Analytics . Please see this document to learn more. Effective HorizontalPodAutoscaler \u00b6 EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with native HorizontalPodAutoscaler but extends more features like prediction-driven autoscaling. Please see this document to learn more. Analytics \u00b6 \u667a\u80fd\u63a8\u8350\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u81ea\u52a8\u5206\u6790\u96c6\u7fa4\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002\u5c31\u50cf\u624b\u673a\u52a9\u624b\u4e00\u6837\uff0c\u667a\u80fd\u63a8\u8350\u4f1a\u5b9a\u671f\u7684\u626b\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u5e76\u7ed9\u51fa\u63a8\u8350\u5efa\u8bae\u3002\u76ee\u524d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u4f18\u5316\u80fd\u529b\uff1a \u8d44\u6e90\u63a8\u8350 : \u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6570\u63a8\u8350 : \u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 Please see this document to learn more. QoS Ensurance \u00b6 Kubernetes is capable of starting multiple pods on same node, and as a result, some of the user applications may be impacted when there are resources(e.g. cpu) consumption competition. To mitigate this, Crane allows users defining PrioirtyClass for the pods and QoSEnsurancePolicy, and then detects disruption and ensure the high priority pods not being impacted by resource competition. Avoidance Actions: Disable Schedule : disable scheduling by setting node taint and condition Throttle : throttle the low priority pods by squeezing cgroup settings Evict : evict low priority pods Please see this document to learn more. \u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6 \u00b6 \u539f\u751f\u7684 Kubernetes \u8c03\u5ea6\u5668\u53ea\u80fd\u57fa\u4e8e\u8d44\u6e90\u7684 Request \u8fdb\u884c\u8c03\u5ea6\u4e1a\u52a1\uff0c\u8fd9\u5f88\u5bb9\u6613\u5bfc\u81f4\u96c6\u7fa4\u8d1f\u8f7d\u4e0d\u5747\u7684\u95ee\u9898\u3002\u4e0e\u4e4b\u5bf9\u6bd4\u7684\u662f\uff0c Crane-scheudler \u53ef\u4ee5\u76f4\u63a5\u4ece Prometheus \u83b7\u53d6\u8282\u70b9\u7684\u771f\u5b9e\u8d1f\u8f7d\u60c5\u51b5\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8c03\u5ea6\u3002 \u66f4\u591a\u8bf7\u53c2\u89c1 \u6587\u6863 \u3002 Repositories \u00b6 Crane is composed of the following components: craned - main crane control plane. Predictor - Predicts resources metrics trends based on historical data. AnalyticsController - Analyzes resources and generate related recommendations. RecommendationController - Recommend Pod resource requests and autoscaler. ClusterNodePredictionController - Create Predictor for nodes. EffectiveHPAController - Effective HPA for horizontal scaling. EffectiveVPAController - Effective VPA for vertical scaling. metric-adaptor - Metric server for driving the scaling. crane-agent - Ensure critical workloads SLO based on abnormally detection. gocrane/api - This repository defines component-level APIs for the Crane platform. gocrane/fadvisor - Financial advisor which collect resource prices from cloud API. gocrane/crane-scheduler - \u4e00\u4e2a\u53ef\u4ee5\u57fa\u4e8e\u771f\u5b9e\u8d1f\u8f7d\u5bf9\u4e1a\u52a1\u8fdb\u884c\u8c03\u5ea6\u7684 Kubernestes \u8c03\u5ea6\u5668\u3002","title":"\u4ecb\u7ecd"},{"location":"zh/#_1","text":"The goal of Crane is to provide a one-stop-shop project to help Kubernetes users to save cloud resource usage with a rich set of functionalities: Time Series Prediction based on monitoring data Usage and Cost visibility Usage & Cost Optimization including: R2 (Resource Re-allocation) R3 (Request & Replicas Recommendation) Effective Pod Autoscaling (Effective Horizontal & Vertical Pod Autoscaling) Cost Optimization Enhanced QoS based on Pod PriorityClass Load-aware Scheduling","title":"\u4ecb\u7ecd"},{"location":"zh/#features","text":"","title":"Features"},{"location":"zh/#time-series-prediction","text":"TimeSeriesPrediction defines metric spec to predict kubernetes resources like Pod or Node. The prediction module is the core component that other crane components relied on, like EHPA and Analytics . Please see this document to learn more.","title":"Time Series Prediction"},{"location":"zh/#effective-horizontalpodautoscaler","text":"EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with native HorizontalPodAutoscaler but extends more features like prediction-driven autoscaling. Please see this document to learn more.","title":"Effective HorizontalPodAutoscaler"},{"location":"zh/#analytics","text":"\u667a\u80fd\u63a8\u8350\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u81ea\u52a8\u5206\u6790\u96c6\u7fa4\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002\u5c31\u50cf\u624b\u673a\u52a9\u624b\u4e00\u6837\uff0c\u667a\u80fd\u63a8\u8350\u4f1a\u5b9a\u671f\u7684\u626b\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u5e76\u7ed9\u51fa\u63a8\u8350\u5efa\u8bae\u3002\u76ee\u524d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u4f18\u5316\u80fd\u529b\uff1a \u8d44\u6e90\u63a8\u8350 : \u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6570\u63a8\u8350 : \u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 Please see this document to learn more.","title":"Analytics"},{"location":"zh/#qos-ensurance","text":"Kubernetes is capable of starting multiple pods on same node, and as a result, some of the user applications may be impacted when there are resources(e.g. cpu) consumption competition. To mitigate this, Crane allows users defining PrioirtyClass for the pods and QoSEnsurancePolicy, and then detects disruption and ensure the high priority pods not being impacted by resource competition. Avoidance Actions: Disable Schedule : disable scheduling by setting node taint and condition Throttle : throttle the low priority pods by squeezing cgroup settings Evict : evict low priority pods Please see this document to learn more.","title":"QoS Ensurance"},{"location":"zh/#_2","text":"\u539f\u751f\u7684 Kubernetes \u8c03\u5ea6\u5668\u53ea\u80fd\u57fa\u4e8e\u8d44\u6e90\u7684 Request \u8fdb\u884c\u8c03\u5ea6\u4e1a\u52a1\uff0c\u8fd9\u5f88\u5bb9\u6613\u5bfc\u81f4\u96c6\u7fa4\u8d1f\u8f7d\u4e0d\u5747\u7684\u95ee\u9898\u3002\u4e0e\u4e4b\u5bf9\u6bd4\u7684\u662f\uff0c Crane-scheudler \u53ef\u4ee5\u76f4\u63a5\u4ece Prometheus \u83b7\u53d6\u8282\u70b9\u7684\u771f\u5b9e\u8d1f\u8f7d\u60c5\u51b5\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u8c03\u5ea6\u3002 \u66f4\u591a\u8bf7\u53c2\u89c1 \u6587\u6863 \u3002","title":"\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6"},{"location":"zh/#repositories","text":"Crane is composed of the following components: craned - main crane control plane. Predictor - Predicts resources metrics trends based on historical data. AnalyticsController - Analyzes resources and generate related recommendations. RecommendationController - Recommend Pod resource requests and autoscaler. ClusterNodePredictionController - Create Predictor for nodes. EffectiveHPAController - Effective HPA for horizontal scaling. EffectiveVPAController - Effective VPA for vertical scaling. metric-adaptor - Metric server for driving the scaling. crane-agent - Ensure critical workloads SLO based on abnormally detection. gocrane/api - This repository defines component-level APIs for the Crane platform. gocrane/fadvisor - Financial advisor which collect resource prices from cloud API. gocrane/crane-scheduler - \u4e00\u4e2a\u53ef\u4ee5\u57fa\u4e8e\u771f\u5b9e\u8d1f\u8f7d\u5bf9\u4e1a\u52a1\u8fdb\u884c\u8c03\u5ea6\u7684 Kubernestes \u8c03\u5ea6\u5668\u3002","title":"Repositories"},{"location":"zh/CONTRIBUTING/","text":"Contributing to Crane \u00b6 Welcome to Crane! This document is a guideline about how to contribute to Crane. Become a contributor \u00b6 You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides . Report bugs \u00b6 Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug. Suggest enhancements \u00b6 If you have an idea to improve Crane, submit an feature request .","title":"\u8d21\u732e"},{"location":"zh/CONTRIBUTING/#contributing-to-crane","text":"Welcome to Crane! This document is a guideline about how to contribute to Crane.","title":"Contributing to Crane"},{"location":"zh/CONTRIBUTING/#become-a-contributor","text":"You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides .","title":"Become a contributor"},{"location":"zh/CONTRIBUTING/#report-bugs","text":"Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug.","title":"Report bugs"},{"location":"zh/CONTRIBUTING/#suggest-enhancements","text":"If you have an idea to improve Crane, submit an feature request .","title":"Suggest enhancements"},{"location":"zh/code-standards/","text":"Code standards \u00b6 This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project import need to be organized \u00b6 import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" ) logs standard \u00b6 logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err )) event is needed for critical reconcile loop \u00b6 event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ()) comment \u00b6 every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) } functions \u00b6 function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils variable \u00b6 variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop folder and file \u00b6 folder name should be letter with lower case and number file name should be letter and number and _ unit test \u00b6 Test-driven developing Complex function that include condition decide should add unit test for it don't forget to run make fmt before you submit code \u00b6","title":"\u4ee3\u7801\u6807\u51c6"},{"location":"zh/code-standards/#code-standards","text":"This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project","title":"Code standards"},{"location":"zh/code-standards/#import-need-to-be-organized","text":"import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" )","title":"import need to be organized"},{"location":"zh/code-standards/#logs-standard","text":"logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err ))","title":"logs standard"},{"location":"zh/code-standards/#event-is-needed-for-critical-reconcile-loop","text":"event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ())","title":"event is needed for critical reconcile loop"},{"location":"zh/code-standards/#comment","text":"every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) }","title":"comment"},{"location":"zh/code-standards/#functions","text":"function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils","title":"functions"},{"location":"zh/code-standards/#variable","text":"variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop","title":"variable"},{"location":"zh/code-standards/#folder-and-file","text":"folder name should be letter with lower case and number file name should be letter and number and _","title":"folder and file"},{"location":"zh/code-standards/#unit-test","text":"Test-driven developing Complex function that include condition decide should add unit test for it","title":"unit test"},{"location":"zh/code-standards/#dont-forget-to-run-make-fmt-before-you-submit-code","text":"","title":"don't forget to run make fmt before you submit code"},{"location":"zh/developer-guide/","text":"First, please make sure you've got a working Go environment and Docker environment . Clone crane \u00b6 Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane Building Binaries \u00b6 Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder. Building Docker Images \u00b6 You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"\u5f00\u53d1\u8005\u6307\u5357"},{"location":"zh/developer-guide/#clone-crane","text":"Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane","title":"Clone crane"},{"location":"zh/developer-guide/#building-binaries","text":"Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder.","title":"Building Binaries"},{"location":"zh/developer-guide/#building-docker-images","text":"You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"Building Docker Images"},{"location":"zh/installation/","text":"\u4ea7\u54c1\u90e8\u7f72\u6307\u5357 \u00b6 \u4e3a\u4e86\u8ba9\u60a8\u66f4\u5feb\u7684\u90e8\u7f72 Crane \uff0c\u672c\u6587\u6863\u63d0\u4f9b\u6e05\u6670\u7684\uff1a \u90e8\u7f72\u73af\u5883\u8981\u6c42 \u5177\u4f53\u5b89\u88c5\u6b65\u9aa4 Crane \u5b89\u88c5\u65f6\u95f4\u572810\u5206\u949f\u5de6\u53f3\uff0c\u5177\u4f53\u65f6\u95f4\u4e5f\u4f9d\u8d56\u96c6\u7fa4\u89c4\u6a21\u4ee5\u53ca\u786c\u4ef6\u80fd\u529b\u3002\u76ee\u524d\u5b89\u88c5\u5df2\u7ecf\u975e\u5e38\u6210\u719f\uff0c\u5982\u679c\u60a8\u5b89\u88c5\u4e2d\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u53ef\u4ee5\u91c7\u53d6\u5982\u4e0b\u51e0\u79cd\u65b9\u5f0f\uff1a \u8bf7\u9996\u5148\u68c0\u67e5\u540e\u6587\u7684 F&Q \u53ef\u4ee5\u63d0\u51fa\u4e00\u4e2a Issue \uff0c\u6211\u4eec\u4f1a\u8ba4\u771f\u5bf9\u5f85\u6bcf\u4e00\u4e2a Issue \u90e8\u7f72\u73af\u5883\u8981\u6c42 \u00b6 Kubernetes 1.18+ Helm 3.1.0 \u5b89\u88c5\u6d41\u7a0b \u00b6 \u5b89\u88c5 Helm \u00b6 \u5efa\u8bae\u53c2\u8003 Helm \u5b98\u7f51 \u5b89\u88c5\u6587\u6863 \u3002 \u5b89\u88c5 Prometheus \u548c Grafana \u00b6 \u4f7f\u7528 Helm \u5b89\u88c5 Prometheus \u548c Grafana\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u5df2\u7ecf\u5728\u73af\u5883\u4e2d\u90e8\u7f72\u4e86 Prometheus \u548c Grafana\uff0c\u53ef\u4ee5\u8df3\u8fc7\u8be5\u6b65\u9aa4\u3002 \u7f51\u7edc\u95ee\u9898 \u5982\u679c\u4f60\u7684\u7f51\u7edc\u65e0\u6cd5\u8bbf\u95eeGitHub\u8d44\u6e90(GitHub Release, GitHub Raw Content raw.githubusercontent.com )\u3002 \u90a3\u4e48\u4f60\u53ef\u4ee5\u5c1d\u8bd5\u955c\u50cf\u4ed3\u5e93\u3002\u4f46\u955c\u50cf\u4ed3\u5e93\u5177\u6709\u4e00\u5b9a\u7684 \u65f6\u5ef6 \u3002 \u955c\u50cf\u4ed3\u5e93 Crane \u4f7f\u7528 Prometheus \u6293\u53d6\u96c6\u7fa4\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u8d44\u6e90\u7684\u4f7f\u7528\u60c5\u51b5\u3002\u5b89\u88c5 Prometheus\uff1a Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus Crane \u7684 Fadvisor \u4f7f\u7528 Grafana \u5c55\u793a\u6210\u672c\u9884\u4f30\u3002\u5b89\u88c5 Grafana\uff1a Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana \u5b89\u88c5 Crane \u548c Fadvisor \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor \u5b89\u88c5 Crane-scheduler\uff08\u53ef\u9009\uff09 \u00b6 helm install scheduler -n crane-system --create-namespace crane/scheduler \u9a8c\u8bc1\u5b89\u88c5\u662f\u5426\u6210\u529f \u00b6 \u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u68c0\u67e5\u5b89\u88c5\u7684 Deployment \u662f\u5426\u6b63\u5e38\uff1a kubectl get deploy -n crane-system \u7ed3\u679c\u7c7b\u4f3c\u5982\u4e0b\uff1a NAME READY UP-TO-DATE AVAILABLE AGE craned 1 /1 1 1 31m fadvisor 1 /1 1 1 41m grafana 1 /1 1 1 42m metric-adapter 1 /1 1 1 31m prometheus-kube-state-metrics 1 /1 1 1 43m prometheus-server 1 /1 1 1 43m \u53ef\u4ee5\u67e5\u770b\u672c\u7bc7 \u6587\u6863 \u83b7\u53d6\u66f4\u591a\u6709\u5173 Crane Helm Chart \u7684\u4fe1\u606f\u3002 Access Dashboard \u00b6 You can use the dashboard to view and manage crane manifests. Port Forward \u00b6 Easy access to the dashboard through kubectl port-forward . kubectl -n crane-system port-forward service/craned 9090 :9090 NodePort \u00b6 # Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"NodePort\"}}' # Get Dashboard link base on your cluster configuration PORT = $( kubectl get svc -n crane-system craned -o jsonpath = '{.spec.ports[?(@.name == \"dashboard-service\")].nodePort}' ) NODE_IP = $( kubectl get node -ojsonpath = '{.items[].status.addresses[?(@.type == \"InternalIP\")].address}' ) echo \"Dashboard link: http:// ${ NODE_IP } : ${ PORT } \" LoadBalancer \u00b6 Quick Start \u00b6 # Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' Example \u00b6 $ kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' service/craned patched $ kubectl get svc -n crane-system craned NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE craned LoadBalancer 10.101.123.74 10.200.0.4 443:30908/TCP,8082:32426/TCP,9090:31331/TCP,8080:31072/TCP 57m # Access dashboard via 10.200.0.4:9090 Ingress \u00b6 kubernetes/ingress-nginx \u00b6 If the cluster version is < 1.19, you can create the ingress resources like this: apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : ingressClassName : nginx rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / backend : serviceName : craned servicePort : 9090 If the cluster uses Kubernetes version >= 1.19.x, then its suggested to create the second ingress resources, using yaml examples shown below. These examples are in conformity with the networking.kubernetes.io/v1 api. apiVersion : networking.k8s.io/v1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / pathType : Prefix backend : service : name : craned port : number : 9090 ingressClassName : nginx Example: $ kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.102.235.229 10.200.0.5 80:32568/TCP,443:30144/TCP 91m ingress-nginx-controller-admission ClusterIP 10.102.49.240 <none> 443/TCP 91m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.5 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................ Traefik \u00b6 apiVersion : traefik.containo.us/v1alpha1 kind : IngressRoute metadata : name : dashboard-crane-ingress namespace : crane-system spec : entryPoints : - web routes : - kind : Rule match : Host(`dashboard.gocrane.io`) services : - name : craned port : 9090 $ kubectl get svc -n traefik-v2 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE traefik LoadBalancer 10.107.109.44 10.200.0.6 80:30102/TCP,443:30139/TCP 16m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................ \u81ea\u5b9a\u4e49\u5b89\u88c5 \u00b6 \u901a\u8fc7 YAML \u5b89\u88c5 Crane \u3002 Main Mirror git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter git clone https://e.coding.net/finops/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter \u5982\u679c\u60a8\u60f3\u81ea\u5b9a\u4e49 Crane \u91cc\u914d\u7f6e Prometheus \u7684 HTTP \u5730\u5740\uff0c\u8bf7\u53c2\u8003\u4ee5\u4e0b\u7684\u547d\u4ee4\u3002\u5982\u679c\u60a8\u5728\u96c6\u7fa4\u91cc\u5df2\u5b58\u5728\u4e00\u4e2a Prometheus\uff0c\u8bf7\u5c06 Server \u5730\u5740\u586b\u4e8e CUSTOMIZE_PROMETHEUS \u3002 export CUSTOMIZE_PROMETHEUS= if [ $CUSTOMIZE_PROMETHEUS ]; then sed -i '' \"s/http:\\/\\/prometheus-server.crane-system.svc.cluster.local:8080/${CUSTOMIZE_PROMETHEUS}/\" deploy/craned/deployment.yaml ; fi \u5b89\u88c5\u5e38\u89c1\u95ee\u9898 \u00b6 \u5b89\u88c5 Crane \u62a5\u9519 \u00b6 \u5f53\u60a8\u6267\u884c helm install crane -n crane-system --create-namespace crane/crane \u547d\u4ee4\u65f6\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\u5982\u4e0b\u9519\u8bef\uff1a Error: rendered manifests contain a resource that already exists. Unable to continue with install: APIService \"v1beta1.custom.metrics.k8s.io\" in namespace \"\" exists and cannot be imported into the current release: invalid ownership metadata ; label validation error: missing key \"app.kubernetes.io/managed-by\" : must be set to \"Helm\" ; annotation validation error: missing key \"meta.helm.sh/release-name\" : must be set to \"crane\" ; annotation validation error: missing key \"meta.helm.sh/release-namespace\" : must be set to \"crane-system\" \u539f\u56e0\uff1a\u96c6\u7fa4\u5b89\u88c5\u8fc7 custom metric \u7684 APIService\uff0c\u6240\u4ee5\u62a5\u9519\u3002\u53ef\u4ee5\u628a\u4e4b\u524d\u7684\u5220\u9664\u518d\u91cd\u65b0\u6267\u884c\u5b89\u88c5 Crane \u7684\u547d\u4ee4\uff0c\u5220\u9664\u65b9\u5f0f\uff1a kubectl delete apiservice v1beta1.custom.metrics.k8s.io \u3002 \u83b7\u53d6 Crane URL \u7684\u5176\u5b83\u65b9\u5f0f \u00b6 NodePort \u65b9\u5f0f \u00b6 \u60a8\u53ef\u4ee5\u5c06 Crane \u7684 Service \u7684\u7c7b\u578b\u6362\u6210 NodePort \u7c7b\u578b\uff0c\u8fd9\u6837\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u96c6\u7fa4\u4efb\u610f\u8282\u70b9 IP + \u8be5\u670d\u52a1\u91ccdashboard- service \u7aef\u53e3\u53f7\u7684\u65b9\u5f0f\uff0c\u6253\u5f00\u63a7\u5236\u53f0\u3002 \u5177\u4f53\u64cd\u4f5c\uff1a\u4fee\u6539 crane-system \u547d\u540d\u7a7a\u95f4\u4e0b\u540d\u4e3a craned \u7684 Service\uff0c\u5c06\u5176\u8bbf\u95ee\u65b9\u5f0f\u8be5\u4e3a NodePort \u7684\u65b9\u5f0f\uff0c\u7136\u540e\u83b7\u53d6\u67d0\u4e00\u96c6\u7fa4\u7684\u8282\u70b9 IP\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u7aef\u53e3\u53f7\uff0c\u7aef\u53e3\u53f7\u5982\u4e0b\u6240\u793a\uff1a \u6ce8\u610f\uff1a\u82e5\u60a8\u7684\u96c6\u7fa4\u8282\u70b9\u53ea\u6709\u5185\u7f51 IP\uff0c\u5219\u8bbf\u95ee\u8be5 IP \u7684\u8ba1\u7b97\u673a\u9700\u8981\u5728\u540c\u4e00\u5185\u7f51\u3002\u82e5\u96c6\u7fa4\u8282\u70b9\u62e5\u6709\u5916\u7f51 IP\uff0c\u5219\u6ca1\u6709\u76f8\u5173\u95ee\u9898\u3002 LoadBalance \u65b9\u5f0f \u00b6 \u82e5\u60a8\u4f7f\u7528\u7684\u662f\u516c\u6709\u4e91\u5382\u5546\u7684\u670d\u52a1\uff0c\u60a8\u53ef\u4ee5\u5c06 Crane \u7684 Service \u7684\u7c7b\u578b\u6362\u6210\u516c\u7f51 LB \u7c7b\u578b\uff0c\u8fd9\u6837\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7 LB IP + 9090 \u7aef\u53e3\u53f7\u7684\u65b9\u5f0f\uff0c\u6253\u5f00\u63a7\u5236\u53f0\u3002 \u5177\u4f53\u64cd\u4f5c\uff1a\u4fee\u6539 crane-system \u547d\u540d\u7a7a\u95f4\u4e0b\u540d\u4e3a craned \u7684 Service\uff0c\u5c06\u5176\u8bbf\u95ee\u65b9\u5f0f\u8be5\u4e3a\u516c\u7f51 LB \u7684\u65b9\u5f0f\u3002","title":"\u5b89\u88c5"},{"location":"zh/installation/#_1","text":"\u4e3a\u4e86\u8ba9\u60a8\u66f4\u5feb\u7684\u90e8\u7f72 Crane \uff0c\u672c\u6587\u6863\u63d0\u4f9b\u6e05\u6670\u7684\uff1a \u90e8\u7f72\u73af\u5883\u8981\u6c42 \u5177\u4f53\u5b89\u88c5\u6b65\u9aa4 Crane \u5b89\u88c5\u65f6\u95f4\u572810\u5206\u949f\u5de6\u53f3\uff0c\u5177\u4f53\u65f6\u95f4\u4e5f\u4f9d\u8d56\u96c6\u7fa4\u89c4\u6a21\u4ee5\u53ca\u786c\u4ef6\u80fd\u529b\u3002\u76ee\u524d\u5b89\u88c5\u5df2\u7ecf\u975e\u5e38\u6210\u719f\uff0c\u5982\u679c\u60a8\u5b89\u88c5\u4e2d\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u53ef\u4ee5\u91c7\u53d6\u5982\u4e0b\u51e0\u79cd\u65b9\u5f0f\uff1a \u8bf7\u9996\u5148\u68c0\u67e5\u540e\u6587\u7684 F&Q \u53ef\u4ee5\u63d0\u51fa\u4e00\u4e2a Issue \uff0c\u6211\u4eec\u4f1a\u8ba4\u771f\u5bf9\u5f85\u6bcf\u4e00\u4e2a Issue","title":"\u4ea7\u54c1\u90e8\u7f72\u6307\u5357"},{"location":"zh/installation/#_2","text":"Kubernetes 1.18+ Helm 3.1.0","title":"\u90e8\u7f72\u73af\u5883\u8981\u6c42"},{"location":"zh/installation/#_3","text":"","title":"\u5b89\u88c5\u6d41\u7a0b"},{"location":"zh/installation/#helm","text":"\u5efa\u8bae\u53c2\u8003 Helm \u5b98\u7f51 \u5b89\u88c5\u6587\u6863 \u3002","title":"\u5b89\u88c5 Helm"},{"location":"zh/installation/#prometheus-grafana","text":"\u4f7f\u7528 Helm \u5b89\u88c5 Prometheus \u548c Grafana\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u5df2\u7ecf\u5728\u73af\u5883\u4e2d\u90e8\u7f72\u4e86 Prometheus \u548c Grafana\uff0c\u53ef\u4ee5\u8df3\u8fc7\u8be5\u6b65\u9aa4\u3002 \u7f51\u7edc\u95ee\u9898 \u5982\u679c\u4f60\u7684\u7f51\u7edc\u65e0\u6cd5\u8bbf\u95eeGitHub\u8d44\u6e90(GitHub Release, GitHub Raw Content raw.githubusercontent.com )\u3002 \u90a3\u4e48\u4f60\u53ef\u4ee5\u5c1d\u8bd5\u955c\u50cf\u4ed3\u5e93\u3002\u4f46\u955c\u50cf\u4ed3\u5e93\u5177\u6709\u4e00\u5b9a\u7684 \u65f6\u5ef6 \u3002 \u955c\u50cf\u4ed3\u5e93 Crane \u4f7f\u7528 Prometheus \u6293\u53d6\u96c6\u7fa4\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u8d44\u6e90\u7684\u4f7f\u7528\u60c5\u51b5\u3002\u5b89\u88c5 Prometheus\uff1a Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus Crane \u7684 Fadvisor \u4f7f\u7528 Grafana \u5c55\u793a\u6210\u672c\u9884\u4f30\u3002\u5b89\u88c5 Grafana\uff1a Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://gitee.com/finops/helm-charts/raw/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana","title":"\u5b89\u88c5 Prometheus \u548c Grafana"},{"location":"zh/installation/#crane-fadvisor","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor","title":"\u5b89\u88c5 Crane \u548c Fadvisor"},{"location":"zh/installation/#crane-scheduler","text":"helm install scheduler -n crane-system --create-namespace crane/scheduler","title":"\u5b89\u88c5 Crane-scheduler\uff08\u53ef\u9009\uff09"},{"location":"zh/installation/#_4","text":"\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u68c0\u67e5\u5b89\u88c5\u7684 Deployment \u662f\u5426\u6b63\u5e38\uff1a kubectl get deploy -n crane-system \u7ed3\u679c\u7c7b\u4f3c\u5982\u4e0b\uff1a NAME READY UP-TO-DATE AVAILABLE AGE craned 1 /1 1 1 31m fadvisor 1 /1 1 1 41m grafana 1 /1 1 1 42m metric-adapter 1 /1 1 1 31m prometheus-kube-state-metrics 1 /1 1 1 43m prometheus-server 1 /1 1 1 43m \u53ef\u4ee5\u67e5\u770b\u672c\u7bc7 \u6587\u6863 \u83b7\u53d6\u66f4\u591a\u6709\u5173 Crane Helm Chart \u7684\u4fe1\u606f\u3002","title":"\u9a8c\u8bc1\u5b89\u88c5\u662f\u5426\u6210\u529f"},{"location":"zh/installation/#access-dashboard","text":"You can use the dashboard to view and manage crane manifests.","title":"Access Dashboard"},{"location":"zh/installation/#port-forward","text":"Easy access to the dashboard through kubectl port-forward . kubectl -n crane-system port-forward service/craned 9090 :9090","title":"Port Forward"},{"location":"zh/installation/#nodeport","text":"# Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"NodePort\"}}' # Get Dashboard link base on your cluster configuration PORT = $( kubectl get svc -n crane-system craned -o jsonpath = '{.spec.ports[?(@.name == \"dashboard-service\")].nodePort}' ) NODE_IP = $( kubectl get node -ojsonpath = '{.items[].status.addresses[?(@.type == \"InternalIP\")].address}' ) echo \"Dashboard link: http:// ${ NODE_IP } : ${ PORT } \"","title":"NodePort"},{"location":"zh/installation/#loadbalancer","text":"","title":"LoadBalancer"},{"location":"zh/installation/#quick-start","text":"# Change service type kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}'","title":"Quick Start"},{"location":"zh/installation/#example","text":"$ kubectl patch svc craned -n crane-system -p '{\"spec\": {\"type\": \"LoadBalancer\"}}' service/craned patched $ kubectl get svc -n crane-system craned NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE craned LoadBalancer 10.101.123.74 10.200.0.4 443:30908/TCP,8082:32426/TCP,9090:31331/TCP,8080:31072/TCP 57m # Access dashboard via 10.200.0.4:9090","title":"Example"},{"location":"zh/installation/#ingress","text":"","title":"Ingress"},{"location":"zh/installation/#kubernetesingress-nginx","text":"If the cluster version is < 1.19, you can create the ingress resources like this: apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : ingressClassName : nginx rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / backend : serviceName : craned servicePort : 9090 If the cluster uses Kubernetes version >= 1.19.x, then its suggested to create the second ingress resources, using yaml examples shown below. These examples are in conformity with the networking.kubernetes.io/v1 api. apiVersion : networking.k8s.io/v1 kind : Ingress metadata : name : ingress-crane-dashboard namespace : crane-system spec : rules : - host : dashboard.gocrane.io # change to your domain http : paths : - path : / pathType : Prefix backend : service : name : craned port : number : 9090 ingressClassName : nginx Example: $ kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.102.235.229 10.200.0.5 80:32568/TCP,443:30144/TCP 91m ingress-nginx-controller-admission ClusterIP 10.102.49.240 <none> 443/TCP 91m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.5 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................","title":"kubernetes/ingress-nginx"},{"location":"zh/installation/#traefik","text":"apiVersion : traefik.containo.us/v1alpha1 kind : IngressRoute metadata : name : dashboard-crane-ingress namespace : crane-system spec : entryPoints : - web routes : - kind : Rule match : Host(`dashboard.gocrane.io`) services : - name : craned port : 9090 $ kubectl get svc -n traefik-v2 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE traefik LoadBalancer 10.107.109.44 10.200.0.6 80:30102/TCP,443:30139/TCP 16m $ curl -H \"Host: dashboard.gocrane.io\" 10.200.0.6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /> <title>Crane Dashboard</title> ................................................................","title":"Traefik"},{"location":"zh/installation/#_5","text":"\u901a\u8fc7 YAML \u5b89\u88c5 Crane \u3002 Main Mirror git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter git clone https://e.coding.net/finops/gocrane/crane.git CRANE_LATEST_VERSION = $( curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")' ) git checkout $CRANE_LATEST_VERSION kubectl apply -f deploy/manifests kubectl apply -f deploy/craned kubectl apply -f deploy/metric-adapter \u5982\u679c\u60a8\u60f3\u81ea\u5b9a\u4e49 Crane \u91cc\u914d\u7f6e Prometheus \u7684 HTTP \u5730\u5740\uff0c\u8bf7\u53c2\u8003\u4ee5\u4e0b\u7684\u547d\u4ee4\u3002\u5982\u679c\u60a8\u5728\u96c6\u7fa4\u91cc\u5df2\u5b58\u5728\u4e00\u4e2a Prometheus\uff0c\u8bf7\u5c06 Server \u5730\u5740\u586b\u4e8e CUSTOMIZE_PROMETHEUS \u3002 export CUSTOMIZE_PROMETHEUS= if [ $CUSTOMIZE_PROMETHEUS ]; then sed -i '' \"s/http:\\/\\/prometheus-server.crane-system.svc.cluster.local:8080/${CUSTOMIZE_PROMETHEUS}/\" deploy/craned/deployment.yaml ; fi","title":"\u81ea\u5b9a\u4e49\u5b89\u88c5"},{"location":"zh/installation/#_6","text":"","title":"\u5b89\u88c5\u5e38\u89c1\u95ee\u9898"},{"location":"zh/installation/#crane","text":"\u5f53\u60a8\u6267\u884c helm install crane -n crane-system --create-namespace crane/crane \u547d\u4ee4\u65f6\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\u5982\u4e0b\u9519\u8bef\uff1a Error: rendered manifests contain a resource that already exists. Unable to continue with install: APIService \"v1beta1.custom.metrics.k8s.io\" in namespace \"\" exists and cannot be imported into the current release: invalid ownership metadata ; label validation error: missing key \"app.kubernetes.io/managed-by\" : must be set to \"Helm\" ; annotation validation error: missing key \"meta.helm.sh/release-name\" : must be set to \"crane\" ; annotation validation error: missing key \"meta.helm.sh/release-namespace\" : must be set to \"crane-system\" \u539f\u56e0\uff1a\u96c6\u7fa4\u5b89\u88c5\u8fc7 custom metric \u7684 APIService\uff0c\u6240\u4ee5\u62a5\u9519\u3002\u53ef\u4ee5\u628a\u4e4b\u524d\u7684\u5220\u9664\u518d\u91cd\u65b0\u6267\u884c\u5b89\u88c5 Crane \u7684\u547d\u4ee4\uff0c\u5220\u9664\u65b9\u5f0f\uff1a kubectl delete apiservice v1beta1.custom.metrics.k8s.io \u3002","title":"\u5b89\u88c5 Crane \u62a5\u9519"},{"location":"zh/installation/#crane-url","text":"","title":"\u83b7\u53d6 Crane URL \u7684\u5176\u5b83\u65b9\u5f0f"},{"location":"zh/installation/#nodeport_1","text":"\u60a8\u53ef\u4ee5\u5c06 Crane \u7684 Service \u7684\u7c7b\u578b\u6362\u6210 NodePort \u7c7b\u578b\uff0c\u8fd9\u6837\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u96c6\u7fa4\u4efb\u610f\u8282\u70b9 IP + \u8be5\u670d\u52a1\u91ccdashboard- service \u7aef\u53e3\u53f7\u7684\u65b9\u5f0f\uff0c\u6253\u5f00\u63a7\u5236\u53f0\u3002 \u5177\u4f53\u64cd\u4f5c\uff1a\u4fee\u6539 crane-system \u547d\u540d\u7a7a\u95f4\u4e0b\u540d\u4e3a craned \u7684 Service\uff0c\u5c06\u5176\u8bbf\u95ee\u65b9\u5f0f\u8be5\u4e3a NodePort \u7684\u65b9\u5f0f\uff0c\u7136\u540e\u83b7\u53d6\u67d0\u4e00\u96c6\u7fa4\u7684\u8282\u70b9 IP\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u7aef\u53e3\u53f7\uff0c\u7aef\u53e3\u53f7\u5982\u4e0b\u6240\u793a\uff1a \u6ce8\u610f\uff1a\u82e5\u60a8\u7684\u96c6\u7fa4\u8282\u70b9\u53ea\u6709\u5185\u7f51 IP\uff0c\u5219\u8bbf\u95ee\u8be5 IP \u7684\u8ba1\u7b97\u673a\u9700\u8981\u5728\u540c\u4e00\u5185\u7f51\u3002\u82e5\u96c6\u7fa4\u8282\u70b9\u62e5\u6709\u5916\u7f51 IP\uff0c\u5219\u6ca1\u6709\u76f8\u5173\u95ee\u9898\u3002","title":"NodePort \u65b9\u5f0f"},{"location":"zh/installation/#loadbalance","text":"\u82e5\u60a8\u4f7f\u7528\u7684\u662f\u516c\u6709\u4e91\u5382\u5546\u7684\u670d\u52a1\uff0c\u60a8\u53ef\u4ee5\u5c06 Crane \u7684 Service \u7684\u7c7b\u578b\u6362\u6210\u516c\u7f51 LB \u7c7b\u578b\uff0c\u8fd9\u6837\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7 LB IP + 9090 \u7aef\u53e3\u53f7\u7684\u65b9\u5f0f\uff0c\u6253\u5f00\u63a7\u5236\u53f0\u3002 \u5177\u4f53\u64cd\u4f5c\uff1a\u4fee\u6539 crane-system \u547d\u540d\u7a7a\u95f4\u4e0b\u540d\u4e3a craned \u7684 Service\uff0c\u5c06\u5176\u8bbf\u95ee\u65b9\u5f0f\u8be5\u4e3a\u516c\u7f51 LB \u7684\u65b9\u5f0f\u3002","title":"LoadBalance \u65b9\u5f0f"},{"location":"zh/mirror/","text":"\u955c\u50cf\u8d44\u6e90 \u00b6 \u5173\u4e8e\u955c\u50cf\u8d44\u6e90 \u00b6 \u56e0\u4e3a\u5404\u79cd\u7f51\u7edc\u95ee\u9898\uff0c\u5bfc\u81f4\u90e8\u5206\u5730\u57df\u96be\u4ee5\u8bbf\u95eeGitHub \u8d44\u6e90\uff0c\u5982GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com \u3002 \u4e3a\u4e86\u66f4\u597d\u7684\u4f7f\u7528\u4f53\u9a8c\uff0cGoCrane \u4e3a\u60a8\u989d\u5916\u63d0\u4f9b\u4e86\u591a\u4e2a\u955c\u50cf\u4ed3\u5e93\uff0c\u4f46\u5177\u6709\u4e00\u5b9a\u7684\u65f6\u5ef6\u3002 Image Registry \u00b6 GoCrane\u63d0\u4f9b\u4e86\u4e00\u79cd\u53cb\u597d\u7684\u65b9\u5f0f\u6765\u4f7f\u7528\u955c\u50cf\u8fdb\u884c\u90e8\u7f72\u548c\u6d4b\u8bd5\u3002 GoCrane\u4f7f\u7528CI(GitHub Action)\u8fdb\u884c\u955c\u50cf\u6784\u5efa\u3002 Platforms \u00b6 GoCrane \u73b0\u5728\u652f\u6301 linux/amd64 \u548c linux/arm64\u3002 GoCrane \u4e5f\u5728\u5173\u6ce8ARM\u7528\u6237\uff0c\u8b6c\u5982 apple m1/m2\u3002 Repo \u00b6 \u7531\u4e8e\u7f51\u7edc\u539f\u56e0\uff0cGoCrane \u5c06\u540c\u65f6\u5c06\u955c\u50cf\u63a8\u9001\u5230\u4e09\u4e2a\u955c\u50cf\u4ed3\u5e93\u3002 Tips \u70b9\u51fb\u94fe\u63a5\uff0c\u67e5\u9605\u66f4\u591a DockerHub Coding GitHub Container Registry \u5982\u679c\u4f60\u5728\u4e2d\u56fd\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528 Coding\u3002\u8be5\u4ed3\u5e93\u7684\u901f\u5ea6\u6bd4\u5176\u4ed6\u4e24\u4e2a\u5feb\u3002 \u5982\u679c\u4f60\u5728\u4e2d\u56fd\u5883\u5916\uff0c\u6211\u4eec\u63a8\u8350\u4f60\u4f7f\u7528 DockHub\u4ee5\u53caGHCR\u3002\u5982\u679c\u4f60\u4f7f\u7528Coding\uff0c\u901f\u5ea6\u4e0a\u9762\u4e0d\u592a\u7406\u60f3\u3002 Build logic \u00b6 \u6bcf\u4e2a\u5206\u652f \u4f60\u53ef\u4ee5\u4f7f\u7528\u8be5\u5206\u652f\u955c\u50cf\u5c1d\u8bd5\u6700\u65b0\u7684\u7279\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4f9d\u65e7\u4fdd\u5b58\u8f83\u65e9\u4e4b\u524d\u7684\u955c\u50cf\u3002 \u6bcf\u4e2apull request \u5f53\u4f60\u53d1\u8d77\u4e00\u4e2apull request\u5230crane repo\u7684\u65f6\u5019\uff0c\u5c06\u4f1a\u81ea\u52a8\u89e6\u53d1CI\u4efb\u52a1\u6765\u6784\u5efa\u5bf9\u5e94\u7684\u955c\u50cf\u3002CI\u4f1a\u5c06\u6700\u540e\u7684\u955c\u50cf\u7ed3\u679c\u901a\u8fc7\u8bc4\u8bba\u7684\u65b9\u5f0f\u9644\u52a0\u5728\u5bf9\u5e94\u7684pull request\u4e2d\u3002 How to use the images? \u00b6 \u8fd9\u91cc\u5c06\u4f7f\u7528 main \u5206\u652f\u4f5c\u4e3a\u4f8b\u5b50\u3002 Git commit hash \u4e3a abc123\u3002 Base on the branch name \u00b6 Tips branch name\u7684\u955c\u50cf\u4e00\u76f4\u6307\u5411\u6700\u65b0\u7684Git commit\u3002\u5f53\u4f60\u60f3\u5c1d\u8bd5\u65b0\u7279\u6027\u7684\u65f6\u5019\uff0c\u4e0d\u8981\u5fd8\u8bb0\u91cd\u65b0\u62c9\u53d6\u955c\u50cf\u3002 DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main docker pull ghcr.io/gocrane/crane/craned:main Base on the branch name and the specific commit hash \u00b6 DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main-abc123 docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main-abc123 docker pull ghcr.io/gocrane/crane/craned:main-abc123 Helm Resources \u00b6 Tips \u6bcf\u516d\u5c0f\u65f6\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u7684\u6700\u65b0\u7248\u672c Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public Git Resources \u00b6 Tips \u6bcf\u5929\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u4ed3\u5e93 Warning Now Coding is not support to fetch raw contents directly. You must be get token first. Coding \u00b6 Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public Gitee \u00b6 Origin Mirror Type Public https://github.com/gocrane/crane.git https://gitee.com/finops/crane Git Public https://github.com/gocrane/helm-charts.git https://gitee.com/finops/helm-charts Git Public \u83b7\u53d6 Coding Git \u4ed3\u5e93\u6e90\u6587\u4ef6\u5185\u5bb9 \u00b6 Warning Now Coding is not support to fetch raw contents directly. You must be get token first. \u5728\u8fd9\u91cc\u5c06\u4e3a\u60a8\u4ecb\u7ecd\uff0c\u5982\u4f55\u901a\u8fc7HTTP\u8bf7\u6c42\u76f4\u63a5\u83b7\u53d6 Coding Git \u4ed3\u5e93\u4e2d\u7684\u6e90\u6587\u4ef6\u5185\u5bb9\u3002 Coding Git \u4ed3\u5e93\u7684\u5173\u952e\u53c2\u6570 \u00b6 \u4e0e\u5e38\u89c4\u7684API\u8bf7\u6c42\u7c7b\u4f3c\uff0cCoding Git\u4ed3\u5e93\u63d0\u4f9b\u4e86\u5bf9\u5e94\u7684API\u63a5\u53e3\u3002 \u4e0b\u9762\u4e3a\u60a8\u4ecb\u7ecd\u76f8\u5173\u7684\u53c2\u6570\u3002 Example \u4ee5 https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml \u4f5c\u4e3a\u4f8b\u5b50\u3002 \u70b9\u51fb\u8bbf\u95ee \u53c2\u6570 \u8bf4\u660e \u4f8b\u5b50 team \u56e2\u961f\u540d\u79f0 finops project \u9879\u76ee\u540d\u79f0 gocrane repo Git \u4ed3\u5e93\u540d\u79f0 helm-charts branch \u5206\u652f\u540d\u79f0 main file path \u9879\u76ee\u4e2d\u7684\u6587\u4ef6\u8def\u5f84 /integration/grafana/override_values.yaml \u6784\u9020HTTP\u8bf7\u6c42 \u00b6 \u6839\u636e\u4e0a\u9762\u6240\u63d0\u5230\u7684\u5c5e\u6027\uff0c\u6309\u7167\u4e0b\u9762\u7684URL\u6784\u9020\u89c4\u5219\u4f9d\u6b21\u586b\u5165\uff0c\u5373\u53ef\u83b7\u5f97\u4e00\u4e2a\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u6e90\u6587\u4ef6\u5185\u5bb9\u7684URL\u3002 https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips \u5c1d\u8bd5\u4ee5\u4e0b\u7684\u547d\u4ee4 curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"\u955c\u50cf\u8d44\u6e90"},{"location":"zh/mirror/#_1","text":"","title":"\u955c\u50cf\u8d44\u6e90"},{"location":"zh/mirror/#_2","text":"\u56e0\u4e3a\u5404\u79cd\u7f51\u7edc\u95ee\u9898\uff0c\u5bfc\u81f4\u90e8\u5206\u5730\u57df\u96be\u4ee5\u8bbf\u95eeGitHub \u8d44\u6e90\uff0c\u5982GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com \u3002 \u4e3a\u4e86\u66f4\u597d\u7684\u4f7f\u7528\u4f53\u9a8c\uff0cGoCrane \u4e3a\u60a8\u989d\u5916\u63d0\u4f9b\u4e86\u591a\u4e2a\u955c\u50cf\u4ed3\u5e93\uff0c\u4f46\u5177\u6709\u4e00\u5b9a\u7684\u65f6\u5ef6\u3002","title":"\u5173\u4e8e\u955c\u50cf\u8d44\u6e90"},{"location":"zh/mirror/#image-registry","text":"GoCrane\u63d0\u4f9b\u4e86\u4e00\u79cd\u53cb\u597d\u7684\u65b9\u5f0f\u6765\u4f7f\u7528\u955c\u50cf\u8fdb\u884c\u90e8\u7f72\u548c\u6d4b\u8bd5\u3002 GoCrane\u4f7f\u7528CI(GitHub Action)\u8fdb\u884c\u955c\u50cf\u6784\u5efa\u3002","title":"Image Registry"},{"location":"zh/mirror/#platforms","text":"GoCrane \u73b0\u5728\u652f\u6301 linux/amd64 \u548c linux/arm64\u3002 GoCrane \u4e5f\u5728\u5173\u6ce8ARM\u7528\u6237\uff0c\u8b6c\u5982 apple m1/m2\u3002","title":"Platforms"},{"location":"zh/mirror/#repo","text":"\u7531\u4e8e\u7f51\u7edc\u539f\u56e0\uff0cGoCrane \u5c06\u540c\u65f6\u5c06\u955c\u50cf\u63a8\u9001\u5230\u4e09\u4e2a\u955c\u50cf\u4ed3\u5e93\u3002 Tips \u70b9\u51fb\u94fe\u63a5\uff0c\u67e5\u9605\u66f4\u591a DockerHub Coding GitHub Container Registry \u5982\u679c\u4f60\u5728\u4e2d\u56fd\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528 Coding\u3002\u8be5\u4ed3\u5e93\u7684\u901f\u5ea6\u6bd4\u5176\u4ed6\u4e24\u4e2a\u5feb\u3002 \u5982\u679c\u4f60\u5728\u4e2d\u56fd\u5883\u5916\uff0c\u6211\u4eec\u63a8\u8350\u4f60\u4f7f\u7528 DockHub\u4ee5\u53caGHCR\u3002\u5982\u679c\u4f60\u4f7f\u7528Coding\uff0c\u901f\u5ea6\u4e0a\u9762\u4e0d\u592a\u7406\u60f3\u3002","title":"Repo"},{"location":"zh/mirror/#build-logic","text":"\u6bcf\u4e2a\u5206\u652f \u4f60\u53ef\u4ee5\u4f7f\u7528\u8be5\u5206\u652f\u955c\u50cf\u5c1d\u8bd5\u6700\u65b0\u7684\u7279\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4f9d\u65e7\u4fdd\u5b58\u8f83\u65e9\u4e4b\u524d\u7684\u955c\u50cf\u3002 \u6bcf\u4e2apull request \u5f53\u4f60\u53d1\u8d77\u4e00\u4e2apull request\u5230crane repo\u7684\u65f6\u5019\uff0c\u5c06\u4f1a\u81ea\u52a8\u89e6\u53d1CI\u4efb\u52a1\u6765\u6784\u5efa\u5bf9\u5e94\u7684\u955c\u50cf\u3002CI\u4f1a\u5c06\u6700\u540e\u7684\u955c\u50cf\u7ed3\u679c\u901a\u8fc7\u8bc4\u8bba\u7684\u65b9\u5f0f\u9644\u52a0\u5728\u5bf9\u5e94\u7684pull request\u4e2d\u3002","title":"Build logic"},{"location":"zh/mirror/#how-to-use-the-images","text":"\u8fd9\u91cc\u5c06\u4f7f\u7528 main \u5206\u652f\u4f5c\u4e3a\u4f8b\u5b50\u3002 Git commit hash \u4e3a abc123\u3002","title":"How to use the images?"},{"location":"zh/mirror/#base-on-the-branch-name","text":"Tips branch name\u7684\u955c\u50cf\u4e00\u76f4\u6307\u5411\u6700\u65b0\u7684Git commit\u3002\u5f53\u4f60\u60f3\u5c1d\u8bd5\u65b0\u7279\u6027\u7684\u65f6\u5019\uff0c\u4e0d\u8981\u5fd8\u8bb0\u91cd\u65b0\u62c9\u53d6\u955c\u50cf\u3002 DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main docker pull ghcr.io/gocrane/crane/craned:main","title":"Base on the branch name"},{"location":"zh/mirror/#base-on-the-branch-name-and-the-specific-commit-hash","text":"DockerHub Coding GitHub Container Registry docker pull gocrane/craned:main-abc123 docker pull finops-docker.pkg.coding.net/gocrane/crane/craned:main-abc123 docker pull ghcr.io/gocrane/crane/craned:main-abc123","title":"Base on the branch name and the specific commit hash"},{"location":"zh/mirror/#helm-resources","text":"Tips \u6bcf\u516d\u5c0f\u65f6\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u7684\u6700\u65b0\u7248\u672c Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public","title":"Helm Resources"},{"location":"zh/mirror/#git-resources","text":"Tips \u6bcf\u5929\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u4ed3\u5e93 Warning Now Coding is not support to fetch raw contents directly. You must be get token first.","title":"Git Resources"},{"location":"zh/mirror/#coding","text":"Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public","title":"Coding"},{"location":"zh/mirror/#gitee","text":"Origin Mirror Type Public https://github.com/gocrane/crane.git https://gitee.com/finops/crane Git Public https://github.com/gocrane/helm-charts.git https://gitee.com/finops/helm-charts Git Public","title":"Gitee"},{"location":"zh/mirror/#coding-git","text":"Warning Now Coding is not support to fetch raw contents directly. You must be get token first. \u5728\u8fd9\u91cc\u5c06\u4e3a\u60a8\u4ecb\u7ecd\uff0c\u5982\u4f55\u901a\u8fc7HTTP\u8bf7\u6c42\u76f4\u63a5\u83b7\u53d6 Coding Git \u4ed3\u5e93\u4e2d\u7684\u6e90\u6587\u4ef6\u5185\u5bb9\u3002","title":"\u83b7\u53d6 Coding Git \u4ed3\u5e93\u6e90\u6587\u4ef6\u5185\u5bb9"},{"location":"zh/mirror/#coding-git_1","text":"\u4e0e\u5e38\u89c4\u7684API\u8bf7\u6c42\u7c7b\u4f3c\uff0cCoding Git\u4ed3\u5e93\u63d0\u4f9b\u4e86\u5bf9\u5e94\u7684API\u63a5\u53e3\u3002 \u4e0b\u9762\u4e3a\u60a8\u4ecb\u7ecd\u76f8\u5173\u7684\u53c2\u6570\u3002 Example \u4ee5 https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml \u4f5c\u4e3a\u4f8b\u5b50\u3002 \u70b9\u51fb\u8bbf\u95ee \u53c2\u6570 \u8bf4\u660e \u4f8b\u5b50 team \u56e2\u961f\u540d\u79f0 finops project \u9879\u76ee\u540d\u79f0 gocrane repo Git \u4ed3\u5e93\u540d\u79f0 helm-charts branch \u5206\u652f\u540d\u79f0 main file path \u9879\u76ee\u4e2d\u7684\u6587\u4ef6\u8def\u5f84 /integration/grafana/override_values.yaml","title":"Coding Git \u4ed3\u5e93\u7684\u5173\u952e\u53c2\u6570"},{"location":"zh/mirror/#http","text":"\u6839\u636e\u4e0a\u9762\u6240\u63d0\u5230\u7684\u5c5e\u6027\uff0c\u6309\u7167\u4e0b\u9762\u7684URL\u6784\u9020\u89c4\u5219\u4f9d\u6b21\u586b\u5165\uff0c\u5373\u53ef\u83b7\u5f97\u4e00\u4e2a\u53ef\u4ee5\u76f4\u63a5\u83b7\u53d6\u6e90\u6587\u4ef6\u5185\u5bb9\u7684URL\u3002 https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips \u5c1d\u8bd5\u4ee5\u4e0b\u7684\u547d\u4ee4 curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"\u6784\u9020HTTP\u8bf7\u6c42"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/","text":"Advanced CPUSet Manager \u00b6 Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet. Table of Contents \u00b6 Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations Motivation \u00b6 Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service. Goals \u00b6 Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus Non-Goals/Future Work \u00b6 Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered Proposal \u00b6 Relax restrictions of cpuset allocation \u00b6 Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2 Add new annotation to describe the requirement of cpuset contorl manger \u00b6 apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use. Advanced CPU Manager component \u00b6 Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet User Stories \u00b6 Users can update pod annotaion to control cpuset policy flexibly Story 1 \u00b6 make pod from none to share without recreating pod Story 2 \u00b6 make pod from exclusive to share, so offline process can use these CPUs Risks and Mitigations \u00b6 kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Advanced CpuSet Manager"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#advanced-cpuset-manager","text":"Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet.","title":"Advanced CPUSet Manager"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#table-of-contents","text":"Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations","title":"Table of Contents"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#motivation","text":"Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service.","title":"Motivation"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#goals","text":"Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus","title":"Goals"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#non-goalsfuture-work","text":"Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered","title":"Non-Goals/Future Work"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#proposal","text":"","title":"Proposal"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#relax-restrictions-of-cpuset-allocation","text":"Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2","title":"Relax restrictions of cpuset allocation"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#add-new-annotation-to-describe-the-requirement-of-cpuset-contorl-manger","text":"apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use.","title":"Add new annotation to describe the  requirement of cpuset contorl manger"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#advanced-cpu-manager-component","text":"Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet","title":"Advanced CPU Manager component"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#user-stories","text":"Users can update pod annotaion to control cpuset policy flexibly","title":"User Stories"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#story-1","text":"make pod from none to share without recreating pod","title":"Story 1"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#story-2","text":"make pod from exclusive to share, so offline process can use these CPUs","title":"Story 2"},{"location":"zh/proposals/20220228-advanced-cpuset-manger/#risks-and-mitigations","text":"kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Risks and Mitigations"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/","text":"Provide a policy-based abnormal detection mechanism in crane-agent \u00b6 Table of Contents \u00b6 Summary \u00b6 Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine. Motivation \u00b6 The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance. Goals \u00b6 Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code. Non-Goals \u00b6 How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope. Proposal \u00b6 User Stories \u00b6 Story 1 \u00b6 A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status. Story 2 \u00b6 The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly. Story 3 \u00b6 The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night. Functional Requirements \u00b6 Implementation Details \u00b6 API \u00b6 NodeQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 } PodQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future. Metrics \u00b6 Built-in metrics \u00b6 Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine. External metrics (New) \u00b6 Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node. Embedded metrics TSDB \u00b6 In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from. Policy \u00b6 The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#provide-a-policy-based-abnormal-detection-mechanism-in-crane-agent","text":"","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#summary","text":"Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine.","title":"Summary"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#motivation","text":"The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance.","title":"Motivation"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#goals","text":"Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code.","title":"Goals"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#non-goals","text":"How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope.","title":"Non-Goals"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#proposal","text":"","title":"Proposal"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#user-stories","text":"","title":"User Stories"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#story-1","text":"A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status.","title":"Story 1"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#story-2","text":"The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly.","title":"Story 2"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#story-3","text":"The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night.","title":"Story 3"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#functional-requirements","text":"","title":"Functional Requirements"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#implementation-details","text":"","title":"Implementation Details"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#api","text":"","title":"API"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#nodeqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 }","title":"NodeQOSEnsurancePolicy"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#podqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future.","title":"PodQOSEnsurancePolicy"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#metrics","text":"","title":"Metrics"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#built-in-metrics","text":"Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine.","title":"Built-in metrics"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#external-metrics-new","text":"Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node.","title":"External metrics (New)"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#embedded-metrics-tsdb","text":"In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from.","title":"Embedded metrics TSDB"},{"location":"zh/proposals/20220402-policy-based-abnomal-detection/#policy","text":"The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Policy"},{"location":"zh/proposals/20220706-recommendation-definition/","text":"Recommendation Definition \u00b6 This proposal aims at definition for universal resource optimization. Table of Contents \u00b6 Motivation \u00b6 Proposal \u00b6 Api Definition \u00b6 RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` } Recommendation Configuration \u00b6 Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Definition"},{"location":"zh/proposals/20220706-recommendation-definition/#recommendation-definition","text":"This proposal aims at definition for universal resource optimization.","title":"Recommendation Definition"},{"location":"zh/proposals/20220706-recommendation-definition/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh/proposals/20220706-recommendation-definition/#motivation","text":"","title":"Motivation"},{"location":"zh/proposals/20220706-recommendation-definition/#proposal","text":"","title":"Proposal"},{"location":"zh/proposals/20220706-recommendation-definition/#api-definition","text":"RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` }","title":"Api Definition"},{"location":"zh/proposals/20220706-recommendation-definition/#recommendation-configuration","text":"Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Configuration"},{"location":"zh/proposals/20220706-universal-resource-optimization/","text":"Universal Resource Optimization \u00b6 Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud. Table of Contents \u00b6 Motivation \u00b6 Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds. Goals \u00b6 Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud Non-Goals \u00b6 Cloud Resources that not included in kubernetes Proposal \u00b6 Recommendation Definition Recommendation Framework User Stories \u00b6 Story 1 \u00b6 As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production. Story 2 \u00b6 As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists. Story 3 \u00b6 As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Universal Resource Optimization"},{"location":"zh/proposals/20220706-universal-resource-optimization/#universal-resource-optimization","text":"Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud.","title":"Universal Resource Optimization"},{"location":"zh/proposals/20220706-universal-resource-optimization/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh/proposals/20220706-universal-resource-optimization/#motivation","text":"Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds.","title":"Motivation"},{"location":"zh/proposals/20220706-universal-resource-optimization/#goals","text":"Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud","title":"Goals"},{"location":"zh/proposals/20220706-universal-resource-optimization/#non-goals","text":"Cloud Resources that not included in kubernetes","title":"Non-Goals"},{"location":"zh/proposals/20220706-universal-resource-optimization/#proposal","text":"Recommendation Definition Recommendation Framework","title":"Proposal"},{"location":"zh/proposals/20220706-universal-resource-optimization/#user-stories","text":"","title":"User Stories"},{"location":"zh/proposals/20220706-universal-resource-optimization/#story-1","text":"As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production.","title":"Story 1"},{"location":"zh/proposals/20220706-universal-resource-optimization/#story-2","text":"As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists.","title":"Story 2"},{"location":"zh/proposals/20220706-universal-resource-optimization/#story-3","text":"As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Story 3"},{"location":"zh/proposals/20220712-recommendation-framework-internal/","text":"Recommendation Framework Internal \u00b6 Summary \u00b6 This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly. Motivation \u00b6 At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type. Goals \u00b6 Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules. Non-Goals \u00b6 Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework. Proposal \u00b6 Architecture \u00b6 Phases \u00b6 We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework. Fliter \u00b6 The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it. Prepare \u00b6 Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic. Recommend \u00b6 The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it. Observe \u00b6 Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Recommendation Framework Internal"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#recommendation-framework-internal","text":"","title":"Recommendation Framework Internal"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#summary","text":"This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly.","title":"Summary"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#motivation","text":"At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type.","title":"Motivation"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#goals","text":"Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules.","title":"Goals"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#non-goals","text":"Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework.","title":"Non-Goals"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#proposal","text":"","title":"Proposal"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#architecture","text":"","title":"Architecture"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#phases","text":"We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework.","title":"Phases"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#fliter","text":"The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it.","title":"Fliter"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#prepare","text":"Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic.","title":"Prepare"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#recommend","text":"The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it.","title":"Recommend"},{"location":"zh/proposals/20220712-recommendation-framework-internal/#observe","text":"Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Observe"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/","text":"Pod Sorting And Precise Execution For Crane Agent \u00b6 \u8be5proposal\u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5b8c\u5584\u4e86\u901a\u7528\u6392\u5e8f\u3002\u5e76\u4e14\u5b9e\u73b0\u4e86\u4e00\u5957\u7cbe\u51c6\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u5728\u6267\u884c\u538b\u5236/\u9a71\u9010\u7b49\u64cd\u4f5c\u65f6\uff0c\u64cd\u4f5c\u5230\u7528\u6237\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u5373\u505c\u6b62\u7684\u7cbe\u786e\u64cd\u4f5c\u903b\u8f91\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\uff1b \u5177\u4f53\u6765\u8bf4\uff1a \u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5b8c\u5584\u4e86\u901a\u7528\u6392\u5e8f\u548ccpu usage\u4e3a\u4e3b\u8981\u53c2\u8003\u7684cpu\u7ef4\u5ea6\u6392\u5e8f\uff1b \u9488\u5bf9cpu usage\uff0c\u5b9e\u73b0\u4e86\u6267\u884c\u538b\u5236/\u9a71\u9010\u7b49\u64cd\u4f5c\u65f6\uff0c\u64cd\u4f5c\u5230\u7528\u6237\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u5373\u505c\u6b62\u7684\u7cbe\u786e\u64cd\u4f5c\u903b\u8f91\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\uff1b \u5b9e\u73b0\u4e86\u4e00\u5957\u7cbe\u786e\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b8c\u5584\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u4e00\u4e9b\u5217\u5c5e\u6027\u548c\u5b9e\u73b0\uff0c\u5373\u53ef\u5728\u65e0\u9700\u5173\u5fc3\u5177\u4f53\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u6837\u5177\u6709\u540ccpu usage\u4e00\u6837\u7684\u7cbe\u786e\u64cd\u4f5c\u80fd\u529b\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u666e\u9002\u6027\u548c\u6269\u5c55\u6027\u3002 Table of Contents \u00b6 Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal \u4e30\u5bccpod\u7684\u6392\u5e8f\u7b56\u7565 metric\u5c5e\u6027\u7684\u5b9a\u4e49 \u5982\u4f55\u6839\u636e\u6c34\u4f4d\u7ebf\u8fdb\u884c\u7cbe\u51c6\u63a7\u5236 \u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c analyzer\u9636\u6bb5 executor\u9636\u6bb5 Non-Goals/Future Work User Stories Motivation \u00b6 \u5f53\u524d\u5728crane-agent\u4e2d\uff0c\u5f53\u8d85\u8fc7NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u6267\u884cevict\uff0cthrottle\u7b49\u64cd\u4f5c\u65f6\u5148\u5bf9\u4f4e\u4f18\u5148\u7ea7\u7684pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5f53\u524d\u6392\u5e8f\u7684\u4f9d\u636e\u662fpod\u7684ProrityClass\uff0c\u7136\u540e\u5728\u6392\u5e8f\u7684pod\u8fdb\u884cthrottle\u6216\u8005evict\u64cd\u4f5c\uff1b \u76ee\u524d\u5b58\u5728\u7684\u95ee\u9898\u6709\uff1a \u6392\u5e8f\u53ea\u53c2\u8003ProrityClass\uff0c\u65e0\u6cd5\u6ee1\u8db3\u57fa\u4e8e\u5176\u4ed6\u7279\u6027\u7684\u6392\u5e8f\uff1b\u540c\u65f6\u4e5f\u65e0\u6cd5\u6ee1\u8db3\u6309\u7167\u6c34\u4f4d\u7ebf\u7cbe\u786e\u64cd\u4f5c\u5bf9\u7075\u6d3b\u6392\u5e8f\u7684\u9700\u6c42\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5c3d\u5feb\u8ba9\u8282\u70b9\u8fbe\u5230\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u7684\u8981\u6c42\u3002\u4f8b\u5982\u6211\u4eec\u5e0c\u671b\u5c3d\u5feb\u964d\u4f4e\u4f4e\u4f18\u5148\u7ea7\u4e1a\u52a1\u7684cpu\u4f7f\u7528\u91cf\u65f6\uff0c\u5e94\u8be5\u9009\u51facpu\u4f7f\u7528\u91cf\u8f83\u591a\u7684pod\uff0c\u8fd9\u6837\u80fd\u591f\u66f4\u5feb\u5730\u964d\u4f4ecpu\u7528\u91cf\uff0c\u4fdd\u969c\u9ad8\u4f18\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd\u3002 \u5728\u89e6\u53d1NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5bf9\u4e8e\u8282\u70b9\u4e0a\u7684\u6240\u6709\u4f4e\u4e8e\u6307\u5b9aProrityClass\u7684pod\u8fdb\u884c\u64cd\u4f5c\uff1b\u4f8b\u5982\uff0c\u5f53\u524d\u8282\u70b9\u4e0a\u670910\u4e2apod\u4f4e\u4e8e\u6307\u5b9aProrityClass\uff0c\u5728\u89e6\u53d1\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5bf9\u8fd910\u4e2apod\u90fd\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u53ef\u80fd\u5728\u64cd\u4f5c\u5b8c\u6210\u5bf9\u7b2c\u4e00\u4e2apod\u7684\u64cd\u4f5c\u540e\u5c31\u53ef\u4ee5\u4f4e\u4e8eNodeQOSEnsurancePolicy\u4e2d\u7684\u6307\u6807\u503c\u4e86\uff0c\u5bf9\u5269\u4e0b\u7684pod\u7684\u64cd\u4f5c\uff0c\u5c5e\u4e8e\u8fc7\u5ea6\u64cd\u4f5c\uff0c\u662f\u53ef\u4ee5\u907f\u514d\u7684\u3002\u5982\u679c\u80fd\u4ee5NodeQOSEnsurancePolicy\u4e2d\u7684\u6307\u6807\u503c\u4f5c\u4e3a\u6c34\u4f4d\u7ebf\u5bf9pod\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c\uff0c\u64cd\u4f5c\u5230\u521a\u597d\u4f4e\u4e8e\u6c34\u4f4d\u7ebf\u662f\u66f4\u4e3a\u5408\u9002\u7684\uff0c\u5c31\u80fd\u907f\u514d\u5bf9\u4f4e\u4f18\u5148\u7ea7\u670d\u52a1\u7684\u8fc7\u5ea6\u5f71\u54cd\u3002 Goals \u00b6 \u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5305\u62ec\u4ee5pod cpu\u7528\u91cf\u4e3a\u4e3b\u8981\u53c2\u7167\u7684\u6392\u5e8f\uff0c\u4ee5pod\u5185\u5b58\u7528\u91cf\u4e3a\u4e3b\u8981\u53c2\u7167\u7684\u6392\u5e8f\uff0c\u57fa\u4e8e\u8fd0\u884c\u65f6\u95f4\u7684\u6392\u5e8f\uff0c\u57fa\u4e8e\u6269\u5c55\u8d44\u6e90\u4f7f\u7528\u7387\u7684\u6392\u5e8f\u3002 \u5b9e\u73b0\u4e00\u5957\u5305\u542b\u6392\u5e8f\u548c\u7cbe\u786e\u64cd\u4f5c\u7684\u6846\u67b6\uff0c\u652f\u6301\u5bf9\u4e0d\u540c\u7684\u6307\u6807\u4e30\u5bcc\u6392\u5e8f\u89c4\u5219\uff0c\u5e76\u4e14\u5b9e\u73b0\u7cbe\u786e\u64cd\u4f5c\u3002 \u5b9e\u73b0\u9488\u5bf9cpu usage\u548cmemmory usage\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u5f53\u6574\u673a\u8d1f\u8f7d\u8d85\u8fc7NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5148\u5bf9\u4f4e\u4f18\u5148\u7ea7\u7684pod\u8fdb\u884c\u6392\u5e8f\uff0c\u7136\u540e\u6309\u7167\u987a\u5e8f\u64cd\u4f5c\u5230\u521a\u597d\u4f4e\u4e8e\u6c34\u4f4d\u7ebf\u4e3a\u6b62\u3002 Proposal \u00b6 \u4e30\u5bccpod\u7684\u6392\u5e8f\u7b56\u7565 \u00b6 \u8be5proposal\u5b9e\u73b0\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\uff08\u4e4b\u540e\u4f1a\u66f4\u591a\u5730\u5b8c\u5584\uff09\uff1a classAndPriority\uff1a \u6bd4\u8f83\u4e24\u4e2apod\u7684QOSClass\u548cclass value\uff0c\u4f18\u5148\u6bd4\u8f83QOSClass\uff0c\u518d\u6bd4\u8f83class value\uff1bpriority\u9ad8\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 runningTime\uff1a\u6bd4\u8f83\u4e24\u4e2apod\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u8fd0\u884c\u65f6\u95f4\u957f\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 \u5982\u679c\u4ec5\u9700\u4f7f\u7528\u8fd9\u4e24\u4e2a\u6392\u5e8f\u7b56\u7565\uff0c\u4f7f\u7528\u9ed8\u8ba4\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\uff1a\u4f1a\u9996\u5148\u6bd4\u8f83pod\u7684\u4f18\u5148\u7ea7\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u5bf9\u5e94\u6307\u6807\u7684\u7528\u91cf\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u6709\u4e00\u4e2a\u7ef4\u5ea6\u53ef\u4ee5\u6bd4\u8f83\u51fa\u7ed3\u679c\u5373\u4e3apod\u7684\u6392\u5e8f\u7ed3\u679c func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f \u4f1a\u4f9d\u6b21\u6bd4\u8f83\u4e24\u4e2apod\u7684\u4f18\u5148\u7ea7\uff0c\u5982\u679c\u4f18\u5148\u7ea7\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u518d\u6bd4\u8f83cpu\u7528\u91cf\uff0c\u5982\u679ccpu\u7528\u91cf\u4e5f\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u7ee7\u7eed\u6bd4\u8f83ext cpu\u8d44\u6e90\u7528\u91cf\uff08\u8fd9\u4e2a\u662fcpu\u5c5e\u6027\u8f83\u4e3a\u7279\u6b8a\u7684\u4e00\u70b9\uff09, \u6700\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u5f53\u67d0\u4e00\u4e2a\u6307\u6807\u5b58\u5728\u5dee\u5f02\u65f6\u5373\u53ef\u8fd4\u56de\u6bd4\u8f83\u7ed3\u679c func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ). Sort ( pods ) } ext cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f \u4f1a\u9996\u5148\u6bd4\u8f83\u4e24\u4e2apod\u662f\u5426\u4f7f\u7528\u4e86\u6269\u5c55\u7684cpu\u8d44\u6e90\uff0c\u5728\u90fd\u4f7f\u7528\u4e86\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u8f83 \u6269\u5c55cpu\u8d44\u6e90\u4f7f\u7528\u91cf/ \u6269\u5c55cpu\u8d44\u6e90limit\u7684\u6bd4\u503c \u9488\u5bf9\u9700\u8981\u81ea\u5b9a\u4e49\u7684\u6307\u6807\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0\u5982\u4e0b\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u968f\u610f\u642d\u914d\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0pod\u7684\u7075\u6d3b\u81ea\u5b9a\u4e49\u6392\u5e8f\uff0c\u4ee5 \u4ee3\u8868\u81ea\u5b9a\u4e49metric\u6307\u6807\uff0c \u4ee3\u8868\u81ea\u5b9a\u4e49\u7684\u9488\u5bf9 \u7684\u6392\u5e8f\u7b56\u7565 func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } \u5176\u4e2d \u53ea\u9700\u8981\u5b9e\u73b0\u5982\u4e0b\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef func ( p1 , p2 podinfo . PodContext ) int32 metric\u5c5e\u6027\u7684\u5b9a\u4e49 \u00b6 \u4e3a\u4e86\u66f4\u597d\u7684\u57fa\u4e8eNodeQOSEnsurancePolicy\u914d\u7f6e\u7684metric\u8fdb\u884c\u6392\u5e8f\u548c\u7cbe\u51c6\u63a7\u5236\uff0c\u5bf9metric\u5f15\u5165\u5c5e\u6027\u7684\u6982\u5ff5\u3002 metric\u7684\u5c5e\u6027\u5305\u542b\u5982\u4e0b\u51e0\u4e2a\uff1a Name \u8868\u660e\u4e86metric\u7684\u540d\u79f0\uff0c\u9700\u8981\u540ccollector\u6a21\u5757\u4e2d\u6536\u96c6\u5230\u7684\u6307\u6807\u540d\u79f0\u4e00\u81f4 ActionPriority \u8868\u793a\u6307\u6807\u7684\u4f18\u5148\u7ea7\uff0c0\u4e3a\u6700\u4f4e\uff0c10\u4e3a\u6700\u9ad8 SortAble \u8868\u660e\u8be5\u6307\u6807\u662f\u5426\u53ef\u4ee5\u6392\u5e8f SortFunc \u5bf9\u5e94\u7684\u6392\u5e8f\u65b9\u6cd5\uff0c\u6392\u5e8f\u65b9\u6cd5\u53ef\u4ee5\u6392\u5217\u7ec4\u5408\u4e00\u4e9b\u901a\u7528\u65b9\u6cd5\uff0c\u518d\u7ed3\u5408\u6307\u6807\u81ea\u8eab\u7684\u6392\u5e8f\uff0c\u5c06\u5728\u4e0b\u6587\u8be6\u7ec6\u4ecb\u7ecd ThrottleAble \u8868\u660e\u9488\u5bf9\u8be5\u6307\u6807\uff0c\u662f\u5426\u53ef\u4ee5\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u4f8b\u5982\u9488\u5bf9cpu\u4f7f\u7528\u91cf\u8fd9\u4e2ametric\uff0c\u5c31\u6709\u76f8\u5bf9\u5e94\u7684\u538b\u5236\u624b\u6bb5\uff0c\u4f46\u662f\u5bf9\u4e8ememory\u4f7f\u7528\u91cf\u8fd9\u79cd\u6307\u6807\uff0c\u5c31\u53ea\u80fd\u8fdb\u884cpod\u7684\u9a71\u9010\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u538b\u5236 ThrottleQuantified \u8868\u660e\u538b\u5236\uff08restore\uff09\u4e00\u4e2apod\u540e\uff0c\u80fd\u5426\u51c6\u786e\u8ba1\u7b97\u51fa\u7ecf\u8fc7\u538b\u5236\u540e\u91ca\u653e\u51fa\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u6211\u4eec\u5c06\u53ef\u4ee5\u51c6\u786e\u91cf\u5316\u7684\u6307\u6807\u79f0\u4e3a\u53efQuantified\uff0c\u5426\u5219\u4e3a\u4e0d\u53efQuantified\uff1b \u6bd4\u5982cpu\u7528\u91cf\uff0c\u53ef\u4ee5\u901a\u8fc7\u9650\u5236cgroup\u7528\u91cf\u8fdb\u884c\u538b\u5236\uff0c\u540c\u65f6\u53ef\u4ee5\u901a\u8fc7\u5f53\u524d\u8fd0\u884c\u503c\u548c\u538b\u5236\u540e\u7684\u503c\u8ba1\u7b97\u538b\u5236\u540e\u91ca\u653e\u7684cpu\u4f7f\u7528\u91cf\uff1b\u800c\u6bd4\u5982memory usage\u5c31\u4e0d\u5c5e\u4e8e\u538b\u5236\u53ef\u91cf\u5316metric\uff0c\u56e0\u4e3amemory\u6ca1\u6709\u5bf9\u5e94\u7684throttle\u5b9e\u73b0\uff0c\u4e5f\u5c31\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u538b\u5236\u4e00\u4e2apod\u540e\u91ca\u653e\u51fa\u6765\u7684memory\u8d44\u6e90\u5177\u4f53\u7528\u91cf\uff1b ThrottleFunc\uff0c\u6267\u884cThrottle\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efThrottle\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a RestoreFunc\uff0c\u88abThrottle\u540e\uff0c\u6267\u884c\u6062\u590d\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efRestore\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a EvictAble\uff0cEvictQuantified\uff0cEvictFunc \u5bf9evict\u52a8\u4f5c\u7684\u76f8\u5173\u5b9a\u4e49\uff0c\u5177\u4f53\u5185\u5bb9\u548cThrottle\u52a8\u4f5c\u7c7b\u4f3c type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } \u7528\u6237\u53ef\u4ee5\u81ea\u884c\u5b9a\u4e49\u81ea\u5df1\u7684metric\uff0c\u5728\u6784\u9020\u5b8c\u6210\u540e\uff0c\u901a\u8fc7registerMetricMap()\u8fdb\u884c\u6ce8\u518c\u5373\u53ef \u5982\u4f55\u6839\u636e\u6c34\u4f4d\u7ebf\u8fdb\u884c\u7cbe\u51c6\u63a7\u5236 \u00b6 \u6839\u636e\u591a\u4e2aNodeQOSEnsurancePolicy\u53ca\u5176\u4e2d\u7684objectiveEnsurances\u6784\u5efa\u591a\u6761\u6c34\u4f4d\u7ebf: \u6309\u7167objectiveEnsurances\u5bf9\u5e94\u7684action\u8fdb\u884c\u5206\u7c7b\uff0c\u76ee\u524dcrane-agent\u67093\u4e2a\u9488\u5bf9\u8282\u70b9Qos\u8fdb\u884c\u4fdd\u969c\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662fEvict\uff0cThtottleDown\uff08\u5f53\u524d\u7528\u91cf\u9ad8\u4e8eobjectiveEnsurances\u4e2d\u7684\u503c\u65f6\u5bf9pod\u8fdb\u884c\u7528\u91cf\u538b\u5236\uff09\u548cThrottleUp\uff08\u5f53\u524d\u7528\u91cf\u4f4e\u4e8eobjectiveEnsurances\u4e2d\u7684\u503c\u65f6\u5bf9pod\u7684\u7528\u91cf\u8fdb\u884c\u653e\u5bbd\u6062\u590d\uff09\uff0c\u56e0\u6b64\u4f1a\u6709\u4e09\u4e2a\u6c34\u4f4d\u7ebf\u96c6\u5408\uff0c\u5206\u522b\u662f ThrottleDownWaterLine\uff0cThrottleUpWaterLine\u548cEvictWaterLine \u518d\u5bf9\u540c\u4e00\u64cd\u4f5c\u79cd\u7c7b\u4e2d\u7684\u6c34\u4f4d\u7ebf\u6309\u7167\u5176metric rule\uff08\u56fe\u4e2d\u4ee5metric A\uff0cmetric Z\u4f5c\u4e3a\u793a\u610f\uff09\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u8bb0\u5f55\u6bcf\u4e2aobjectiveEnsurances\u6c34\u4f4d\u7ebf\u7684\u503c\uff0c\u8bb0\u4e3awaterLine\uff1b ThrottleDownWaterLine\uff0cThrottleUpWaterLine\u548cEvictWaterLine\u7684\u7ed3\u6784\u662f\u8fd9\u6837\u7684\uff1a type WaterLines map[WaterLineMetric]*WaterLine \u5176\u4e2dWaterLineMetric\u5c31\u662f\u4e0a\u9762\u7684metric\u7684Name\u5b57\u6bb5\uff0cvalue\u7684WaterLine\u5c31\u662f\u8d44\u6e90\u6570\u503c type WaterLine resource.Quantity \u6700\u7ec8\u5f62\u6210\u4e00\u4e2a\u7c7b\u4f3c\u4e0b\u56fe\u7684\u6570\u636e\u5b58\u50a8\uff1a \u6784\u9020\u5b9e\u65f6\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c\uff1a \u7ed3\u5408\u5f53\u524d\u8282\u70b9\u7684\u6307\u6807\u5b9e\u65f6\u7528\u91cf\u4e0eWaterLines\u4e2d\u8be5\u6307\u6807\u5bf9\u5e94\u7684\u6c34\u4f4d\u7ebf\u4e2d\u6700\u5c0f\u503c\u7684\u5dee\u503c\u6784\u9020\u5982\u4e0b\u7684\u6570\u636e\u7ed3\u6784\uff0c\u4ee3\u8868\u5230\u5f53\u524d\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c type GapToWaterLines map[WaterLineMetric]float64 \u5176\u4e2dkey\u503c\u4e3ametric\u7684Name\u5b57\u6bb5\uff0cvalue\u4e3a\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c\uff1b \u9700\u8981\u6ce8\u610f\u5bf9\u4e8eThrottleUp\uff0c\u9700\u8981\u7528\u6c34\u4f4d\u7ebf\u6700\u5c0f\u503c-\u5f53\u524d\u7528\u91cf\u4f5c\u4e3agap\u503c\uff0c\u5bf9\u4e8e\u5176\u4ed6\u4e24\u8005\uff0c\u4f7f\u7528\u5f53\u524d\u7528\u91cf-\u6c34\u4f4d\u7ebf\u6700\u5c0f\u503c\u4f5c\u4e3agap\u503c\uff0c\u5373\u59cb\u7ec8\u4fdd\u6301gap\u503c\u4e3a\u6b63 \u4e0b\u9762\u4e09\u4e2a\u6570\u636e\u5206\u522b\u4ee3\u8868\u4e86\u9700\u8981\u6267\u884cevict\uff0cThtottleDown\u548cThrottleUp\u64cd\u4f5c\u7684\u6307\u6807\u53ca\u5176\u5bf9\u5e94\u7684\u5230\u6700\u4f4e\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] \u4ee5CpuUsage\u8fd9\u4e2ametric\u4e3a\u4f8b\uff0c\u6784\u9020\u8282\u70b9cpu\u7528\u91cf\u76f8\u5173\u7684waterline\u7684\u6d41\u7a0b\u548c\u76f8\u5173\u6570\u636e\u7ed3\u6784\u5982\u4e0b\uff1a \u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c \u00b6 \u8be5proposal\u4e3a\u4e86\u5b9e\u73b0\u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u5c06\u5bf9analyzer\u90e8\u5206\u548cexecutor\u90e8\u5206\u505a\u4e00\u5b9a\u7684\u4fee\u6539\uff0c\u5927\u4f53\u6d41\u7a0b\u662f\uff1a \u5728analyzer\u9636\u6bb5\u6784\u9020\u9488\u5bf9\u4e0d\u540c\u64cd\u4f5c\uff08\u9a71\u9010\uff0c\u538b\u5236\u7b49\uff09\u548c\u4e0d\u540cmetric\u7684\u6c34\u4f4d\u7ebf\uff0c\u5c06\u539f\u5148\u7684\u6392\u5e8f\u903b\u8f91\u5220\u9664\uff0c\u540e\u79fb\u5230\u9700\u8981\u8fdb\u884c\u6b63\u5f0f\u64cd\u4f5c\u7684executor\u9636\u6bb5\uff0c\u5e76\u4e14\u53ef\u80fd\u4f1a\u9700\u8981\u8fdb\u884c\u591a\u8f6e\u6392\u5e8f\uff1b \u5728executor\u9636\u6bb5\uff0c\u6839\u636e\u6c34\u4f4d\u7ebf\u4e2d\u7684\u6d89\u53ca\u7684\u6307\u6807\u8fdb\u884c\u5176\u76f8\u5e94\u7684\u6392\u5e8f\uff0c\u83b7\u53d6\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020GapToWaterLines\uff0c\u5e76\u8fdb\u884c\u7cbe\u786e\u64cd\u4f5c analyzer\u9636\u6bb5 \u00b6 \u5728\u8be5\u9636\u6bb5\u8fdb\u884cNodeQOSEnsurancePolicy\u5230WaterLines\u7684\u8f6c\u6362\uff0c\u5e76\u5bf9\u76f8\u540cactionName\u548cmetricrule\u7684\u89c4\u5219\u8fdb\u884c\u5408\u5e76\uff0c\u5177\u4f53\u5185\u5bb9\u4e0a\u6587\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86 executor\u9636\u6bb5 \u00b6 \u538b\u5236\u8fc7\u7a0b\uff1a \u9996\u5148\u5206\u6790ThrottoleDownGapToWaterLines\u4e2d\u6d89\u53ca\u7684metrics\uff0c\u5c06\u8fd9\u4e9bmetrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u5219\u901a\u8fc7GetHighestPriorityThrottleAbleMetric\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\uff08\u5177\u6709throttleFunc\uff09\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c\uff0c\u56e0\u4e3a\u4f46\u51e1\u5b58\u5728\u4e00\u4e2a\u4e0d\u53efQuantified\u7684metric\uff0c\u5c31\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c \u901a\u8fc7getStateFunc()\u83b7\u53d6\u5f53\u524d\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u4f9d\u636eThrottoleDownGapToWaterLines\u548c\u5b9e\u65f6\u7528\u91cf\u6784\u9020GapToWaterLine\uff08\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6784\u9020GapToWaterLine\u65f6\uff0c\u4f1a\u4ee5\u6ce8\u518c\u8fc7\u7684metric\u8fdb\u884c\u904d\u5386\uff0c\u6240\u4ee5\u6700\u7ec8\u6784\u9020\u51fa\u6765\u7684GapToWaterLine\u4e2d\u7684metrics\uff0c\u4f1a\u662fThrottoleDownGapToWaterLines \u4e2d\u6ce8\u518c\u8fc7\u7684metric\uff0c\u907f\u514d\u4e86\u5728NodeQOSEnsurancePolicy\u4e2d\u914d\u7f6e\u9519\u8bef\u4e0d\u5b58\u5728\u6216\u672a\u6ce8\u518cmetric\u7684\u60c5\u51b5\uff09 \u5982\u679cGapToWaterLine\u4e2d\u6709metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff08HasUsageMissedMetric\uff09\uff0c\u5219\u901a\u8fc7GetHighestPriorityThrottleAbleMetric\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\uff08\u5177\u6709throttleFunc\uff09\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c\uff0c\u56e0\u4e3a\u5982\u679c\u5b58\u5728metric\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5c31\u65e0\u6cd5\u83b7\u77e5\u548c\u6c34\u4f4d\u7ebf\u7684gap\uff0c\u4e5f\u5c31\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c \u5982\u679c\u4e0d\u5b58\u57283\u4e2d\u7684\u60c5\u51b5\uff0c\u5219\u904d\u5386ThrottoleDownGapToWaterLines\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5982\u679c\u6ca1\u6709\u5c31\u4f7f\u7528GeneralSorter\u8fdb\u884c\u6392\u5e8f\uff0c\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684ThrottleFunc\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230ThrottoleDownGapToWaterLines\u4e2d\u8be5metric\u5bf9\u5e94\u7684gap\u5df2\u4e0d\u5b58\u5728 //\u5c06\u6240\u6709\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206 metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // \u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u64cd\u4f5c if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { //\u83b7\u53d6\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020\u548c\u6c34\u4f4d\u7ebf\u5dee\u8ddd ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //\u5982\u679c\u89e6\u53d1\u6c34\u4f4d\u7ebf\u4e2d\u5b58\u5728metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5219\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource //\u904d\u5386\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metric\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5426\u5219\u4f7f\u7528GeneralSorter\u6392\u5e8f\uff1b //\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684\u64cd\u4f5c\u65b9\u6cd5\u5bf9pod\u6267\u884c\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230\u5bf9\u5e94metric\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\u5df2\u4e0d\u5b58\u5728 for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } \u9a71\u9010\u8fc7\u7a0b\uff1a \u9a71\u9010\u548c\u538b\u5236\u7684\u6d41\u7a0b\u662f\u4e00\u6837\u7684\uff0c\u9664\u4e86\u5728\u5bf9pod\u8fdb\u884c\u64cd\u4f5c\u7684\u65f6\u5019\u9700\u8981\u989d\u5916\u5224\u65ad\u4e00\u4e0bpod\u662f\u5426\u5df2\u7ecf\u88ab\u9a71\u9010\u4e86\uff1b\u53d6\u51fa\u4e00\u4e2a\u6ca1\u6709\u6267\u884c\u8fc7\u7684pod\uff0c\u6267\u884c\u9a71\u9010\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u7684\u5404metric\u8d44\u6e90\u91cf\uff0c\u540c\u65f6\u5728\u5bf9\u5e94\u6c34\u4f4d\u7ebf\u4e2d\u51cf\u53bb\u91ca\u653e\u7684\u503c\uff0c\u76f4\u5230\u6ee1\u8db3\u5f53\u524dmetric\u6c34\u4f4d\u7ebf\u8981\u6c42 metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } } Non-Goals/Future Work \u00b6 \u5f53\u524d\u53ea\u652f\u6301cpu usage\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u4f46\u662f\u6846\u67b6\u53ef\u4ee5\u590d\u7528\uff0c\u540e\u7eed\u53ef\u4ee5\u57fa\u4e8e\u7cbe\u51c6\u63a7\u5236\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u66f4\u591a\u7ef4\u5ea6\u6307\u6807\u7684\u7cbe\u51c6\u63a7\u5236\u3002 \u5728\u505a\u7cbe\u51c6\u63a7\u5236\u65f6\uff0c\u76ee\u524d\u53ea\u8003\u8651metric\u672c\u8eab\u91ca\u653e\u91cf\uff0c\u672a\u8003\u8651\u4e0d\u540cmetric\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd\u3002\u6bd4\u5982\u538b\u5236cpu usage\u65f6\uff0cmemory usage\u4e5f\u4f1a\u53d7\u5230\u5f71\u54cd\u3002\u5982\u679c\u6307\u6807\u975e\u5e38\u591a\uff0c\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\u4f1a\u975e\u5e38\u590d\u6742\uff0c\u6240\u4ee5\u6682\u65f6\u4e0d\u8003\u8651\u4e0d\u540cmetric\u76f4\u63a5\u7684\u76f8\u4e92\u5f71\u54cd\u3002 User Stories \u00b6 \u7528\u6237\u53ef\u4ee5\u4f7f\u7528crane-agent\u8fdb\u884c\u66f4\u597d\u7684QoS\u4fdd\u969c\u3002\u652f\u6301\u66f4\u5feb\u901f\u7684\u964d\u4f4e\u8282\u70b9\u8d1f\u8f7d\uff0c\u4ee5\u4fdd\u969c\u9ad8\u4f18\u5148\u7ea7\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd\u3002\u540c\u65f6\u5bf9\u4f4e\u4f18\u5148\u7ea7\u4e1a\u52a1\u7684\u538b\u5236/\u9a71\u9010\u52a8\u4f5c\uff0c\u8fdb\u884c\u7cbe\u786e\u63a7\u5236\uff0c\u907f\u514d\u8fc7\u5ea6\u64cd\u4f5c\u3002 \u7528\u6237\u53ef\u4ee5\u501f\u52a9\u5b9e\u73b0\u7684\u7cbe\u51c6\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u5728\u65e0\u9700\u5173\u5fc3\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5b9e\u73b0\u81ea\u5b9a\u4e49metric\u76f8\u5173\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0\u4ee5\u81ea\u5b9a\u4e49metric\u4e3a\u6838\u5fc3\u7684\u5177\u6709\u7cbe\u786e\u64cd\u4f5c\u548c\u6392\u5e8f\u80fd\u529b\u7684QoS\u529f\u80fd\u3002","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#pod-sorting-and-precise-execution-for-crane-agent","text":"\u8be5proposal\u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5b8c\u5584\u4e86\u901a\u7528\u6392\u5e8f\u3002\u5e76\u4e14\u5b9e\u73b0\u4e86\u4e00\u5957\u7cbe\u51c6\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u5728\u6267\u884c\u538b\u5236/\u9a71\u9010\u7b49\u64cd\u4f5c\u65f6\uff0c\u64cd\u4f5c\u5230\u7528\u6237\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u5373\u505c\u6b62\u7684\u7cbe\u786e\u64cd\u4f5c\u903b\u8f91\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\uff1b \u5177\u4f53\u6765\u8bf4\uff1a \u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5b8c\u5584\u4e86\u901a\u7528\u6392\u5e8f\u548ccpu usage\u4e3a\u4e3b\u8981\u53c2\u8003\u7684cpu\u7ef4\u5ea6\u6392\u5e8f\uff1b \u9488\u5bf9cpu usage\uff0c\u5b9e\u73b0\u4e86\u6267\u884c\u538b\u5236/\u9a71\u9010\u7b49\u64cd\u4f5c\u65f6\uff0c\u64cd\u4f5c\u5230\u7528\u6237\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u5373\u505c\u6b62\u7684\u7cbe\u786e\u64cd\u4f5c\u903b\u8f91\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\uff1b \u5b9e\u73b0\u4e86\u4e00\u5957\u7cbe\u786e\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b8c\u5584\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u4e00\u4e9b\u5217\u5c5e\u6027\u548c\u5b9e\u73b0\uff0c\u5373\u53ef\u5728\u65e0\u9700\u5173\u5fc3\u5177\u4f53\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u6837\u5177\u6709\u540ccpu usage\u4e00\u6837\u7684\u7cbe\u786e\u64cd\u4f5c\u80fd\u529b\uff0c\u5177\u6709\u4e00\u5b9a\u7684\u666e\u9002\u6027\u548c\u6269\u5c55\u6027\u3002","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#table-of-contents","text":"Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal \u4e30\u5bccpod\u7684\u6392\u5e8f\u7b56\u7565 metric\u5c5e\u6027\u7684\u5b9a\u4e49 \u5982\u4f55\u6839\u636e\u6c34\u4f4d\u7ebf\u8fdb\u884c\u7cbe\u51c6\u63a7\u5236 \u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c analyzer\u9636\u6bb5 executor\u9636\u6bb5 Non-Goals/Future Work User Stories","title":"Table of Contents"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#motivation","text":"\u5f53\u524d\u5728crane-agent\u4e2d\uff0c\u5f53\u8d85\u8fc7NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u6267\u884cevict\uff0cthrottle\u7b49\u64cd\u4f5c\u65f6\u5148\u5bf9\u4f4e\u4f18\u5148\u7ea7\u7684pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5f53\u524d\u6392\u5e8f\u7684\u4f9d\u636e\u662fpod\u7684ProrityClass\uff0c\u7136\u540e\u5728\u6392\u5e8f\u7684pod\u8fdb\u884cthrottle\u6216\u8005evict\u64cd\u4f5c\uff1b \u76ee\u524d\u5b58\u5728\u7684\u95ee\u9898\u6709\uff1a \u6392\u5e8f\u53ea\u53c2\u8003ProrityClass\uff0c\u65e0\u6cd5\u6ee1\u8db3\u57fa\u4e8e\u5176\u4ed6\u7279\u6027\u7684\u6392\u5e8f\uff1b\u540c\u65f6\u4e5f\u65e0\u6cd5\u6ee1\u8db3\u6309\u7167\u6c34\u4f4d\u7ebf\u7cbe\u786e\u64cd\u4f5c\u5bf9\u7075\u6d3b\u6392\u5e8f\u7684\u9700\u6c42\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5c3d\u5feb\u8ba9\u8282\u70b9\u8fbe\u5230\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u7684\u8981\u6c42\u3002\u4f8b\u5982\u6211\u4eec\u5e0c\u671b\u5c3d\u5feb\u964d\u4f4e\u4f4e\u4f18\u5148\u7ea7\u4e1a\u52a1\u7684cpu\u4f7f\u7528\u91cf\u65f6\uff0c\u5e94\u8be5\u9009\u51facpu\u4f7f\u7528\u91cf\u8f83\u591a\u7684pod\uff0c\u8fd9\u6837\u80fd\u591f\u66f4\u5feb\u5730\u964d\u4f4ecpu\u7528\u91cf\uff0c\u4fdd\u969c\u9ad8\u4f18\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd\u3002 \u5728\u89e6\u53d1NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5bf9\u4e8e\u8282\u70b9\u4e0a\u7684\u6240\u6709\u4f4e\u4e8e\u6307\u5b9aProrityClass\u7684pod\u8fdb\u884c\u64cd\u4f5c\uff1b\u4f8b\u5982\uff0c\u5f53\u524d\u8282\u70b9\u4e0a\u670910\u4e2apod\u4f4e\u4e8e\u6307\u5b9aProrityClass\uff0c\u5728\u89e6\u53d1\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5bf9\u8fd910\u4e2apod\u90fd\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u53ef\u80fd\u5728\u64cd\u4f5c\u5b8c\u6210\u5bf9\u7b2c\u4e00\u4e2apod\u7684\u64cd\u4f5c\u540e\u5c31\u53ef\u4ee5\u4f4e\u4e8eNodeQOSEnsurancePolicy\u4e2d\u7684\u6307\u6807\u503c\u4e86\uff0c\u5bf9\u5269\u4e0b\u7684pod\u7684\u64cd\u4f5c\uff0c\u5c5e\u4e8e\u8fc7\u5ea6\u64cd\u4f5c\uff0c\u662f\u53ef\u4ee5\u907f\u514d\u7684\u3002\u5982\u679c\u80fd\u4ee5NodeQOSEnsurancePolicy\u4e2d\u7684\u6307\u6807\u503c\u4f5c\u4e3a\u6c34\u4f4d\u7ebf\u5bf9pod\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c\uff0c\u64cd\u4f5c\u5230\u521a\u597d\u4f4e\u4e8e\u6c34\u4f4d\u7ebf\u662f\u66f4\u4e3a\u5408\u9002\u7684\uff0c\u5c31\u80fd\u907f\u514d\u5bf9\u4f4e\u4f18\u5148\u7ea7\u670d\u52a1\u7684\u8fc7\u5ea6\u5f71\u54cd\u3002","title":"Motivation"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#goals","text":"\u4e30\u5bcc\u4e86crane-agent\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5305\u62ec\u4ee5pod cpu\u7528\u91cf\u4e3a\u4e3b\u8981\u53c2\u7167\u7684\u6392\u5e8f\uff0c\u4ee5pod\u5185\u5b58\u7528\u91cf\u4e3a\u4e3b\u8981\u53c2\u7167\u7684\u6392\u5e8f\uff0c\u57fa\u4e8e\u8fd0\u884c\u65f6\u95f4\u7684\u6392\u5e8f\uff0c\u57fa\u4e8e\u6269\u5c55\u8d44\u6e90\u4f7f\u7528\u7387\u7684\u6392\u5e8f\u3002 \u5b9e\u73b0\u4e00\u5957\u5305\u542b\u6392\u5e8f\u548c\u7cbe\u786e\u64cd\u4f5c\u7684\u6846\u67b6\uff0c\u652f\u6301\u5bf9\u4e0d\u540c\u7684\u6307\u6807\u4e30\u5bcc\u6392\u5e8f\u89c4\u5219\uff0c\u5e76\u4e14\u5b9e\u73b0\u7cbe\u786e\u64cd\u4f5c\u3002 \u5b9e\u73b0\u9488\u5bf9cpu usage\u548cmemmory usage\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u5f53\u6574\u673a\u8d1f\u8f7d\u8d85\u8fc7NodeQOSEnsurancePolicy\u4e2d\u6307\u5b9a\u7684\u6c34\u4f4d\u7ebf\u540e\uff0c\u4f1a\u5148\u5bf9\u4f4e\u4f18\u5148\u7ea7\u7684pod\u8fdb\u884c\u6392\u5e8f\uff0c\u7136\u540e\u6309\u7167\u987a\u5e8f\u64cd\u4f5c\u5230\u521a\u597d\u4f4e\u4e8e\u6c34\u4f4d\u7ebf\u4e3a\u6b62\u3002","title":"Goals"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#proposal","text":"","title":"Proposal"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#pod","text":"\u8be5proposal\u5b9e\u73b0\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\uff08\u4e4b\u540e\u4f1a\u66f4\u591a\u5730\u5b8c\u5584\uff09\uff1a classAndPriority\uff1a \u6bd4\u8f83\u4e24\u4e2apod\u7684QOSClass\u548cclass value\uff0c\u4f18\u5148\u6bd4\u8f83QOSClass\uff0c\u518d\u6bd4\u8f83class value\uff1bpriority\u9ad8\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 runningTime\uff1a\u6bd4\u8f83\u4e24\u4e2apod\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u8fd0\u884c\u65f6\u95f4\u957f\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 \u5982\u679c\u4ec5\u9700\u4f7f\u7528\u8fd9\u4e24\u4e2a\u6392\u5e8f\u7b56\u7565\uff0c\u4f7f\u7528\u9ed8\u8ba4\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\uff1a\u4f1a\u9996\u5148\u6bd4\u8f83pod\u7684\u4f18\u5148\u7ea7\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u5bf9\u5e94\u6307\u6807\u7684\u7528\u91cf\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u6709\u4e00\u4e2a\u7ef4\u5ea6\u53ef\u4ee5\u6bd4\u8f83\u51fa\u7ed3\u679c\u5373\u4e3apod\u7684\u6392\u5e8f\u7ed3\u679c func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f \u4f1a\u4f9d\u6b21\u6bd4\u8f83\u4e24\u4e2apod\u7684\u4f18\u5148\u7ea7\uff0c\u5982\u679c\u4f18\u5148\u7ea7\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u518d\u6bd4\u8f83cpu\u7528\u91cf\uff0c\u5982\u679ccpu\u7528\u91cf\u4e5f\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u7ee7\u7eed\u6bd4\u8f83ext cpu\u8d44\u6e90\u7528\u91cf\uff08\u8fd9\u4e2a\u662fcpu\u5c5e\u6027\u8f83\u4e3a\u7279\u6b8a\u7684\u4e00\u70b9\uff09, \u6700\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u5f53\u67d0\u4e00\u4e2a\u6307\u6807\u5b58\u5728\u5dee\u5f02\u65f6\u5373\u53ef\u8fd4\u56de\u6bd4\u8f83\u7ed3\u679c func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ). Sort ( pods ) } ext cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f \u4f1a\u9996\u5148\u6bd4\u8f83\u4e24\u4e2apod\u662f\u5426\u4f7f\u7528\u4e86\u6269\u5c55\u7684cpu\u8d44\u6e90\uff0c\u5728\u90fd\u4f7f\u7528\u4e86\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u8f83 \u6269\u5c55cpu\u8d44\u6e90\u4f7f\u7528\u91cf/ \u6269\u5c55cpu\u8d44\u6e90limit\u7684\u6bd4\u503c \u9488\u5bf9\u9700\u8981\u81ea\u5b9a\u4e49\u7684\u6307\u6807\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0\u5982\u4e0b\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u968f\u610f\u642d\u914d\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0pod\u7684\u7075\u6d3b\u81ea\u5b9a\u4e49\u6392\u5e8f\uff0c\u4ee5 \u4ee3\u8868\u81ea\u5b9a\u4e49metric\u6307\u6807\uff0c \u4ee3\u8868\u81ea\u5b9a\u4e49\u7684\u9488\u5bf9 \u7684\u6392\u5e8f\u7b56\u7565 func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } \u5176\u4e2d \u53ea\u9700\u8981\u5b9e\u73b0\u5982\u4e0b\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef func ( p1 , p2 podinfo . PodContext ) int32","title":"\u4e30\u5bccpod\u7684\u6392\u5e8f\u7b56\u7565"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#metric","text":"\u4e3a\u4e86\u66f4\u597d\u7684\u57fa\u4e8eNodeQOSEnsurancePolicy\u914d\u7f6e\u7684metric\u8fdb\u884c\u6392\u5e8f\u548c\u7cbe\u51c6\u63a7\u5236\uff0c\u5bf9metric\u5f15\u5165\u5c5e\u6027\u7684\u6982\u5ff5\u3002 metric\u7684\u5c5e\u6027\u5305\u542b\u5982\u4e0b\u51e0\u4e2a\uff1a Name \u8868\u660e\u4e86metric\u7684\u540d\u79f0\uff0c\u9700\u8981\u540ccollector\u6a21\u5757\u4e2d\u6536\u96c6\u5230\u7684\u6307\u6807\u540d\u79f0\u4e00\u81f4 ActionPriority \u8868\u793a\u6307\u6807\u7684\u4f18\u5148\u7ea7\uff0c0\u4e3a\u6700\u4f4e\uff0c10\u4e3a\u6700\u9ad8 SortAble \u8868\u660e\u8be5\u6307\u6807\u662f\u5426\u53ef\u4ee5\u6392\u5e8f SortFunc \u5bf9\u5e94\u7684\u6392\u5e8f\u65b9\u6cd5\uff0c\u6392\u5e8f\u65b9\u6cd5\u53ef\u4ee5\u6392\u5217\u7ec4\u5408\u4e00\u4e9b\u901a\u7528\u65b9\u6cd5\uff0c\u518d\u7ed3\u5408\u6307\u6807\u81ea\u8eab\u7684\u6392\u5e8f\uff0c\u5c06\u5728\u4e0b\u6587\u8be6\u7ec6\u4ecb\u7ecd ThrottleAble \u8868\u660e\u9488\u5bf9\u8be5\u6307\u6807\uff0c\u662f\u5426\u53ef\u4ee5\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u4f8b\u5982\u9488\u5bf9cpu\u4f7f\u7528\u91cf\u8fd9\u4e2ametric\uff0c\u5c31\u6709\u76f8\u5bf9\u5e94\u7684\u538b\u5236\u624b\u6bb5\uff0c\u4f46\u662f\u5bf9\u4e8ememory\u4f7f\u7528\u91cf\u8fd9\u79cd\u6307\u6807\uff0c\u5c31\u53ea\u80fd\u8fdb\u884cpod\u7684\u9a71\u9010\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u538b\u5236 ThrottleQuantified \u8868\u660e\u538b\u5236\uff08restore\uff09\u4e00\u4e2apod\u540e\uff0c\u80fd\u5426\u51c6\u786e\u8ba1\u7b97\u51fa\u7ecf\u8fc7\u538b\u5236\u540e\u91ca\u653e\u51fa\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u6211\u4eec\u5c06\u53ef\u4ee5\u51c6\u786e\u91cf\u5316\u7684\u6307\u6807\u79f0\u4e3a\u53efQuantified\uff0c\u5426\u5219\u4e3a\u4e0d\u53efQuantified\uff1b \u6bd4\u5982cpu\u7528\u91cf\uff0c\u53ef\u4ee5\u901a\u8fc7\u9650\u5236cgroup\u7528\u91cf\u8fdb\u884c\u538b\u5236\uff0c\u540c\u65f6\u53ef\u4ee5\u901a\u8fc7\u5f53\u524d\u8fd0\u884c\u503c\u548c\u538b\u5236\u540e\u7684\u503c\u8ba1\u7b97\u538b\u5236\u540e\u91ca\u653e\u7684cpu\u4f7f\u7528\u91cf\uff1b\u800c\u6bd4\u5982memory usage\u5c31\u4e0d\u5c5e\u4e8e\u538b\u5236\u53ef\u91cf\u5316metric\uff0c\u56e0\u4e3amemory\u6ca1\u6709\u5bf9\u5e94\u7684throttle\u5b9e\u73b0\uff0c\u4e5f\u5c31\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u538b\u5236\u4e00\u4e2apod\u540e\u91ca\u653e\u51fa\u6765\u7684memory\u8d44\u6e90\u5177\u4f53\u7528\u91cf\uff1b ThrottleFunc\uff0c\u6267\u884cThrottle\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efThrottle\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a RestoreFunc\uff0c\u88abThrottle\u540e\uff0c\u6267\u884c\u6062\u590d\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efRestore\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a EvictAble\uff0cEvictQuantified\uff0cEvictFunc \u5bf9evict\u52a8\u4f5c\u7684\u76f8\u5173\u5b9a\u4e49\uff0c\u5177\u4f53\u5185\u5bb9\u548cThrottle\u52a8\u4f5c\u7c7b\u4f3c type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } \u7528\u6237\u53ef\u4ee5\u81ea\u884c\u5b9a\u4e49\u81ea\u5df1\u7684metric\uff0c\u5728\u6784\u9020\u5b8c\u6210\u540e\uff0c\u901a\u8fc7registerMetricMap()\u8fdb\u884c\u6ce8\u518c\u5373\u53ef","title":"metric\u5c5e\u6027\u7684\u5b9a\u4e49"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#_1","text":"\u6839\u636e\u591a\u4e2aNodeQOSEnsurancePolicy\u53ca\u5176\u4e2d\u7684objectiveEnsurances\u6784\u5efa\u591a\u6761\u6c34\u4f4d\u7ebf: \u6309\u7167objectiveEnsurances\u5bf9\u5e94\u7684action\u8fdb\u884c\u5206\u7c7b\uff0c\u76ee\u524dcrane-agent\u67093\u4e2a\u9488\u5bf9\u8282\u70b9Qos\u8fdb\u884c\u4fdd\u969c\u7684\u64cd\u4f5c\uff0c\u5206\u522b\u662fEvict\uff0cThtottleDown\uff08\u5f53\u524d\u7528\u91cf\u9ad8\u4e8eobjectiveEnsurances\u4e2d\u7684\u503c\u65f6\u5bf9pod\u8fdb\u884c\u7528\u91cf\u538b\u5236\uff09\u548cThrottleUp\uff08\u5f53\u524d\u7528\u91cf\u4f4e\u4e8eobjectiveEnsurances\u4e2d\u7684\u503c\u65f6\u5bf9pod\u7684\u7528\u91cf\u8fdb\u884c\u653e\u5bbd\u6062\u590d\uff09\uff0c\u56e0\u6b64\u4f1a\u6709\u4e09\u4e2a\u6c34\u4f4d\u7ebf\u96c6\u5408\uff0c\u5206\u522b\u662f ThrottleDownWaterLine\uff0cThrottleUpWaterLine\u548cEvictWaterLine \u518d\u5bf9\u540c\u4e00\u64cd\u4f5c\u79cd\u7c7b\u4e2d\u7684\u6c34\u4f4d\u7ebf\u6309\u7167\u5176metric rule\uff08\u56fe\u4e2d\u4ee5metric A\uff0cmetric Z\u4f5c\u4e3a\u793a\u610f\uff09\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u8bb0\u5f55\u6bcf\u4e2aobjectiveEnsurances\u6c34\u4f4d\u7ebf\u7684\u503c\uff0c\u8bb0\u4e3awaterLine\uff1b ThrottleDownWaterLine\uff0cThrottleUpWaterLine\u548cEvictWaterLine\u7684\u7ed3\u6784\u662f\u8fd9\u6837\u7684\uff1a type WaterLines map[WaterLineMetric]*WaterLine \u5176\u4e2dWaterLineMetric\u5c31\u662f\u4e0a\u9762\u7684metric\u7684Name\u5b57\u6bb5\uff0cvalue\u7684WaterLine\u5c31\u662f\u8d44\u6e90\u6570\u503c type WaterLine resource.Quantity \u6700\u7ec8\u5f62\u6210\u4e00\u4e2a\u7c7b\u4f3c\u4e0b\u56fe\u7684\u6570\u636e\u5b58\u50a8\uff1a \u6784\u9020\u5b9e\u65f6\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c\uff1a \u7ed3\u5408\u5f53\u524d\u8282\u70b9\u7684\u6307\u6807\u5b9e\u65f6\u7528\u91cf\u4e0eWaterLines\u4e2d\u8be5\u6307\u6807\u5bf9\u5e94\u7684\u6c34\u4f4d\u7ebf\u4e2d\u6700\u5c0f\u503c\u7684\u5dee\u503c\u6784\u9020\u5982\u4e0b\u7684\u6570\u636e\u7ed3\u6784\uff0c\u4ee3\u8868\u5230\u5f53\u524d\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c type GapToWaterLines map[WaterLineMetric]float64 \u5176\u4e2dkey\u503c\u4e3ametric\u7684Name\u5b57\u6bb5\uff0cvalue\u4e3a\u7528\u91cf\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c\uff1b \u9700\u8981\u6ce8\u610f\u5bf9\u4e8eThrottleUp\uff0c\u9700\u8981\u7528\u6c34\u4f4d\u7ebf\u6700\u5c0f\u503c-\u5f53\u524d\u7528\u91cf\u4f5c\u4e3agap\u503c\uff0c\u5bf9\u4e8e\u5176\u4ed6\u4e24\u8005\uff0c\u4f7f\u7528\u5f53\u524d\u7528\u91cf-\u6c34\u4f4d\u7ebf\u6700\u5c0f\u503c\u4f5c\u4e3agap\u503c\uff0c\u5373\u59cb\u7ec8\u4fdd\u6301gap\u503c\u4e3a\u6b63 \u4e0b\u9762\u4e09\u4e2a\u6570\u636e\u5206\u522b\u4ee3\u8868\u4e86\u9700\u8981\u6267\u884cevict\uff0cThtottleDown\u548cThrottleUp\u64cd\u4f5c\u7684\u6307\u6807\u53ca\u5176\u5bf9\u5e94\u7684\u5230\u6700\u4f4e\u6c34\u4f4d\u7ebf\u7684\u5dee\u503c EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] \u4ee5CpuUsage\u8fd9\u4e2ametric\u4e3a\u4f8b\uff0c\u6784\u9020\u8282\u70b9cpu\u7528\u91cf\u76f8\u5173\u7684waterline\u7684\u6d41\u7a0b\u548c\u76f8\u5173\u6570\u636e\u7ed3\u6784\u5982\u4e0b\uff1a","title":"\u5982\u4f55\u6839\u636e\u6c34\u4f4d\u7ebf\u8fdb\u884c\u7cbe\u51c6\u63a7\u5236"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#pod_1","text":"\u8be5proposal\u4e3a\u4e86\u5b9e\u73b0\u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u5c06\u5bf9analyzer\u90e8\u5206\u548cexecutor\u90e8\u5206\u505a\u4e00\u5b9a\u7684\u4fee\u6539\uff0c\u5927\u4f53\u6d41\u7a0b\u662f\uff1a \u5728analyzer\u9636\u6bb5\u6784\u9020\u9488\u5bf9\u4e0d\u540c\u64cd\u4f5c\uff08\u9a71\u9010\uff0c\u538b\u5236\u7b49\uff09\u548c\u4e0d\u540cmetric\u7684\u6c34\u4f4d\u7ebf\uff0c\u5c06\u539f\u5148\u7684\u6392\u5e8f\u903b\u8f91\u5220\u9664\uff0c\u540e\u79fb\u5230\u9700\u8981\u8fdb\u884c\u6b63\u5f0f\u64cd\u4f5c\u7684executor\u9636\u6bb5\uff0c\u5e76\u4e14\u53ef\u80fd\u4f1a\u9700\u8981\u8fdb\u884c\u591a\u8f6e\u6392\u5e8f\uff1b \u5728executor\u9636\u6bb5\uff0c\u6839\u636e\u6c34\u4f4d\u7ebf\u4e2d\u7684\u6d89\u53ca\u7684\u6307\u6807\u8fdb\u884c\u5176\u76f8\u5e94\u7684\u6392\u5e8f\uff0c\u83b7\u53d6\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020GapToWaterLines\uff0c\u5e76\u8fdb\u884c\u7cbe\u786e\u64cd\u4f5c","title":"\u4ee5\u6c34\u4f4d\u7ebf\u4e3a\u57fa\u51c6\u8fdb\u884cpod\u7684\u7cbe\u786e\u64cd\u4f5c"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#analyzer","text":"\u5728\u8be5\u9636\u6bb5\u8fdb\u884cNodeQOSEnsurancePolicy\u5230WaterLines\u7684\u8f6c\u6362\uff0c\u5e76\u5bf9\u76f8\u540cactionName\u548cmetricrule\u7684\u89c4\u5219\u8fdb\u884c\u5408\u5e76\uff0c\u5177\u4f53\u5185\u5bb9\u4e0a\u6587\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86","title":"analyzer\u9636\u6bb5"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#executor","text":"\u538b\u5236\u8fc7\u7a0b\uff1a \u9996\u5148\u5206\u6790ThrottoleDownGapToWaterLines\u4e2d\u6d89\u53ca\u7684metrics\uff0c\u5c06\u8fd9\u4e9bmetrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u5219\u901a\u8fc7GetHighestPriorityThrottleAbleMetric\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\uff08\u5177\u6709throttleFunc\uff09\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c\uff0c\u56e0\u4e3a\u4f46\u51e1\u5b58\u5728\u4e00\u4e2a\u4e0d\u53efQuantified\u7684metric\uff0c\u5c31\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c \u901a\u8fc7getStateFunc()\u83b7\u53d6\u5f53\u524d\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u4f9d\u636eThrottoleDownGapToWaterLines\u548c\u5b9e\u65f6\u7528\u91cf\u6784\u9020GapToWaterLine\uff08\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6784\u9020GapToWaterLine\u65f6\uff0c\u4f1a\u4ee5\u6ce8\u518c\u8fc7\u7684metric\u8fdb\u884c\u904d\u5386\uff0c\u6240\u4ee5\u6700\u7ec8\u6784\u9020\u51fa\u6765\u7684GapToWaterLine\u4e2d\u7684metrics\uff0c\u4f1a\u662fThrottoleDownGapToWaterLines \u4e2d\u6ce8\u518c\u8fc7\u7684metric\uff0c\u907f\u514d\u4e86\u5728NodeQOSEnsurancePolicy\u4e2d\u914d\u7f6e\u9519\u8bef\u4e0d\u5b58\u5728\u6216\u672a\u6ce8\u518cmetric\u7684\u60c5\u51b5\uff09 \u5982\u679cGapToWaterLine\u4e2d\u6709metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff08HasUsageMissedMetric\uff09\uff0c\u5219\u901a\u8fc7GetHighestPriorityThrottleAbleMetric\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\uff08\u5177\u6709throttleFunc\uff09\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c\uff0c\u56e0\u4e3a\u5982\u679c\u5b58\u5728metric\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5c31\u65e0\u6cd5\u83b7\u77e5\u548c\u6c34\u4f4d\u7ebf\u7684gap\uff0c\u4e5f\u5c31\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u7684\u64cd\u4f5c \u5982\u679c\u4e0d\u5b58\u57283\u4e2d\u7684\u60c5\u51b5\uff0c\u5219\u904d\u5386ThrottoleDownGapToWaterLines\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5982\u679c\u6ca1\u6709\u5c31\u4f7f\u7528GeneralSorter\u8fdb\u884c\u6392\u5e8f\uff0c\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684ThrottleFunc\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230ThrottoleDownGapToWaterLines\u4e2d\u8be5metric\u5bf9\u5e94\u7684gap\u5df2\u4e0d\u5b58\u5728 //\u5c06\u6240\u6709\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206 metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // \u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u64cd\u4f5c if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { //\u83b7\u53d6\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020\u548c\u6c34\u4f4d\u7ebf\u5dee\u8ddd ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //\u5982\u679c\u89e6\u53d1\u6c34\u4f4d\u7ebf\u4e2d\u5b58\u5728metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5219\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource //\u904d\u5386\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metric\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5426\u5219\u4f7f\u7528GeneralSorter\u6392\u5e8f\uff1b //\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684\u64cd\u4f5c\u65b9\u6cd5\u5bf9pod\u6267\u884c\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230\u5bf9\u5e94metric\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\u5df2\u4e0d\u5b58\u5728 for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } \u9a71\u9010\u8fc7\u7a0b\uff1a \u9a71\u9010\u548c\u538b\u5236\u7684\u6d41\u7a0b\u662f\u4e00\u6837\u7684\uff0c\u9664\u4e86\u5728\u5bf9pod\u8fdb\u884c\u64cd\u4f5c\u7684\u65f6\u5019\u9700\u8981\u989d\u5916\u5224\u65ad\u4e00\u4e0bpod\u662f\u5426\u5df2\u7ecf\u88ab\u9a71\u9010\u4e86\uff1b\u53d6\u51fa\u4e00\u4e2a\u6ca1\u6709\u6267\u884c\u8fc7\u7684pod\uff0c\u6267\u884c\u9a71\u9010\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u7684\u5404metric\u8d44\u6e90\u91cf\uff0c\u540c\u65f6\u5728\u5bf9\u5e94\u6c34\u4f4d\u7ebf\u4e2d\u51cf\u53bb\u91ca\u653e\u7684\u503c\uff0c\u76f4\u5230\u6ee1\u8db3\u5f53\u524dmetric\u6c34\u4f4d\u7ebf\u8981\u6c42 metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } }","title":"executor\u9636\u6bb5"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#non-goalsfuture-work","text":"\u5f53\u524d\u53ea\u652f\u6301cpu usage\u7684\u7cbe\u786e\u64cd\u4f5c\uff0c\u4f46\u662f\u6846\u67b6\u53ef\u4ee5\u590d\u7528\uff0c\u540e\u7eed\u53ef\u4ee5\u57fa\u4e8e\u7cbe\u51c6\u63a7\u5236\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u66f4\u591a\u7ef4\u5ea6\u6307\u6807\u7684\u7cbe\u51c6\u63a7\u5236\u3002 \u5728\u505a\u7cbe\u51c6\u63a7\u5236\u65f6\uff0c\u76ee\u524d\u53ea\u8003\u8651metric\u672c\u8eab\u91ca\u653e\u91cf\uff0c\u672a\u8003\u8651\u4e0d\u540cmetric\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd\u3002\u6bd4\u5982\u538b\u5236cpu usage\u65f6\uff0cmemory usage\u4e5f\u4f1a\u53d7\u5230\u5f71\u54cd\u3002\u5982\u679c\u6307\u6807\u975e\u5e38\u591a\uff0c\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\u4f1a\u975e\u5e38\u590d\u6742\uff0c\u6240\u4ee5\u6682\u65f6\u4e0d\u8003\u8651\u4e0d\u540cmetric\u76f4\u63a5\u7684\u76f8\u4e92\u5f71\u54cd\u3002","title":"Non-Goals/Future Work"},{"location":"zh/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#user-stories","text":"\u7528\u6237\u53ef\u4ee5\u4f7f\u7528crane-agent\u8fdb\u884c\u66f4\u597d\u7684QoS\u4fdd\u969c\u3002\u652f\u6301\u66f4\u5feb\u901f\u7684\u964d\u4f4e\u8282\u70b9\u8d1f\u8f7d\uff0c\u4ee5\u4fdd\u969c\u9ad8\u4f18\u5148\u7ea7\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd\u3002\u540c\u65f6\u5bf9\u4f4e\u4f18\u5148\u7ea7\u4e1a\u52a1\u7684\u538b\u5236/\u9a71\u9010\u52a8\u4f5c\uff0c\u8fdb\u884c\u7cbe\u786e\u63a7\u5236\uff0c\u907f\u514d\u8fc7\u5ea6\u64cd\u4f5c\u3002 \u7528\u6237\u53ef\u4ee5\u501f\u52a9\u5b9e\u73b0\u7684\u7cbe\u51c6\u64cd\u4f5c(\u538b\u5236/\u9a71\u9010)\u7684\u6846\u67b6\uff0c\u5728\u65e0\u9700\u5173\u5fc3\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5b9e\u73b0\u81ea\u5b9a\u4e49metric\u76f8\u5173\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0\u4ee5\u81ea\u5b9a\u4e49metric\u4e3a\u6838\u5fc3\u7684\u5177\u6709\u7cbe\u786e\u64cd\u4f5c\u548c\u6392\u5e8f\u80fd\u529b\u7684QoS\u529f\u80fd\u3002","title":"User Stories"},{"location":"zh/roadmaps/roadmap-2022/","text":"Crane Roadmap for 2022 \u00b6 Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan. 0.1.0 [released] \u00b6 Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing 0.2.0\uff1a[released] \u00b6 Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio 0.3.0 [released] \u00b6 UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA 0.4.0 [released] \u00b6 UI to support EPA. 0.5.0 [released] \u00b6 Resource and Replicas Recommendation Load-aware Scheduler 0.6.0 [released] \u00b6 Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics 0.7.0 [July] \u00b6 Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator 0.8.0 [August] \u00b6 External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization 0.9.0 [September] \u00b6 Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard 0.10.0 [October] \u00b6 Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison 0.11.0 [November] \u00b6 Multi-cluster cost dashboard 0.12.0 [December] \u00b6 Multi-cluster cost optimization","title":2022},{"location":"zh/roadmaps/roadmap-2022/#crane-roadmap-for-2022","text":"Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan.","title":"Crane Roadmap for 2022"},{"location":"zh/roadmaps/roadmap-2022/#010-released","text":"Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing","title":"0.1.0 [released]"},{"location":"zh/roadmaps/roadmap-2022/#020released","text":"Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio","title":"0.2.0\uff1a[released]"},{"location":"zh/roadmaps/roadmap-2022/#030-released","text":"UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA","title":"0.3.0 [released]"},{"location":"zh/roadmaps/roadmap-2022/#040-released","text":"UI to support EPA.","title":"0.4.0 [released]"},{"location":"zh/roadmaps/roadmap-2022/#050-released","text":"Resource and Replicas Recommendation Load-aware Scheduler","title":"0.5.0 [released]"},{"location":"zh/roadmaps/roadmap-2022/#060-released","text":"Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics","title":"0.6.0 [released]"},{"location":"zh/roadmaps/roadmap-2022/#070-july","text":"Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator","title":"0.7.0 [July]"},{"location":"zh/roadmaps/roadmap-2022/#080-august","text":"External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization","title":"0.8.0 [August]"},{"location":"zh/roadmaps/roadmap-2022/#090-september","text":"Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard","title":"0.9.0 [September]"},{"location":"zh/roadmaps/roadmap-2022/#0100-october","text":"Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison","title":"0.10.0 [October]"},{"location":"zh/roadmaps/roadmap-2022/#0110-november","text":"Multi-cluster cost dashboard","title":"0.11.0 [November]"},{"location":"zh/roadmaps/roadmap-2022/#0120-december","text":"Multi-cluster cost optimization","title":"0.12.0 [December]"},{"location":"zh/tutorials/analytics-and-recommendation/","text":"\u667a\u80fd\u63a8\u8350 \u00b6 \u667a\u80fd\u63a8\u8350\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u81ea\u52a8\u5206\u6790\u96c6\u7fa4\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002\u5c31\u50cf\u624b\u673a\u52a9\u624b\u4e00\u6837\uff0c\u667a\u80fd\u63a8\u8350\u4f1a\u5b9a\u671f\u7684\u626b\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u5e76\u7ed9\u51fa\u63a8\u8350\u5efa\u8bae\u3002\u76ee\u524d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u4f18\u5316\u80fd\u529b\uff1a \u8d44\u6e90\u63a8\u8350 : \u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6570\u63a8\u8350 : \u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u5e94\u7528\u53ef\u4ee5\u6839\u636e\u8d44\u6e90\u63a8\u8350\u8c03\u6574 request \u4e5f\u53ef\u4ee5\u6839\u636e\u526f\u672c\u6570\u63a8\u8350\u8c03\u6574\u526f\u672c\u6570\uff0c\u8fd9\u4e24\u79cd\u4f18\u5316\u90fd\u80fd\u5e2e\u52a9\u60a8\u964d\u4f4e\u6210\u672c\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u60a8\u7684\u9700\u6c42\u9009\u62e9\u91c7\u7528\u76f8\u5e94\u7684\u4f18\u5316\u5efa\u8bae\u3002 \u67b6\u6784 \u00b6 \u4e00\u6b21\u5206\u6790\u7684\u8fc7\u7a0b \u00b6 \u7528\u6237\u521b\u5efa Analytics \u5bf9\u8c61\uff0c\u901a\u8fc7 ResourceSelector \u9009\u62e9\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0c\u652f\u6301\u9009\u62e9\u591a\u7c7b\u578b\uff08\u57fa\u4e8eGroup,Kind,Version\uff09\u7684\u6279\u91cf\u9009\u62e9 \u5e76\u884c\u5206\u6790\u6bcf\u4e2a\u9009\u62e9\u7684\u8d44\u6e90\uff0c\u5c1d\u8bd5\u8fdb\u884c\u5206\u6790\u63a8\u8350\uff0c\u6bcf\u6b21\u5206\u6790\u8fc7\u7a0b\u5206\u6210\u7b5b\u9009\u548c\u63a8\u8350\u4e24\u4e2a\u9636\u6bb5\uff1a \u7b5b\u9009\uff1a\u6392\u9664\u4e0d\u6ee1\u8db3\u63a8\u8350\u6761\u4ef6\u7684\u8d44\u6e90\u3002\u6bd4\u5982\u5bf9\u4e8e\u5f39\u6027\u63a8\u8350\uff0c\u6392\u9664\u6ca1\u6709 running pod \u7684 workload \u63a8\u8350\uff1a\u901a\u8fc7\u7b97\u6cd5\u8ba1\u7b97\u5206\u6790\uff0c\u7ed9\u51fa\u63a8\u8350\u7ed3\u679c \u5982\u679c\u901a\u8fc7\u7b5b\u9009\uff0c\u521b\u5efa Recommendation \u5bf9\u8c61\uff0c\u5c06\u63a8\u8350\u7ed3\u679c\u5c55\u793a\u5728 Recommendation.Status \u672a\u901a\u8fc7\u7b5b\u9009\u7684\u539f\u56e0\u548c\u72b6\u6001\u5c55\u793a\u5728 Analytics.Status \u6839\u636e\u8fd0\u884c\u95f4\u9694\u7b49\u5f85\u4e0b\u6b21\u5206\u6790 \u540d\u8bcd\u89e3\u91ca \u00b6 \u5206\u6790 \u00b6 \u5206\u6790\u5b9a\u4e49\u4e86\u4e00\u4e2a\u626b\u63cf\u5206\u6790\u4efb\u52a1\u3002\u652f\u6301\u4e24\u79cd\u4efb\u52a1\u7c7b\u578b\uff1a\u8d44\u6e90\u63a8\u8350\u548c\u5f39\u6027\u63a8\u8350\u3002Crane \u5b9a\u671f\u8fd0\u884c\u5206\u6790\u4efb\u52a1\uff0c\u5e76\u4ea7\u751f\u63a8\u8350\u7ed3\u679c\u3002 \u63a8\u8350 \u00b6 \u63a8\u8350\u5c55\u793a\u4e86\u4e00\u4e2a\u4f18\u5316\u63a8\u8350\u7684\u7ed3\u679c\u3002\u63a8\u8350\u7684\u7ed3\u679c\u662f\u4e00\u6bb5 YAML \u914d\u7f6e\uff0c\u6839\u636e\u7ed3\u679c\u7528\u6237\u53ef\u4ee5\u8fdb\u884c\u76f8\u5e94\u7684\u4f18\u5316\u52a8\u4f5c\uff0c\u6bd4\u5982\u8c03\u6574\u5e94\u7528\u7684\u8d44\u6e90\u914d\u7f6e\u3002 \u53c2\u6570\u914d\u7f6e \u00b6 \u4e0d\u540c\u7684\u5206\u6790\u91c7\u7528\u4e0d\u540c\u7684\u8ba1\u7b97\u6a21\u578b\uff0cCrane \u63d0\u4f9b\u4e86\u4e00\u5957\u9ed8\u8ba4\u7684\u8ba1\u7b97\u6a21\u578b\u4ee5\u53ca\u4e00\u5957\u914d\u5957\u7684\u914d\u7f6e\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u914d\u7f6e\u6765\u5b9a\u5236\u63a8\u8350\u7684\u6548\u679c\u3002\u652f\u6301\u4fee\u6539\u5168\u5c40\u7684\u9ed8\u8ba4\u914d\u7f6e\u548c\u4fee\u6539\u5355\u4e2a\u5206\u6790\u4efb\u52a1\u7684\u914d\u7f6e\u3002","title":"\u63a8\u8350\u603b\u4f53\u4ecb\u7ecd"},{"location":"zh/tutorials/analytics-and-recommendation/#_1","text":"\u667a\u80fd\u63a8\u8350\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u81ea\u52a8\u5206\u6790\u96c6\u7fa4\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002\u5c31\u50cf\u624b\u673a\u52a9\u624b\u4e00\u6837\uff0c\u667a\u80fd\u63a8\u8350\u4f1a\u5b9a\u671f\u7684\u626b\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u5e76\u7ed9\u51fa\u63a8\u8350\u5efa\u8bae\u3002\u76ee\u524d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e24\u79cd\u4f18\u5316\u80fd\u529b\uff1a \u8d44\u6e90\u63a8\u8350 : \u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6570\u63a8\u8350 : \u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u5e94\u7528\u53ef\u4ee5\u6839\u636e\u8d44\u6e90\u63a8\u8350\u8c03\u6574 request \u4e5f\u53ef\u4ee5\u6839\u636e\u526f\u672c\u6570\u63a8\u8350\u8c03\u6574\u526f\u672c\u6570\uff0c\u8fd9\u4e24\u79cd\u4f18\u5316\u90fd\u80fd\u5e2e\u52a9\u60a8\u964d\u4f4e\u6210\u672c\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u60a8\u7684\u9700\u6c42\u9009\u62e9\u91c7\u7528\u76f8\u5e94\u7684\u4f18\u5316\u5efa\u8bae\u3002","title":"\u667a\u80fd\u63a8\u8350"},{"location":"zh/tutorials/analytics-and-recommendation/#_2","text":"","title":"\u67b6\u6784"},{"location":"zh/tutorials/analytics-and-recommendation/#_3","text":"\u7528\u6237\u521b\u5efa Analytics \u5bf9\u8c61\uff0c\u901a\u8fc7 ResourceSelector \u9009\u62e9\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0c\u652f\u6301\u9009\u62e9\u591a\u7c7b\u578b\uff08\u57fa\u4e8eGroup,Kind,Version\uff09\u7684\u6279\u91cf\u9009\u62e9 \u5e76\u884c\u5206\u6790\u6bcf\u4e2a\u9009\u62e9\u7684\u8d44\u6e90\uff0c\u5c1d\u8bd5\u8fdb\u884c\u5206\u6790\u63a8\u8350\uff0c\u6bcf\u6b21\u5206\u6790\u8fc7\u7a0b\u5206\u6210\u7b5b\u9009\u548c\u63a8\u8350\u4e24\u4e2a\u9636\u6bb5\uff1a \u7b5b\u9009\uff1a\u6392\u9664\u4e0d\u6ee1\u8db3\u63a8\u8350\u6761\u4ef6\u7684\u8d44\u6e90\u3002\u6bd4\u5982\u5bf9\u4e8e\u5f39\u6027\u63a8\u8350\uff0c\u6392\u9664\u6ca1\u6709 running pod \u7684 workload \u63a8\u8350\uff1a\u901a\u8fc7\u7b97\u6cd5\u8ba1\u7b97\u5206\u6790\uff0c\u7ed9\u51fa\u63a8\u8350\u7ed3\u679c \u5982\u679c\u901a\u8fc7\u7b5b\u9009\uff0c\u521b\u5efa Recommendation \u5bf9\u8c61\uff0c\u5c06\u63a8\u8350\u7ed3\u679c\u5c55\u793a\u5728 Recommendation.Status \u672a\u901a\u8fc7\u7b5b\u9009\u7684\u539f\u56e0\u548c\u72b6\u6001\u5c55\u793a\u5728 Analytics.Status \u6839\u636e\u8fd0\u884c\u95f4\u9694\u7b49\u5f85\u4e0b\u6b21\u5206\u6790","title":"\u4e00\u6b21\u5206\u6790\u7684\u8fc7\u7a0b"},{"location":"zh/tutorials/analytics-and-recommendation/#_4","text":"","title":"\u540d\u8bcd\u89e3\u91ca"},{"location":"zh/tutorials/analytics-and-recommendation/#_5","text":"\u5206\u6790\u5b9a\u4e49\u4e86\u4e00\u4e2a\u626b\u63cf\u5206\u6790\u4efb\u52a1\u3002\u652f\u6301\u4e24\u79cd\u4efb\u52a1\u7c7b\u578b\uff1a\u8d44\u6e90\u63a8\u8350\u548c\u5f39\u6027\u63a8\u8350\u3002Crane \u5b9a\u671f\u8fd0\u884c\u5206\u6790\u4efb\u52a1\uff0c\u5e76\u4ea7\u751f\u63a8\u8350\u7ed3\u679c\u3002","title":"\u5206\u6790"},{"location":"zh/tutorials/analytics-and-recommendation/#_6","text":"\u63a8\u8350\u5c55\u793a\u4e86\u4e00\u4e2a\u4f18\u5316\u63a8\u8350\u7684\u7ed3\u679c\u3002\u63a8\u8350\u7684\u7ed3\u679c\u662f\u4e00\u6bb5 YAML \u914d\u7f6e\uff0c\u6839\u636e\u7ed3\u679c\u7528\u6237\u53ef\u4ee5\u8fdb\u884c\u76f8\u5e94\u7684\u4f18\u5316\u52a8\u4f5c\uff0c\u6bd4\u5982\u8c03\u6574\u5e94\u7528\u7684\u8d44\u6e90\u914d\u7f6e\u3002","title":"\u63a8\u8350"},{"location":"zh/tutorials/analytics-and-recommendation/#_7","text":"\u4e0d\u540c\u7684\u5206\u6790\u91c7\u7528\u4e0d\u540c\u7684\u8ba1\u7b97\u6a21\u578b\uff0cCrane \u63d0\u4f9b\u4e86\u4e00\u5957\u9ed8\u8ba4\u7684\u8ba1\u7b97\u6a21\u578b\u4ee5\u53ca\u4e00\u5957\u914d\u5957\u7684\u914d\u7f6e\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u914d\u7f6e\u6765\u5b9a\u5236\u63a8\u8350\u7684\u6548\u679c\u3002\u652f\u6301\u4fee\u6539\u5168\u5c40\u7684\u9ed8\u8ba4\u914d\u7f6e\u548c\u4fee\u6539\u5355\u4e2a\u5206\u6790\u4efb\u52a1\u7684\u914d\u7f6e\u3002","title":"\u53c2\u6570\u914d\u7f6e"},{"location":"zh/tutorials/dynamic-scheduler-plugin/","text":"Dynamic Scheduler\uff1a\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6\u5668\u63d2\u4ef6 \u00b6 \u4ecb\u7ecd \u00b6 kubernetes \u7684\u539f\u751f\u8c03\u5ea6\u5668\u53ea\u80fd\u901a\u8fc7\u8d44\u6e90\u8bf7\u6c42\u6765\u8c03\u5ea6 pod\uff0c\u8fd9\u5f88\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8d1f\u8f7d\u4e0d\u5747\u7684\u95ee\u9898\uff1a \u5bf9\u4e8e\u67d0\u4e9b\u8282\u70b9\uff0c\u5b9e\u9645\u8d1f\u8f7d\u4e0e\u8d44\u6e90\u8bf7\u6c42\u76f8\u5dee\u4e0d\u5927\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5f88\u5927\u6982\u7387\u51fa\u73b0\u7a33\u5b9a\u6027\u95ee\u9898\u3002 \u5bf9\u4e8e\u5176\u4ed6\u8282\u70b9\u6765\u8bf4\uff0c\u5b9e\u9645\u8d1f\u8f7d\u8fdc\u5c0f\u4e8e\u8d44\u6e90\u8bf7\u6c42\uff0c\u8fd9\u5c06\u5bfc\u81f4\u8d44\u6e90\u7684\u5de8\u5927\u6d6a\u8d39\u3002 \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u52a8\u6001\u8c03\u5ea6\u5668\u6839\u636e\u5b9e\u9645\u7684\u8282\u70b9\u5229\u7528\u7387\u6784\u5efa\u4e86\u4e00\u4e2a\u7b80\u5355\u4f46\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u5e76\u8fc7\u6ee4\u6389\u90a3\u4e9b\u8d1f\u8f7d\u9ad8\u7684\u8282\u70b9\u6765\u5e73\u8861\u96c6\u7fa4\u3002 \u8bbe\u8ba1\u7ec6\u8282 \u00b6 \u67b6\u6784 \u00b6 \u5982\u4e0a\u56fe\uff0c\u52a8\u6001\u8c03\u5ea6\u5668\u4f9d\u8d56\u4e8e Prometheus \u548c Node-exporter \u6536\u96c6\u548c\u6c47\u603b\u6307\u6807\u6570\u636e\uff0c\u5b83\u7531\u4e24\u4e2a\u7ec4\u4ef6\u7ec4\u6210\uff1a Note Node-annotator \u76ee\u524d\u662f Crane-scheduler-controller \u7684\u4e00\u4e2a\u6a21\u5757. Node-annotator \u5b9a\u671f\u4ece Prometheus \u62c9\u53d6\u6570\u636e\uff0c\u5e76\u4ee5\u6ce8\u91ca\u7684\u5f62\u5f0f\u5728\u8282\u70b9\u4e0a\u7528\u65f6\u95f4\u6233\u6807\u8bb0\u5b83\u4eec\u3002 Dynamic plugin \u76f4\u63a5\u4ece\u8282\u70b9\u7684\u6ce8\u91ca\u4e2d\u8bfb\u53d6\u8d1f\u8f7d\u6570\u636e\uff0c\u8fc7\u6ee4\u5e76\u57fa\u4e8e\u7b80\u5355\u7684\u7b97\u6cd5\u5bf9\u5019\u9009\u8282\u70b9\u8fdb\u884c\u8bc4\u5206\u3002 \u8c03\u5ea6\u7b56\u7565 \u00b6 \u52a8\u6001\u8c03\u5ea6\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ed8\u8ba4\u503c \u8c03\u5ea6\u7b56\u7565 \u5e76\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u7b56\u7565\u3002\u9ed8\u8ba4\u7b56\u7565\u4f9d\u8d56\u4e8e\u4ee5\u4e0b\u6307\u6807\uff1a cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d \u5728\u8c03\u5ea6\u7684 Filter \u9636\u6bb5\uff0c\u5982\u679c\u8be5\u8282\u70b9\u7684\u5b9e\u9645\u4f7f\u7528\u7387\u5927\u4e8e\u4e0a\u8ff0\u4efb\u4e00\u6307\u6807\u7684\u9608\u503c\uff0c\u5219\u8be5\u8282\u70b9\u5c06\u88ab\u8fc7\u6ee4\u3002\u800c\u5728 Score \u9636\u6bb5\uff0c\u6700\u7ec8\u5f97\u5206\u662f\u8fd9\u4e9b\u6307\u6807\u503c\u7684\u52a0\u6743\u548c\u3002 Hot Value \u00b6 \u5728\u751f\u4ea7\u96c6\u7fa4\u4e2d\uff0c\u53ef\u80fd\u4f1a\u9891\u7e41\u51fa\u73b0\u8c03\u5ea6\u70ed\u70b9\uff0c\u56e0\u4e3a\u521b\u5efa Pod \u540e\u8282\u70b9\u7684\u8d1f\u8f7d\u4e0d\u80fd\u7acb\u5373\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u6307\u6807\uff0c\u540d\u4e3a Hot Value \uff0c\u8868\u793a\u8282\u70b9\u6700\u8fd1\u51e0\u6b21\u7684\u8c03\u5ea6\u9891\u7387\u3002\u5e76\u4e14\u8282\u70b9\u7684\u6700\u7ec8\u4f18\u5148\u7ea7\u662f\u6700\u7ec8\u5f97\u5206\u51cf\u53bb Hot Value \u3002","title":"\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#dynamic-scheduler","text":"","title":"Dynamic Scheduler\uff1a\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6\u5668\u63d2\u4ef6"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#_1","text":"kubernetes \u7684\u539f\u751f\u8c03\u5ea6\u5668\u53ea\u80fd\u901a\u8fc7\u8d44\u6e90\u8bf7\u6c42\u6765\u8c03\u5ea6 pod\uff0c\u8fd9\u5f88\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8d1f\u8f7d\u4e0d\u5747\u7684\u95ee\u9898\uff1a \u5bf9\u4e8e\u67d0\u4e9b\u8282\u70b9\uff0c\u5b9e\u9645\u8d1f\u8f7d\u4e0e\u8d44\u6e90\u8bf7\u6c42\u76f8\u5dee\u4e0d\u5927\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5f88\u5927\u6982\u7387\u51fa\u73b0\u7a33\u5b9a\u6027\u95ee\u9898\u3002 \u5bf9\u4e8e\u5176\u4ed6\u8282\u70b9\u6765\u8bf4\uff0c\u5b9e\u9645\u8d1f\u8f7d\u8fdc\u5c0f\u4e8e\u8d44\u6e90\u8bf7\u6c42\uff0c\u8fd9\u5c06\u5bfc\u81f4\u8d44\u6e90\u7684\u5de8\u5927\u6d6a\u8d39\u3002 \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u52a8\u6001\u8c03\u5ea6\u5668\u6839\u636e\u5b9e\u9645\u7684\u8282\u70b9\u5229\u7528\u7387\u6784\u5efa\u4e86\u4e00\u4e2a\u7b80\u5355\u4f46\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u5e76\u8fc7\u6ee4\u6389\u90a3\u4e9b\u8d1f\u8f7d\u9ad8\u7684\u8282\u70b9\u6765\u5e73\u8861\u96c6\u7fa4\u3002","title":"\u4ecb\u7ecd"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#_2","text":"","title":"\u8bbe\u8ba1\u7ec6\u8282"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#_3","text":"\u5982\u4e0a\u56fe\uff0c\u52a8\u6001\u8c03\u5ea6\u5668\u4f9d\u8d56\u4e8e Prometheus \u548c Node-exporter \u6536\u96c6\u548c\u6c47\u603b\u6307\u6807\u6570\u636e\uff0c\u5b83\u7531\u4e24\u4e2a\u7ec4\u4ef6\u7ec4\u6210\uff1a Note Node-annotator \u76ee\u524d\u662f Crane-scheduler-controller \u7684\u4e00\u4e2a\u6a21\u5757. Node-annotator \u5b9a\u671f\u4ece Prometheus \u62c9\u53d6\u6570\u636e\uff0c\u5e76\u4ee5\u6ce8\u91ca\u7684\u5f62\u5f0f\u5728\u8282\u70b9\u4e0a\u7528\u65f6\u95f4\u6233\u6807\u8bb0\u5b83\u4eec\u3002 Dynamic plugin \u76f4\u63a5\u4ece\u8282\u70b9\u7684\u6ce8\u91ca\u4e2d\u8bfb\u53d6\u8d1f\u8f7d\u6570\u636e\uff0c\u8fc7\u6ee4\u5e76\u57fa\u4e8e\u7b80\u5355\u7684\u7b97\u6cd5\u5bf9\u5019\u9009\u8282\u70b9\u8fdb\u884c\u8bc4\u5206\u3002","title":"\u67b6\u6784"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#_4","text":"\u52a8\u6001\u8c03\u5ea6\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ed8\u8ba4\u503c \u8c03\u5ea6\u7b56\u7565 \u5e76\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u7b56\u7565\u3002\u9ed8\u8ba4\u7b56\u7565\u4f9d\u8d56\u4e8e\u4ee5\u4e0b\u6307\u6807\uff1a cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d \u5728\u8c03\u5ea6\u7684 Filter \u9636\u6bb5\uff0c\u5982\u679c\u8be5\u8282\u70b9\u7684\u5b9e\u9645\u4f7f\u7528\u7387\u5927\u4e8e\u4e0a\u8ff0\u4efb\u4e00\u6307\u6807\u7684\u9608\u503c\uff0c\u5219\u8be5\u8282\u70b9\u5c06\u88ab\u8fc7\u6ee4\u3002\u800c\u5728 Score \u9636\u6bb5\uff0c\u6700\u7ec8\u5f97\u5206\u662f\u8fd9\u4e9b\u6307\u6807\u503c\u7684\u52a0\u6743\u548c\u3002","title":"\u8c03\u5ea6\u7b56\u7565"},{"location":"zh/tutorials/dynamic-scheduler-plugin/#hot-value","text":"\u5728\u751f\u4ea7\u96c6\u7fa4\u4e2d\uff0c\u53ef\u80fd\u4f1a\u9891\u7e41\u51fa\u73b0\u8c03\u5ea6\u70ed\u70b9\uff0c\u56e0\u4e3a\u521b\u5efa Pod \u540e\u8282\u70b9\u7684\u8d1f\u8f7d\u4e0d\u80fd\u7acb\u5373\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u6307\u6807\uff0c\u540d\u4e3a Hot Value \uff0c\u8868\u793a\u8282\u70b9\u6700\u8fd1\u51e0\u6b21\u7684\u8c03\u5ea6\u9891\u7387\u3002\u5e76\u4e14\u8282\u70b9\u7684\u6700\u7ec8\u4f18\u5148\u7ea7\u662f\u6700\u7ec8\u5f97\u5206\u51cf\u53bb Hot Value \u3002","title":"Hot Value"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/","text":"\u57fa\u4e8e Effective HPA \u5b9e\u73b0\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u667a\u80fd\u5f39\u6027\u5b9e\u8df5 \u00b6 Kubernetes HPA \u652f\u6301\u4e86\u4e30\u5bcc\u7684\u5f39\u6027\u6269\u5c55\u80fd\u529b\uff0cKubernetes \u5e73\u53f0\u5f00\u53d1\u8005\u90e8\u7f72\u670d\u52a1\u5b9e\u73b0\u81ea\u5b9a\u4e49 Metric \u7684\u670d\u52a1\uff0cKubernetes \u7528\u6237\u914d\u7f6e\u591a\u9879\u5185\u7f6e\u7684\u8d44\u6e90\u6307\u6807\u6216\u8005\u81ea\u5b9a\u4e49 Metric \u6307\u6807\u5b9e\u73b0\u81ea\u5b9a\u4e49\u6c34\u5e73\u5f39\u6027\u3002 Effective HPA \u517c\u5bb9\u793e\u533a\u7684 Kubernetes HPA \u7684\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u5f39\u6027\u7b56\u7565\uff0c\u6bd4\u5982\u57fa\u4e8e\u9884\u6d4b\u7684\u5f39\u6027\u548c\u57fa\u4e8e Cron \u5468\u671f\u7684\u5f39\u6027\u7b49\u3002 Prometheus \u662f\u5f53\u4e0b\u6d41\u884c\u7684\u5f00\u6e90\u76d1\u63a7\u7cfb\u7edf\uff0c\u901a\u8fc7 Prometheus \u53ef\u4ee5\u83b7\u53d6\u5230\u7528\u6237\u7684\u81ea\u5b9a\u4e49\u6307\u6807\u914d\u7f6e\u3002 \u672c\u6587\u5c06\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u4ecb\u7ecd\u4e86\u5982\u4f55\u57fa\u4e8e Effective HPA \u5b9e\u73b0\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u667a\u80fd\u5f39\u6027\u3002\u90e8\u5206\u914d\u7f6e\u6765\u81ea\u4e8e \u5b98\u65b9\u6587\u6863 \u90e8\u7f72\u73af\u5883\u8981\u6c42 \u00b6 Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus \u53c2\u8003 \u5b89\u88dd\u6587\u6863 \u5728\u96c6\u7fa4\u4e2d\u5b89\u88c5 Crane\uff0cPrometheus \u53ef\u4ee5\u4f7f\u7528\u5b89\u88c5\u6587\u6863\u4e2d\u7684\u4e5f\u53ef\u4ee5\u662f\u5df2\u90e8\u7f72\u7684 Prometheus\u3002 \u73af\u5883\u642d\u5efa \u00b6 \u5b89\u88c5 PrometheusAdapter \u00b6 Crane \u7ec4\u4ef6 Metric-Adapter \u548c PrometheusAdapter \u90fd\u57fa\u4e8e custom-metric-apiserver \u5b9e\u73b0\u4e86 Custom Metric \u548c External Metric \u7684 ApiService\u3002\u5728\u5b89\u88c5 Crane \u65f6\u4f1a\u5c06\u5bf9\u5e94\u7684 ApiService \u5b89\u88c5\u4e3a Crane \u7684 Metric-Adapter\uff0c\u56e0\u6b64\u5b89\u88c5 PrometheusAdapter \u524d\u9700\u8981\u5220\u9664 ApiService \u4ee5\u786e\u4fdd Helm \u5b89\u88c5\u6210\u529f\u3002 # \u67e5\u770b\u5f53\u524d\u96c6\u7fa4 ApiService kubectl get apiservice \u56e0\u4e3a\u5b89\u88c5\u4e86 Crane\uff0c \u7ed3\u679c\u5982\u4e0b\uff1a NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d \u5220\u9664 crane \u5b89\u88c5\u7684 ApiService kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io \u901a\u8fc7 Helm \u5b89\u88c5 PrometheusAdapter helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter \u518d\u5c06 ApiService \u6539\u56de Crane \u7684 Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml \u914d\u7f6e Metric-Adapter \u5f00\u542f RemoteAdapter \u529f\u80fd \u00b6 \u5728\u5b89\u88c5 PrometheusAdapter \u65f6\u6ca1\u6709\u5c06 ApiService \u6307\u5411 PrometheusAdapter\uff0c\u56e0\u6b64\u4e3a\u4e86\u8ba9 PrometheusAdapter \u4e5f\u53ef\u4ee5\u63d0\u4f9b\u81ea\u5b9a\u4e49 Metric\uff0c\u901a\u8fc7 Crane Metric Adapter \u7684 RemoteAdapter \u529f\u80fd\u5c06\u8bf7\u6c42\u8f6c\u53d1\u7ed9 PrometheusAdapter\u3002 \u4fee\u6539 Metric-Adapter \u7684\u914d\u7f6e\uff0c\u5c06 PrometheusAdapter \u7684 Service \u914d\u7f6e\u6210 Crane Metric Adapter \u7684 RemoteAdapter # \u67e5\u770b\u5f53\u524d\u96c6\u7fa4 ApiService kubectl edit deploy metric-adapter -n crane-system \u6839\u636e PrometheusAdapter \u7684\u914d\u7f6e\u505a\u4ee5\u4e0b\u4fee\u6539\uff1a apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #\u6dfb\u52a0\u5916\u90e8 Adapter \u914d\u7f6e - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443 RemoteAdapter \u80fd\u529b \u00b6 Kubernetes \u9650\u5236\u4e00\u4e2a ApiService \u53ea\u80fd\u914d\u7f6e\u4e00\u4e2a\u540e\u7aef\u670d\u52a1\uff0c\u56e0\u6b64\uff0c\u4e3a\u4e86\u5728\u4e00\u4e2a\u96c6\u7fa4\u5185\u4f7f\u7528 Crane \u63d0\u4f9b\u7684 Metric \u548c PrometheusAdapter \u63d0\u4f9b\u7684 Metric\uff0cCrane \u652f\u6301\u4e86 RemoteAdapter \u89e3\u51b3\u6b64\u95ee\u9898 Crane Metric-Adapter \u652f\u6301\u914d\u7f6e\u4e00\u4e2a Kubernetes Service \u4f5c\u4e3a\u4e00\u4e2a\u8fdc\u7a0b Adapter Crane Metric-Adapter \u5904\u7406\u8bf7\u6c42\u65f6\u4f1a\u5148\u68c0\u67e5\u662f\u5426\u662f Crane \u63d0\u4f9b\u7684 Local Metric\uff0c\u5982\u679c\u4e0d\u662f\uff0c\u5219\u8f6c\u53d1\u7ed9\u8fdc\u7a0b Adapter \u8fd0\u884c\u4f8b\u5b50 \u00b6 \u51c6\u5907\u5e94\u7528 \u00b6 \u5c06\u4ee5\u4e0b\u5e94\u7528\u90e8\u7f72\u5230\u96c6\u7fa4\u4e2d\uff0c\u5e94\u7528\u66b4\u9732\u4e86 Metric \u5c55\u793a\u6bcf\u79d2\u6536\u5230\u7684 http \u8bf7\u6c42\u6570\u91cf\u3002 sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml \u5f53\u5e94\u7528\u90e8\u7f72\u5b8c\u6210\u540e\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u547d\u4ee4\u68c0\u67e5 http_requests_total Metric\uff1a curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics \u914d\u7f6e\u91c7\u96c6\u89c4\u5219 \u00b6 \u914d\u7f6e Prometheus \u7684 ScrapeConfig\uff0c\u6536\u96c6\u5e94\u7528\u7684 Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server \u6dfb\u52a0\u4ee5\u4e0b\u914d\u7f6e - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod \u6b64\u65f6\uff0c\u60a8\u53ef\u4ee5\u5728 Prometheus \u67e5\u8be2 psql\uff1asum(rate(http_requests_total[5m])) by (pod) \u9a8c\u8bc1 PrometheusAdapter \u00b6 PrometheusAdapter \u9ed8\u8ba4\u7684 Rule \u914d\u7f6e\u652f\u6301\u5c06 http_requests_total \u8f6c\u6362\u6210 Pods \u7c7b\u578b\u7684 Custom Metric\uff0c\u901a\u8fc7\u547d\u4ee4\u9a8c\u8bc1\uff1a kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . \u7ed3\u679c\u5e94\u5305\u62ec pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } \u8fd9\u8868\u660e\u73b0\u5728\u53ef\u4ee5\u901a\u8fc7 Pod Metric \u914d\u7f6e HPA\u3002 \u914d\u7f6e\u5f39\u6027 \u00b6 \u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u521b\u5efa Effective HPA\u3002\u6b64\u65f6 Effective HPA \u53ef\u4ee5\u901a\u8fc7 Pod Metric http_requests \u8fdb\u884c\u5f39\u6027\uff1a \u5982\u4f55\u5b9a\u4e49\u4e00\u4e2a\u81ea\u5b9a\u4e49\u6307\u6807\u5f00\u542f\u9884\u6d4b\u529f\u80fd \u00b6 \u5728 Effective HPA \u7684 Annotation \u6309\u4ee5\u4e0b\u89c4\u5219\u6dfb\u52a0\u914d\u7f6e\uff1a annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml \u67e5\u770b TimeSeriesPrediction \u72b6\u6001\uff0c\u5982\u679c\u5e94\u7528\u8fd0\u884c\u65f6\u95f4\u8f83\u77ed\uff0c\u53ef\u80fd\u4f1a\u65e0\u6cd5\u9884\u6d4b\uff1a apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests \u67e5\u770b Effective HPA \u521b\u5efa\u7684 HPA \u5bf9\u8c61\uff0c\u53ef\u4ee5\u89c2\u6d4b\u5230\u5df2\u7ecf\u521b\u5efa\u51fa\u57fa\u4e8e\u81ea\u5b9a\u4e49\u6307\u6807\u9884\u6d4b\u7684 Metric: crane_custom.pods_http_requests apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app \u603b\u7ed3 \u00b6 \u7531\u4e8e\u751f\u4ea7\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u57fa\u4e8e\u591a\u6307\u6807\u7684\u5f39\u6027\uff08CPU/Memory/\u81ea\u5b9a\u4e49\u6307\u6807\uff09\u5f80\u5f80\u662f\u751f\u4ea7\u5e94\u7528\u7684\u5e38\u89c1\u9009\u62e9\uff0c\u56e0\u6b64 Effective HPA \u901a\u8fc7\u9884\u6d4b\u7b97\u6cd5\u8986\u76d6\u4e86\u591a\u6307\u6807\u7684\u5f39\u6027\uff0c\u8fbe\u5230\u4e86\u5e2e\u52a9\u66f4\u591a\u4e1a\u52a1\u5728\u751f\u4ea7\u73af\u5883\u843d\u5730\u6c34\u5e73\u5f39\u6027\u7684\u6210\u6548\u3002","title":"\u57fa\u4e8e\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u5f39\u6027\u9884\u6d4b"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#effective-hpa","text":"Kubernetes HPA \u652f\u6301\u4e86\u4e30\u5bcc\u7684\u5f39\u6027\u6269\u5c55\u80fd\u529b\uff0cKubernetes \u5e73\u53f0\u5f00\u53d1\u8005\u90e8\u7f72\u670d\u52a1\u5b9e\u73b0\u81ea\u5b9a\u4e49 Metric \u7684\u670d\u52a1\uff0cKubernetes \u7528\u6237\u914d\u7f6e\u591a\u9879\u5185\u7f6e\u7684\u8d44\u6e90\u6307\u6807\u6216\u8005\u81ea\u5b9a\u4e49 Metric \u6307\u6807\u5b9e\u73b0\u81ea\u5b9a\u4e49\u6c34\u5e73\u5f39\u6027\u3002 Effective HPA \u517c\u5bb9\u793e\u533a\u7684 Kubernetes HPA \u7684\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u5f39\u6027\u7b56\u7565\uff0c\u6bd4\u5982\u57fa\u4e8e\u9884\u6d4b\u7684\u5f39\u6027\u548c\u57fa\u4e8e Cron \u5468\u671f\u7684\u5f39\u6027\u7b49\u3002 Prometheus \u662f\u5f53\u4e0b\u6d41\u884c\u7684\u5f00\u6e90\u76d1\u63a7\u7cfb\u7edf\uff0c\u901a\u8fc7 Prometheus \u53ef\u4ee5\u83b7\u53d6\u5230\u7528\u6237\u7684\u81ea\u5b9a\u4e49\u6307\u6807\u914d\u7f6e\u3002 \u672c\u6587\u5c06\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u4ecb\u7ecd\u4e86\u5982\u4f55\u57fa\u4e8e Effective HPA \u5b9e\u73b0\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u667a\u80fd\u5f39\u6027\u3002\u90e8\u5206\u914d\u7f6e\u6765\u81ea\u4e8e \u5b98\u65b9\u6587\u6863","title":"\u57fa\u4e8e Effective HPA \u5b9e\u73b0\u81ea\u5b9a\u4e49\u6307\u6807\u7684\u667a\u80fd\u5f39\u6027\u5b9e\u8df5"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_1","text":"Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus \u53c2\u8003 \u5b89\u88dd\u6587\u6863 \u5728\u96c6\u7fa4\u4e2d\u5b89\u88c5 Crane\uff0cPrometheus \u53ef\u4ee5\u4f7f\u7528\u5b89\u88c5\u6587\u6863\u4e2d\u7684\u4e5f\u53ef\u4ee5\u662f\u5df2\u90e8\u7f72\u7684 Prometheus\u3002","title":"\u90e8\u7f72\u73af\u5883\u8981\u6c42"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_2","text":"","title":"\u73af\u5883\u642d\u5efa"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#prometheusadapter","text":"Crane \u7ec4\u4ef6 Metric-Adapter \u548c PrometheusAdapter \u90fd\u57fa\u4e8e custom-metric-apiserver \u5b9e\u73b0\u4e86 Custom Metric \u548c External Metric \u7684 ApiService\u3002\u5728\u5b89\u88c5 Crane \u65f6\u4f1a\u5c06\u5bf9\u5e94\u7684 ApiService \u5b89\u88c5\u4e3a Crane \u7684 Metric-Adapter\uff0c\u56e0\u6b64\u5b89\u88c5 PrometheusAdapter \u524d\u9700\u8981\u5220\u9664 ApiService \u4ee5\u786e\u4fdd Helm \u5b89\u88c5\u6210\u529f\u3002 # \u67e5\u770b\u5f53\u524d\u96c6\u7fa4 ApiService kubectl get apiservice \u56e0\u4e3a\u5b89\u88c5\u4e86 Crane\uff0c \u7ed3\u679c\u5982\u4e0b\uff1a NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d \u5220\u9664 crane \u5b89\u88c5\u7684 ApiService kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io \u901a\u8fc7 Helm \u5b89\u88c5 PrometheusAdapter helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter \u518d\u5c06 ApiService \u6539\u56de Crane \u7684 Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml","title":"\u5b89\u88c5 PrometheusAdapter"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#metric-adapter-remoteadapter","text":"\u5728\u5b89\u88c5 PrometheusAdapter \u65f6\u6ca1\u6709\u5c06 ApiService \u6307\u5411 PrometheusAdapter\uff0c\u56e0\u6b64\u4e3a\u4e86\u8ba9 PrometheusAdapter \u4e5f\u53ef\u4ee5\u63d0\u4f9b\u81ea\u5b9a\u4e49 Metric\uff0c\u901a\u8fc7 Crane Metric Adapter \u7684 RemoteAdapter \u529f\u80fd\u5c06\u8bf7\u6c42\u8f6c\u53d1\u7ed9 PrometheusAdapter\u3002 \u4fee\u6539 Metric-Adapter \u7684\u914d\u7f6e\uff0c\u5c06 PrometheusAdapter \u7684 Service \u914d\u7f6e\u6210 Crane Metric Adapter \u7684 RemoteAdapter # \u67e5\u770b\u5f53\u524d\u96c6\u7fa4 ApiService kubectl edit deploy metric-adapter -n crane-system \u6839\u636e PrometheusAdapter \u7684\u914d\u7f6e\u505a\u4ee5\u4e0b\u4fee\u6539\uff1a apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #\u6dfb\u52a0\u5916\u90e8 Adapter \u914d\u7f6e - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443","title":"\u914d\u7f6e Metric-Adapter \u5f00\u542f RemoteAdapter \u529f\u80fd"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#remoteadapter","text":"Kubernetes \u9650\u5236\u4e00\u4e2a ApiService \u53ea\u80fd\u914d\u7f6e\u4e00\u4e2a\u540e\u7aef\u670d\u52a1\uff0c\u56e0\u6b64\uff0c\u4e3a\u4e86\u5728\u4e00\u4e2a\u96c6\u7fa4\u5185\u4f7f\u7528 Crane \u63d0\u4f9b\u7684 Metric \u548c PrometheusAdapter \u63d0\u4f9b\u7684 Metric\uff0cCrane \u652f\u6301\u4e86 RemoteAdapter \u89e3\u51b3\u6b64\u95ee\u9898 Crane Metric-Adapter \u652f\u6301\u914d\u7f6e\u4e00\u4e2a Kubernetes Service \u4f5c\u4e3a\u4e00\u4e2a\u8fdc\u7a0b Adapter Crane Metric-Adapter \u5904\u7406\u8bf7\u6c42\u65f6\u4f1a\u5148\u68c0\u67e5\u662f\u5426\u662f Crane \u63d0\u4f9b\u7684 Local Metric\uff0c\u5982\u679c\u4e0d\u662f\uff0c\u5219\u8f6c\u53d1\u7ed9\u8fdc\u7a0b Adapter","title":"RemoteAdapter \u80fd\u529b"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_3","text":"","title":"\u8fd0\u884c\u4f8b\u5b50"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_4","text":"\u5c06\u4ee5\u4e0b\u5e94\u7528\u90e8\u7f72\u5230\u96c6\u7fa4\u4e2d\uff0c\u5e94\u7528\u66b4\u9732\u4e86 Metric \u5c55\u793a\u6bcf\u79d2\u6536\u5230\u7684 http \u8bf7\u6c42\u6570\u91cf\u3002 sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml \u5f53\u5e94\u7528\u90e8\u7f72\u5b8c\u6210\u540e\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u547d\u4ee4\u68c0\u67e5 http_requests_total Metric\uff1a curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics","title":"\u51c6\u5907\u5e94\u7528"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_5","text":"\u914d\u7f6e Prometheus \u7684 ScrapeConfig\uff0c\u6536\u96c6\u5e94\u7528\u7684 Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server \u6dfb\u52a0\u4ee5\u4e0b\u914d\u7f6e - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod \u6b64\u65f6\uff0c\u60a8\u53ef\u4ee5\u5728 Prometheus \u67e5\u8be2 psql\uff1asum(rate(http_requests_total[5m])) by (pod)","title":"\u914d\u7f6e\u91c7\u96c6\u89c4\u5219"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#prometheusadapter_1","text":"PrometheusAdapter \u9ed8\u8ba4\u7684 Rule \u914d\u7f6e\u652f\u6301\u5c06 http_requests_total \u8f6c\u6362\u6210 Pods \u7c7b\u578b\u7684 Custom Metric\uff0c\u901a\u8fc7\u547d\u4ee4\u9a8c\u8bc1\uff1a kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . \u7ed3\u679c\u5e94\u5305\u62ec pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } \u8fd9\u8868\u660e\u73b0\u5728\u53ef\u4ee5\u901a\u8fc7 Pod Metric \u914d\u7f6e HPA\u3002","title":"\u9a8c\u8bc1 PrometheusAdapter"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_6","text":"\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u521b\u5efa Effective HPA\u3002\u6b64\u65f6 Effective HPA \u53ef\u4ee5\u901a\u8fc7 Pod Metric http_requests \u8fdb\u884c\u5f39\u6027\uff1a","title":"\u914d\u7f6e\u5f39\u6027"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_7","text":"\u5728 Effective HPA \u7684 Annotation \u6309\u4ee5\u4e0b\u89c4\u5219\u6dfb\u52a0\u914d\u7f6e\uff1a annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml \u67e5\u770b TimeSeriesPrediction \u72b6\u6001\uff0c\u5982\u679c\u5e94\u7528\u8fd0\u884c\u65f6\u95f4\u8f83\u77ed\uff0c\u53ef\u80fd\u4f1a\u65e0\u6cd5\u9884\u6d4b\uff1a apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests \u67e5\u770b Effective HPA \u521b\u5efa\u7684 HPA \u5bf9\u8c61\uff0c\u53ef\u4ee5\u89c2\u6d4b\u5230\u5df2\u7ecf\u521b\u5efa\u51fa\u57fa\u4e8e\u81ea\u5b9a\u4e49\u6307\u6807\u9884\u6d4b\u7684 Metric: crane_custom.pods_http_requests apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app","title":"\u5982\u4f55\u5b9a\u4e49\u4e00\u4e2a\u81ea\u5b9a\u4e49\u6307\u6807\u5f00\u542f\u9884\u6d4b\u529f\u80fd"},{"location":"zh/tutorials/effective-hpa-with-prometheus-adapter/#_8","text":"\u7531\u4e8e\u751f\u4ea7\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u57fa\u4e8e\u591a\u6307\u6807\u7684\u5f39\u6027\uff08CPU/Memory/\u81ea\u5b9a\u4e49\u6307\u6807\uff09\u5f80\u5f80\u662f\u751f\u4ea7\u5e94\u7528\u7684\u5e38\u89c1\u9009\u62e9\uff0c\u56e0\u6b64 Effective HPA \u901a\u8fc7\u9884\u6d4b\u7b97\u6cd5\u8986\u76d6\u4e86\u591a\u6307\u6807\u7684\u5f39\u6027\uff0c\u8fbe\u5230\u4e86\u5e2e\u52a9\u66f4\u591a\u4e1a\u52a1\u5728\u751f\u4ea7\u73af\u5883\u843d\u5730\u6c34\u5e73\u5f39\u6027\u7684\u6210\u6548\u3002","title":"\u603b\u7ed3"},{"location":"zh/tutorials/replicas-recommendation/","text":"\u526f\u672c\u6570\u63a8\u8350 \u00b6 Kubernetes \u7528\u6237\u5728\u521b\u5efa\u5e94\u7528\u8d44\u6e90\u65f6\u5e38\u5e38\u662f\u57fa\u4e8e\u7ecf\u9a8c\u503c\u6765\u8bbe\u7f6e\u526f\u672c\u6570\u6216\u8005 EHPA \u914d\u7f6e\u3002\u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u4ea7\u54c1\u529f\u80fd \u00b6 \u7b97\u6cd5\uff1a\u8ba1\u7b97\u526f\u672c\u6570\u7684\u7b97\u6cd5\u53c2\u8003\u4e86 HPA \u7684\u8ba1\u7b97\u516c\u5f0f\uff0c\u5e76\u4e14\u652f\u6301\u81ea\u5b9a\u4e49\u7b97\u6cd5\u7684\u5173\u952e\u914d\u7f6e HPA \u63a8\u8350\uff1a\u526f\u672c\u6570\u63a8\u8350\u4f1a\u626b\u63cf\u51fa\u9002\u5408\u914d\u7f6e\u6c34\u5e73\u5f39\u6027\uff08EHPA\uff09\u7684\u5e94\u7528\uff0c\u5e76\u7ed9\u51fa EHPA \u7684\u914d\u7f6e, EHPA \u662f Crane \u63d0\u4f9b\u4e86\u667a\u80fd\u6c34\u5e73\u5f39\u6027\u4ea7\u54c1 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u8fc7 Analytics \u7684 ResourceSelector\uff0c\u7528\u6237\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u4e2a\u5de5\u4f5c\u8d1f\u8f7d \u521b\u5efa\u5f39\u6027\u5206\u6790 \u00b6 \u521b\u5efa\u4e00\u4e2a \u5f39\u6027\u5206\u6790 Analytics \uff0c\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7\u5b9e\u4f8b deployment: nginx \u4f5c\u4e3a\u4e00\u4e2a\u4f8b\u5b50 Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-replicas.yaml kubectl get analytics analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics replicas.workload-min-replicas : \"1\" replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" \u7ed3\u679c\u5982\u4e0b: NAME AGE nginx-replicas 16m \u67e5\u770b Analytics \u8be6\u60c5: kubectl get analytics nginx-replicas -o yaml \u7ed3\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:06Z\" recommendations : - lastStartTime : \"2022-06-17T06:56:06Z\" message : Success name : nginx-replicas-replicas-wq6wm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db \u67e5\u770b\u5206\u6790\u7ed3\u679c \u00b6 \u67e5\u770b Recommendation \u7ed3\u679c\uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml \u5206\u6790\u7ed3\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-17T06:56:06Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b app : nginx name : nginx-replicas-replicas-wq6wm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b resourceVersion : \"2182455668\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-wq6wm uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:07Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\" \u6279\u91cf\u63a8\u8350 \u00b6 \u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u8350\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u5f53 namespace \u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9\u7684\u8d44\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u5f53 namespace \u4e0d\u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9 Analytics namespace \u4e0b\u7684\u8d44\u6e90 resourceSelectors \u901a\u8fc7\u6570\u7ec4\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9009\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8d44\u6e90 \u5f39\u6027\u63a8\u8350\u8ba1\u7b97\u6a21\u578b \u00b6 \u7b5b\u9009\u9636\u6bb5 \u00b6 \u4f4e\u526f\u672c\u6570\u7684\u5de5\u4f5c\u8d1f\u8f7d: \u8fc7\u4f4e\u7684\u526f\u672c\u6570\u53ef\u80fd\u5f39\u6027\u9700\u6c42\u4e0d\u9ad8\uff0c\u5173\u8054\u914d\u7f6e: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas \u5b58\u5728\u4e00\u5b9a\u6bd4\u4f8b\u975e Running Pod \u7684\u5de5\u4f5c\u8d1f\u8f7d: \u5982\u679c\u5de5\u4f5c\u8d1f\u8f7d\u7684 Pod \u5927\u591a\u4e0d\u80fd\u6b63\u5e38\u8fd0\u884c\uff0c\u53ef\u80fd\u4e0d\u9002\u5408\u5f39\u6027\uff0c\u5173\u8054\u914d\u7f6e: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio \u4f4e CPU \u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8d1f\u8f7d: \u8fc7\u4f4e\u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8d1f\u8f7d\u610f\u5473\u7740\u6ca1\u6709\u4e1a\u52a1\u538b\u529b\uff0c\u6b64\u65f6\u901a\u8fc7\u4f7f\u7528\u7387\u63a8\u8350\u5f39\u6027\u4e0d\u51c6\uff0c\u5173\u8054\u914d\u7f6e: ehpa.min-cpu-usage-threshold CPU \u4f7f\u7528\u91cf\u7684\u6ce2\u52a8\u7387\u8fc7\u4f4e: \u4f7f\u7528\u91cf\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u500d\u6570\u5b9a\u4e49\u4e3a\u6ce2\u52a8\u7387\uff0c\u6ce2\u52a8\u7387\u8fc7\u4f4e\u7684\u5de5\u4f5c\u8d1f\u8f7d\u901a\u8fc7\u5f39\u6027\u964d\u672c\u7684\u6536\u76ca\u4e0d\u5927\uff0c\u5173\u8054\u914d\u7f6e: ehpa.fluctuation-threshold \u63a8\u8350 \u00b6 \u63a8\u8350\u9636\u6bb5\u901a\u8fc7\u4ee5\u4e0b\u6a21\u578b\u63a8\u8350\u4e00\u4e2a EffectiveHPA \u7684 Spec\u3002\u6bcf\u4e2a\u5b57\u6bb5\u7684\u63a8\u8350\u903b\u8f91\u5982\u4e0b\uff1a \u63a8\u8350 TargetUtilization \u539f\u7406: \u4f7f\u7528 Pod P99 \u8d44\u6e90\u5229\u7528\u7387\u63a8\u8350\u5f39\u6027\u7684\u76ee\u6807\u3002\u56e0\u4e3a\u5982\u679c\u5e94\u7528\u53ef\u4ee5\u5728 P99 \u65f6\u95f4\u5185\u63a5\u53d7\u8fd9\u4e2a\u5229\u7528\u7387\uff0c\u53ef\u4ee5\u63a8\u65ad\u51fa\u53ef\u4f5c\u4e3a\u5f39\u6027\u7684\u76ee\u6807\u3002 \u901a\u8fc7 Percentile \u7b97\u6cd5\u5f97\u5230 Pod \u8fc7\u53bb\u4e03\u5929 \u7684 P99 \u4f7f\u7528\u91cf: \\(pod\\_cpu\\_usage\\_p99\\) \u5bf9\u5e94\u7684\u5229\u7528\u7387: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) \u4e3a\u4e86\u9632\u6b62\u5229\u7528\u7387\u8fc7\u5927\u6216\u8fc7\u5c0f\uff0ctarget_pod_cpu_utilization \u9700\u8981\u5c0f\u4e8e ehpa.min-cpu-target-utilization \u548c\u5927\u4e8e ehpa.max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) \u63a8\u8350 minReplicas \u539f\u7406: \u4f7f\u7528 workload \u8fc7\u53bb\u4e03\u5929\u5185\u6bcf\u5c0f\u65f6\u8d1f\u8f7d\u6700\u4f4e\u7684\u5229\u7528\u7387\u63a8\u8350 minReplicas\u3002 \u8ba1\u7b97\u8fc7\u53bb7\u5929 workload \u6bcf\u5c0f\u65f6\u4f7f\u7528\u91cf\u4e2d\u4f4d\u6570\u7684\u6700\u4f4e\u503c: \\(workload\\_cpu\\_usage\\_medium\\_min\\) \u5bf9\u5e94\u7684\u6700\u4f4e\u5229\u7528\u7387\u5bf9\u5e94\u7684\u526f\u672c\u6570: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) \u4e3a\u4e86\u9632\u6b62 minReplicas \u8fc7\u5c0f\uff0cminReplicas \u9700\u8981\u5927\u4e8e\u7b49\u4e8e ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) \u63a8\u8350 maxReplicas \u539f\u7406: \u4f7f\u7528 workload \u8fc7\u53bb\u548c\u672a\u6765\u4e03\u5929\u7684\u8d1f\u8f7d\u63a8\u8350\u6700\u5927\u526f\u672c\u6570\u3002 \u8ba1\u7b97\u8fc7\u53bb\u4e03\u5929\u548c\u672a\u6765\u4e03\u5929 workload cpu \u4f7f\u7528\u91cf\u7684 P95: \\(workload\\_cpu\\_usage\\_p95\\) \u5bf9\u5e94\u7684\u526f\u672c\u6570: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) \u4e3a\u4e86\u5e94\u5bf9\u6d41\u91cf\u6d2a\u5cf0\uff0c\u653e\u5927\u4e00\u5b9a\u500d\u6570: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) \u63a8\u8350CPU\u4ee5\u5916 MetricSpec \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7ee7\u627f\u76f8\u5e94\u9664 CpuUtilization \u4ee5\u5916\u7684\u5176\u4ed6 MetricSpec \u63a8\u8350 Behavior \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7ee7\u627f\u76f8\u5e94\u7684 Behavior \u914d\u7f6e \u9884\u6d4b \u5c1d\u8bd5\u9884\u6d4b\u5de5\u4f5c\u8d1f\u8f7d\u672a\u6765\u4e03\u5929\u7684 CPU \u4f7f\u7528\u91cf\uff0c\u7b97\u6cd5\u662f DSP \u5982\u679c\u9884\u6d4b\u6210\u529f\u5219\u6dfb\u52a0\u9884\u6d4b\u914d\u7f6e \u5982\u679c\u4e0d\u53ef\u9884\u6d4b\u5219\u4e0d\u6dfb\u52a0\u9884\u6d4b\u914d\u7f6e\uff0c\u9000\u5316\u6210\u4e0d\u5177\u6709\u9884\u6d4b\u529f\u80fd\u7684 EffectiveHPA \u5f39\u6027\u5206\u6790\u8ba1\u7b97\u914d\u7f6e \u00b6 \u914d\u7f6e\u9879 \u9ed8\u8ba4\u503c \u63cf\u8ff0 ehpa.deployment-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.statefulset-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.workload-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.pod-min-ready-seconds 30 \u5b9a\u4e49\u4e86 Pod \u662f\u5426 Ready \u7684\u79d2\u6570 ehpa.pod-available-ratio 0.5 Ready Pod \u6bd4\u4f8b\u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.default-min-replicas 2 \u6700\u5c0f minReplicas ehpa.max-replicas-factor 3 \u8ba1\u7b97 maxReplicas \u7684\u500d\u6570 ehpa.min-cpu-usage-threshold 10 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.fluctuation-threshold 1.5 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true \u7ee7\u627f\u73b0\u6709\u7684 HPA \u914d\u7f6e","title":"\u526f\u672c\u6570\u63a8\u8350"},{"location":"zh/tutorials/replicas-recommendation/#_1","text":"Kubernetes \u7528\u6237\u5728\u521b\u5efa\u5e94\u7528\u8d44\u6e90\u65f6\u5e38\u5e38\u662f\u57fa\u4e8e\u7ecf\u9a8c\u503c\u6765\u8bbe\u7f6e\u526f\u672c\u6570\u6216\u8005 EHPA \u914d\u7f6e\u3002\u901a\u8fc7\u526f\u672c\u6570\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u526f\u672c\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002","title":"\u526f\u672c\u6570\u63a8\u8350"},{"location":"zh/tutorials/replicas-recommendation/#_2","text":"\u7b97\u6cd5\uff1a\u8ba1\u7b97\u526f\u672c\u6570\u7684\u7b97\u6cd5\u53c2\u8003\u4e86 HPA \u7684\u8ba1\u7b97\u516c\u5f0f\uff0c\u5e76\u4e14\u652f\u6301\u81ea\u5b9a\u4e49\u7b97\u6cd5\u7684\u5173\u952e\u914d\u7f6e HPA \u63a8\u8350\uff1a\u526f\u672c\u6570\u63a8\u8350\u4f1a\u626b\u63cf\u51fa\u9002\u5408\u914d\u7f6e\u6c34\u5e73\u5f39\u6027\uff08EHPA\uff09\u7684\u5e94\u7528\uff0c\u5e76\u7ed9\u51fa EHPA \u7684\u914d\u7f6e, EHPA \u662f Crane \u63d0\u4f9b\u4e86\u667a\u80fd\u6c34\u5e73\u5f39\u6027\u4ea7\u54c1 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u8fc7 Analytics \u7684 ResourceSelector\uff0c\u7528\u6237\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u4e2a\u5de5\u4f5c\u8d1f\u8f7d","title":"\u4ea7\u54c1\u529f\u80fd"},{"location":"zh/tutorials/replicas-recommendation/#_3","text":"\u521b\u5efa\u4e00\u4e2a \u5f39\u6027\u5206\u6790 Analytics \uff0c\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7\u5b9e\u4f8b deployment: nginx \u4f5c\u4e3a\u4e00\u4e2a\u4f8b\u5b50 Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-replicas.yaml kubectl get analytics analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics replicas.workload-min-replicas : \"1\" replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" \u7ed3\u679c\u5982\u4e0b: NAME AGE nginx-replicas 16m \u67e5\u770b Analytics \u8be6\u60c5: kubectl get analytics nginx-replicas -o yaml \u7ed3\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:06Z\" recommendations : - lastStartTime : \"2022-06-17T06:56:06Z\" message : Success name : nginx-replicas-replicas-wq6wm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db","title":"\u521b\u5efa\u5f39\u6027\u5206\u6790"},{"location":"zh/tutorials/replicas-recommendation/#_4","text":"\u67e5\u770b Recommendation \u7ed3\u679c\uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml \u5206\u6790\u7ed3\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-17T06:56:06Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b app : nginx name : nginx-replicas-replicas-wq6wm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b resourceVersion : \"2182455668\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-wq6wm uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:07Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\"","title":"\u67e5\u770b\u5206\u6790\u7ed3\u679c"},{"location":"zh/tutorials/replicas-recommendation/#_5","text":"\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u8350\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u5f53 namespace \u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9\u7684\u8d44\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u5f53 namespace \u4e0d\u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9 Analytics namespace \u4e0b\u7684\u8d44\u6e90 resourceSelectors \u901a\u8fc7\u6570\u7ec4\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9009\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8d44\u6e90","title":"\u6279\u91cf\u63a8\u8350"},{"location":"zh/tutorials/replicas-recommendation/#_6","text":"","title":"\u5f39\u6027\u63a8\u8350\u8ba1\u7b97\u6a21\u578b"},{"location":"zh/tutorials/replicas-recommendation/#_7","text":"\u4f4e\u526f\u672c\u6570\u7684\u5de5\u4f5c\u8d1f\u8f7d: \u8fc7\u4f4e\u7684\u526f\u672c\u6570\u53ef\u80fd\u5f39\u6027\u9700\u6c42\u4e0d\u9ad8\uff0c\u5173\u8054\u914d\u7f6e: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas \u5b58\u5728\u4e00\u5b9a\u6bd4\u4f8b\u975e Running Pod \u7684\u5de5\u4f5c\u8d1f\u8f7d: \u5982\u679c\u5de5\u4f5c\u8d1f\u8f7d\u7684 Pod \u5927\u591a\u4e0d\u80fd\u6b63\u5e38\u8fd0\u884c\uff0c\u53ef\u80fd\u4e0d\u9002\u5408\u5f39\u6027\uff0c\u5173\u8054\u914d\u7f6e: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio \u4f4e CPU \u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8d1f\u8f7d: \u8fc7\u4f4e\u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8d1f\u8f7d\u610f\u5473\u7740\u6ca1\u6709\u4e1a\u52a1\u538b\u529b\uff0c\u6b64\u65f6\u901a\u8fc7\u4f7f\u7528\u7387\u63a8\u8350\u5f39\u6027\u4e0d\u51c6\uff0c\u5173\u8054\u914d\u7f6e: ehpa.min-cpu-usage-threshold CPU \u4f7f\u7528\u91cf\u7684\u6ce2\u52a8\u7387\u8fc7\u4f4e: \u4f7f\u7528\u91cf\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u500d\u6570\u5b9a\u4e49\u4e3a\u6ce2\u52a8\u7387\uff0c\u6ce2\u52a8\u7387\u8fc7\u4f4e\u7684\u5de5\u4f5c\u8d1f\u8f7d\u901a\u8fc7\u5f39\u6027\u964d\u672c\u7684\u6536\u76ca\u4e0d\u5927\uff0c\u5173\u8054\u914d\u7f6e: ehpa.fluctuation-threshold","title":"\u7b5b\u9009\u9636\u6bb5"},{"location":"zh/tutorials/replicas-recommendation/#_8","text":"\u63a8\u8350\u9636\u6bb5\u901a\u8fc7\u4ee5\u4e0b\u6a21\u578b\u63a8\u8350\u4e00\u4e2a EffectiveHPA \u7684 Spec\u3002\u6bcf\u4e2a\u5b57\u6bb5\u7684\u63a8\u8350\u903b\u8f91\u5982\u4e0b\uff1a \u63a8\u8350 TargetUtilization \u539f\u7406: \u4f7f\u7528 Pod P99 \u8d44\u6e90\u5229\u7528\u7387\u63a8\u8350\u5f39\u6027\u7684\u76ee\u6807\u3002\u56e0\u4e3a\u5982\u679c\u5e94\u7528\u53ef\u4ee5\u5728 P99 \u65f6\u95f4\u5185\u63a5\u53d7\u8fd9\u4e2a\u5229\u7528\u7387\uff0c\u53ef\u4ee5\u63a8\u65ad\u51fa\u53ef\u4f5c\u4e3a\u5f39\u6027\u7684\u76ee\u6807\u3002 \u901a\u8fc7 Percentile \u7b97\u6cd5\u5f97\u5230 Pod \u8fc7\u53bb\u4e03\u5929 \u7684 P99 \u4f7f\u7528\u91cf: \\(pod\\_cpu\\_usage\\_p99\\) \u5bf9\u5e94\u7684\u5229\u7528\u7387: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) \u4e3a\u4e86\u9632\u6b62\u5229\u7528\u7387\u8fc7\u5927\u6216\u8fc7\u5c0f\uff0ctarget_pod_cpu_utilization \u9700\u8981\u5c0f\u4e8e ehpa.min-cpu-target-utilization \u548c\u5927\u4e8e ehpa.max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) \u63a8\u8350 minReplicas \u539f\u7406: \u4f7f\u7528 workload \u8fc7\u53bb\u4e03\u5929\u5185\u6bcf\u5c0f\u65f6\u8d1f\u8f7d\u6700\u4f4e\u7684\u5229\u7528\u7387\u63a8\u8350 minReplicas\u3002 \u8ba1\u7b97\u8fc7\u53bb7\u5929 workload \u6bcf\u5c0f\u65f6\u4f7f\u7528\u91cf\u4e2d\u4f4d\u6570\u7684\u6700\u4f4e\u503c: \\(workload\\_cpu\\_usage\\_medium\\_min\\) \u5bf9\u5e94\u7684\u6700\u4f4e\u5229\u7528\u7387\u5bf9\u5e94\u7684\u526f\u672c\u6570: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) \u4e3a\u4e86\u9632\u6b62 minReplicas \u8fc7\u5c0f\uff0cminReplicas \u9700\u8981\u5927\u4e8e\u7b49\u4e8e ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) \u63a8\u8350 maxReplicas \u539f\u7406: \u4f7f\u7528 workload \u8fc7\u53bb\u548c\u672a\u6765\u4e03\u5929\u7684\u8d1f\u8f7d\u63a8\u8350\u6700\u5927\u526f\u672c\u6570\u3002 \u8ba1\u7b97\u8fc7\u53bb\u4e03\u5929\u548c\u672a\u6765\u4e03\u5929 workload cpu \u4f7f\u7528\u91cf\u7684 P95: \\(workload\\_cpu\\_usage\\_p95\\) \u5bf9\u5e94\u7684\u526f\u672c\u6570: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) \u4e3a\u4e86\u5e94\u5bf9\u6d41\u91cf\u6d2a\u5cf0\uff0c\u653e\u5927\u4e00\u5b9a\u500d\u6570: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) \u63a8\u8350CPU\u4ee5\u5916 MetricSpec \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7ee7\u627f\u76f8\u5e94\u9664 CpuUtilization \u4ee5\u5916\u7684\u5176\u4ed6 MetricSpec \u63a8\u8350 Behavior \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7ee7\u627f\u76f8\u5e94\u7684 Behavior \u914d\u7f6e \u9884\u6d4b \u5c1d\u8bd5\u9884\u6d4b\u5de5\u4f5c\u8d1f\u8f7d\u672a\u6765\u4e03\u5929\u7684 CPU \u4f7f\u7528\u91cf\uff0c\u7b97\u6cd5\u662f DSP \u5982\u679c\u9884\u6d4b\u6210\u529f\u5219\u6dfb\u52a0\u9884\u6d4b\u914d\u7f6e \u5982\u679c\u4e0d\u53ef\u9884\u6d4b\u5219\u4e0d\u6dfb\u52a0\u9884\u6d4b\u914d\u7f6e\uff0c\u9000\u5316\u6210\u4e0d\u5177\u6709\u9884\u6d4b\u529f\u80fd\u7684 EffectiveHPA","title":"\u63a8\u8350"},{"location":"zh/tutorials/replicas-recommendation/#_9","text":"\u914d\u7f6e\u9879 \u9ed8\u8ba4\u503c \u63cf\u8ff0 ehpa.deployment-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.statefulset-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.workload-min-replicas 1 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.pod-min-ready-seconds 30 \u5b9a\u4e49\u4e86 Pod \u662f\u5426 Ready \u7684\u79d2\u6570 ehpa.pod-available-ratio 0.5 Ready Pod \u6bd4\u4f8b\u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.default-min-replicas 2 \u6700\u5c0f minReplicas ehpa.max-replicas-factor 3 \u8ba1\u7b97 maxReplicas \u7684\u500d\u6570 ehpa.min-cpu-usage-threshold 10 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.fluctuation-threshold 1.5 \u5c0f\u4e8e\u8be5\u503c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u505a\u5f39\u6027\u63a8\u8350 ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true \u7ee7\u627f\u73b0\u6709\u7684 HPA \u914d\u7f6e","title":"\u5f39\u6027\u5206\u6790\u8ba1\u7b97\u914d\u7f6e"},{"location":"zh/tutorials/resource-recommendation/","text":"\u8d44\u6e90\u63a8\u8350 \u00b6 Kubernetes \u7528\u6237\u5728\u521b\u5efa\u5e94\u7528\u8d44\u6e90\u65f6\u5e38\u5e38\u662f\u57fa\u4e8e\u7ecf\u9a8c\u503c\u6765\u8bbe\u7f6e request \u548c limit\u3002\u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002 \u4ea7\u54c1\u529f\u80fd \u00b6 \u8d44\u6e90\u63a8\u8350\u662f VPA \u7684\u8f7b\u91cf\u5316\u5b9e\u73b0\uff0c\u4e14\u66f4\u7075\u6d3b\u3002 \u7b97\u6cd5\uff1a\u7b97\u6cd5\u6a21\u578b\u91c7\u7528\u4e86 VPA \u7684\u6ed1\u52a8\u7a97\u53e3\uff08Moving Window\uff09\u7b97\u6cd5\uff0c\u5e76\u4e14\u652f\u6301\u81ea\u5b9a\u4e49\u7b97\u6cd5\u7684\u5173\u952e\u914d\u7f6e\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u8fc7 Analytics \u7684 ResourceSelector\uff0c\u7528\u6237\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u800c\u65e0\u9700\u4e00\u4e2a\u4e00\u4e2a\u7684\u521b\u5efa VPA \u5bf9\u8c61 \u66f4\u8f7b\u4fbf\uff1a\u7531\u4e8e VPA \u7684 Auto \u6a21\u5f0f\u5728\u66f4\u65b0\u5bb9\u5668\u8d44\u6e90\u914d\u7f6e\u65f6\u4f1a\u5bfc\u81f4\u5bb9\u5668\u91cd\u5efa\uff0c\u56e0\u6b64\u5f88\u96be\u5728\u751f\u4ea7\u4e0a\u4f7f\u7528\u81ea\u52a8\u6a21\u5f0f\uff0c\u8d44\u6e90\u63a8\u8350\u7ed9\u7528\u6237\u63d0\u4f9b\u8d44\u6e90\u5efa\u8bae\uff0c\u628a\u53d8\u66f4\u7684\u51b3\u5b9a\u4ea4\u7ed9\u7528\u6237\u51b3\u5b9a \u521b\u5efa\u8d44\u6e90\u5206\u6790 \u00b6 \u6211\u4eec\u901a\u8fc7 deployment: nginx \u548c Analytics \u4f5c\u4e3a\u4e00\u4e2a\u4f8b\u5b50\u6f14\u793a\u5982\u4f55\u5f00\u59cb\u4e00\u6b21\u8d44\u6e90\u63a8\u8350\u4e4b\u65c5\uff1a Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"HPA\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment \u7ed3\u679c\u5982\u4e0b: NAME AGE nginx-resource 16m \u67e5\u770b Analytics \u8be6\u60c5: kubectl get analytics nginx-resource -o yaml \u7ed3\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e \u67e5\u770b\u5206\u6790\u7ed3\u679c \u00b6 \u67e5\u770b\u5206\u6790\u7ed3\u679c Recommendation \uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml \u5206\u6790\u7ed3\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\" \u6279\u91cf\u63a8\u8350 \u00b6 \u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u8350\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u5f53 namespace \u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9\u7684\u8d44\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u5f53 namespace \u4e0d\u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9 Analytics namespace \u4e0b\u7684\u8d44\u6e90 resourceSelectors \u901a\u8fc7\u6570\u7ec4\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9009\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8d44\u6e90 \u8d44\u6e90\u63a8\u8350\u8ba1\u7b97\u6a21\u578b \u00b6 \u7b5b\u9009\u9636\u6bb5 \u00b6 \u6ca1\u6709 Pod \u7684\u5de5\u4f5c\u8d1f\u8f7d: \u5982\u679c\u5de5\u4f5c\u8d1f\u8f7d\u6ca1\u6709 Pod\uff0c\u65e0\u6cd5\u8fdb\u884c\u7b97\u6cd5\u5206\u6790\u3002 \u63a8\u8350 \u00b6 \u91c7\u7528 VPA \u7684\u6ed1\u52a8\u7a97\u53e3\uff08Moving Window\uff09\u7b97\u6cd5\u5206\u522b\u8ba1\u7b97\u6bcf\u4e2a\u5bb9\u5668\u7684 CPU \u548c Memory \u5e76\u7ed9\u51fa\u5bf9\u5e94\u7684\u63a8\u8350\u503c \u5e38\u89c1\u95ee\u9898 \u00b6 \u5982\u4f55\u8ba9\u63a8\u8350\u7ed3\u679c\u66f4\u51c6\u786e \u00b6 \u5e94\u7528\u5728\u76d1\u63a7\u7cfb\u7edf\uff08\u6bd4\u5982 Prometheus\uff09\u4e2d\u7684\u5386\u53f2\u6570\u636e\u8d8a\u4e45\uff0c\u63a8\u8350\u7ed3\u679c\u5c31\u8d8a\u51c6\u786e\uff0c\u5efa\u8bae\u751f\u4ea7\u4e0a\u8d85\u8fc7\u4e24\u5468\u65f6\u95f4\u3002\u5bf9\u65b0\u5efa\u5e94\u7528\u7684\u9884\u6d4b\u5f80\u5f80\u4e0d\u51c6\uff0c\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u914d\u7f6e\u4fdd\u8bc1\u53ea\u5bf9\u5386\u53f2\u6570\u636e\u957f\u5ea6\u8d85\u8fc7\u4e00\u5b9a\u5929\u6570\u7684\u4e1a\u52a1\u63a8\u8350\u3002","title":"\u8d44\u6e90\u63a8\u8350"},{"location":"zh/tutorials/resource-recommendation/#_1","text":"Kubernetes \u7528\u6237\u5728\u521b\u5efa\u5e94\u7528\u8d44\u6e90\u65f6\u5e38\u5e38\u662f\u57fa\u4e8e\u7ecf\u9a8c\u503c\u6765\u8bbe\u7f6e request \u548c limit\u3002\u901a\u8fc7\u8d44\u6e90\u63a8\u8350\u7684\u7b97\u6cd5\u5206\u6790\u5e94\u7528\u7684\u771f\u5b9e\u7528\u91cf\u63a8\u8350\u66f4\u5408\u9002\u7684\u8d44\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u5e76\u91c7\u7eb3\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002","title":"\u8d44\u6e90\u63a8\u8350"},{"location":"zh/tutorials/resource-recommendation/#_2","text":"\u8d44\u6e90\u63a8\u8350\u662f VPA \u7684\u8f7b\u91cf\u5316\u5b9e\u73b0\uff0c\u4e14\u66f4\u7075\u6d3b\u3002 \u7b97\u6cd5\uff1a\u7b97\u6cd5\u6a21\u578b\u91c7\u7528\u4e86 VPA \u7684\u6ed1\u52a8\u7a97\u53e3\uff08Moving Window\uff09\u7b97\u6cd5\uff0c\u5e76\u4e14\u652f\u6301\u81ea\u5b9a\u4e49\u7b97\u6cd5\u7684\u5173\u952e\u914d\u7f6e\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u8fc7 Analytics \u7684 ResourceSelector\uff0c\u7528\u6237\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u800c\u65e0\u9700\u4e00\u4e2a\u4e00\u4e2a\u7684\u521b\u5efa VPA \u5bf9\u8c61 \u66f4\u8f7b\u4fbf\uff1a\u7531\u4e8e VPA \u7684 Auto \u6a21\u5f0f\u5728\u66f4\u65b0\u5bb9\u5668\u8d44\u6e90\u914d\u7f6e\u65f6\u4f1a\u5bfc\u81f4\u5bb9\u5668\u91cd\u5efa\uff0c\u56e0\u6b64\u5f88\u96be\u5728\u751f\u4ea7\u4e0a\u4f7f\u7528\u81ea\u52a8\u6a21\u5f0f\uff0c\u8d44\u6e90\u63a8\u8350\u7ed9\u7528\u6237\u63d0\u4f9b\u8d44\u6e90\u5efa\u8bae\uff0c\u628a\u53d8\u66f4\u7684\u51b3\u5b9a\u4ea4\u7ed9\u7528\u6237\u51b3\u5b9a","title":"\u4ea7\u54c1\u529f\u80fd"},{"location":"zh/tutorials/resource-recommendation/#_3","text":"\u6211\u4eec\u901a\u8fc7 deployment: nginx \u548c Analytics \u4f5c\u4e3a\u4e00\u4e2a\u4f8b\u5b50\u6f14\u793a\u5982\u4f55\u5f00\u59cb\u4e00\u6b21\u8d44\u6e90\u63a8\u8350\u4e4b\u65c5\uff1a Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"HPA\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment \u7ed3\u679c\u5982\u4e0b: NAME AGE nginx-resource 16m \u67e5\u770b Analytics \u8be6\u60c5: kubectl get analytics nginx-resource -o yaml \u7ed3\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e","title":"\u521b\u5efa\u8d44\u6e90\u5206\u6790"},{"location":"zh/tutorials/resource-recommendation/#_4","text":"\u67e5\u770b\u5206\u6790\u7ed3\u679c Recommendation \uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml \u5206\u6790\u7ed3\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\"","title":"\u67e5\u770b\u5206\u6790\u7ed3\u679c"},{"location":"zh/tutorials/resource-recommendation/#_5","text":"\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u8350\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u5f53 namespace \u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9\u7684\u8d44\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u5f53 namespace \u4e0d\u7b49\u4e8e crane-system \u65f6\uff0c Analytics \u9009\u62e9 Analytics namespace \u4e0b\u7684\u8d44\u6e90 resourceSelectors \u901a\u8fc7\u6570\u7ec4\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8d44\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9009\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8d44\u6e90","title":"\u6279\u91cf\u63a8\u8350"},{"location":"zh/tutorials/resource-recommendation/#_6","text":"","title":"\u8d44\u6e90\u63a8\u8350\u8ba1\u7b97\u6a21\u578b"},{"location":"zh/tutorials/resource-recommendation/#_7","text":"\u6ca1\u6709 Pod \u7684\u5de5\u4f5c\u8d1f\u8f7d: \u5982\u679c\u5de5\u4f5c\u8d1f\u8f7d\u6ca1\u6709 Pod\uff0c\u65e0\u6cd5\u8fdb\u884c\u7b97\u6cd5\u5206\u6790\u3002","title":"\u7b5b\u9009\u9636\u6bb5"},{"location":"zh/tutorials/resource-recommendation/#_8","text":"\u91c7\u7528 VPA \u7684\u6ed1\u52a8\u7a97\u53e3\uff08Moving Window\uff09\u7b97\u6cd5\u5206\u522b\u8ba1\u7b97\u6bcf\u4e2a\u5bb9\u5668\u7684 CPU \u548c Memory \u5e76\u7ed9\u51fa\u5bf9\u5e94\u7684\u63a8\u8350\u503c","title":"\u63a8\u8350"},{"location":"zh/tutorials/resource-recommendation/#_9","text":"","title":"\u5e38\u89c1\u95ee\u9898"},{"location":"zh/tutorials/resource-recommendation/#_10","text":"\u5e94\u7528\u5728\u76d1\u63a7\u7cfb\u7edf\uff08\u6bd4\u5982 Prometheus\uff09\u4e2d\u7684\u5386\u53f2\u6570\u636e\u8d8a\u4e45\uff0c\u63a8\u8350\u7ed3\u679c\u5c31\u8d8a\u51c6\u786e\uff0c\u5efa\u8bae\u751f\u4ea7\u4e0a\u8d85\u8fc7\u4e24\u5468\u65f6\u95f4\u3002\u5bf9\u65b0\u5efa\u5e94\u7528\u7684\u9884\u6d4b\u5f80\u5f80\u4e0d\u51c6\uff0c\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u914d\u7f6e\u4fdd\u8bc1\u53ea\u5bf9\u5386\u53f2\u6570\u636e\u957f\u5ea6\u8d85\u8fc7\u4e00\u5b9a\u5929\u6570\u7684\u4e1a\u52a1\u63a8\u8350\u3002","title":"\u5982\u4f55\u8ba9\u63a8\u8350\u7ed3\u679c\u66f4\u51c6\u786e"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/","text":"Crane-scheduler \u00b6 \u6982\u8ff0 \u00b6 Crane-scheduler \u662f\u4e00\u7ec4\u57fa\u4e8e scheduler framework \u7684\u8c03\u5ea6\u63d2\u4ef6\uff0c \u5305\u542b\uff1a Dynamic scheduler\uff1a\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6\u5668\u63d2\u4ef6 \u5f00\u59cb \u00b6 \u5b89\u88c5 Prometheus \u00b6 \u786e\u4fdd\u4f60\u7684 Kubernetes \u96c6\u7fa4\u5df2\u5b89\u88c5 Prometheus\u3002\u5982\u679c\u6ca1\u6709\uff0c\u8bf7\u53c2\u8003 Install Prometheus . \u914d\u7f6e Prometheus \u89c4\u5219 \u00b6 \u914d\u7f6e Prometheus \u7684\u89c4\u5219\u4ee5\u83b7\u53d6\u9884\u671f\u7684\u805a\u5408\u6570\u636e\uff1a apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting Prometheus \u7684\u91c7\u6837\u95f4\u9694\u5fc5\u987b\u5c0f\u4e8e30\u79d2\uff0c\u4e0d\u7136\u53ef\u80fd\u4f1a\u5bfc\u81f4\u89c4\u5219\u65e0\u6cd5\u6b63\u5e38\u751f\u6548\u3002\u5982\uff1a cpu_usage_active \u3002 \u5b89\u88c5 Crane-scheduler \u00b6 \u6709\u4e24\u79cd\u9009\u62e9\uff1a \u5b89\u88c5 Crane-scheduler \u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u8c03\u5ea6\u5668 \u7528 Crane-scheduler \u66ff\u6362\u539f\u751f Kube-scheduler \u5b89\u88c5 Crane-scheduler \u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u8c03\u5ea6\u5668 \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler \u7528 Crane-scheduler \u66ff\u6362\u539f\u751f Kube-scheduler \u00b6 \u5907\u4efd /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ \u901a\u8fc7\u4fee\u6539 kube-scheduler \u7684\u914d\u7f6e\u6587\u4ef6\uff08 scheduler-config.yaml ) \u542f\u7528\u52a8\u6001\u8c03\u5ea6\u63d2\u4ef6\u5e76\u914d\u7f6e\u63d2\u4ef6\u53c2\u6570\uff1a scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... \u65b0\u5efa /etc/kubernetes/policy.yaml \uff0c\u7528\u4f5c\u52a8\u6001\u63d2\u4ef6\u7684\u8c03\u5ea6\u7b56\u7565\uff1a /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 \u4fee\u6539 kube-scheduler.yaml \u5e76\u7528 Crane-scheduler\u7684\u955c\u50cf\u66ff\u6362 kube-scheduler \u955c\u50cf\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... \u5b89\u88c5 crane-scheduler-controller \uff1a Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml \u4f7f\u7528 Crane-scheduler \u8c03\u5ea6 Pod \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u793a\u4f8b\u6d4b\u8bd5 Crane-scheduler \uff1a apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note \u5982\u679c\u60f3\u5c06 crane-scheduler \u7528\u4f5c\u9ed8\u8ba4\u8c03\u5ea6\u5668\uff0c\u8bf7\u5c06 crane-scheduler \u66f4\u6539\u4e3a default-scheduler \u3002 \u5982\u679c\u6d4b\u8bd5 pod \u8c03\u5ea6\u6210\u529f\uff0c\u5c06\u4f1a\u6709\u4ee5\u4e0b\u4e8b\u4ef6\uff1a Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"\u6982\u8ff0"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler","text":"","title":"Crane-scheduler"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#_1","text":"Crane-scheduler \u662f\u4e00\u7ec4\u57fa\u4e8e scheduler framework \u7684\u8c03\u5ea6\u63d2\u4ef6\uff0c \u5305\u542b\uff1a Dynamic scheduler\uff1a\u8d1f\u8f7d\u611f\u77e5\u8c03\u5ea6\u5668\u63d2\u4ef6","title":"\u6982\u8ff0"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#_2","text":"","title":"\u5f00\u59cb"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#prometheus","text":"\u786e\u4fdd\u4f60\u7684 Kubernetes \u96c6\u7fa4\u5df2\u5b89\u88c5 Prometheus\u3002\u5982\u679c\u6ca1\u6709\uff0c\u8bf7\u53c2\u8003 Install Prometheus .","title":"\u5b89\u88c5 Prometheus"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#prometheus_1","text":"\u914d\u7f6e Prometheus \u7684\u89c4\u5219\u4ee5\u83b7\u53d6\u9884\u671f\u7684\u805a\u5408\u6570\u636e\uff1a apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting Prometheus \u7684\u91c7\u6837\u95f4\u9694\u5fc5\u987b\u5c0f\u4e8e30\u79d2\uff0c\u4e0d\u7136\u53ef\u80fd\u4f1a\u5bfc\u81f4\u89c4\u5219\u65e0\u6cd5\u6b63\u5e38\u751f\u6548\u3002\u5982\uff1a cpu_usage_active \u3002","title":"\u914d\u7f6e Prometheus \u89c4\u5219"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler_1","text":"\u6709\u4e24\u79cd\u9009\u62e9\uff1a \u5b89\u88c5 Crane-scheduler \u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u8c03\u5ea6\u5668 \u7528 Crane-scheduler \u66ff\u6362\u539f\u751f Kube-scheduler","title":"\u5b89\u88c5 Crane-scheduler"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler_2","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler","title":"\u5b89\u88c5 Crane-scheduler \u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u8c03\u5ea6\u5668"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler-kube-scheduler","text":"\u5907\u4efd /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ \u901a\u8fc7\u4fee\u6539 kube-scheduler \u7684\u914d\u7f6e\u6587\u4ef6\uff08 scheduler-config.yaml ) \u542f\u7528\u52a8\u6001\u8c03\u5ea6\u63d2\u4ef6\u5e76\u914d\u7f6e\u63d2\u4ef6\u53c2\u6570\uff1a scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... \u65b0\u5efa /etc/kubernetes/policy.yaml \uff0c\u7528\u4f5c\u52a8\u6001\u63d2\u4ef6\u7684\u8c03\u5ea6\u7b56\u7565\uff1a /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 \u4fee\u6539 kube-scheduler.yaml \u5e76\u7528 Crane-scheduler\u7684\u955c\u50cf\u66ff\u6362 kube-scheduler \u955c\u50cf\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... \u5b89\u88c5 crane-scheduler-controller \uff1a Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml","title":"\u7528 Crane-scheduler \u66ff\u6362\u539f\u751f Kube-scheduler"},{"location":"zh/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler-pod","text":"\u4f7f\u7528\u4ee5\u4e0b\u793a\u4f8b\u6d4b\u8bd5 Crane-scheduler \uff1a apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note \u5982\u679c\u60f3\u5c06 crane-scheduler \u7528\u4f5c\u9ed8\u8ba4\u8c03\u5ea6\u5668\uff0c\u8bf7\u5c06 crane-scheduler \u66f4\u6539\u4e3a default-scheduler \u3002 \u5982\u679c\u6d4b\u8bd5 pod \u8c03\u5ea6\u6210\u529f\uff0c\u5c06\u4f1a\u6709\u4ee5\u4e0b\u4e8b\u4ef6\uff1a Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"\u4f7f\u7528 Crane-scheduler \u8c03\u5ea6 Pod"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/","text":"DSP\u9884\u6d4b\u7b97\u6cd5 \u00b6 Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09 \u6d41\u7a0b \u00b6 \u9884\u5904\u7406 \u00b6 \u586b\u5145\u7f3a\u5931\u6570\u636e \u00b6 \u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\) \u53bb\u9664\u5f02\u5e38\u70b9 \u00b6 \u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u00b6 \u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002 \u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570 \u00b6 \u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002 \u9884\u6d4b \u00b6 \u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002 \u5e94\u7528 \u00b6 Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#dsp","text":"Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_1","text":"","title":"\u6d41\u7a0b"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_2","text":"","title":"\u9884\u5904\u7406"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_3","text":"\u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\)","title":"\u586b\u5145\u7f3a\u5931\u6570\u636e"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_4","text":"\u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002","title":"\u53bb\u9664\u5f02\u5e38\u70b9"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_5","text":"\u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002","title":"\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_6","text":"\u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002","title":"\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_7","text":"\u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002","title":"\u9884\u6d4b"},{"location":"zh/tutorials/timeseriees-forecasting-by-dsp/#_8","text":"Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"\u5e94\u7528"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/","text":"EffectiveHorizontalPodAutoscaler \u00b6 EffectiveHorizontalPodAutoscaler\uff08\u7b80\u79f0 EHPA\uff09\u662f Crane \u63d0\u4f9b\u7684\u5f39\u6027\u4f38\u7f29\u4ea7\u54c1\uff0c\u5b83\u57fa\u4e8e\u793e\u533a HPA \u505a\u5e95\u5c42\u7684\u5f39\u6027\u63a7\u5236\uff0c\u652f\u6301\u66f4\u4e30\u5bcc\u7684\u5f39\u6027\u89e6\u53d1\u7b56\u7565\uff08\u9884\u6d4b\uff0c\u89c2\u6d4b\uff0c\u5468\u671f\uff09\uff0c\u8ba9\u5f39\u6027\u66f4\u52a0\u9ad8\u6548\uff0c\u5e76\u4fdd\u969c\u4e86\u670d\u52a1\u7684\u8d28\u91cf\u3002 \u63d0\u524d\u6269\u5bb9\uff0c\u4fdd\u8bc1\u670d\u52a1\u8d28\u91cf\uff1a\u901a\u8fc7\u7b97\u6cd5\u9884\u6d4b\u672a\u6765\u7684\u6d41\u91cf\u6d2a\u5cf0\u63d0\u524d\u6269\u5bb9\uff0c\u907f\u514d\u6269\u5bb9\u4e0d\u53ca\u65f6\u5bfc\u81f4\u7684\u96ea\u5d29\u548c\u670d\u52a1\u7a33\u5b9a\u6027\u6545\u969c\u3002 \u51cf\u5c11\u65e0\u6548\u7f29\u5bb9\uff1a\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u53ef\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u7f29\u5bb9\uff0c\u7a33\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u8d44\u6e90\u4f7f\u7528\u7387\uff0c\u6d88\u9664\u7a81\u523a\u8bef\u5224\u3002 \u652f\u6301 Cron \u914d\u7f6e\uff1a\u652f\u6301 Cron-based \u5f39\u6027\u914d\u7f6e\uff0c\u5e94\u5bf9\u5927\u4fc3\u7b49\u5f02\u5e38\u6d41\u91cf\u6d2a\u5cf0\u3002 \u517c\u5bb9\u793e\u533a\uff1a\u4f7f\u7528\u793e\u533a HPA \u4f5c\u4e3a\u5f39\u6027\u63a7\u5236\u7684\u6267\u884c\u5c42\uff0c\u80fd\u529b\u5b8c\u5168\u517c\u5bb9\u793e\u533a\u3002 \u4ea7\u54c1\u529f\u80fd \u00b6 \u4e00\u4e2a\u7b80\u5355\u7684 EHPA yaml \u6587\u4ef6\u5982\u4e0b\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef \u914d\u7f6e\u4f60\u5e0c\u671b\u5f39\u6027\u7684\u5de5\u4f5c\u8d1f\u8f7d\u3002 MinReplicas \u6307\u5b9a\u4e86\u81ea\u52a8\u7f29\u5bb9\u7684\u6700\u5c0f\u503c\u3002 MaxReplicas \u6307\u5b9a\u4e86\u81ea\u52a8\u6269\u5bb9\u7684\u6700\u5927\u503c\u3002 ScaleStrategy \u5b9a\u4e49\u4e86\u5f39\u6027\u7684\u7b56\u7565\uff0c\u503c\u53ef\u4ee5\u662f \"Auto\" and \"Preview\". Metrics \u5b9a\u4e49\u4e86\u5f39\u6027\u9608\u503c\u914d\u7f6e\u3002 Prediction \u5b9a\u4e49\u4e86\u9884\u6d4b\u7b97\u6cd5\u914d\u7f6e\u3002 PredictionWindowSeconds \u6307\u5b9a\u5f80\u540e\u9884\u6d4b\u591a\u4e45\u7684\u6570\u636e\u3002 \u57fa\u4e8e\u9884\u6d4b\u7684\u5f39\u6027 \u00b6 \u5927\u591a\u6570\u5728\u7ebf\u5e94\u7528\u7684\u8d1f\u8f7d\u90fd\u6709\u5468\u671f\u6027\u7684\u7279\u5f81\u3002\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6309\u5929\u6216\u8005\u6309\u5468\u7684\u8d8b\u52bf\u9884\u6d4b\u672a\u6765\u7684\u8d1f\u8f7d\u3002EHPA \u4f7f\u7528 DSP \u7b97\u6cd5\u6765\u9884\u6d4b\u5e94\u7528\u672a\u6765\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a\u5f00\u542f\u4e86\u9884\u6d4b\u80fd\u529b\u7684 EHPA \u6a21\u7248\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" \u76d1\u63a7\u6570\u636e\u515c\u5e95 \u00b6 \u5728\u4f7f\u7528\u9884\u6d4b\u7b97\u6cd5\u9884\u6d4b\u65f6\uff0c\u4f60\u53ef\u80fd\u4f1a\u62c5\u5fc3\u9884\u6d4b\u6570\u636e\u4e0d\u51c6\u5e26\u6765\u4e00\u5b9a\u7684\u98ce\u9669\uff0cEHPA \u5728\u8ba1\u7b97\u526f\u672c\u6570\u65f6\uff0c\u4e0d\u4ec5\u4f1a\u6309\u9884\u6d4b\u6570\u636e\u8ba1\u7b97\uff0c\u540c\u65f6\u4e5f\u4f1a\u8003\u8651\u5b9e\u9645\u76d1\u63a7\u6570\u636e\u6765\u515c\u5e95\uff0c\u63d0\u5347\u4e86\u5f39\u6027\u7684\u5b89\u5168\u6027\u3002 \u5b9e\u73b0\u7684\u539f\u7406\u662f\u5f53\u4f60\u5728 EHPA \u4e2d\u5b9a\u4e49 spec.metrics \u5e76\u4e14\u5f00\u542f\u5f39\u6027\u9884\u6d4b\u65f6\uff0cEffectiveHPAController \u4f1a\u5728\u521b\u5efa\u5e95\u5c42\u7ba1\u7406\u7684 HPA \u65f6\u6309\u7b56\u7565\u81ea\u52a8\u751f\u6210\u591a\u6761 Metric Spec\u3002 \u4f8b\u5982\uff0c\u5f53\u7528\u6237\u5728 EHPA \u7684 yaml \u91cc\u5b9a\u4e49\u5982\u4e0b Metric Spec\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 \u5b83\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u4e24\u6761 HPA \u7684\u9608\u503c\u914d\u7f6e\uff1a apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource \u5728\u4e0a\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u7528\u6237\u5728 EHPA \u521b\u5efa\u7684 Metric \u9608\u503c\u914d\u7f6e\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5e95\u5c42 HPA \u4e0a\u7684\u4e24\u6761 Metric \u9608\u503c\u914d\u7f6e\uff1a\u9884\u6d4b Metric \u9608\u503c\u548c\u5b9e\u9645\u76d1\u63a7 Metric \u9608\u503c \u9884\u6d4b Metric \u9608\u503c \u662f\u4e00\u4e2a custom metric\u3002\u503c\u901a\u8fc7 Crane \u7684 MetricAdapter \u63d0\u4f9b\u3002 \u5b9e\u9645\u76d1\u63a7 Metric \u9608\u503c \u662f\u4e00\u4e2a resource metric\uff0c\u5b83\u548c\u7528\u6237\u5728 EHPA \u4e0a\u5b9a\u4e49\u7684\u4e00\u6837\u3002\u8fd9\u6837 HPA \u4f1a\u6839\u636e\u5e94\u7528\u5b9e\u9645\u76d1\u63a7\u7684 Metric \u8ba1\u7b97\u526f\u672c\u6570\u3002 HPA \u5728\u914d\u7f6e\u4e86\u591a\u4e2a\u5f39\u6027 Metric \u9608\u503c\u65f6\uff0c\u5728\u8ba1\u7b97\u526f\u672c\u6570\u65f6\u4f1a\u5206\u522b\u8ba1\u7b97\u6bcf\u6761 Metric \u5bf9\u5e94\u7684\u526f\u672c\u6570\uff0c\u5e76\u9009\u62e9 \u6700\u5927 \u7684\u90a3\u4e2a\u526f\u672c\u6570\u4f5c\u4e3a\u6700\u7ec8\u7684\u63a8\u8350\u5f39\u6027\u7ed3\u679c\u3002 \u6c34\u5e73\u5f39\u6027\u7684\u6267\u884c\u6d41\u7a0b \u00b6 EffectiveHPAController \u521b\u5efa HorizontalPodAutoscaler \u548c TimeSeriesPrediction \u5bf9\u8c61 PredictionCore \u4ece prometheus \u83b7\u53d6\u5386\u53f2 metric \u901a\u8fc7\u9884\u6d4b\u7b97\u6cd5\u8ba1\u7b97\uff0c\u5c06\u7ed3\u679c\u8bb0\u5f55\u5230 TimeSeriesPrediction HPAController \u901a\u8fc7 metric client \u4ece KubeApiServer \u8bfb\u53d6 metric \u6570\u636e KubeApiServer \u5c06\u8bf7\u6c42\u8def\u7531\u5230 Crane \u7684 MetricAdapter\u3002 HPAController \u8ba1\u7b97\u6240\u6709\u7684 Metric \u8fd4\u56de\u7684\u7ed3\u679c\u5f97\u5230\u6700\u7ec8\u7684\u5f39\u6027\u526f\u672c\u63a8\u8350\u3002 HPAController \u8c03\u7528 scale API \u5bf9\u76ee\u6807\u5e94\u7528\u6269/\u7f29\u5bb9\u3002 \u6574\u4f53\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a \u7528\u6237\u6848\u4f8b \u00b6 \u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u751f\u4ea7\u73af\u5883\u7684\u5ba2\u6237\u6848\u4f8b\u6765\u4ecb\u7ecd EHPA \u7684\u843d\u5730\u6548\u679c\u3002 \u6211\u4eec\u5c06\u751f\u4ea7\u4e0a\u7684\u6570\u636e\u5728\u9884\u53d1\u73af\u5883\u91cd\u653e\uff0c\u5bf9\u6bd4\u4f7f\u7528 EHPA \u548c\u793e\u533a\u7684 HPA \u7684\u5f39\u6027\u6548\u679c\u3002 \u4e0b\u56fe\u7684\u7ea2\u7ebf\u662f\u5e94\u7528\u5728\u4e00\u5929\u5185\u7684\u5b9e\u9645 CPU \u4f7f\u7528\u91cf\u66f2\u7ebf\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u57288\u70b9\uff0c12\u70b9\uff0c\u665a\u4e0a8\u70b9\u65f6\u662f\u4f7f\u7528\u9ad8\u5cf0\u3002\u7eff\u7ebf\u662f EHPA \u9884\u6d4b\u7684 CPU \u4f7f\u7528\u91cf\u3002 \u4e0b\u56fe\u662f\u5bf9\u5e94\u7684\u81ea\u52a8\u5f39\u6027\u7684\u526f\u672c\u6570\u66f2\u7ebf\uff0c\u7ea2\u7ebf\u662f\u793e\u533a HPA \u7684\u526f\u672c\u6570\u66f2\u7ebf\uff0c\u7eff\u7ebf\u662f EHPA \u7684\u526f\u672c\u6570\u66f2\u7ebf\u3002 \u53ef\u4ee5\u770b\u5230 EHPA \u5177\u6709\u4ee5\u4e0b\u4f18\u52bf\uff1a \u5728\u6d41\u91cf\u6d2a\u5cf0\u6765\u4e34\u524d\u6269\u5bb9\u3002 \u5f53\u6d41\u91cf\u5148\u964d\u540e\u7acb\u523b\u5347\u65f6\u4e0d\u505a\u65e0\u6548\u7f29\u5bb9\u3002 \u76f8\u6bd4 HPA \u66f4\u5c11\u7684\u5f39\u6027\u6b21\u6570\u5374\u66f4\u9ad8\u6548\u3002 ScaleStrategy \u5f39\u6027\u7b56\u7565 \u00b6 EHPA \u63d0\u4f9b\u4e86\u4e24\u79cd\u5f39\u6027\u7b56\u7565\uff1a Auto \u548c Preview \u3002\u7528\u6237\u53ef\u4ee5\u968f\u65f6\u5207\u6362\u5b83\u5e76\u7acb\u5373\u751f\u6548\u3002 Auto \u00b6 Auto \u7b56\u7565\u4e0b EHPA \u4f1a\u81ea\u52a8\u6267\u884c\u5f39\u6027\u884c\u4e3a\u3002\u9ed8\u8ba4 EHPA \u7684\u7b56\u7565\u662f Auto\u3002\u5728\u8fd9\u4e2a\u6a21\u5f0f\u4e0b EHPA \u4f1a\u521b\u5efa\u4e00\u4e2a\u793e\u533a\u7684 HPA \u5bf9\u8c61\u5e76\u81ea\u52a8\u63a5\u7ba1\u5b83\u7684\u751f\u547d\u5468\u671f\u3002\u6211\u4eec\u4e0d\u5efa\u8bae\u7528\u6237\u4fee\u6539\u6216\u8005\u63a7\u5236\u8fd9\u4e2a\u5e95\u5c42\u7684 HPA \u5bf9\u8c61\uff0c\u5f53 EHPA \u88ab\u5220\u9664\u65f6\uff0c\u5e95\u5c42\u7684 HPA \u5bf9\u8c61\u4e5f\u4f1a\u4e00\u5e76\u5220\u9664\u3002 Preview \u00b6 Preview \u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba9 EHPA \u4e0d\u81ea\u52a8\u6267\u884c\u5f39\u6027\u7684\u80fd\u529b\u3002\u6240\u4ee5\u4f60\u53ef\u4ee5\u901a\u8fc7 EHPA \u7684 desiredReplicas \u5b57\u6bb5\u89c2\u6d4b EHPA \u8ba1\u7b97\u51fa\u7684\u526f\u672c\u6570\u3002\u7528\u6237\u53ef\u4ee5\u968f\u65f6\u5728\u4e24\u4e2a\u6a21\u5f0f\u95f4\u5207\u6362\uff0c\u5f53\u7528\u6237\u5207\u6362\u5230 Preview \u6a21\u5f0f\u65f6\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 spec.specificReplicas \u8c03\u6574\u5e94\u7528\u7684\u526f\u672c\u6570\uff0c\u5982\u679c spec.specificReplicas \u4e3a\u7a7a\uff0c\u5219\u4e0d\u4f1a\u5bf9\u5e94\u7528\u6267\u884c\u5f39\u6027\uff0c\u4f46\u662f\u4f9d\u7136\u4f1a\u6267\u884c\u526f\u672c\u6570\u7684\u8ba1\u7b97\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a\u914d\u7f6e\u6210 Preview \u6a21\u5f0f\u7684 EHPA \u6a21\u7248\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target HorizontalPodAutoscaler \u793e\u533a\u517c\u5bb9 \u00b6 EHPA \u4ece\u8bbe\u8ba1\u4e4b\u51fa\u5c31\u5e0c\u671b\u548c\u793e\u533a\u7684 HPA \u517c\u5bb9\uff0c\u56e0\u4e3a\u6211\u4eec\u4e0d\u5e0c\u671b\u91cd\u65b0\u9020\u4e00\u4e2a\u7c7b\u4f3c HPA \u7684\u8f6e\u5b50\uff0cHPA \u5728\u4e0d\u65ad\u6f14\u8fdb\u7684\u8fc7\u7a0b\u5df2\u7ecf\u89e3\u51b3\u4e86\u5f88\u591a\u901a\u7528\u7684\u95ee\u9898\uff0cEHPA \u5e0c\u671b\u5728 HPA \u7684\u57fa\u7840\u4e0a\u63d0\u4f9b\u66f4\u9ad8\u9636\u7684 CRD\uff0cEHPA \u7684\u529f\u80fd\u662f\u793e\u533a HPA \u7684\u8d85\u96c6\u3002 EHPA \u4e5f\u4f1a\u6301\u7eed\u8ddf\u8fdb\u652f\u6301 HPA \u7684\u65b0\u529f\u80fd\u3002 EffectiveHorizontalPodAutoscaler status \u00b6 EHPA \u7684 Status \u5305\u62ec\u4e86\u81ea\u8eab\u7684 Status \u540c\u65f6\u4e5f\u6c47\u805a\u4e86\u5e95\u5c42 HPA \u7684\u90e8\u5206 Status\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a EHPA \u7684 Status yaml\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0 Cron-based autoscaling \u00b6 EffectiveHorizontalPodAutoscaler \u652f\u6301\u57fa\u4e8e cron \u7684\u81ea\u52a8\u7f29\u653e\u3002 \u9664\u4e86\u57fa\u4e8e\u76d1\u63a7\u6307\u6807\uff0c\u6709\u65f6\u8282\u5047\u65e5\u548c\u5de5\u4f5c\u65e5\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6d41\u91cf\u5b58\u5728\u5dee\u5f02\uff0c\u7b80\u5355\u7684\u9884\u6d4b\u7b97\u6cd5\u53ef\u80fd\u6548\u679c\u4e0d\u4f73\u3002\u7136\u540e\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u5468\u672b cron \u6765\u652f\u6301\u66f4\u5927\u6570\u91cf\u7684\u526f\u672c\u6765\u5f25\u8865\u9884\u6d4b\u7684\u4e0d\u8db3\u3002 \u5bf9\u4e8e\u4e00\u4e9b\u975e web \u6d41\u91cf\u7684\u5e94\u7528\uff0c\u6bd4\u5982\u4e00\u4e9b\u5e94\u7528\u4e0d\u9700\u8981\u5728\u5468\u672b\u4f7f\u7528\uff0c\u53ef\u4ee5\u628a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u51cf\u5c11\u5230 1\uff0c\u4e5f\u53ef\u4ee5\u914d\u7f6e cron \u6765\u964d\u4f4e\u4f60\u7684\u670d\u52a1\u6210\u672c\u3002 \u4ee5\u4e0b\u662f EHPA Spec \u4e2d\u7684 cron \u4e3b\u8981\u5b57\u6bb5\uff1a CronSpec \uff1a\u53ef\u4ee5\u8bbe\u7f6e\u591a\u4e2a cron \u81ea\u52a8\u4f38\u7f29\u914d\u7f6e\uff0ccron cycle \u53ef\u4ee5\u8bbe\u7f6e\u5faa\u73af\u7684\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\uff0c\u5e76\u4e14\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u53ef\u4ee5\u5728\u65f6\u95f4\u8303\u56f4\u5185\u6301\u7eed\u4fdd\u6301\u4e3a\u8bbe\u5b9a\u7684\u76ee\u6807\u503c\u3002 Name \uff1acron \u6807\u8bc6\u7b26 TargetReplicas \uff1a\u6b64 cron \u65f6\u95f4\u8303\u56f4\u5185\u5de5\u4f5c\u8d1f\u8f7d\u7684\u76ee\u6807\u526f\u672c\u6570\u3002 Start \uff1acron \u7684\u5f00\u59cb\u65f6\u95f4\uff0c\u6807\u51c6 linux crontab \u683c\u5f0f End \uff1acron \u7684\u7ed3\u675f\u65f6\u95f4\uff0c\u6807\u51c6 linux crontab \u683c\u5f0f \u4e00\u4e9b\u4e91\u5382\u5546\u548c\u793e\u533a\u5f53\u524d\u7684 cron \u81ea\u52a8\u7f29\u653e\u529f\u80fd\u5b58\u5728\u4e00\u4e9b\u7f3a\u70b9\u3002 cron \u80fd\u529b\u5355\u72ec\u63d0\u4f9b\uff0c\u6ca1\u6709\u5728\u5168\u5c40\u89c6\u56fe\u4e2d\u8fdb\u884c\u81ea\u52a8\u7f29\u653e\uff0c\u4e0e HPA \u517c\u5bb9\u6027\u5dee\uff0c\u4e0e\u5176\u4ed6\u7f29\u653e\u89e6\u53d1\u5668\u51b2\u7a81\u3002 cron \u7684\u8bed\u4e49\u548c\u884c\u4e3a\u4e0d\u662f\u5f88\u5339\u914d\uff0c\u4f7f\u7528\u65f6\u751a\u81f3\u5f88\u96be\u7406\u89e3\uff0c\u5f88\u5bb9\u6613\u8bef\u5bfc\u7528\u6237\uff0c\u5bfc\u81f4\u81ea\u52a8\u4f38\u7f29\u5931\u8d25\u3002 \u4e0b\u56fe\u663e\u793a\u4e86\u5f53\u524d EHPA cron \u81ea\u52a8\u4f38\u7f29\u5b9e\u73b0\u4e0e\u5176\u4ed6 cron \u80fd\u529b\u7684\u5bf9\u6bd4\u3002 \u9488\u5bf9\u4ee5\u4e0a\u95ee\u9898\uff0cEHPA \u5b9e\u73b0\u7684 cron autoscaling \u662f\u5728\u4e0e HPA \u517c\u5bb9\u7684\u57fa\u7840\u4e0a\u8bbe\u8ba1\u7684\uff0ccron \u4f5c\u4e3a HPA \u7684\u4e00\u4e2a\u6307\u6807\uff0c\u4e0e\u5176\u4ed6\u6307\u6807\u4e00\u8d77\u4f5c\u7528\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u3002 \u53e6\u5916\uff0ccron \u7684\u8bbe\u7f6e\u4e5f\u5f88\u7b80\u5355\u3002\u5355\u72ec\u914d\u7f6e cron \u65f6\uff0c\u4e0d\u5728\u6d3b\u52a8\u65f6\u95f4\u8303\u56f4\u5185\u65f6\uff0c\u4e0d\u4f1a\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u6267\u884c\u7f29\u653e\u3002 Cron working without other metrics \u00b6 \u5047\u8bbe\u4f60\u6ca1\u6709\u914d\u7f6e\u5176\u4ed6\u6307\u6807\uff0c\u4f60\u53ea\u9700\u914d\u7f6e cron \u672c\u8eab\u5373\u53ef\u5de5\u4f5c\u3002 apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef \u5173\u8054\u5230\u9700\u6269\u7f29\u5bb9\u7684\u5de5\u4f5c\u8d1f\u8f7d scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas : autoscaler \u7f29\u653e\u7684\u6700\u4f4e\u526f\u672c\u6570 maxReplicas : 100 # MaxReplicas : autoscaler \u7f29\u653e\u7684\u6700\u5927\u526f\u672c\u6570 scaleStrategy : Auto # ScaleStrategy : \u7f29\u653e\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u5019\uff0c\u6240\u91c7\u7528\u7684\u7b56\u7565\u3002\u53ef\u9009\u503c\u4e3a \"Auto\" \"Manual\" # \u6700\u597d\u5c06Cron Scheduling\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u5b8c\u6574\u7684\u65f6\u95f4\u5468\u671f\uff0c\u4f8b\u5982\uff1a \u4e00\u5929\uff0c\u4e00\u5468 # \u4e0b\u9762\u662f\u4e00\u5929\u7684Cron Scheduling #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #\u672c\u5730\u65f6\u533a(timezone: \"Local\")\u610f\u5473\u7740\u60a8\u4f7f\u7528\u8fd0\u884cCraned\u6240\u5728\u7684\u670d\u52a1\u5668\uff08\u6216\u8005\u53ef\u80fd\u662f\u5bb9\u5668\uff09\u7684\u65f6\u533a\u3002\u4f8b\u5982\uff0c\u5f53Craned \u662f\u4ee5UTC\u65f6\u533a\u5f00\u59cb\uff0c\u90a3\u4e48\u5b83\u5c31\u662fUTC\u3002\u5982\u679c\u4e00\u5f00\u59cb\u662fAsia/Shanghai\uff0c\u90a3\u4e48\u5b83\u5c31\u662fAsia/Shanghai\u3002 crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec \u5177\u6709\u4ee5\u4e0b\u5b57\u6bb5: name \u5b9a\u4e49\u4e86 cron \u7684\u540d\u5b57\uff0ccron \u540d\u5b57\u5728\u540c\u4e00\u4e2a Ehpa \u4e2d\u5fc5\u987b\u662f\u552f\u4e00\u7684 description \u5b9a\u4e49 cron \u7684\u8be6\u7ec6\u63cf\u8ff0\u3002\u5b83\u53ef\u4ee5\u662f\u7a7a\u7684\u3002 timezone \u5b9a\u4e49Crane\u6240\u8981\u8c03\u5ea6\u7684 cron \u65f6\u533a\u3002\u5982\u679c\u672a\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4f7f\u7528 UTC \u65f6\u533a\u3002\u4f60\u53ef\u4ee5\u5c06\u5b83\u8bbe\u7f6e\u4e3a Local \uff0c\u8fd9\u5c06\u4f7f\u7528\u6b63\u5728\u8fd0\u884c\u7684Crane\u5bb9\u5668\u6240\u5728\u7684\u65f6\u533a\u3002\u5176\u5b9e\uff0c\u4f60\u5b9a\u4e49 America/Los_Angeles \u4e5f\u662f\u53ef\u4ee5\u7684\u3002 start \u5b9a\u4e49 cron \u5f00\u59cb\u8c03\u5ea6\u7684\u65f6\u95f4\uff0c\u662f crontab \u683c\u5f0f\u3002\u53c2\u8003 wiki-Cron end \u5b9a\u4e49 cron \u7ed3\u675f\u8c03\u5ea6\u7684\u65f6\u95f4\uff0c\u662f crontab \u683c\u5f0f\u3002\u53c2\u8003 wiki-Cron targetReplicas \u5b9a\u4e49\u76ee\u6807\u526f\u672c\u5728 cron \u5904\u4e8e\u6d3b\u52a8\u72b6\u6001\u65f6\u8981\u6269\u5c55\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u8fd9\u610f\u5473\u7740\u76ee\u6807\u526f\u672c\u6570\u4ecb\u4e8e\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\u4e4b\u95f4\u751f\u6548\u3002 \u4ee5\u4e0aYAML\u5b9a\u4e49\uff0c\u610f\u5473\u7740\u4e00\u5929\u5f53\u4e2d\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u5728\u6bcf\u5c0f\u65f6\u6240\u9700\u8981\u4fdd\u6301\u7684\u526f\u672c\u6570\u3002\u5de5\u4f5c\u8d1f\u8f7d\u5c06\u4f1a\u6bcf\u5929\u6309\u7167\u8be5\u89c4\u5219\u6267\u884c\u3002 #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u8bb0\u4f4f \u4e0d\u8981\u8bbe\u7f6e\u5f00\u59cb\u65f6\u95f4\u5728\u7ed3\u675f\u65f6\u95f4\u4e4b\u540e \u3002 \u4f8b\u5982\uff0c\u5f53\u4f60\u8bbe\u7f6e\u4ee5\u4e0b\u5185\u5bb9\u65f6\uff1a crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 \u4ee5\u4e0a\u65e0\u6548\uff0c\u56e0\u4e3a\u5f00\u59cb\u603b\u662f\u665a\u4e8e\u7ed3\u675f\u3002 HPA \u63a7\u5236\u5668\u59cb\u7ec8\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u6240\u63cf\u8ff0\u7684\u526f\u672c\u6570\u8fdb\u884c\u6269\u5c55\uff0c\u8fd9\u610f\u5473\u7740\u4fdd\u7559\u539f\u6709\u526f\u672c\u6570\u4e0d\u53d8\u3002 Horizontal scaling process \u00b6 cron \u9a71\u52a8\u548c\u6269\u5c55\u8fc7\u7a0b\u6709\u516d\u4e2a\u6b65\u9aa4\uff1a EffectiveHPAController \u521b\u5efa HorizontalPodAutoscaler \uff0c\u5b83\u88ab\u6ce8\u5165\u5230 spec \u4e2d\u7684 external cron metrics \u4e2d\u3002 HPAController \u4ece KubeApiServer \u8bfb\u53d6 external cron metrics KubeApiServer \u5c06\u8bf7\u6c42\u8f6c\u53d1\u7ed9 MetricAdapter \u548c MetricServer MetricAdapter \u627e\u5230\u76ee\u6807 hpa \u7684 cron scaler \uff0c\u5e76\u68c0\u6d4b cron scaler \u662f\u5426\u5904\u4e8e\u6d3b\u52a8\u72b6\u6001\u3002\u8fd9\u610f\u5473\u7740\u5f53\u524d\u65f6\u95f4\u4ecb\u4e8e cron \u5f00\u59cb\u548c\u7ed3\u675f\u8ba1\u5212\u65f6\u95f4\u4e4b\u95f4\u3002\u5b83\u5c06\u8fd4\u56de TargetReplicas \u4e2d\u5b9a\u4e49\u7684 CronSpec \u3002 HPAController \u8ba1\u7b97\u6240\u6709 metrics \u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6700\u5927\u7684\u4e00\u4e2a\u4e3a\u76ee\u6807\u526f\u672c\u6570\u3002\u5e76\u7531\u6b64\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 scale replicas \u3002 HPAController \u4f7f\u7528 Scale Api \u7f29\u653e\u76ee\u6807 \u4f7f\u7528 EHPA \u65f6\uff0c\u7528\u6237\u53ef\u4ee5\u53ea\u914d\u7f6e cron metric\uff0c\u8ba9 EHPA \u7528\u4f5c cron hpa\u3002 \u4e00\u4e2a EHPA \u7684\u591a\u4e2a crons \u5c06\u8f6c\u6362\u4e3a\u4e00\u4e2a external metrics \u3002 HPA \u5c06\u83b7\u53d6 external metrics \u5e76\u5728\u534f\u8c03\u65f6\u8ba1\u7b97\u76ee\u6807\u526f\u672c\u3002\u5f53\u5b58\u5728\u591a\u4e2a\u6307\u6807\u7684\u5de5\u4f5c\u8d1f\u8f7d\u65f6\uff0cHPA \u5c06\u9009\u62e9\u6700\u5927\u7684\u526f\u672c\u6570\u6765\u6269\u5c55\u3002 Cron working with other metrics together \u00b6 EffectiveHorizontalPodAutoscaler \u517c\u5bb9 HorizontalPodAutoscaler \uff08\u5185\u7f6e\u5728 kubernetes\uff09\u3002\u56e0\u6b64\uff0c\u5982\u679c\u4f60\u4e3a HPA \u914d\u7f6e\u4e86\u6307\u6807\uff0c\u4f8b\u5982 cpu \u6216\u5185\u5b58\uff0c\u90a3\u4e48 HPA \u5c06\u6839\u636e\u5b83\u89c2\u5bdf\u5230\u7684\u5b9e\u65f6\u6307\u6807\u5bf9\u526f\u672c\u6570\u8fdb\u884c\u6269\u5c55\u3002 \u901a\u8fc7 EHPA\uff0c\u7528\u6237\u53ef\u4ee5\u540c\u65f6\u914d\u7f6e CronMetric \u3001 PredictionMetric \u3001 OriginalMetric \u3002 \u6211\u4eec\u5f3a\u70c8\u5efa\u8bae\u4f60\u914d\u7f6e\u6240\u6709\u7ef4\u5ea6\u7684\u6307\u6807\u3002\u5b83\u4eec\u5206\u522b\u4ee3\u8868 cron \u526f\u672c\u3001\u5148\u524d\u9884\u6d4b\u7684\u526f\u672c\u3001\u540e\u89c2\u5bdf\u7684\u526f\u672c\u3002 \u8fd9\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u529f\u80fd\u3002\u56e0\u4e3a HPA \u603b\u662f\u9009\u62e9\u7531\u6240\u6709\u7ef4\u5ea6 metrics \u8ba1\u7b97\u7684\u6700\u5927\u526f\u672c\u8fdb\u884c\u6269\u5c55\u3002 \u8fd9\u5c06\u4fdd\u8bc1\u4f60\u5de5\u4f5c\u8d1f\u8f7d\u7684 QoS\uff0c\u5f53\u4f60\u540c\u65f6\u914d\u7f6e\u4e09\u79cd\u7c7b\u578b\u7684\u81ea\u52a8\u7f29\u653e\u65f6\uff0c\u6839\u636e\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u6307\u6807\u8ba1\u7b97\u7684\u526f\u672c\u6700\u5927\uff0c\u7136\u540e\u5b83\u5c06\u4f7f\u7528\u6700\u5927\u7684\u4e00\u4e2a\u3002 \u5c3d\u7ba1\u7531\u4e8e\u67d0\u4e9b\u610f\u60f3\u4e0d\u5230\u7684\u539f\u56e0\uff0c\u5bfc\u81f4\u7531 PredictionMetric \u8ba1\u7b97\u7684\u526f\u672c\u66f4\u5c0f\u3002\u56e0\u6b64\uff0c\u4f60\u4e0d\u5fc5\u62c5\u5fc3 QoS\u3002 Mechanism \u00b6 \u5f53 metrics adapter \u5904\u7406 external cron metrics \u8bf7\u6c42\u65f6\uff0c metrics adapter \u5c06\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\u3002 graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; \u6ca1\u6709\u6d3b\u8dc3\u7684cron\uff0c\u6709\u4e24\u79cd\u60c5\u51b5\uff1a \u6ca1\u6709\u5176\u4ed6 hpa \u6307\u6807\u4e0e cron \u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u8fd4\u56de\u5f53\u524d\u5de5\u4f5c\u8d1f\u8f7d\u526f\u672c\u4ee5\u4fdd\u7559\u539f\u59cb\u6240\u9700\u7684\u526f\u672c \u5f53\u5176\u4ed6 hpa \u6307\u6807\u4e0e cron \u4e00\u8d77\u4f7f\u7528\uff0c\u5c06\u4f1a\u8fd4\u56de\u6700\u5c0f\u503c\u4ee5\u6d88\u9664cron\u5bf9\u5176\u4ed6\u6307\u6807\u7684\u5f71\u54cd\u3002\u5f53 cron \u4e0e\u5176\u4ed6\u6307\u6807\u4e00\u8d77\u5de5\u4f5c\u65f6\uff0c\u5b83\u4e0d\u5e94\u8be5\u8fd4\u56de\u5de5\u4f5c\u8d1f\u8f7d\u7684\u539f\u59cb\u526f\u672c\u6570\uff0c\u56e0\u4e3a\u53ef\u80fd\u6709\u5176\u4ed6\u6307\u6807\u60f3\u8981\u7f29\u5c0f\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u3002 HPA Controller \u9009\u62e9\u7531\u6240\u6709\u6307\u6807\u8ba1\u7b97\u7684\u6700\u5927\u526f\u672c\uff08\u8fd9\u662f\u786c\u4ee3\u7801\u4e2d\u7684 hpa \u9ed8\u8ba4\u7b56\u7565)\uff0ccron \u4f1a\u5f71\u54cd hpa\u3002\u6240\u4ee5\u6211\u4eec\u5e94\u8be5\u5728 cron \u4e0d\u6d3b\u52a8\u65f6\u79fb\u9664 cron \u6548\u679c\uff0c\u5b83\u5e94\u8be5\u8fd4\u56de\u6700\u5c0f\u503c\u3002 \u6709\u6d3b\u8dc3\u7684cron\u3002\u6211\u4eec\u4f7f\u7528 cron spec \u4e2d\u6307\u5b9a\u7684\u6700\u5927\u76ee\u6807\u526f\u672c\u3002\u57fa\u672c\u4e0a\uff0c\u5728\u540c\u4e00\u65f6\u95f4\u6bb5\u5185\u4e0d\u5e94\u6709\u8d85\u8fc7\u4e00\u4e2a\u6d3b\u8dc3\u7684 cron\uff0c\u8fd9\u4e0d\u662f\u6700\u4f73\u5b9e\u8df5\u3002 HPA \u5c06\u83b7\u53d6 cron external metrics \uff0c\u7136\u540e\u5b83\u4f1a\u81ea\u884c\u8ba1\u7b97\u526f\u672c\u6570\u3002 Use Case \u00b6 \u5f53\u4f60\u9700\u8981\u5728\u5348\u591c\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u526f\u672c\u6570\u4fdd\u6301\u5728\u6700\u4f4e\u9650\u5ea6\uff0c\u6839\u636e\u8be5\u9700\u6c42\u914d\u7f6e\u4e86 cron\u3002 \u4f60\u9700\u8981 HPA \u6765\u83b7\u53d6\u6307\u6807\u670d\u52a1\u5668\u89c2\u5bdf\u5230\u7684\u771f\u5b9e\u6307\u6807\uff0c\u4ee5\u6839\u636e\u5b9e\u65f6\u89c2\u5bdf\u5230\u7684\u6307\u6807\u8fdb\u884c\u6269\u5c55\u3002 \u6700\u540e\uff0c\u4f60\u914d\u7f6e\u4e00\u4e2a prediction-driven metric \uff0c\u901a\u8fc7\u9884\u6d4b\u65b9\u5f0f\u63d0\u524d\u6269\u5927\u89c4\u6a21\u5e76\u5728\u672b\u671f\u7f29\u5c0f\u89c4\u6a21\u3002 apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef \u5173\u8054\u5230\u9700\u6269\u7f29\u5bb9\u7684\u5de5\u4f5c\u8d1f\u8f7d scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas : \u7f29\u653e\u7684\u6700\u5c0f\u526f\u672c\u6570 maxReplicas : 100 # MaxReplicas : \u7f29\u653e\u7684\u6700\u5927\u526f\u672c\u6570 scaleStrategy : Auto # ScaleStrategy : \u7f29\u653e\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u5019\uff0c\u6240\u91c7\u7528\u7684\u7b56\u7565\u3002\u53ef\u9009\u503c\u4e3a \"Auto\" \"Manual\" # Metrics \u5305\u542b\u4e86\u7528\u4e8e\u8ba1\u7b97\u6240\u9700\u526f\u672c\u6570\u7684\u6307\u6807\u3002 metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction \u7684\u914d\u7f6e\u5b9a\u4e49\u4e86\u9700\u8981\u9884\u6d4b\u7684\u8d44\u6e90 # \u82e5\u4e0d\u914d\u7f6e\uff0c\u5219\u9ed8\u8ba4\u4e0d\u542f\u52a8 prediction prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds \u662f\u9884\u6d4b\u672a\u6765\u6307\u6807\u7684\u65f6\u95f4\u7a97\u53e3\u3002 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100 \u5e38\u89c1\u95ee\u9898 \u00b6 \u9519\u8bef: unable to get metric crane_pod_cpu_usage \u00b6 \u5f53\u4f60\u67e5\u770b EffectiveHorizontalPodAutoscaler \u7684 Status \u65f6\uff0c\u53ef\u4ee5\u4f1a\u770b\u5230\u8fd9\u6837\u7684\u9519\u8bef\uff1a - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive \u539f\u56e0\uff1a\u4e0d\u662f\u6240\u6709\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7684 CPU \u4f7f\u7528\u7387\u90fd\u662f\u53ef\u9884\u6d4b\u7684\uff0c\u5f53\u65e0\u6cd5\u9884\u6d4b\u65f6\u5c31\u4f1a\u663e\u793a\u4ee5\u4e0a\u9519\u8bef\u3002 \u89e3\u51b3\u65b9\u6848\uff1a \u7b49\u4e00\u6bb5\u65f6\u95f4\u518d\u770b\u3002\u9884\u6d4b\u7b97\u6cd5 DSP \u9700\u8981\u4e00\u5b9a\u65f6\u95f4\u7684\u6570\u636e\u624d\u80fd\u8fdb\u884c\u9884\u6d4b\u3002\u5e0c\u671b\u4e86\u89e3\u7b97\u6cd5\u7ec6\u8282\u7684\u53ef\u4ee5\u67e5\u770b\u7b97\u6cd5\u7684\u6587\u6863\u3002 EffectiveHorizontalPodAutoscaler \u63d0\u4f9b\u4e00\u79cd\u4fdd\u62a4\u673a\u5236\uff0c\u5f53\u9884\u6d4b\u5931\u6548\u65f6\u4f9d\u7136\u80fd\u901a\u8fc7\u5b9e\u9645\u7684 CPU \u4f7f\u7528\u7387\u5de5\u4f5c\u3002","title":"\u667a\u80fd\u6c34\u5e73\u5f39\u6027"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler","text":"EffectiveHorizontalPodAutoscaler\uff08\u7b80\u79f0 EHPA\uff09\u662f Crane \u63d0\u4f9b\u7684\u5f39\u6027\u4f38\u7f29\u4ea7\u54c1\uff0c\u5b83\u57fa\u4e8e\u793e\u533a HPA \u505a\u5e95\u5c42\u7684\u5f39\u6027\u63a7\u5236\uff0c\u652f\u6301\u66f4\u4e30\u5bcc\u7684\u5f39\u6027\u89e6\u53d1\u7b56\u7565\uff08\u9884\u6d4b\uff0c\u89c2\u6d4b\uff0c\u5468\u671f\uff09\uff0c\u8ba9\u5f39\u6027\u66f4\u52a0\u9ad8\u6548\uff0c\u5e76\u4fdd\u969c\u4e86\u670d\u52a1\u7684\u8d28\u91cf\u3002 \u63d0\u524d\u6269\u5bb9\uff0c\u4fdd\u8bc1\u670d\u52a1\u8d28\u91cf\uff1a\u901a\u8fc7\u7b97\u6cd5\u9884\u6d4b\u672a\u6765\u7684\u6d41\u91cf\u6d2a\u5cf0\u63d0\u524d\u6269\u5bb9\uff0c\u907f\u514d\u6269\u5bb9\u4e0d\u53ca\u65f6\u5bfc\u81f4\u7684\u96ea\u5d29\u548c\u670d\u52a1\u7a33\u5b9a\u6027\u6545\u969c\u3002 \u51cf\u5c11\u65e0\u6548\u7f29\u5bb9\uff1a\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u53ef\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u7f29\u5bb9\uff0c\u7a33\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u8d44\u6e90\u4f7f\u7528\u7387\uff0c\u6d88\u9664\u7a81\u523a\u8bef\u5224\u3002 \u652f\u6301 Cron \u914d\u7f6e\uff1a\u652f\u6301 Cron-based \u5f39\u6027\u914d\u7f6e\uff0c\u5e94\u5bf9\u5927\u4fc3\u7b49\u5f02\u5e38\u6d41\u91cf\u6d2a\u5cf0\u3002 \u517c\u5bb9\u793e\u533a\uff1a\u4f7f\u7528\u793e\u533a HPA \u4f5c\u4e3a\u5f39\u6027\u63a7\u5236\u7684\u6267\u884c\u5c42\uff0c\u80fd\u529b\u5b8c\u5168\u517c\u5bb9\u793e\u533a\u3002","title":"EffectiveHorizontalPodAutoscaler"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_1","text":"\u4e00\u4e2a\u7b80\u5355\u7684 EHPA yaml \u6587\u4ef6\u5982\u4e0b\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef \u914d\u7f6e\u4f60\u5e0c\u671b\u5f39\u6027\u7684\u5de5\u4f5c\u8d1f\u8f7d\u3002 MinReplicas \u6307\u5b9a\u4e86\u81ea\u52a8\u7f29\u5bb9\u7684\u6700\u5c0f\u503c\u3002 MaxReplicas \u6307\u5b9a\u4e86\u81ea\u52a8\u6269\u5bb9\u7684\u6700\u5927\u503c\u3002 ScaleStrategy \u5b9a\u4e49\u4e86\u5f39\u6027\u7684\u7b56\u7565\uff0c\u503c\u53ef\u4ee5\u662f \"Auto\" and \"Preview\". Metrics \u5b9a\u4e49\u4e86\u5f39\u6027\u9608\u503c\u914d\u7f6e\u3002 Prediction \u5b9a\u4e49\u4e86\u9884\u6d4b\u7b97\u6cd5\u914d\u7f6e\u3002 PredictionWindowSeconds \u6307\u5b9a\u5f80\u540e\u9884\u6d4b\u591a\u4e45\u7684\u6570\u636e\u3002","title":"\u4ea7\u54c1\u529f\u80fd"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_2","text":"\u5927\u591a\u6570\u5728\u7ebf\u5e94\u7528\u7684\u8d1f\u8f7d\u90fd\u6709\u5468\u671f\u6027\u7684\u7279\u5f81\u3002\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6309\u5929\u6216\u8005\u6309\u5468\u7684\u8d8b\u52bf\u9884\u6d4b\u672a\u6765\u7684\u8d1f\u8f7d\u3002EHPA \u4f7f\u7528 DSP \u7b97\u6cd5\u6765\u9884\u6d4b\u5e94\u7528\u672a\u6765\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a\u5f00\u542f\u4e86\u9884\u6d4b\u80fd\u529b\u7684 EHPA \u6a21\u7248\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\"","title":"\u57fa\u4e8e\u9884\u6d4b\u7684\u5f39\u6027"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_3","text":"\u5728\u4f7f\u7528\u9884\u6d4b\u7b97\u6cd5\u9884\u6d4b\u65f6\uff0c\u4f60\u53ef\u80fd\u4f1a\u62c5\u5fc3\u9884\u6d4b\u6570\u636e\u4e0d\u51c6\u5e26\u6765\u4e00\u5b9a\u7684\u98ce\u9669\uff0cEHPA \u5728\u8ba1\u7b97\u526f\u672c\u6570\u65f6\uff0c\u4e0d\u4ec5\u4f1a\u6309\u9884\u6d4b\u6570\u636e\u8ba1\u7b97\uff0c\u540c\u65f6\u4e5f\u4f1a\u8003\u8651\u5b9e\u9645\u76d1\u63a7\u6570\u636e\u6765\u515c\u5e95\uff0c\u63d0\u5347\u4e86\u5f39\u6027\u7684\u5b89\u5168\u6027\u3002 \u5b9e\u73b0\u7684\u539f\u7406\u662f\u5f53\u4f60\u5728 EHPA \u4e2d\u5b9a\u4e49 spec.metrics \u5e76\u4e14\u5f00\u542f\u5f39\u6027\u9884\u6d4b\u65f6\uff0cEffectiveHPAController \u4f1a\u5728\u521b\u5efa\u5e95\u5c42\u7ba1\u7406\u7684 HPA \u65f6\u6309\u7b56\u7565\u81ea\u52a8\u751f\u6210\u591a\u6761 Metric Spec\u3002 \u4f8b\u5982\uff0c\u5f53\u7528\u6237\u5728 EHPA \u7684 yaml \u91cc\u5b9a\u4e49\u5982\u4e0b Metric Spec\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 \u5b83\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u4e24\u6761 HPA \u7684\u9608\u503c\u914d\u7f6e\uff1a apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource \u5728\u4e0a\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u7528\u6237\u5728 EHPA \u521b\u5efa\u7684 Metric \u9608\u503c\u914d\u7f6e\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5e95\u5c42 HPA \u4e0a\u7684\u4e24\u6761 Metric \u9608\u503c\u914d\u7f6e\uff1a\u9884\u6d4b Metric \u9608\u503c\u548c\u5b9e\u9645\u76d1\u63a7 Metric \u9608\u503c \u9884\u6d4b Metric \u9608\u503c \u662f\u4e00\u4e2a custom metric\u3002\u503c\u901a\u8fc7 Crane \u7684 MetricAdapter \u63d0\u4f9b\u3002 \u5b9e\u9645\u76d1\u63a7 Metric \u9608\u503c \u662f\u4e00\u4e2a resource metric\uff0c\u5b83\u548c\u7528\u6237\u5728 EHPA \u4e0a\u5b9a\u4e49\u7684\u4e00\u6837\u3002\u8fd9\u6837 HPA \u4f1a\u6839\u636e\u5e94\u7528\u5b9e\u9645\u76d1\u63a7\u7684 Metric \u8ba1\u7b97\u526f\u672c\u6570\u3002 HPA \u5728\u914d\u7f6e\u4e86\u591a\u4e2a\u5f39\u6027 Metric \u9608\u503c\u65f6\uff0c\u5728\u8ba1\u7b97\u526f\u672c\u6570\u65f6\u4f1a\u5206\u522b\u8ba1\u7b97\u6bcf\u6761 Metric \u5bf9\u5e94\u7684\u526f\u672c\u6570\uff0c\u5e76\u9009\u62e9 \u6700\u5927 \u7684\u90a3\u4e2a\u526f\u672c\u6570\u4f5c\u4e3a\u6700\u7ec8\u7684\u63a8\u8350\u5f39\u6027\u7ed3\u679c\u3002","title":"\u76d1\u63a7\u6570\u636e\u515c\u5e95"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_4","text":"EffectiveHPAController \u521b\u5efa HorizontalPodAutoscaler \u548c TimeSeriesPrediction \u5bf9\u8c61 PredictionCore \u4ece prometheus \u83b7\u53d6\u5386\u53f2 metric \u901a\u8fc7\u9884\u6d4b\u7b97\u6cd5\u8ba1\u7b97\uff0c\u5c06\u7ed3\u679c\u8bb0\u5f55\u5230 TimeSeriesPrediction HPAController \u901a\u8fc7 metric client \u4ece KubeApiServer \u8bfb\u53d6 metric \u6570\u636e KubeApiServer \u5c06\u8bf7\u6c42\u8def\u7531\u5230 Crane \u7684 MetricAdapter\u3002 HPAController \u8ba1\u7b97\u6240\u6709\u7684 Metric \u8fd4\u56de\u7684\u7ed3\u679c\u5f97\u5230\u6700\u7ec8\u7684\u5f39\u6027\u526f\u672c\u63a8\u8350\u3002 HPAController \u8c03\u7528 scale API \u5bf9\u76ee\u6807\u5e94\u7528\u6269/\u7f29\u5bb9\u3002 \u6574\u4f53\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a","title":"\u6c34\u5e73\u5f39\u6027\u7684\u6267\u884c\u6d41\u7a0b"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_5","text":"\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u751f\u4ea7\u73af\u5883\u7684\u5ba2\u6237\u6848\u4f8b\u6765\u4ecb\u7ecd EHPA \u7684\u843d\u5730\u6548\u679c\u3002 \u6211\u4eec\u5c06\u751f\u4ea7\u4e0a\u7684\u6570\u636e\u5728\u9884\u53d1\u73af\u5883\u91cd\u653e\uff0c\u5bf9\u6bd4\u4f7f\u7528 EHPA \u548c\u793e\u533a\u7684 HPA \u7684\u5f39\u6027\u6548\u679c\u3002 \u4e0b\u56fe\u7684\u7ea2\u7ebf\u662f\u5e94\u7528\u5728\u4e00\u5929\u5185\u7684\u5b9e\u9645 CPU \u4f7f\u7528\u91cf\u66f2\u7ebf\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u57288\u70b9\uff0c12\u70b9\uff0c\u665a\u4e0a8\u70b9\u65f6\u662f\u4f7f\u7528\u9ad8\u5cf0\u3002\u7eff\u7ebf\u662f EHPA \u9884\u6d4b\u7684 CPU \u4f7f\u7528\u91cf\u3002 \u4e0b\u56fe\u662f\u5bf9\u5e94\u7684\u81ea\u52a8\u5f39\u6027\u7684\u526f\u672c\u6570\u66f2\u7ebf\uff0c\u7ea2\u7ebf\u662f\u793e\u533a HPA \u7684\u526f\u672c\u6570\u66f2\u7ebf\uff0c\u7eff\u7ebf\u662f EHPA \u7684\u526f\u672c\u6570\u66f2\u7ebf\u3002 \u53ef\u4ee5\u770b\u5230 EHPA \u5177\u6709\u4ee5\u4e0b\u4f18\u52bf\uff1a \u5728\u6d41\u91cf\u6d2a\u5cf0\u6765\u4e34\u524d\u6269\u5bb9\u3002 \u5f53\u6d41\u91cf\u5148\u964d\u540e\u7acb\u523b\u5347\u65f6\u4e0d\u505a\u65e0\u6548\u7f29\u5bb9\u3002 \u76f8\u6bd4 HPA \u66f4\u5c11\u7684\u5f39\u6027\u6b21\u6570\u5374\u66f4\u9ad8\u6548\u3002","title":"\u7528\u6237\u6848\u4f8b"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#scalestrategy","text":"EHPA \u63d0\u4f9b\u4e86\u4e24\u79cd\u5f39\u6027\u7b56\u7565\uff1a Auto \u548c Preview \u3002\u7528\u6237\u53ef\u4ee5\u968f\u65f6\u5207\u6362\u5b83\u5e76\u7acb\u5373\u751f\u6548\u3002","title":"ScaleStrategy \u5f39\u6027\u7b56\u7565"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#auto","text":"Auto \u7b56\u7565\u4e0b EHPA \u4f1a\u81ea\u52a8\u6267\u884c\u5f39\u6027\u884c\u4e3a\u3002\u9ed8\u8ba4 EHPA \u7684\u7b56\u7565\u662f Auto\u3002\u5728\u8fd9\u4e2a\u6a21\u5f0f\u4e0b EHPA \u4f1a\u521b\u5efa\u4e00\u4e2a\u793e\u533a\u7684 HPA \u5bf9\u8c61\u5e76\u81ea\u52a8\u63a5\u7ba1\u5b83\u7684\u751f\u547d\u5468\u671f\u3002\u6211\u4eec\u4e0d\u5efa\u8bae\u7528\u6237\u4fee\u6539\u6216\u8005\u63a7\u5236\u8fd9\u4e2a\u5e95\u5c42\u7684 HPA \u5bf9\u8c61\uff0c\u5f53 EHPA \u88ab\u5220\u9664\u65f6\uff0c\u5e95\u5c42\u7684 HPA \u5bf9\u8c61\u4e5f\u4f1a\u4e00\u5e76\u5220\u9664\u3002","title":"Auto"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#preview","text":"Preview \u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba9 EHPA \u4e0d\u81ea\u52a8\u6267\u884c\u5f39\u6027\u7684\u80fd\u529b\u3002\u6240\u4ee5\u4f60\u53ef\u4ee5\u901a\u8fc7 EHPA \u7684 desiredReplicas \u5b57\u6bb5\u89c2\u6d4b EHPA \u8ba1\u7b97\u51fa\u7684\u526f\u672c\u6570\u3002\u7528\u6237\u53ef\u4ee5\u968f\u65f6\u5728\u4e24\u4e2a\u6a21\u5f0f\u95f4\u5207\u6362\uff0c\u5f53\u7528\u6237\u5207\u6362\u5230 Preview \u6a21\u5f0f\u65f6\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 spec.specificReplicas \u8c03\u6574\u5e94\u7528\u7684\u526f\u672c\u6570\uff0c\u5982\u679c spec.specificReplicas \u4e3a\u7a7a\uff0c\u5219\u4e0d\u4f1a\u5bf9\u5e94\u7528\u6267\u884c\u5f39\u6027\uff0c\u4f46\u662f\u4f9d\u7136\u4f1a\u6267\u884c\u526f\u672c\u6570\u7684\u8ba1\u7b97\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a\u914d\u7f6e\u6210 Preview \u6a21\u5f0f\u7684 EHPA \u6a21\u7248\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target","title":"Preview"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontalpodautoscaler","text":"EHPA \u4ece\u8bbe\u8ba1\u4e4b\u51fa\u5c31\u5e0c\u671b\u548c\u793e\u533a\u7684 HPA \u517c\u5bb9\uff0c\u56e0\u4e3a\u6211\u4eec\u4e0d\u5e0c\u671b\u91cd\u65b0\u9020\u4e00\u4e2a\u7c7b\u4f3c HPA \u7684\u8f6e\u5b50\uff0cHPA \u5728\u4e0d\u65ad\u6f14\u8fdb\u7684\u8fc7\u7a0b\u5df2\u7ecf\u89e3\u51b3\u4e86\u5f88\u591a\u901a\u7528\u7684\u95ee\u9898\uff0cEHPA \u5e0c\u671b\u5728 HPA \u7684\u57fa\u7840\u4e0a\u63d0\u4f9b\u66f4\u9ad8\u9636\u7684 CRD\uff0cEHPA \u7684\u529f\u80fd\u662f\u793e\u533a HPA \u7684\u8d85\u96c6\u3002 EHPA \u4e5f\u4f1a\u6301\u7eed\u8ddf\u8fdb\u652f\u6301 HPA \u7684\u65b0\u529f\u80fd\u3002","title":"HorizontalPodAutoscaler \u793e\u533a\u517c\u5bb9"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler-status","text":"EHPA \u7684 Status \u5305\u62ec\u4e86\u81ea\u8eab\u7684 Status \u540c\u65f6\u4e5f\u6c47\u805a\u4e86\u5e95\u5c42 HPA \u7684\u90e8\u5206 Status\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e2a EHPA \u7684 Status yaml\u4f8b\u5b50\uff1a apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0","title":"EffectiveHorizontalPodAutoscaler status"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-based-autoscaling","text":"EffectiveHorizontalPodAutoscaler \u652f\u6301\u57fa\u4e8e cron \u7684\u81ea\u52a8\u7f29\u653e\u3002 \u9664\u4e86\u57fa\u4e8e\u76d1\u63a7\u6307\u6807\uff0c\u6709\u65f6\u8282\u5047\u65e5\u548c\u5de5\u4f5c\u65e5\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6d41\u91cf\u5b58\u5728\u5dee\u5f02\uff0c\u7b80\u5355\u7684\u9884\u6d4b\u7b97\u6cd5\u53ef\u80fd\u6548\u679c\u4e0d\u4f73\u3002\u7136\u540e\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u5468\u672b cron \u6765\u652f\u6301\u66f4\u5927\u6570\u91cf\u7684\u526f\u672c\u6765\u5f25\u8865\u9884\u6d4b\u7684\u4e0d\u8db3\u3002 \u5bf9\u4e8e\u4e00\u4e9b\u975e web \u6d41\u91cf\u7684\u5e94\u7528\uff0c\u6bd4\u5982\u4e00\u4e9b\u5e94\u7528\u4e0d\u9700\u8981\u5728\u5468\u672b\u4f7f\u7528\uff0c\u53ef\u4ee5\u628a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u51cf\u5c11\u5230 1\uff0c\u4e5f\u53ef\u4ee5\u914d\u7f6e cron \u6765\u964d\u4f4e\u4f60\u7684\u670d\u52a1\u6210\u672c\u3002 \u4ee5\u4e0b\u662f EHPA Spec \u4e2d\u7684 cron \u4e3b\u8981\u5b57\u6bb5\uff1a CronSpec \uff1a\u53ef\u4ee5\u8bbe\u7f6e\u591a\u4e2a cron \u81ea\u52a8\u4f38\u7f29\u914d\u7f6e\uff0ccron cycle \u53ef\u4ee5\u8bbe\u7f6e\u5faa\u73af\u7684\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\uff0c\u5e76\u4e14\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u53ef\u4ee5\u5728\u65f6\u95f4\u8303\u56f4\u5185\u6301\u7eed\u4fdd\u6301\u4e3a\u8bbe\u5b9a\u7684\u76ee\u6807\u503c\u3002 Name \uff1acron \u6807\u8bc6\u7b26 TargetReplicas \uff1a\u6b64 cron \u65f6\u95f4\u8303\u56f4\u5185\u5de5\u4f5c\u8d1f\u8f7d\u7684\u76ee\u6807\u526f\u672c\u6570\u3002 Start \uff1acron \u7684\u5f00\u59cb\u65f6\u95f4\uff0c\u6807\u51c6 linux crontab \u683c\u5f0f End \uff1acron \u7684\u7ed3\u675f\u65f6\u95f4\uff0c\u6807\u51c6 linux crontab \u683c\u5f0f \u4e00\u4e9b\u4e91\u5382\u5546\u548c\u793e\u533a\u5f53\u524d\u7684 cron \u81ea\u52a8\u7f29\u653e\u529f\u80fd\u5b58\u5728\u4e00\u4e9b\u7f3a\u70b9\u3002 cron \u80fd\u529b\u5355\u72ec\u63d0\u4f9b\uff0c\u6ca1\u6709\u5728\u5168\u5c40\u89c6\u56fe\u4e2d\u8fdb\u884c\u81ea\u52a8\u7f29\u653e\uff0c\u4e0e HPA \u517c\u5bb9\u6027\u5dee\uff0c\u4e0e\u5176\u4ed6\u7f29\u653e\u89e6\u53d1\u5668\u51b2\u7a81\u3002 cron \u7684\u8bed\u4e49\u548c\u884c\u4e3a\u4e0d\u662f\u5f88\u5339\u914d\uff0c\u4f7f\u7528\u65f6\u751a\u81f3\u5f88\u96be\u7406\u89e3\uff0c\u5f88\u5bb9\u6613\u8bef\u5bfc\u7528\u6237\uff0c\u5bfc\u81f4\u81ea\u52a8\u4f38\u7f29\u5931\u8d25\u3002 \u4e0b\u56fe\u663e\u793a\u4e86\u5f53\u524d EHPA cron \u81ea\u52a8\u4f38\u7f29\u5b9e\u73b0\u4e0e\u5176\u4ed6 cron \u80fd\u529b\u7684\u5bf9\u6bd4\u3002 \u9488\u5bf9\u4ee5\u4e0a\u95ee\u9898\uff0cEHPA \u5b9e\u73b0\u7684 cron autoscaling \u662f\u5728\u4e0e HPA \u517c\u5bb9\u7684\u57fa\u7840\u4e0a\u8bbe\u8ba1\u7684\uff0ccron \u4f5c\u4e3a HPA \u7684\u4e00\u4e2a\u6307\u6807\uff0c\u4e0e\u5176\u4ed6\u6307\u6807\u4e00\u8d77\u4f5c\u7528\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u3002 \u53e6\u5916\uff0ccron \u7684\u8bbe\u7f6e\u4e5f\u5f88\u7b80\u5355\u3002\u5355\u72ec\u914d\u7f6e cron \u65f6\uff0c\u4e0d\u5728\u6d3b\u52a8\u65f6\u95f4\u8303\u56f4\u5185\u65f6\uff0c\u4e0d\u4f1a\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u6267\u884c\u7f29\u653e\u3002","title":"Cron-based autoscaling"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-without-other-metrics","text":"\u5047\u8bbe\u4f60\u6ca1\u6709\u914d\u7f6e\u5176\u4ed6\u6307\u6807\uff0c\u4f60\u53ea\u9700\u914d\u7f6e cron \u672c\u8eab\u5373\u53ef\u5de5\u4f5c\u3002 apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef \u5173\u8054\u5230\u9700\u6269\u7f29\u5bb9\u7684\u5de5\u4f5c\u8d1f\u8f7d scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas : autoscaler \u7f29\u653e\u7684\u6700\u4f4e\u526f\u672c\u6570 maxReplicas : 100 # MaxReplicas : autoscaler \u7f29\u653e\u7684\u6700\u5927\u526f\u672c\u6570 scaleStrategy : Auto # ScaleStrategy : \u7f29\u653e\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u5019\uff0c\u6240\u91c7\u7528\u7684\u7b56\u7565\u3002\u53ef\u9009\u503c\u4e3a \"Auto\" \"Manual\" # \u6700\u597d\u5c06Cron Scheduling\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u5b8c\u6574\u7684\u65f6\u95f4\u5468\u671f\uff0c\u4f8b\u5982\uff1a \u4e00\u5929\uff0c\u4e00\u5468 # \u4e0b\u9762\u662f\u4e00\u5929\u7684Cron Scheduling #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #\u672c\u5730\u65f6\u533a(timezone: \"Local\")\u610f\u5473\u7740\u60a8\u4f7f\u7528\u8fd0\u884cCraned\u6240\u5728\u7684\u670d\u52a1\u5668\uff08\u6216\u8005\u53ef\u80fd\u662f\u5bb9\u5668\uff09\u7684\u65f6\u533a\u3002\u4f8b\u5982\uff0c\u5f53Craned \u662f\u4ee5UTC\u65f6\u533a\u5f00\u59cb\uff0c\u90a3\u4e48\u5b83\u5c31\u662fUTC\u3002\u5982\u679c\u4e00\u5f00\u59cb\u662fAsia/Shanghai\uff0c\u90a3\u4e48\u5b83\u5c31\u662fAsia/Shanghai\u3002 crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec \u5177\u6709\u4ee5\u4e0b\u5b57\u6bb5: name \u5b9a\u4e49\u4e86 cron \u7684\u540d\u5b57\uff0ccron \u540d\u5b57\u5728\u540c\u4e00\u4e2a Ehpa \u4e2d\u5fc5\u987b\u662f\u552f\u4e00\u7684 description \u5b9a\u4e49 cron \u7684\u8be6\u7ec6\u63cf\u8ff0\u3002\u5b83\u53ef\u4ee5\u662f\u7a7a\u7684\u3002 timezone \u5b9a\u4e49Crane\u6240\u8981\u8c03\u5ea6\u7684 cron \u65f6\u533a\u3002\u5982\u679c\u672a\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u4f7f\u7528 UTC \u65f6\u533a\u3002\u4f60\u53ef\u4ee5\u5c06\u5b83\u8bbe\u7f6e\u4e3a Local \uff0c\u8fd9\u5c06\u4f7f\u7528\u6b63\u5728\u8fd0\u884c\u7684Crane\u5bb9\u5668\u6240\u5728\u7684\u65f6\u533a\u3002\u5176\u5b9e\uff0c\u4f60\u5b9a\u4e49 America/Los_Angeles \u4e5f\u662f\u53ef\u4ee5\u7684\u3002 start \u5b9a\u4e49 cron \u5f00\u59cb\u8c03\u5ea6\u7684\u65f6\u95f4\uff0c\u662f crontab \u683c\u5f0f\u3002\u53c2\u8003 wiki-Cron end \u5b9a\u4e49 cron \u7ed3\u675f\u8c03\u5ea6\u7684\u65f6\u95f4\uff0c\u662f crontab \u683c\u5f0f\u3002\u53c2\u8003 wiki-Cron targetReplicas \u5b9a\u4e49\u76ee\u6807\u526f\u672c\u5728 cron \u5904\u4e8e\u6d3b\u52a8\u72b6\u6001\u65f6\u8981\u6269\u5c55\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u8fd9\u610f\u5473\u7740\u76ee\u6807\u526f\u672c\u6570\u4ecb\u4e8e\u5f00\u59cb\u65f6\u95f4\u548c\u7ed3\u675f\u65f6\u95f4\u4e4b\u95f4\u751f\u6548\u3002 \u4ee5\u4e0aYAML\u5b9a\u4e49\uff0c\u610f\u5473\u7740\u4e00\u5929\u5f53\u4e2d\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u5728\u6bcf\u5c0f\u65f6\u6240\u9700\u8981\u4fdd\u6301\u7684\u526f\u672c\u6570\u3002\u5de5\u4f5c\u8d1f\u8f7d\u5c06\u4f1a\u6bcf\u5929\u6309\u7167\u8be5\u89c4\u5219\u6267\u884c\u3002 #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u8bb0\u4f4f \u4e0d\u8981\u8bbe\u7f6e\u5f00\u59cb\u65f6\u95f4\u5728\u7ed3\u675f\u65f6\u95f4\u4e4b\u540e \u3002 \u4f8b\u5982\uff0c\u5f53\u4f60\u8bbe\u7f6e\u4ee5\u4e0b\u5185\u5bb9\u65f6\uff1a crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 \u4ee5\u4e0a\u65e0\u6548\uff0c\u56e0\u4e3a\u5f00\u59cb\u603b\u662f\u665a\u4e8e\u7ed3\u675f\u3002 HPA \u63a7\u5236\u5668\u59cb\u7ec8\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u6240\u63cf\u8ff0\u7684\u526f\u672c\u6570\u8fdb\u884c\u6269\u5c55\uff0c\u8fd9\u610f\u5473\u7740\u4fdd\u7559\u539f\u6709\u526f\u672c\u6570\u4e0d\u53d8\u3002","title":"Cron working without other metrics"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontal-scaling-process","text":"cron \u9a71\u52a8\u548c\u6269\u5c55\u8fc7\u7a0b\u6709\u516d\u4e2a\u6b65\u9aa4\uff1a EffectiveHPAController \u521b\u5efa HorizontalPodAutoscaler \uff0c\u5b83\u88ab\u6ce8\u5165\u5230 spec \u4e2d\u7684 external cron metrics \u4e2d\u3002 HPAController \u4ece KubeApiServer \u8bfb\u53d6 external cron metrics KubeApiServer \u5c06\u8bf7\u6c42\u8f6c\u53d1\u7ed9 MetricAdapter \u548c MetricServer MetricAdapter \u627e\u5230\u76ee\u6807 hpa \u7684 cron scaler \uff0c\u5e76\u68c0\u6d4b cron scaler \u662f\u5426\u5904\u4e8e\u6d3b\u52a8\u72b6\u6001\u3002\u8fd9\u610f\u5473\u7740\u5f53\u524d\u65f6\u95f4\u4ecb\u4e8e cron \u5f00\u59cb\u548c\u7ed3\u675f\u8ba1\u5212\u65f6\u95f4\u4e4b\u95f4\u3002\u5b83\u5c06\u8fd4\u56de TargetReplicas \u4e2d\u5b9a\u4e49\u7684 CronSpec \u3002 HPAController \u8ba1\u7b97\u6240\u6709 metrics \u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6700\u5927\u7684\u4e00\u4e2a\u4e3a\u76ee\u6807\u526f\u672c\u6570\u3002\u5e76\u7531\u6b64\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 scale replicas \u3002 HPAController \u4f7f\u7528 Scale Api \u7f29\u653e\u76ee\u6807 \u4f7f\u7528 EHPA \u65f6\uff0c\u7528\u6237\u53ef\u4ee5\u53ea\u914d\u7f6e cron metric\uff0c\u8ba9 EHPA \u7528\u4f5c cron hpa\u3002 \u4e00\u4e2a EHPA \u7684\u591a\u4e2a crons \u5c06\u8f6c\u6362\u4e3a\u4e00\u4e2a external metrics \u3002 HPA \u5c06\u83b7\u53d6 external metrics \u5e76\u5728\u534f\u8c03\u65f6\u8ba1\u7b97\u76ee\u6807\u526f\u672c\u3002\u5f53\u5b58\u5728\u591a\u4e2a\u6307\u6807\u7684\u5de5\u4f5c\u8d1f\u8f7d\u65f6\uff0cHPA \u5c06\u9009\u62e9\u6700\u5927\u7684\u526f\u672c\u6570\u6765\u6269\u5c55\u3002","title":"Horizontal scaling process"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-with-other-metrics-together","text":"EffectiveHorizontalPodAutoscaler \u517c\u5bb9 HorizontalPodAutoscaler \uff08\u5185\u7f6e\u5728 kubernetes\uff09\u3002\u56e0\u6b64\uff0c\u5982\u679c\u4f60\u4e3a HPA \u914d\u7f6e\u4e86\u6307\u6807\uff0c\u4f8b\u5982 cpu \u6216\u5185\u5b58\uff0c\u90a3\u4e48 HPA \u5c06\u6839\u636e\u5b83\u89c2\u5bdf\u5230\u7684\u5b9e\u65f6\u6307\u6807\u5bf9\u526f\u672c\u6570\u8fdb\u884c\u6269\u5c55\u3002 \u901a\u8fc7 EHPA\uff0c\u7528\u6237\u53ef\u4ee5\u540c\u65f6\u914d\u7f6e CronMetric \u3001 PredictionMetric \u3001 OriginalMetric \u3002 \u6211\u4eec\u5f3a\u70c8\u5efa\u8bae\u4f60\u914d\u7f6e\u6240\u6709\u7ef4\u5ea6\u7684\u6307\u6807\u3002\u5b83\u4eec\u5206\u522b\u4ee3\u8868 cron \u526f\u672c\u3001\u5148\u524d\u9884\u6d4b\u7684\u526f\u672c\u3001\u540e\u89c2\u5bdf\u7684\u526f\u672c\u3002 \u8fd9\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u529f\u80fd\u3002\u56e0\u4e3a HPA \u603b\u662f\u9009\u62e9\u7531\u6240\u6709\u7ef4\u5ea6 metrics \u8ba1\u7b97\u7684\u6700\u5927\u526f\u672c\u8fdb\u884c\u6269\u5c55\u3002 \u8fd9\u5c06\u4fdd\u8bc1\u4f60\u5de5\u4f5c\u8d1f\u8f7d\u7684 QoS\uff0c\u5f53\u4f60\u540c\u65f6\u914d\u7f6e\u4e09\u79cd\u7c7b\u578b\u7684\u81ea\u52a8\u7f29\u653e\u65f6\uff0c\u6839\u636e\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u6307\u6807\u8ba1\u7b97\u7684\u526f\u672c\u6700\u5927\uff0c\u7136\u540e\u5b83\u5c06\u4f7f\u7528\u6700\u5927\u7684\u4e00\u4e2a\u3002 \u5c3d\u7ba1\u7531\u4e8e\u67d0\u4e9b\u610f\u60f3\u4e0d\u5230\u7684\u539f\u56e0\uff0c\u5bfc\u81f4\u7531 PredictionMetric \u8ba1\u7b97\u7684\u526f\u672c\u66f4\u5c0f\u3002\u56e0\u6b64\uff0c\u4f60\u4e0d\u5fc5\u62c5\u5fc3 QoS\u3002","title":"Cron working with other metrics together"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#mechanism","text":"\u5f53 metrics adapter \u5904\u7406 external cron metrics \u8bf7\u6c42\u65f6\uff0c metrics adapter \u5c06\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\u3002 graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; \u6ca1\u6709\u6d3b\u8dc3\u7684cron\uff0c\u6709\u4e24\u79cd\u60c5\u51b5\uff1a \u6ca1\u6709\u5176\u4ed6 hpa \u6307\u6807\u4e0e cron \u4e00\u8d77\u4f7f\u7528\uff0c\u7136\u540e\u8fd4\u56de\u5f53\u524d\u5de5\u4f5c\u8d1f\u8f7d\u526f\u672c\u4ee5\u4fdd\u7559\u539f\u59cb\u6240\u9700\u7684\u526f\u672c \u5f53\u5176\u4ed6 hpa \u6307\u6807\u4e0e cron \u4e00\u8d77\u4f7f\u7528\uff0c\u5c06\u4f1a\u8fd4\u56de\u6700\u5c0f\u503c\u4ee5\u6d88\u9664cron\u5bf9\u5176\u4ed6\u6307\u6807\u7684\u5f71\u54cd\u3002\u5f53 cron \u4e0e\u5176\u4ed6\u6307\u6807\u4e00\u8d77\u5de5\u4f5c\u65f6\uff0c\u5b83\u4e0d\u5e94\u8be5\u8fd4\u56de\u5de5\u4f5c\u8d1f\u8f7d\u7684\u539f\u59cb\u526f\u672c\u6570\uff0c\u56e0\u4e3a\u53ef\u80fd\u6709\u5176\u4ed6\u6307\u6807\u60f3\u8981\u7f29\u5c0f\u5de5\u4f5c\u8d1f\u8f7d\u7684\u526f\u672c\u6570\u3002 HPA Controller \u9009\u62e9\u7531\u6240\u6709\u6307\u6807\u8ba1\u7b97\u7684\u6700\u5927\u526f\u672c\uff08\u8fd9\u662f\u786c\u4ee3\u7801\u4e2d\u7684 hpa \u9ed8\u8ba4\u7b56\u7565)\uff0ccron \u4f1a\u5f71\u54cd hpa\u3002\u6240\u4ee5\u6211\u4eec\u5e94\u8be5\u5728 cron \u4e0d\u6d3b\u52a8\u65f6\u79fb\u9664 cron \u6548\u679c\uff0c\u5b83\u5e94\u8be5\u8fd4\u56de\u6700\u5c0f\u503c\u3002 \u6709\u6d3b\u8dc3\u7684cron\u3002\u6211\u4eec\u4f7f\u7528 cron spec \u4e2d\u6307\u5b9a\u7684\u6700\u5927\u76ee\u6807\u526f\u672c\u3002\u57fa\u672c\u4e0a\uff0c\u5728\u540c\u4e00\u65f6\u95f4\u6bb5\u5185\u4e0d\u5e94\u6709\u8d85\u8fc7\u4e00\u4e2a\u6d3b\u8dc3\u7684 cron\uff0c\u8fd9\u4e0d\u662f\u6700\u4f73\u5b9e\u8df5\u3002 HPA \u5c06\u83b7\u53d6 cron external metrics \uff0c\u7136\u540e\u5b83\u4f1a\u81ea\u884c\u8ba1\u7b97\u526f\u672c\u6570\u3002","title":"Mechanism"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#use-case","text":"\u5f53\u4f60\u9700\u8981\u5728\u5348\u591c\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u526f\u672c\u6570\u4fdd\u6301\u5728\u6700\u4f4e\u9650\u5ea6\uff0c\u6839\u636e\u8be5\u9700\u6c42\u914d\u7f6e\u4e86 cron\u3002 \u4f60\u9700\u8981 HPA \u6765\u83b7\u53d6\u6307\u6807\u670d\u52a1\u5668\u89c2\u5bdf\u5230\u7684\u771f\u5b9e\u6307\u6807\uff0c\u4ee5\u6839\u636e\u5b9e\u65f6\u89c2\u5bdf\u5230\u7684\u6307\u6807\u8fdb\u884c\u6269\u5c55\u3002 \u6700\u540e\uff0c\u4f60\u914d\u7f6e\u4e00\u4e2a prediction-driven metric \uff0c\u901a\u8fc7\u9884\u6d4b\u65b9\u5f0f\u63d0\u524d\u6269\u5927\u89c4\u6a21\u5e76\u5728\u672b\u671f\u7f29\u5c0f\u89c4\u6a21\u3002 apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef \u5173\u8054\u5230\u9700\u6269\u7f29\u5bb9\u7684\u5de5\u4f5c\u8d1f\u8f7d scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas : \u7f29\u653e\u7684\u6700\u5c0f\u526f\u672c\u6570 maxReplicas : 100 # MaxReplicas : \u7f29\u653e\u7684\u6700\u5927\u526f\u672c\u6570 scaleStrategy : Auto # ScaleStrategy : \u7f29\u653e\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u5019\uff0c\u6240\u91c7\u7528\u7684\u7b56\u7565\u3002\u53ef\u9009\u503c\u4e3a \"Auto\" \"Manual\" # Metrics \u5305\u542b\u4e86\u7528\u4e8e\u8ba1\u7b97\u6240\u9700\u526f\u672c\u6570\u7684\u6307\u6807\u3002 metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction \u7684\u914d\u7f6e\u5b9a\u4e49\u4e86\u9700\u8981\u9884\u6d4b\u7684\u8d44\u6e90 # \u82e5\u4e0d\u914d\u7f6e\uff0c\u5219\u9ed8\u8ba4\u4e0d\u542f\u52a8 prediction prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds \u662f\u9884\u6d4b\u672a\u6765\u6307\u6807\u7684\u65f6\u95f4\u7a97\u53e3\u3002 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100","title":"Use Case"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#_6","text":"","title":"\u5e38\u89c1\u95ee\u9898"},{"location":"zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#unable-to-get-metric-crane_pod_cpu_usage","text":"\u5f53\u4f60\u67e5\u770b EffectiveHorizontalPodAutoscaler \u7684 Status \u65f6\uff0c\u53ef\u4ee5\u4f1a\u770b\u5230\u8fd9\u6837\u7684\u9519\u8bef\uff1a - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive \u539f\u56e0\uff1a\u4e0d\u662f\u6240\u6709\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7684 CPU \u4f7f\u7528\u7387\u90fd\u662f\u53ef\u9884\u6d4b\u7684\uff0c\u5f53\u65e0\u6cd5\u9884\u6d4b\u65f6\u5c31\u4f1a\u663e\u793a\u4ee5\u4e0a\u9519\u8bef\u3002 \u89e3\u51b3\u65b9\u6848\uff1a \u7b49\u4e00\u6bb5\u65f6\u95f4\u518d\u770b\u3002\u9884\u6d4b\u7b97\u6cd5 DSP \u9700\u8981\u4e00\u5b9a\u65f6\u95f4\u7684\u6570\u636e\u624d\u80fd\u8fdb\u884c\u9884\u6d4b\u3002\u5e0c\u671b\u4e86\u89e3\u7b97\u6cd5\u7ec6\u8282\u7684\u53ef\u4ee5\u67e5\u770b\u7b97\u6cd5\u7684\u6587\u6863\u3002 EffectiveHorizontalPodAutoscaler \u63d0\u4f9b\u4e00\u79cd\u4fdd\u62a4\u673a\u5236\uff0c\u5f53\u9884\u6d4b\u5931\u6548\u65f6\u4f9d\u7136\u80fd\u901a\u8fc7\u5b9e\u9645\u7684 CPU \u4f7f\u7528\u7387\u5de5\u4f5c\u3002","title":"\u9519\u8bef: unable to get metric crane_pod_cpu_usage"},{"location":"zh/tutorials/using-qos-ensurance/","text":"Qos Ensurance \u00b6 Qos Ensurance \u4fdd\u8bc1\u4e86\u8fd0\u884c\u5728 Kubernetes \u4e0a\u7684 Pod \u7684\u7a33\u5b9a\u6027\u3002 \u5177\u6709\u5e72\u6270\u68c0\u6d4b\u548c\u4e3b\u52a8\u56de\u907f\u80fd\u529b\uff0c\u5f53\u8f83\u9ad8\u4f18\u5148\u7ea7\u7684 Pod \u53d7\u5230\u8d44\u6e90\u7ade\u4e89\u7684\u5f71\u54cd\u65f6\uff0cDisable Schedule\u3001Throttle\u4ee5\u53caEvict \u5c06\u5e94\u7528\u4e8e\u4f4e\u4f18\u5148\u7ea7\u7684 Pod\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u548c\u81ea\u5b9a\u4e49\u64cd\u4f5c\uff1b \u540c\u65f6\u5177\u5907\u589e\u5f3a\u7684\u65c1\u8defcpuset\u7ba1\u7406\u80fd\u529b\uff0c\u5728\u7ed1\u6838\u7684\u540c\u65f6\u63d0\u5347\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002 \u5177\u6709\u9884\u6d4b\u7b97\u6cd5\u589e\u5f3a\u7684\u52a8\u6001\u8d44\u6e90\u8d85\u5356\u80fd\u529b\uff0c\u5c06\u7a7a\u95f2\u8d44\u6e90\u590d\u7528\u8d77\u6765\uff0c\u540c\u65f6\u7ed3\u5408crane\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u66f4\u597d\u5730\u590d\u7528\u95f2\u7f6e\u8d44\u6e90\u3002\u540c\u65f6\u5177\u6709\u5f39\u6027\u8d44\u6e90\u9650\u5236\u529f\u80fd\uff0c\u9650\u5236\u590d\u7528\u7a7a\u95f2\u8d44\u6e90\u7684workload\u3002 Qos Ensurance \u67b6\u6784 \u00b6 Qos ensurance \u7684\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5b83\u5305\u542b\u4e09\u4e2a\u6a21\u5757\u3002 State Collector \uff1a\u5b9a\u671f\u6536\u96c6\u6307\u6807 Anomaly Analyzer \uff1a\u4f7f\u7528\u6536\u96c6\u6307\u6807\uff0c\u4ee5\u5206\u6790\u8282\u70b9\u662f\u5426\u53d1\u751f\u5f02\u5e38 Action Executor \uff1a\u6267\u884c\u56de\u907f\u52a8\u4f5c\uff0c\u5305\u62ec Disable Scheduling\u3001Throttle \u548c Eviction\u3002 \u4e3b\u8981\u6d41\u7a0b\uff1a State Collector \u4ece kube-apiserver \u540c\u6b65\u7b56\u7565\u3002 \u5982\u679c\u7b56\u7565\u53d1\u751f\u66f4\u6539\uff0c State Collector \u4f1a\u66f4\u65b0\u6307\u6807\u6536\u96c6\u89c4\u5219\u3002 State Collector \u5b9a\u671f\u6536\u96c6\u6307\u6807\u3002 State Collector \u5c06\u6307\u6807\u4f20\u8f93\u5230 Anomaly Analyzer \u3002 Anomaly Analyzer \u5bf9\u6240\u6709\u89c4\u5219\u8fdb\u884c\u8303\u56f4\u5206\u6790\uff0c\u4ee5\u5206\u6790\u8fbe\u5230\u7684\u56de\u907f\u9608\u503c\u6216\u6062\u590d\u9608\u503c\u3002 Anomaly Analyzer \u5408\u5e76\u5206\u6790\u7ed3\u679c\u5e76\u901a\u77e5 Action Executor \u6267\u884c\u56de\u907f\u52a8\u4f5c\u3002 Action Executor \u6839\u636e\u5206\u6790\u7ed3\u679c\u6267\u884c\u52a8\u4f5c\u3002 \u5e72\u6270\u68c0\u6d4b\u548c\u4e3b\u52a8\u56de\u907f \u00b6 Disable Scheduling \u00b6 \u5b9a\u4e49 AvoidanceAction \u548c NodeQOSEnsurancePolicy \u3002 \u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u56de\u907f\u9608\u503c\u65f6\uff0c\u5c06\u8be5\u8282\u70b9\u8bbe\u7f6e\u4e3a\u7981\u7528\u8c03\u5ea6\u3002 \u793a\u4f8b YAML \u5982\u4e0b\u6240\u793a\uff1a AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 #(1) \u8282\u70b9\u4ece\u7981\u6b62\u8c03\u5ea6\u72b6\u6001\u5230\u6b63\u5e38\u72b6\u6001\u7684\u6700\u5c0f\u7b49\u5f85\u65f6\u95f4 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) \u5f53\u8fbe\u5230\u9608\u503c\u5e76\u6301\u7eed\u591a\u6b21\uff0c\u90a3\u4e48\u6211\u4eec\u8ba4\u4e3a\u89c4\u5219\u88ab\u89e6\u53d1 \u5f53\u9608\u503c\u672a\u8fbe\u5230\u5e76\u7ee7\u7eed\u591a\u6b21, \u90a3\u4e48\u6211\u4eec\u8ba4\u4e3a\u89c4\u5219\u5df2\u6062\u590d \u5173\u8054\u5230 AvoidanceAction \u540d\u79f0 \u52a8\u4f5c\u7684\u7b56\u7565\uff0c\u4f60\u53ef\u4ee5\u5c06\u5176\u8bbe\u7f6e\u4e3a\u201c\u9884\u89c8\u201d\u4ee5\u4e0d\u5b9e\u9645\u6267\u884c \u6307\u6807\u540d\u79f0 \u6307\u6807\u7684\u9608\u503c \u8bf7\u89c2\u770b\u89c6\u9891\u4ee5\u4e86\u89e3\u66f4\u591a Disable Scheduling \u7684\u7ec6\u8282\u3002 Throttle \u00b6 \u5b9a\u4e49 AvoidanceAction \u548c NodeQOSEnsurancePolicy \u3002 \u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u56de\u907f\u9608\u503c\u65f6\uff0c\u5c06\u6267\u884c\u8282\u70b9\u7684 Throttle Action \u3002 \u793a\u4f8b YAML \u5982\u4e0b\u6240\u793a\uff1a AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" CPU \u914d\u989d\u7684\u6700\u5c0f\u6bd4\u4f8b\uff0c\u5982\u679c pod \u88ab\u9650\u5236\u4f4e\u4e8e\u8fd9\u4e2a\u6bd4\u4f8b\uff0c\u5c31\u4f1a\u88ab\u8bbe\u7f6e\u4e3a\u8fd9\u4e2a\u3002 \u8be5\u914d\u7f6e\u8bbe\u7f6e\u7ed9 Throttle Action \u3002\u5b83\u5c06\u5728\u6bcf\u4e2a\u89e6\u53d1\u7684\u56de\u907f\u52a8\u4f5c\u4e2d\u51cf\u5c11\u8fd9\u4e2a CPU \u914d\u989d\u5360\u6bd4\u3002\u5b83\u4f1a\u5728\u6bcf\u4e2a\u6062\u590d\u52a8\u4f5c\u4e2d\u589e\u52a0\u8fd9\u4e2a CPU \u914d\u989d\u5360\u6bd4\u3002 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000 Eviction \u00b6 \u4e0b\u9762\u7684 YAML \u662f\u53e6\u4e00\u79cd\u60c5\u51b5\uff0c\u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u9608\u503c\u65f6\uff0c\u8282\u70b9\u4e0a\u7684\u4f4e\u4f18\u5148\u7ea7 pod \u5c06\u88ab\u9a71\u9010\u3002 AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" pod \u9700\u8981\u4f18\u96c5\u7ec8\u6b62\u7684\u6301\u7eed\u65f6\u95f4\uff08\u4ee5\u79d2\u4e3a\u5355\u4f4d\uff09\u3002 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 \u56de\u907f\u52a8\u4f5c\u7b56\u7565\u3002\u5f53\u8bbe\u7f6e\u4e3a Preview \u65f6\uff0c\u5c06\u4e0d\u4f1a\u88ab\u5b9e\u9645\u6267\u884c Supported Metrics \u00b6 Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization \u7cbe\u786e\u6267\u884c\u56de\u907f\u52a8\u4f5c \u00b6 \u901a\u8fc7\u5982\u4e0b\u4e24\u70b9\u8fdb\u884c\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\u7684\u540c\u65f6\u80fd\u591f\u66f4\u5feb\u5730\u964d\u4f4e\u6307\u6807\u5230\u6307\u5b9a\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\uff0c\u4fdd\u969c\u9ad8\u4f18\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd 1. \u6392\u5e8fpod crane\u5b9e\u73b0\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\uff08\u4e4b\u540e\u4f1a\u66f4\u591a\u5730\u5b8c\u5584\uff09\uff1a classAndPriority\uff1a \u6bd4\u8f83\u4e24\u4e2apod\u7684QOSClass\u548cclass value\uff0c\u4f18\u5148\u6bd4\u8f83QOSClass\uff0c\u518d\u6bd4\u8f83class value\uff1bpriority\u9ad8\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 runningTime\uff1a\u6bd4\u8f83\u4e24\u4e2apod\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u8fd0\u884c\u65f6\u95f4\u957f\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 \u5982\u679c\u4ec5\u9700\u4f7f\u7528\u8fd9\u4e24\u4e2a\u6392\u5e8f\u7b56\u7565\uff0c\u4f7f\u7528\u9ed8\u8ba4\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\uff1a\u4f1a\u9996\u5148\u6bd4\u8f83pod\u7684\u4f18\u5148\u7ea7\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u5bf9\u5e94\u6307\u6807\u7684\u7528\u91cf\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u6709\u4e00\u4e2a\u7ef4\u5ea6\u53ef\u4ee5\u6bd4\u8f83\u51fa\u7ed3\u679c\u5373\u4e3apod\u7684\u6392\u5e8f\u7ed3\u679c \u4ee5cpu usage\u6307\u6807\u7684\u6392\u5e8f\u4e3a\u4f8b\uff0c\u8fd8\u6269\u5c55\u4e86\u4e00\u4e9b\u4e0e\u81ea\u8eab\u6307\u6807\u76f8\u5173\u7684\u6392\u5e8f\u7b56\u7565\uff0c \u5982cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f\uff0c\u4f1a\u4f9d\u6b21\u6bd4\u8f83\u4e24\u4e2apod\u7684\u4f18\u5148\u7ea7\uff0c\u5982\u679c\u4f18\u5148\u7ea7\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u518d\u6bd4\u8f83cpu\u7528\u91cf\uff0c\u5982\u679ccpu\u7528\u91cf\u4e5f\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u7ee7\u7eed\u6bd4\u8f83\u6269\u5c55cpu\u8d44\u6e90\u7528\u91cf, \u6700\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u5f53\u67d0\u4e00\u4e2a\u6307\u6807\u5b58\u5728\u5dee\u5f02\u65f6\u5373\u53ef\u8fd4\u56de\u6bd4\u8f83\u7ed3\u679c\uff1a orderedBy(classAndPriority, cpuUsage, extCpuUsage, runningTime).Sort(pods) \u53c2\u8003\u6c34\u4f4d\u7ebf\u548cpod\u7528\u91cf\u6267\u884c\u56de\u907f\u52a8\u4f5c //\u5c06\u6240\u6709\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206 metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // \u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u64cd\u4f5c if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //\u83b7\u53d6\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020\u548c\u6c34\u4f4d\u7ebf\u5dee\u8ddd ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //\u5982\u679c\u89e6\u53d1\u6c34\u4f4d\u7ebf\u4e2d\u5b58\u5728metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5219\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //\u904d\u5386\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metric\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5426\u5219\u4f7f\u7528GeneralSorter\u6392\u5e8f\uff1b //\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684\u64cd\u4f5c\u65b9\u6cd5\u5bf9pod\u6267\u884c\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230\u5bf9\u5e94metric\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\u5df2\u4e0d\u5b58\u5728 for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } \u5173\u4e8e\u6269\u5c55\u81ea\u5b9a\u4e49\u6307\u6807\u548c\u6392\u5e8f\u53c2\u8003 \"\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f\" \u90e8\u5206 \u589e\u5f3a\u7684\u65c1\u8defcpuset\u7ba1\u7406\u80fd\u529b \u00b6 kubelet\u652f\u6301static\u7684cpu manager\u7b56\u7565\uff0c\u5f53guaranteed pod\u8fd0\u884c\u5728\u8282\u70b9\u4e0a\u65f6\uff0ckebelet\u4f1a\u4e3a\u8be5pod\u5206\u914d\u6307\u5b9a\u7684\u4e13\u5c5ecpu\uff0c\u5176\u4ed6\u8fdb\u7a0b\u65e0\u6cd5\u5360\u7528\uff0c\u8fd9\u4fdd\u8bc1\u4e86guaranteed pod\u7684cpu\u72ec\u5360\uff0c\u4f46\u662f\u4e5f\u9020\u6210\u4e86cpu\u548c\u8282\u70b9\u7684\u7684\u5229\u7528\u7387\u8f83\u4f4e\uff0c\u9020\u6210\u4e86\u4e00\u5b9a\u7684\u6d6a\u8d39\u3002 crane agent\u4e3acpuset\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7b56\u7565\uff0c\u5141\u8bb8pod\u548c\u5176\u4ed6pod\u5171\u4eabcpu\u5f53\u5176\u6307\u5b9a\u4e86cpu\u7ed1\u6838\u65f6\uff0c\u53ef\u4ee5\u5728\u5229\u7528\u7ed1\u6838\u66f4\u5c11\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u66f4\u9ad8\u7684\u7f13\u5b58\u4eb2\u548c\u6027\u7684\u4f18\u70b9\u7684\u524d\u63d0\u4e0b\uff0c\u8fd8\u80fd\u8ba9\u5176\u4ed6workload\u90e8\u7f72\u5171\u7528\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3002 \u63d0\u4f9b\u4e863\u79cdpod cpuset\u7c7b\u578b\uff1a exclusive\uff1a\u7ed1\u6838\u540e\u5176\u4ed6container\u4e0d\u80fd\u518d\u4f7f\u7528\u8be5cpu\uff0c\u72ec\u5360cpu share\uff1a\u7ed1\u6838\u540e\u5176\u4ed6container\u53ef\u4ee5\u4f7f\u7528\u8be5cpu none\uff1a\u9009\u62e9\u6ca1\u6709\u88abexclusive pod\u7684container\u5360\u7528\u7684cpu\uff0c\u53ef\u4ee5\u4f7f\u7528share\u7c7b\u578b\u7684\u7ed1\u6838 share\u7c7b\u578b\u7684\u7ed1\u6838\u7b56\u7565\u53ef\u4ee5\u5728\u5229\u7528\u7ed1\u6838\u66f4\u5c11\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u66f4\u9ad8\u7684\u7f13\u5b58\u4eb2\u548c\u6027\u7684\u4f18\u70b9\u7684\u524d\u63d0\u4e0b\uff0c\u8fd8\u80fd\u8ba9\u5176\u4ed6workload\u90e8\u7f72\u5171\u7528\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387 \u653e\u5bbd\u4e86kubelet\u4e2d\u7ed1\u6838\u7684\u9650\u5236 \u539f\u5148\u9700\u8981\u6240\u6709container\u7684CPU limit\u4e0eCPU request\u76f8\u7b49 \uff0c\u8fd9\u91cc\u53ea\u9700\u8981\u4efb\u610fcontainer\u7684CPU limit\u5927\u4e8e\u6216\u7b49\u4e8e1\u4e14\u7b49\u4e8eCPU request\u5373\u53ef\u4e3a\u8be5container\u8bbe\u7f6e\u7ed1\u6838 \u652f\u6301\u5728pod\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4fee\u6539pod\u7684 cpuset policy\uff0c\u4f1a\u7acb\u5373\u751f\u6548 pod\u7684cpu manager policy\u4ecenone\u8f6c\u6362\u5230share\uff0c\u4eceexclusive\u8f6c\u6362\u5230share\uff0c\u5747\u65e0\u9700\u91cd\u542f \u4f7f\u7528\u65b9\u6cd5\uff1a 1. \u8bbe\u7f6ekubelet\u7684cpuset manager\u4e3a\"none\" 2. \u901a\u8fc7pod annotation\u8bbe\u7f6ecpu manager policy qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share \u9884\u6d4b\u7b97\u6cd5\u589e\u5f3a\u7684\u52a8\u6001\u8d44\u6e90\u8d85\u5356 \u00b6 \u4e3a\u4e86\u63d0\u9ad8\u7a33\u5b9a\u6027\uff0c\u901a\u5e38\u7528\u6237\u5728\u90e8\u7f72\u5e94\u7528\u7684\u65f6\u5019\u4f1a\u8bbe\u7f6e\u9ad8\u4e8e\u5b9e\u9645\u4f7f\u7528\u91cf\u7684Request\u503c\uff0c\u9020\u6210\u8d44\u6e90\u7684\u6d6a\u8d39\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8282\u70b9\u7684\u8d44\u6e90\u5229\u7528\u7387\uff0c\u7528\u6237\u4f1a\u642d\u914d\u90e8\u7f72\u4e00\u4e9bBestEffort\u7684\u5e94\u7528\uff0c\u5229\u7528\u95f2\u7f6e\u8d44\u6e90\uff0c\u5b9e\u73b0\u8d85\u5356\uff1b \u4f46\u662f\u8fd9\u4e9b\u5e94\u7528\u7531\u4e8e\u7f3a\u4e4f\u8d44\u6e90limit\u548crequest\u7684\u7ea6\u675f\u548c\u76f8\u5173\u4fe1\u606f\uff0c\u8c03\u5ea6\u5668\u4f9d\u65e7\u53ef\u80fd\u5c06\u8fd9\u4e9bpod\u8c03\u5ea6\u5230\u8d1f\u8f7d\u8f83\u9ad8\u7684\u8282\u70b9\u4e0a\u53bb\uff0c\u8fd9\u4e0e\u6211\u4eec\u7684\u521d\u8877\u662f\u4e0d\u7b26\u7684\uff0c\u6240\u4ee5\u6700\u597d\u80fd\u4f9d\u636e\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\u8fdb\u884c\u8c03\u5ea6\u3002 crane\u901a\u8fc7\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\u6536\u96c6\u4e86\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\uff0c\u7efc\u5408\u540e\u4f5c\u4e3a\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\uff0c\u589e\u5f3a\u4e86\u8d44\u6e90\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff1a \u901a\u8fc7\u672c\u5730\u6536\u96c6\u7684cpu\u7528\u91cf\u4fe1\u606f nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal exclusiveCPUIdle\u662f\u6307\u88abcpu manager policy\u4e3aexclusive\u7684pod\u5360\u7528\u7684cpu\u7684\u7a7a\u95f2\u91cf\uff0c\u867d\u7136\u8fd9\u90e8\u5206\u8d44\u6e90\u662f\u7a7a\u95f2\u7684\uff0c\u4f46\u662f\u56e0\u4e3a\u72ec\u5360\u7684\u539f\u56e0\uff0c\u662f\u65e0\u6cd5\u88ab\u590d\u7528\u7684\uff0c\u56e0\u6b64\u52a0\u4e0a\u88ab\u7b97\u4f5c\u5df2\u4f7f\u7528\u91cf extResContainerCpuUsageTotal\u662f\u6307\u88ab\u4f5c\u4e3a\u52a8\u6001\u8d44\u6e90\u4f7f\u7528\u7684cpu\u7528\u91cf\uff0c\u9700\u8981\u51cf\u53bb\u4ee5\u514d\u88ab\u4e8c\u6b21\u8ba1\u7b97 \u521b\u5efa\u8282\u70b9cpu\u4f7f\u7528\u91cf\u7684TSP\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u81ea\u52a8\u521b\u5efa\uff0c\u4f1a\u6839\u636e\u5386\u53f2\u9884\u6d4b\u8282\u70b9CPU\u7528\u91cf apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default \u7ed3\u5408\u9884\u6d4b\u7b97\u6cd5\u548c\u5f53\u524d\u5b9e\u9645\u7528\u91cf\u63a8\u7b97\u8282\u70b9\u7684\u5269\u4f59\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u62d3\u5c55\u8d44\u6e90\u8d4b\u4e88\u8282\u70b9\uff0cpod\u53ef\u6807\u660e\u4f7f\u7528\u8be5\u6269\u5c55\u8d44\u6e90\u4f5c\u4e3a\u79bb\u7ebf\u4f5c\u4e1a\u5c06\u7a7a\u95f2\u8d44\u6e90\u5229\u7528\u8d77\u6765\uff0c\u4ee5\u63d0\u5347\u8282\u70b9\u7684\u8d44\u6e90\u5229\u7528\u7387\uff1b \u4f7f\u7528\u65b9\u6cd5\uff1a \u90e8\u7f72pod\u65f6limit\u548crequest\u4f7f\u7528 gocrane.io/<$ResourceName>\uff1a<$value> \u5373\u53ef\uff0c\u5982\u4e0b spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\" \u5f39\u6027\u8d44\u6e90\u9650\u5236\u529f\u80fd \u00b6 \u539f\u751f\u7684BestEffort\u5e94\u7528\u7f3a\u4e4f\u8d44\u6e90\u7528\u91cf\u7684\u516c\u5e73\u4fdd\u8bc1\uff0cCrane\u4fdd\u8bc1\u4f7f\u7528\u52a8\u6001\u8d44\u6e90\u7684BestEffort pod\u5176cpu\u4f7f\u7528\u91cf\u88ab\u9650\u5236\u5728\u5176\u5141\u8bb8\u4f7f\u7528\u7684\u5408\u7406\u8303\u56f4\u5185\uff0cagent\u4fdd\u8bc1\u4f7f\u7528\u6269\u5c55\u8d44\u6e90\u7684pod\u5b9e\u9645\u7528\u91cf\u4e5f\u4e0d\u4f1a\u8d85\u8fc7\u5176\u58f0\u660e\u9650\u5236\uff0c\u540c\u65f6\u5728cpu\u7ade\u4e89\u65f6\u4e5f\u80fd\u6309\u7167\u5404\u81ea\u58f0\u660e\u91cf\u516c\u5e73\u7ade\u4e89\uff1b\u540c\u65f6\u4f7f\u7528\u5f39\u6027\u8d44\u6e90\u7684pod\u4e5f\u4f1a\u53d7\u5230\u6c34\u4f4d\u7ebf\u529f\u80fd\u7684\u7ba1\u7406\u3002 \u4f7f\u7528\u65b9\u6cd5\uff1a \u90e8\u7f72pod\u65f6limit\u548crequest\u4f7f\u7528 gocrane.io/<$ResourceName>\uff1a<$value> \u5373\u53ef \u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f \u00b6 \u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f\u7684\u4f7f\u7528\u540c \u7cbe\u786e\u6267\u884c\u56de\u907f\u52a8\u4f5c \u90e8\u5206\u4e2d\u4ecb\u7ecd\u7684\u6d41\u7a0b\uff0c\u6b64\u5904\u4ecb\u7ecd\u5982\u4f55\u81ea\u5b9a\u4e49\u81ea\u5df1\u7684\u6307\u6807\u53c2\u4e0e\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u6d41\u7a0b \u4e3a\u4e86\u66f4\u597d\u7684\u57fa\u4e8eNodeQOSEnsurancePolicy\u914d\u7f6e\u7684metric\u8fdb\u884c\u6392\u5e8f\u548c\u7cbe\u51c6\u63a7\u5236\uff0c\u5bf9metric\u5f15\u5165\u5c5e\u6027\u7684\u6982\u5ff5\u3002 metric\u7684\u5c5e\u6027\u5305\u542b\u5982\u4e0b\u51e0\u4e2a\uff0c\u81ea\u5b9a\u4e49\u7684\u6307\u6807\u5b9e\u73b0\u8fd9\u4e9b\u5b57\u6bb5\u5373\u53ef\uff1a Name \u8868\u660e\u4e86metric\u7684\u540d\u79f0\uff0c\u9700\u8981\u540ccollector\u6a21\u5757\u4e2d\u6536\u96c6\u5230\u7684\u6307\u6807\u540d\u79f0\u4e00\u81f4 ActionPriority \u8868\u793a\u6307\u6807\u7684\u4f18\u5148\u7ea7\uff0c0\u4e3a\u6700\u4f4e\uff0c10\u4e3a\u6700\u9ad8 SortAble \u8868\u660e\u8be5\u6307\u6807\u662f\u5426\u53ef\u4ee5\u6392\u5e8f\uff0c\u5982\u679c\u4e3atrue\uff0c\u9700\u5b9e\u73b0\u5bf9\u5e94\u7684SortFunc SortFunc \u5bf9\u5e94\u7684\u6392\u5e8f\u65b9\u6cd5\uff0c\u6392\u5e8f\u65b9\u6cd5\u53ef\u4ee5\u6392\u5217\u7ec4\u5408\u4e00\u4e9b\u901a\u7528\u65b9\u6cd5\uff0c\u518d\u7ed3\u5408\u6307\u6807\u81ea\u8eab\u7684\u6392\u5e8f\uff0c\u5c06\u5728\u4e0b\u6587\u8be6\u7ec6\u4ecb\u7ecd ThrottleAble \u8868\u660e\u9488\u5bf9\u8be5\u6307\u6807\uff0c\u662f\u5426\u53ef\u4ee5\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u4f8b\u5982\u9488\u5bf9cpu\u4f7f\u7528\u91cf\u8fd9\u4e2ametric\uff0c\u5c31\u6709\u76f8\u5bf9\u5e94\u7684\u538b\u5236\u624b\u6bb5\uff0c\u4f46\u662f\u5bf9\u4e8ememory\u4f7f\u7528\u91cf\u8fd9\u79cd\u6307\u6807\uff0c\u5c31\u53ea\u80fd\u8fdb\u884cpod\u7684\u9a71\u9010\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u538b\u5236 ThrottleQuantified \u8868\u660e\u538b\u5236\uff08restore\uff09\u4e00\u4e2apod\u540e\uff0c\u80fd\u5426\u51c6\u786e\u8ba1\u7b97\u51fa\u7ecf\u8fc7\u538b\u5236\u540e\u91ca\u653e\u51fa\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u6211\u4eec\u5c06\u53ef\u4ee5\u51c6\u786e\u91cf\u5316\u7684\u6307\u6807\u79f0\u4e3a\u53efQuantified\uff0c\u5426\u5219\u4e3a\u4e0d\u53efQuantified\uff1b \u6bd4\u5982cpu\u7528\u91cf\uff0c\u53ef\u4ee5\u901a\u8fc7\u9650\u5236cgroup\u7528\u91cf\u8fdb\u884c\u538b\u5236\uff0c\u540c\u65f6\u53ef\u4ee5\u901a\u8fc7\u5f53\u524d\u8fd0\u884c\u503c\u548c\u538b\u5236\u540e\u7684\u503c\u8ba1\u7b97\u538b\u5236\u540e\u91ca\u653e\u7684cpu\u4f7f\u7528\u91cf\uff1b\u800c\u6bd4\u5982memory usage\u5c31\u4e0d\u5c5e\u4e8e\u538b\u5236\u53ef\u91cf\u5316metric\uff0c\u56e0\u4e3amemory\u6ca1\u6709\u5bf9\u5e94\u7684throttle\u5b9e\u73b0\uff0c\u4e5f\u5c31\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u538b\u5236\u4e00\u4e2apod\u540e\u91ca\u653e\u51fa\u6765\u7684memory\u8d44\u6e90\u5177\u4f53\u7528\u91cf\uff1b ThrottleFunc\uff0c\u6267\u884cThrottle\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efThrottle\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a RestoreFunc\uff0c\u88abThrottle\u540e\uff0c\u6267\u884c\u6062\u590d\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efRestore\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a EvictAble\uff0cEvictQuantified\uff0cEvictFunc \u5bf9evict\u52a8\u4f5c\u7684\u76f8\u5173\u5b9a\u4e49\uff0c\u5177\u4f53\u5185\u5bb9\u548cThrottle\u52a8\u4f5c\u7c7b\u4f3c type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } \u7528\u6237\u53ef\u4ee5\u81ea\u884c\u5b9a\u4e49\u81ea\u5df1\u7684metric\uff0c\u5728\u6784\u9020\u5b8c\u6210\u540e\uff0c\u901a\u8fc7registerMetricMap()\u8fdb\u884c\u6ce8\u518c \u9488\u5bf9\u9700\u8981\u81ea\u5b9a\u4e49\u7684\u6307\u6807\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0\u5982\u4e0b\u7684\u65b9\u6cd5\uff0c\u642d\u914d\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0pod\u7684\u7075\u6d3b\u81ea\u5b9a\u4e49\u6392\u5e8f\uff0c\u4ee5\u4ee3\u8868\u81ea\u5b9a\u4e49metric\u6307\u6807\uff0c \u4ee3\u8868\u81ea\u5b9a\u4e49\u7684\u9488\u5bf9\u7684\u6392\u5e8f\u7b56\u7565 func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } \u5176\u4e2d <metric-sort-func> \u9700\u8981\u5b9e\u73b0\u5982\u4e0b\u7684\u6392\u5e8f\u65b9\u6cd5 func (p1, p2 podinfo.PodContext) int32","title":"Qos Ensurance"},{"location":"zh/tutorials/using-qos-ensurance/#qos-ensurance","text":"Qos Ensurance \u4fdd\u8bc1\u4e86\u8fd0\u884c\u5728 Kubernetes \u4e0a\u7684 Pod \u7684\u7a33\u5b9a\u6027\u3002 \u5177\u6709\u5e72\u6270\u68c0\u6d4b\u548c\u4e3b\u52a8\u56de\u907f\u80fd\u529b\uff0c\u5f53\u8f83\u9ad8\u4f18\u5148\u7ea7\u7684 Pod \u53d7\u5230\u8d44\u6e90\u7ade\u4e89\u7684\u5f71\u54cd\u65f6\uff0cDisable Schedule\u3001Throttle\u4ee5\u53caEvict \u5c06\u5e94\u7528\u4e8e\u4f4e\u4f18\u5148\u7ea7\u7684 Pod\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u548c\u81ea\u5b9a\u4e49\u64cd\u4f5c\uff1b \u540c\u65f6\u5177\u5907\u589e\u5f3a\u7684\u65c1\u8defcpuset\u7ba1\u7406\u80fd\u529b\uff0c\u5728\u7ed1\u6838\u7684\u540c\u65f6\u63d0\u5347\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002 \u5177\u6709\u9884\u6d4b\u7b97\u6cd5\u589e\u5f3a\u7684\u52a8\u6001\u8d44\u6e90\u8d85\u5356\u80fd\u529b\uff0c\u5c06\u7a7a\u95f2\u8d44\u6e90\u590d\u7528\u8d77\u6765\uff0c\u540c\u65f6\u7ed3\u5408crane\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u66f4\u597d\u5730\u590d\u7528\u95f2\u7f6e\u8d44\u6e90\u3002\u540c\u65f6\u5177\u6709\u5f39\u6027\u8d44\u6e90\u9650\u5236\u529f\u80fd\uff0c\u9650\u5236\u590d\u7528\u7a7a\u95f2\u8d44\u6e90\u7684workload\u3002","title":"Qos Ensurance"},{"location":"zh/tutorials/using-qos-ensurance/#qos-ensurance_1","text":"Qos ensurance \u7684\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5b83\u5305\u542b\u4e09\u4e2a\u6a21\u5757\u3002 State Collector \uff1a\u5b9a\u671f\u6536\u96c6\u6307\u6807 Anomaly Analyzer \uff1a\u4f7f\u7528\u6536\u96c6\u6307\u6807\uff0c\u4ee5\u5206\u6790\u8282\u70b9\u662f\u5426\u53d1\u751f\u5f02\u5e38 Action Executor \uff1a\u6267\u884c\u56de\u907f\u52a8\u4f5c\uff0c\u5305\u62ec Disable Scheduling\u3001Throttle \u548c Eviction\u3002 \u4e3b\u8981\u6d41\u7a0b\uff1a State Collector \u4ece kube-apiserver \u540c\u6b65\u7b56\u7565\u3002 \u5982\u679c\u7b56\u7565\u53d1\u751f\u66f4\u6539\uff0c State Collector \u4f1a\u66f4\u65b0\u6307\u6807\u6536\u96c6\u89c4\u5219\u3002 State Collector \u5b9a\u671f\u6536\u96c6\u6307\u6807\u3002 State Collector \u5c06\u6307\u6807\u4f20\u8f93\u5230 Anomaly Analyzer \u3002 Anomaly Analyzer \u5bf9\u6240\u6709\u89c4\u5219\u8fdb\u884c\u8303\u56f4\u5206\u6790\uff0c\u4ee5\u5206\u6790\u8fbe\u5230\u7684\u56de\u907f\u9608\u503c\u6216\u6062\u590d\u9608\u503c\u3002 Anomaly Analyzer \u5408\u5e76\u5206\u6790\u7ed3\u679c\u5e76\u901a\u77e5 Action Executor \u6267\u884c\u56de\u907f\u52a8\u4f5c\u3002 Action Executor \u6839\u636e\u5206\u6790\u7ed3\u679c\u6267\u884c\u52a8\u4f5c\u3002","title":"Qos Ensurance \u67b6\u6784"},{"location":"zh/tutorials/using-qos-ensurance/#_1","text":"","title":"\u5e72\u6270\u68c0\u6d4b\u548c\u4e3b\u52a8\u56de\u907f"},{"location":"zh/tutorials/using-qos-ensurance/#disable-scheduling","text":"\u5b9a\u4e49 AvoidanceAction \u548c NodeQOSEnsurancePolicy \u3002 \u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u56de\u907f\u9608\u503c\u65f6\uff0c\u5c06\u8be5\u8282\u70b9\u8bbe\u7f6e\u4e3a\u7981\u7528\u8c03\u5ea6\u3002 \u793a\u4f8b YAML \u5982\u4e0b\u6240\u793a\uff1a AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 #(1) \u8282\u70b9\u4ece\u7981\u6b62\u8c03\u5ea6\u72b6\u6001\u5230\u6b63\u5e38\u72b6\u6001\u7684\u6700\u5c0f\u7b49\u5f85\u65f6\u95f4 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) \u5f53\u8fbe\u5230\u9608\u503c\u5e76\u6301\u7eed\u591a\u6b21\uff0c\u90a3\u4e48\u6211\u4eec\u8ba4\u4e3a\u89c4\u5219\u88ab\u89e6\u53d1 \u5f53\u9608\u503c\u672a\u8fbe\u5230\u5e76\u7ee7\u7eed\u591a\u6b21, \u90a3\u4e48\u6211\u4eec\u8ba4\u4e3a\u89c4\u5219\u5df2\u6062\u590d \u5173\u8054\u5230 AvoidanceAction \u540d\u79f0 \u52a8\u4f5c\u7684\u7b56\u7565\uff0c\u4f60\u53ef\u4ee5\u5c06\u5176\u8bbe\u7f6e\u4e3a\u201c\u9884\u89c8\u201d\u4ee5\u4e0d\u5b9e\u9645\u6267\u884c \u6307\u6807\u540d\u79f0 \u6307\u6807\u7684\u9608\u503c \u8bf7\u89c2\u770b\u89c6\u9891\u4ee5\u4e86\u89e3\u66f4\u591a Disable Scheduling \u7684\u7ec6\u8282\u3002","title":"Disable Scheduling"},{"location":"zh/tutorials/using-qos-ensurance/#throttle","text":"\u5b9a\u4e49 AvoidanceAction \u548c NodeQOSEnsurancePolicy \u3002 \u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u56de\u907f\u9608\u503c\u65f6\uff0c\u5c06\u6267\u884c\u8282\u70b9\u7684 Throttle Action \u3002 \u793a\u4f8b YAML \u5982\u4e0b\u6240\u793a\uff1a AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" CPU \u914d\u989d\u7684\u6700\u5c0f\u6bd4\u4f8b\uff0c\u5982\u679c pod \u88ab\u9650\u5236\u4f4e\u4e8e\u8fd9\u4e2a\u6bd4\u4f8b\uff0c\u5c31\u4f1a\u88ab\u8bbe\u7f6e\u4e3a\u8fd9\u4e2a\u3002 \u8be5\u914d\u7f6e\u8bbe\u7f6e\u7ed9 Throttle Action \u3002\u5b83\u5c06\u5728\u6bcf\u4e2a\u89e6\u53d1\u7684\u56de\u907f\u52a8\u4f5c\u4e2d\u51cf\u5c11\u8fd9\u4e2a CPU \u914d\u989d\u5360\u6bd4\u3002\u5b83\u4f1a\u5728\u6bcf\u4e2a\u6062\u590d\u52a8\u4f5c\u4e2d\u589e\u52a0\u8fd9\u4e2a CPU \u914d\u989d\u5360\u6bd4\u3002 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000","title":"Throttle"},{"location":"zh/tutorials/using-qos-ensurance/#eviction","text":"\u4e0b\u9762\u7684 YAML \u662f\u53e6\u4e00\u79cd\u60c5\u51b5\uff0c\u5f53\u8282\u70b9 CPU \u4f7f\u7528\u7387\u89e6\u53d1\u9608\u503c\u65f6\uff0c\u8282\u70b9\u4e0a\u7684\u4f4e\u4f18\u5148\u7ea7 pod \u5c06\u88ab\u9a71\u9010\u3002 AvoidanceAction apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" pod \u9700\u8981\u4f18\u96c5\u7ec8\u6b62\u7684\u6301\u7eed\u65f6\u95f4\uff08\u4ee5\u79d2\u4e3a\u5355\u4f4d\uff09\u3002 NodeQOSEnsurancePolicy apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 \u56de\u907f\u52a8\u4f5c\u7b56\u7565\u3002\u5f53\u8bbe\u7f6e\u4e3a Preview \u65f6\uff0c\u5c06\u4e0d\u4f1a\u88ab\u5b9e\u9645\u6267\u884c","title":"Eviction"},{"location":"zh/tutorials/using-qos-ensurance/#supported-metrics","text":"Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization","title":"Supported Metrics"},{"location":"zh/tutorials/using-qos-ensurance/#_2","text":"\u901a\u8fc7\u5982\u4e0b\u4e24\u70b9\u8fdb\u884c\uff0c\u907f\u514d\u4e86\u5bf9\u4e8e\u4f4e\u4f18pod\u7684\u8fc7\u5ea6\u64cd\u4f5c\u7684\u540c\u65f6\u80fd\u591f\u66f4\u5feb\u5730\u964d\u4f4e\u6307\u6807\u5230\u6307\u5b9a\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\uff0c\u4fdd\u969c\u9ad8\u4f18\u4e1a\u52a1\u4e0d\u53d7\u5f71\u54cd 1. \u6392\u5e8fpod crane\u5b9e\u73b0\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\uff08\u4e4b\u540e\u4f1a\u66f4\u591a\u5730\u5b8c\u5584\uff09\uff1a classAndPriority\uff1a \u6bd4\u8f83\u4e24\u4e2apod\u7684QOSClass\u548cclass value\uff0c\u4f18\u5148\u6bd4\u8f83QOSClass\uff0c\u518d\u6bd4\u8f83class value\uff1bpriority\u9ad8\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 runningTime\uff1a\u6bd4\u8f83\u4e24\u4e2apod\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u8fd0\u884c\u65f6\u95f4\u957f\u7684\u6392\u5728\u540e\u9762\u4f18\u5148\u7ea7\u66f4\u9ad8 \u5982\u679c\u4ec5\u9700\u4f7f\u7528\u8fd9\u4e24\u4e2a\u6392\u5e8f\u7b56\u7565\uff0c\u4f7f\u7528\u9ed8\u8ba4\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\uff1a\u4f1a\u9996\u5148\u6bd4\u8f83pod\u7684\u4f18\u5148\u7ea7\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u5bf9\u5e94\u6307\u6807\u7684\u7528\u91cf\uff0c\u4e4b\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u6709\u4e00\u4e2a\u7ef4\u5ea6\u53ef\u4ee5\u6bd4\u8f83\u51fa\u7ed3\u679c\u5373\u4e3apod\u7684\u6392\u5e8f\u7ed3\u679c \u4ee5cpu usage\u6307\u6807\u7684\u6392\u5e8f\u4e3a\u4f8b\uff0c\u8fd8\u6269\u5c55\u4e86\u4e00\u4e9b\u4e0e\u81ea\u8eab\u6307\u6807\u76f8\u5173\u7684\u6392\u5e8f\u7b56\u7565\uff0c \u5982cpu usage \u4f7f\u7528\u91cf\u7684\u6392\u5e8f\uff0c\u4f1a\u4f9d\u6b21\u6bd4\u8f83\u4e24\u4e2apod\u7684\u4f18\u5148\u7ea7\uff0c\u5982\u679c\u4f18\u5148\u7ea7\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u518d\u6bd4\u8f83cpu\u7528\u91cf\uff0c\u5982\u679ccpu\u7528\u91cf\u4e5f\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u7ee7\u7eed\u6bd4\u8f83\u6269\u5c55cpu\u8d44\u6e90\u7528\u91cf, \u6700\u540e\u6bd4\u8f83pod\u7684\u8fd0\u884c\u65f6\u957f\uff0c\u5f53\u67d0\u4e00\u4e2a\u6307\u6807\u5b58\u5728\u5dee\u5f02\u65f6\u5373\u53ef\u8fd4\u56de\u6bd4\u8f83\u7ed3\u679c\uff1a orderedBy(classAndPriority, cpuUsage, extCpuUsage, runningTime).Sort(pods) \u53c2\u8003\u6c34\u4f4d\u7ebf\u548cpod\u7528\u91cf\u6267\u884c\u56de\u907f\u52a8\u4f5c //\u5c06\u6240\u6709\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metrics\u6839\u636e\u5176Quantified\u5c5e\u6027\u533a\u5206\u4e3a\u4e24\u90e8\u5206 metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // \u5982\u679c\u5b58\u5728\u4e0d\u53efQuantified\u7684metric\uff0c\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u64cd\u4f5c if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //\u83b7\u53d6\u8282\u70b9\u548cworkload\u7684\u6700\u65b0\u7528\u91cf\uff0c\u6784\u9020\u548c\u6c34\u4f4d\u7ebf\u5dee\u8ddd ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //\u5982\u679c\u89e6\u53d1\u6c34\u4f4d\u7ebf\u4e2d\u5b58\u5728metric\u7684\u5b9e\u65f6\u7528\u91cf\u65e0\u6cd5\u83b7\u53d6\uff0c\u5219\u83b7\u53d6\u5177\u6709\u6700\u9ad8ActionPriority\u7684\u4e00\u4e2athrottleAble\u7684metric\u5bf9\u6240\u9009\u62e9\u7684\u6240\u6709pod\u8fdb\u884c\u538b\u5236\u64cd\u4f5c if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //\u904d\u5386\u89e6\u53d1\u6c34\u4f4d\u7ebf\u7684metric\u4e2d\u53ef\u4ee5\u91cf\u5316\u7684metric\uff1a\u5982\u679cmetric\u5177\u6709\u6392\u5e8f\u65b9\u6cd5\u5219\u76f4\u63a5\u4f7f\u7528\u5176SortFunc\u5bf9pod\u8fdb\u884c\u6392\u5e8f\uff0c\u5426\u5219\u4f7f\u7528GeneralSorter\u6392\u5e8f\uff1b //\u4e4b\u540e\u4f7f\u7528\u5176\u5bf9\u5e94\u7684\u64cd\u4f5c\u65b9\u6cd5\u5bf9pod\u6267\u884c\u64cd\u4f5c\uff0c\u5e76\u8ba1\u7b97\u91ca\u653e\u51fa\u6765\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u76f4\u5230\u5bf9\u5e94metric\u5230\u6c34\u4f4d\u7ebf\u7684\u5dee\u8ddd\u5df2\u4e0d\u5b58\u5728 for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } \u5173\u4e8e\u6269\u5c55\u81ea\u5b9a\u4e49\u6307\u6807\u548c\u6392\u5e8f\u53c2\u8003 \"\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f\" \u90e8\u5206","title":"\u7cbe\u786e\u6267\u884c\u56de\u907f\u52a8\u4f5c"},{"location":"zh/tutorials/using-qos-ensurance/#cpuset","text":"kubelet\u652f\u6301static\u7684cpu manager\u7b56\u7565\uff0c\u5f53guaranteed pod\u8fd0\u884c\u5728\u8282\u70b9\u4e0a\u65f6\uff0ckebelet\u4f1a\u4e3a\u8be5pod\u5206\u914d\u6307\u5b9a\u7684\u4e13\u5c5ecpu\uff0c\u5176\u4ed6\u8fdb\u7a0b\u65e0\u6cd5\u5360\u7528\uff0c\u8fd9\u4fdd\u8bc1\u4e86guaranteed pod\u7684cpu\u72ec\u5360\uff0c\u4f46\u662f\u4e5f\u9020\u6210\u4e86cpu\u548c\u8282\u70b9\u7684\u7684\u5229\u7528\u7387\u8f83\u4f4e\uff0c\u9020\u6210\u4e86\u4e00\u5b9a\u7684\u6d6a\u8d39\u3002 crane agent\u4e3acpuset\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7b56\u7565\uff0c\u5141\u8bb8pod\u548c\u5176\u4ed6pod\u5171\u4eabcpu\u5f53\u5176\u6307\u5b9a\u4e86cpu\u7ed1\u6838\u65f6\uff0c\u53ef\u4ee5\u5728\u5229\u7528\u7ed1\u6838\u66f4\u5c11\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u66f4\u9ad8\u7684\u7f13\u5b58\u4eb2\u548c\u6027\u7684\u4f18\u70b9\u7684\u524d\u63d0\u4e0b\uff0c\u8fd8\u80fd\u8ba9\u5176\u4ed6workload\u90e8\u7f72\u5171\u7528\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3002 \u63d0\u4f9b\u4e863\u79cdpod cpuset\u7c7b\u578b\uff1a exclusive\uff1a\u7ed1\u6838\u540e\u5176\u4ed6container\u4e0d\u80fd\u518d\u4f7f\u7528\u8be5cpu\uff0c\u72ec\u5360cpu share\uff1a\u7ed1\u6838\u540e\u5176\u4ed6container\u53ef\u4ee5\u4f7f\u7528\u8be5cpu none\uff1a\u9009\u62e9\u6ca1\u6709\u88abexclusive pod\u7684container\u5360\u7528\u7684cpu\uff0c\u53ef\u4ee5\u4f7f\u7528share\u7c7b\u578b\u7684\u7ed1\u6838 share\u7c7b\u578b\u7684\u7ed1\u6838\u7b56\u7565\u53ef\u4ee5\u5728\u5229\u7528\u7ed1\u6838\u66f4\u5c11\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u66f4\u9ad8\u7684\u7f13\u5b58\u4eb2\u548c\u6027\u7684\u4f18\u70b9\u7684\u524d\u63d0\u4e0b\uff0c\u8fd8\u80fd\u8ba9\u5176\u4ed6workload\u90e8\u7f72\u5171\u7528\uff0c\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387 \u653e\u5bbd\u4e86kubelet\u4e2d\u7ed1\u6838\u7684\u9650\u5236 \u539f\u5148\u9700\u8981\u6240\u6709container\u7684CPU limit\u4e0eCPU request\u76f8\u7b49 \uff0c\u8fd9\u91cc\u53ea\u9700\u8981\u4efb\u610fcontainer\u7684CPU limit\u5927\u4e8e\u6216\u7b49\u4e8e1\u4e14\u7b49\u4e8eCPU request\u5373\u53ef\u4e3a\u8be5container\u8bbe\u7f6e\u7ed1\u6838 \u652f\u6301\u5728pod\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4fee\u6539pod\u7684 cpuset policy\uff0c\u4f1a\u7acb\u5373\u751f\u6548 pod\u7684cpu manager policy\u4ecenone\u8f6c\u6362\u5230share\uff0c\u4eceexclusive\u8f6c\u6362\u5230share\uff0c\u5747\u65e0\u9700\u91cd\u542f \u4f7f\u7528\u65b9\u6cd5\uff1a 1. \u8bbe\u7f6ekubelet\u7684cpuset manager\u4e3a\"none\" 2. \u901a\u8fc7pod annotation\u8bbe\u7f6ecpu manager policy qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share","title":"\u589e\u5f3a\u7684\u65c1\u8defcpuset\u7ba1\u7406\u80fd\u529b"},{"location":"zh/tutorials/using-qos-ensurance/#_3","text":"\u4e3a\u4e86\u63d0\u9ad8\u7a33\u5b9a\u6027\uff0c\u901a\u5e38\u7528\u6237\u5728\u90e8\u7f72\u5e94\u7528\u7684\u65f6\u5019\u4f1a\u8bbe\u7f6e\u9ad8\u4e8e\u5b9e\u9645\u4f7f\u7528\u91cf\u7684Request\u503c\uff0c\u9020\u6210\u8d44\u6e90\u7684\u6d6a\u8d39\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8282\u70b9\u7684\u8d44\u6e90\u5229\u7528\u7387\uff0c\u7528\u6237\u4f1a\u642d\u914d\u90e8\u7f72\u4e00\u4e9bBestEffort\u7684\u5e94\u7528\uff0c\u5229\u7528\u95f2\u7f6e\u8d44\u6e90\uff0c\u5b9e\u73b0\u8d85\u5356\uff1b \u4f46\u662f\u8fd9\u4e9b\u5e94\u7528\u7531\u4e8e\u7f3a\u4e4f\u8d44\u6e90limit\u548crequest\u7684\u7ea6\u675f\u548c\u76f8\u5173\u4fe1\u606f\uff0c\u8c03\u5ea6\u5668\u4f9d\u65e7\u53ef\u80fd\u5c06\u8fd9\u4e9bpod\u8c03\u5ea6\u5230\u8d1f\u8f7d\u8f83\u9ad8\u7684\u8282\u70b9\u4e0a\u53bb\uff0c\u8fd9\u4e0e\u6211\u4eec\u7684\u521d\u8877\u662f\u4e0d\u7b26\u7684\uff0c\u6240\u4ee5\u6700\u597d\u80fd\u4f9d\u636e\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\u8fdb\u884c\u8c03\u5ea6\u3002 crane\u901a\u8fc7\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\u6536\u96c6\u4e86\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\uff0c\u7efc\u5408\u540e\u4f5c\u4e3a\u8282\u70b9\u7684\u7a7a\u95f2\u8d44\u6e90\u91cf\uff0c\u589e\u5f3a\u4e86\u8d44\u6e90\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff1a \u901a\u8fc7\u672c\u5730\u6536\u96c6\u7684cpu\u7528\u91cf\u4fe1\u606f nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal exclusiveCPUIdle\u662f\u6307\u88abcpu manager policy\u4e3aexclusive\u7684pod\u5360\u7528\u7684cpu\u7684\u7a7a\u95f2\u91cf\uff0c\u867d\u7136\u8fd9\u90e8\u5206\u8d44\u6e90\u662f\u7a7a\u95f2\u7684\uff0c\u4f46\u662f\u56e0\u4e3a\u72ec\u5360\u7684\u539f\u56e0\uff0c\u662f\u65e0\u6cd5\u88ab\u590d\u7528\u7684\uff0c\u56e0\u6b64\u52a0\u4e0a\u88ab\u7b97\u4f5c\u5df2\u4f7f\u7528\u91cf extResContainerCpuUsageTotal\u662f\u6307\u88ab\u4f5c\u4e3a\u52a8\u6001\u8d44\u6e90\u4f7f\u7528\u7684cpu\u7528\u91cf\uff0c\u9700\u8981\u51cf\u53bb\u4ee5\u514d\u88ab\u4e8c\u6b21\u8ba1\u7b97 \u521b\u5efa\u8282\u70b9cpu\u4f7f\u7528\u91cf\u7684TSP\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u81ea\u52a8\u521b\u5efa\uff0c\u4f1a\u6839\u636e\u5386\u53f2\u9884\u6d4b\u8282\u70b9CPU\u7528\u91cf apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default \u7ed3\u5408\u9884\u6d4b\u7b97\u6cd5\u548c\u5f53\u524d\u5b9e\u9645\u7528\u91cf\u63a8\u7b97\u8282\u70b9\u7684\u5269\u4f59\u53ef\u7528\u8d44\u6e90\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u62d3\u5c55\u8d44\u6e90\u8d4b\u4e88\u8282\u70b9\uff0cpod\u53ef\u6807\u660e\u4f7f\u7528\u8be5\u6269\u5c55\u8d44\u6e90\u4f5c\u4e3a\u79bb\u7ebf\u4f5c\u4e1a\u5c06\u7a7a\u95f2\u8d44\u6e90\u5229\u7528\u8d77\u6765\uff0c\u4ee5\u63d0\u5347\u8282\u70b9\u7684\u8d44\u6e90\u5229\u7528\u7387\uff1b \u4f7f\u7528\u65b9\u6cd5\uff1a \u90e8\u7f72pod\u65f6limit\u548crequest\u4f7f\u7528 gocrane.io/<$ResourceName>\uff1a<$value> \u5373\u53ef\uff0c\u5982\u4e0b spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\"","title":"\u9884\u6d4b\u7b97\u6cd5\u589e\u5f3a\u7684\u52a8\u6001\u8d44\u6e90\u8d85\u5356"},{"location":"zh/tutorials/using-qos-ensurance/#_4","text":"\u539f\u751f\u7684BestEffort\u5e94\u7528\u7f3a\u4e4f\u8d44\u6e90\u7528\u91cf\u7684\u516c\u5e73\u4fdd\u8bc1\uff0cCrane\u4fdd\u8bc1\u4f7f\u7528\u52a8\u6001\u8d44\u6e90\u7684BestEffort pod\u5176cpu\u4f7f\u7528\u91cf\u88ab\u9650\u5236\u5728\u5176\u5141\u8bb8\u4f7f\u7528\u7684\u5408\u7406\u8303\u56f4\u5185\uff0cagent\u4fdd\u8bc1\u4f7f\u7528\u6269\u5c55\u8d44\u6e90\u7684pod\u5b9e\u9645\u7528\u91cf\u4e5f\u4e0d\u4f1a\u8d85\u8fc7\u5176\u58f0\u660e\u9650\u5236\uff0c\u540c\u65f6\u5728cpu\u7ade\u4e89\u65f6\u4e5f\u80fd\u6309\u7167\u5404\u81ea\u58f0\u660e\u91cf\u516c\u5e73\u7ade\u4e89\uff1b\u540c\u65f6\u4f7f\u7528\u5f39\u6027\u8d44\u6e90\u7684pod\u4e5f\u4f1a\u53d7\u5230\u6c34\u4f4d\u7ebf\u529f\u80fd\u7684\u7ba1\u7406\u3002 \u4f7f\u7528\u65b9\u6cd5\uff1a \u90e8\u7f72pod\u65f6limit\u548crequest\u4f7f\u7528 gocrane.io/<$ResourceName>\uff1a<$value> \u5373\u53ef","title":"\u5f39\u6027\u8d44\u6e90\u9650\u5236\u529f\u80fd"},{"location":"zh/tutorials/using-qos-ensurance/#_5","text":"\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f\u7684\u4f7f\u7528\u540c \u7cbe\u786e\u6267\u884c\u56de\u907f\u52a8\u4f5c \u90e8\u5206\u4e2d\u4ecb\u7ecd\u7684\u6d41\u7a0b\uff0c\u6b64\u5904\u4ecb\u7ecd\u5982\u4f55\u81ea\u5b9a\u4e49\u81ea\u5df1\u7684\u6307\u6807\u53c2\u4e0e\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u6d41\u7a0b \u4e3a\u4e86\u66f4\u597d\u7684\u57fa\u4e8eNodeQOSEnsurancePolicy\u914d\u7f6e\u7684metric\u8fdb\u884c\u6392\u5e8f\u548c\u7cbe\u51c6\u63a7\u5236\uff0c\u5bf9metric\u5f15\u5165\u5c5e\u6027\u7684\u6982\u5ff5\u3002 metric\u7684\u5c5e\u6027\u5305\u542b\u5982\u4e0b\u51e0\u4e2a\uff0c\u81ea\u5b9a\u4e49\u7684\u6307\u6807\u5b9e\u73b0\u8fd9\u4e9b\u5b57\u6bb5\u5373\u53ef\uff1a Name \u8868\u660e\u4e86metric\u7684\u540d\u79f0\uff0c\u9700\u8981\u540ccollector\u6a21\u5757\u4e2d\u6536\u96c6\u5230\u7684\u6307\u6807\u540d\u79f0\u4e00\u81f4 ActionPriority \u8868\u793a\u6307\u6807\u7684\u4f18\u5148\u7ea7\uff0c0\u4e3a\u6700\u4f4e\uff0c10\u4e3a\u6700\u9ad8 SortAble \u8868\u660e\u8be5\u6307\u6807\u662f\u5426\u53ef\u4ee5\u6392\u5e8f\uff0c\u5982\u679c\u4e3atrue\uff0c\u9700\u5b9e\u73b0\u5bf9\u5e94\u7684SortFunc SortFunc \u5bf9\u5e94\u7684\u6392\u5e8f\u65b9\u6cd5\uff0c\u6392\u5e8f\u65b9\u6cd5\u53ef\u4ee5\u6392\u5217\u7ec4\u5408\u4e00\u4e9b\u901a\u7528\u65b9\u6cd5\uff0c\u518d\u7ed3\u5408\u6307\u6807\u81ea\u8eab\u7684\u6392\u5e8f\uff0c\u5c06\u5728\u4e0b\u6587\u8be6\u7ec6\u4ecb\u7ecd ThrottleAble \u8868\u660e\u9488\u5bf9\u8be5\u6307\u6807\uff0c\u662f\u5426\u53ef\u4ee5\u5bf9pod\u8fdb\u884c\u538b\u5236\uff0c\u4f8b\u5982\u9488\u5bf9cpu\u4f7f\u7528\u91cf\u8fd9\u4e2ametric\uff0c\u5c31\u6709\u76f8\u5bf9\u5e94\u7684\u538b\u5236\u624b\u6bb5\uff0c\u4f46\u662f\u5bf9\u4e8ememory\u4f7f\u7528\u91cf\u8fd9\u79cd\u6307\u6807\uff0c\u5c31\u53ea\u80fd\u8fdb\u884cpod\u7684\u9a71\u9010\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u538b\u5236 ThrottleQuantified \u8868\u660e\u538b\u5236\uff08restore\uff09\u4e00\u4e2apod\u540e\uff0c\u80fd\u5426\u51c6\u786e\u8ba1\u7b97\u51fa\u7ecf\u8fc7\u538b\u5236\u540e\u91ca\u653e\u51fa\u7684\u5bf9\u5e94metric\u7684\u8d44\u6e90\u91cf\uff0c\u6211\u4eec\u5c06\u53ef\u4ee5\u51c6\u786e\u91cf\u5316\u7684\u6307\u6807\u79f0\u4e3a\u53efQuantified\uff0c\u5426\u5219\u4e3a\u4e0d\u53efQuantified\uff1b \u6bd4\u5982cpu\u7528\u91cf\uff0c\u53ef\u4ee5\u901a\u8fc7\u9650\u5236cgroup\u7528\u91cf\u8fdb\u884c\u538b\u5236\uff0c\u540c\u65f6\u53ef\u4ee5\u901a\u8fc7\u5f53\u524d\u8fd0\u884c\u503c\u548c\u538b\u5236\u540e\u7684\u503c\u8ba1\u7b97\u538b\u5236\u540e\u91ca\u653e\u7684cpu\u4f7f\u7528\u91cf\uff1b\u800c\u6bd4\u5982memory usage\u5c31\u4e0d\u5c5e\u4e8e\u538b\u5236\u53ef\u91cf\u5316metric\uff0c\u56e0\u4e3amemory\u6ca1\u6709\u5bf9\u5e94\u7684throttle\u5b9e\u73b0\uff0c\u4e5f\u5c31\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u538b\u5236\u4e00\u4e2apod\u540e\u91ca\u653e\u51fa\u6765\u7684memory\u8d44\u6e90\u5177\u4f53\u7528\u91cf\uff1b ThrottleFunc\uff0c\u6267\u884cThrottle\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efThrottle\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a RestoreFunc\uff0c\u88abThrottle\u540e\uff0c\u6267\u884c\u6062\u590d\u52a8\u4f5c\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5982\u679c\u4e0d\u53efRestore\uff0c\u8fd4\u56de\u7684released\u4e3a\u7a7a EvictAble\uff0cEvictQuantified\uff0cEvictFunc \u5bf9evict\u52a8\u4f5c\u7684\u76f8\u5173\u5b9a\u4e49\uff0c\u5177\u4f53\u5185\u5bb9\u548cThrottle\u52a8\u4f5c\u7c7b\u4f3c type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } \u7528\u6237\u53ef\u4ee5\u81ea\u884c\u5b9a\u4e49\u81ea\u5df1\u7684metric\uff0c\u5728\u6784\u9020\u5b8c\u6210\u540e\uff0c\u901a\u8fc7registerMetricMap()\u8fdb\u884c\u6ce8\u518c \u9488\u5bf9\u9700\u8981\u81ea\u5b9a\u4e49\u7684\u6307\u6807\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0\u5982\u4e0b\u7684\u65b9\u6cd5\uff0c\u642d\u914d\u901a\u7528\u7684\u6392\u5e8f\u65b9\u6cd5\u5373\u53ef\u65b9\u4fbf\u5730\u5b9e\u73b0pod\u7684\u7075\u6d3b\u81ea\u5b9a\u4e49\u6392\u5e8f\uff0c\u4ee5\u4ee3\u8868\u81ea\u5b9a\u4e49metric\u6307\u6807\uff0c \u4ee3\u8868\u81ea\u5b9a\u4e49\u7684\u9488\u5bf9\u7684\u6392\u5e8f\u7b56\u7565 func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } \u5176\u4e2d <metric-sort-func> \u9700\u8981\u5b9e\u73b0\u5982\u4e0b\u7684\u6392\u5e8f\u65b9\u6cd5 func (p1, p2 podinfo.PodContext) int32","title":"\u81ea\u5b9a\u4e49\u6307\u6807\u5e72\u6270\u68c0\u6d4b\u56de\u907f\u548c\u81ea\u5b9a\u4e49\u6392\u5e8f"},{"location":"zh/tutorials/using-time-series-prediction/","text":"TimeSeriesPrediction \u00b6 Overview \u00b6 Knowing the future makes things easier for us. \u8bb8\u591a\u4e1a\u52a1\u5728\u65f6\u95f4\u5e8f\u5217\u4e0a\u5929\u7136\u5b58\u5728\u5468\u671f\u6027\u7684\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u90a3\u4e9b\u76f4\u63a5\u6216\u95f4\u63a5\u4e3a\u201c\u4eba\u201d\u670d\u52a1\u7684\u4e1a\u52a1\u3002\u8fd9\u79cd\u5468\u671f\u6027\u662f\u7531\u4eba\u4eec\u65e5\u5e38\u6d3b\u52a8\u7684\u89c4\u5f8b\u6027\u51b3\u5b9a\u7684\u3002\u4f8b\u5982\uff0c\u4eba\u4eec\u4e60\u60ef\u4e8e\u4e2d\u5348\u548c\u665a\u4e0a\u70b9\u5916\u5356\uff1b\u65e9\u665a\u603b\u6709\u4ea4\u901a\u9ad8\u5cf0\uff1b\u5373\u4f7f\u662f\u641c\u7d22\u7b49\u6a21\u5f0f\u4e0d\u90a3\u4e48\u660e\u663e\u7684\u670d\u52a1\uff0c\u591c\u95f4\u7684\u8bf7\u6c42\u91cf\u4e5f\u8fdc\u4f4e\u4e8e\u767d\u5929\u65f6\u95f4\u3002\u5bf9\u4e8e\u8fd9\u7c7b\u4e1a\u52a1\u76f8\u5173\u7684\u5e94\u7528\u6765\u8bf4\uff0c\u4ece\u8fc7\u53bb\u51e0\u5929\u7684\u5386\u53f2\u6570\u636e\u4e2d\u63a8\u65ad\u51fa\u6b21\u65e5\u7684\u6307\u6807\uff0c\u6216\u8005\u4ece\u4e0a\u5468\u4e00\u7684\u6570\u636e\u4e2d\u63a8\u65ad\u51fa\u4e0b\u5468\u4e00\u7684\u8bbf\u95ee\u91cf\u662f\u5f88\u81ea\u7136\u7684\u60f3\u6cd5\u3002\u901a\u8fc7\u9884\u6d4b\u672a\u6765 24 \u5c0f\u65f6\u5185\u7684\u6307\u6807\u6216\u6d41\u91cf\u6a21\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u66f4\u597d\u5730\u7ba1\u7406\u6211\u4eec\u7684\u5e94\u7528\u7a0b\u5e8f\u5b9e\u4f8b\uff0c\u7a33\u5b9a\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u540c\u65f6\u964d\u4f4e\u6210\u672c\u3002 TimeSeriesPrediction \u88ab\u7528\u4e8e\u9884\u6d4b Kubernetes \u5bf9\u8c61\u6307\u6807\u3002\u5b83\u57fa\u4e8e PredictionCore \u8fdb\u884c\u9884\u6d4b\u3002 Features \u00b6 TimeSeriesPrediction \u7684\u793a\u4f8b yaml \u5982\u4e0b\u6240\u793a\uff1a TimeSeriesPrediction apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef \u5b9a\u4e49\u4e86\u5bf9 Kubernetes \u5bf9\u8c61\u7684\u5f15\u7528\uff0c\u5305\u62ec Node \u6216\u5176\u4ed6\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f8b\u5982 Deployment\u3002 spec.predictionMetrics \u5b9a\u4e49\u4e86\u5173\u4e8e spec.targetRef \u7684\u6307\u6807\u3002 spec.predictionWindowSeconds \u662f\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u6301\u7eed\u65f6\u95f4\u3002 TimeSeriesPredictionController \u5c06\u8f6e\u6362 spec.Status \u4e2d\u7684\u9884\u6d4b\u6570\u636e\uff0c\u4ee5\u4f9b\u6d88\u8d39\u8005\u4f7f\u7528\u9884\u6d4b\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 Prediction Metrics \u00b6 TimeSeriesPrediction apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" Metric Type \u00b6 \u73b0\u5728\u6211\u4eec\u53ea\u652f\u6301 prometheus \u4f5c\u4e3a\u6570\u636e\u6e90\u3002\u6211\u4eec\u5b9a\u4e49 MetricType \u4e0e\u6570\u636e\u6e90\u8fdb\u884c\u7ed3\u5408\u3002\u4f46\u662f\u73b0\u5728\u53ef\u80fd\u6709\u4e9b\u6570\u636e\u6e90\u4e0d\u652f\u6301 MetricType \u3002 \u6307\u6807\u67e5\u8be2\u6709\u4ee5\u4e0b\u4e09\u79cd\u7c7b\u578b\uff1a ResourceQuery \u662f kubernetes \u5185\u7f6e\u7684\u8d44\u6e90\u6307\u6807\uff0c\u4f8b\u5982 cpu \u6216 memory\u3002Crane\u76ee\u524d\u53ea\u652f\u6301 CPU \u548c\u5185\u5b58\u3002 RawQuery \u662f\u901a\u8fc7 DSL \u7684\u67e5\u8be2\uff0c\u6bd4\u5982 prometheus \u67e5\u8be2\u8bed\u53e5\u3002\u73b0\u5728\u5df2\u652f\u6301 Prometheus \u3002 ExpressionQuery \u662f\u4e00\u4e2a\u8868\u8fbe\u5f0f\u67e5\u8be2\u3002 Algorithm \u00b6 Algorithm \u5b9a\u4e49\u7b97\u6cd5\u7c7b\u578b\u548c\u53c2\u6570\u6765\u9884\u6d4b\u6307\u6807\u3002\u73b0\u5728\u6709\u4e24\u79cd\u7b97\u6cd5\uff1a dsp \u662f\u4e00\u79cd\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u7684\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8e FFT\uff08\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u64c5\u957f\u9884\u6d4b\u4e00\u4e9b\u5177\u6709\u5b63\u8282\u6027\u548c\u5468\u671f\u7684\u65f6\u95f4\u5e8f\u5217\u3002 percentile \u662f\u4e00\u79cd\u4f30\u8ba1\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u627e\u5230\u4ee3\u8868\u8fc7\u53bb\u65f6\u95f4\u5e8f\u5217\u7684\u63a8\u8350\u503c\u7684\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8e\u6307\u6570\u8870\u51cf\u6743\u91cd\u76f4\u65b9\u56fe\u7edf\u8ba1\u3002\u5b83\u662f\u7528\u6765\u4f30\u8ba1\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\uff0c\u5b83\u4e0d\u64c5\u957f\u9884\u6d4b\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0c\u867d\u7136 percentile \u53ef\u4ee5\u8f93\u51fa\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u6570\u636e\uff0c\u4f46\u662f\u90fd\u662f\u4e00\u6837\u7684\u503c\u3002 \u6240\u4ee5\u5982\u679c\u4f60\u60f3\u9884\u6d4b\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0cdsp \u662f\u4e00\u4e2a\u66f4\u597d\u7684\u9009\u62e9\u3002 dsp params \u00b6 percentile params \u00b6","title":"Time Series Prediction"},{"location":"zh/tutorials/using-time-series-prediction/#timeseriesprediction","text":"","title":"TimeSeriesPrediction"},{"location":"zh/tutorials/using-time-series-prediction/#overview","text":"Knowing the future makes things easier for us. \u8bb8\u591a\u4e1a\u52a1\u5728\u65f6\u95f4\u5e8f\u5217\u4e0a\u5929\u7136\u5b58\u5728\u5468\u671f\u6027\u7684\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u90a3\u4e9b\u76f4\u63a5\u6216\u95f4\u63a5\u4e3a\u201c\u4eba\u201d\u670d\u52a1\u7684\u4e1a\u52a1\u3002\u8fd9\u79cd\u5468\u671f\u6027\u662f\u7531\u4eba\u4eec\u65e5\u5e38\u6d3b\u52a8\u7684\u89c4\u5f8b\u6027\u51b3\u5b9a\u7684\u3002\u4f8b\u5982\uff0c\u4eba\u4eec\u4e60\u60ef\u4e8e\u4e2d\u5348\u548c\u665a\u4e0a\u70b9\u5916\u5356\uff1b\u65e9\u665a\u603b\u6709\u4ea4\u901a\u9ad8\u5cf0\uff1b\u5373\u4f7f\u662f\u641c\u7d22\u7b49\u6a21\u5f0f\u4e0d\u90a3\u4e48\u660e\u663e\u7684\u670d\u52a1\uff0c\u591c\u95f4\u7684\u8bf7\u6c42\u91cf\u4e5f\u8fdc\u4f4e\u4e8e\u767d\u5929\u65f6\u95f4\u3002\u5bf9\u4e8e\u8fd9\u7c7b\u4e1a\u52a1\u76f8\u5173\u7684\u5e94\u7528\u6765\u8bf4\uff0c\u4ece\u8fc7\u53bb\u51e0\u5929\u7684\u5386\u53f2\u6570\u636e\u4e2d\u63a8\u65ad\u51fa\u6b21\u65e5\u7684\u6307\u6807\uff0c\u6216\u8005\u4ece\u4e0a\u5468\u4e00\u7684\u6570\u636e\u4e2d\u63a8\u65ad\u51fa\u4e0b\u5468\u4e00\u7684\u8bbf\u95ee\u91cf\u662f\u5f88\u81ea\u7136\u7684\u60f3\u6cd5\u3002\u901a\u8fc7\u9884\u6d4b\u672a\u6765 24 \u5c0f\u65f6\u5185\u7684\u6307\u6807\u6216\u6d41\u91cf\u6a21\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u66f4\u597d\u5730\u7ba1\u7406\u6211\u4eec\u7684\u5e94\u7528\u7a0b\u5e8f\u5b9e\u4f8b\uff0c\u7a33\u5b9a\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u540c\u65f6\u964d\u4f4e\u6210\u672c\u3002 TimeSeriesPrediction \u88ab\u7528\u4e8e\u9884\u6d4b Kubernetes \u5bf9\u8c61\u6307\u6807\u3002\u5b83\u57fa\u4e8e PredictionCore \u8fdb\u884c\u9884\u6d4b\u3002","title":"Overview"},{"location":"zh/tutorials/using-time-series-prediction/#features","text":"TimeSeriesPrediction \u7684\u793a\u4f8b yaml \u5982\u4e0b\u6240\u793a\uff1a TimeSeriesPrediction apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef \u5b9a\u4e49\u4e86\u5bf9 Kubernetes \u5bf9\u8c61\u7684\u5f15\u7528\uff0c\u5305\u62ec Node \u6216\u5176\u4ed6\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f8b\u5982 Deployment\u3002 spec.predictionMetrics \u5b9a\u4e49\u4e86\u5173\u4e8e spec.targetRef \u7684\u6307\u6807\u3002 spec.predictionWindowSeconds \u662f\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u6301\u7eed\u65f6\u95f4\u3002 TimeSeriesPredictionController \u5c06\u8f6e\u6362 spec.Status \u4e2d\u7684\u9884\u6d4b\u6570\u636e\uff0c\u4ee5\u4f9b\u6d88\u8d39\u8005\u4f7f\u7528\u9884\u6d4b\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002","title":"Features"},{"location":"zh/tutorials/using-time-series-prediction/#prediction-metrics","text":"TimeSeriesPrediction apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\"","title":"Prediction Metrics"},{"location":"zh/tutorials/using-time-series-prediction/#metric-type","text":"\u73b0\u5728\u6211\u4eec\u53ea\u652f\u6301 prometheus \u4f5c\u4e3a\u6570\u636e\u6e90\u3002\u6211\u4eec\u5b9a\u4e49 MetricType \u4e0e\u6570\u636e\u6e90\u8fdb\u884c\u7ed3\u5408\u3002\u4f46\u662f\u73b0\u5728\u53ef\u80fd\u6709\u4e9b\u6570\u636e\u6e90\u4e0d\u652f\u6301 MetricType \u3002 \u6307\u6807\u67e5\u8be2\u6709\u4ee5\u4e0b\u4e09\u79cd\u7c7b\u578b\uff1a ResourceQuery \u662f kubernetes \u5185\u7f6e\u7684\u8d44\u6e90\u6307\u6807\uff0c\u4f8b\u5982 cpu \u6216 memory\u3002Crane\u76ee\u524d\u53ea\u652f\u6301 CPU \u548c\u5185\u5b58\u3002 RawQuery \u662f\u901a\u8fc7 DSL \u7684\u67e5\u8be2\uff0c\u6bd4\u5982 prometheus \u67e5\u8be2\u8bed\u53e5\u3002\u73b0\u5728\u5df2\u652f\u6301 Prometheus \u3002 ExpressionQuery \u662f\u4e00\u4e2a\u8868\u8fbe\u5f0f\u67e5\u8be2\u3002","title":"Metric Type"},{"location":"zh/tutorials/using-time-series-prediction/#algorithm","text":"Algorithm \u5b9a\u4e49\u7b97\u6cd5\u7c7b\u578b\u548c\u53c2\u6570\u6765\u9884\u6d4b\u6307\u6807\u3002\u73b0\u5728\u6709\u4e24\u79cd\u7b97\u6cd5\uff1a dsp \u662f\u4e00\u79cd\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u7684\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8e FFT\uff08\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u64c5\u957f\u9884\u6d4b\u4e00\u4e9b\u5177\u6709\u5b63\u8282\u6027\u548c\u5468\u671f\u7684\u65f6\u95f4\u5e8f\u5217\u3002 percentile \u662f\u4e00\u79cd\u4f30\u8ba1\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u627e\u5230\u4ee3\u8868\u8fc7\u53bb\u65f6\u95f4\u5e8f\u5217\u7684\u63a8\u8350\u503c\u7684\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8e\u6307\u6570\u8870\u51cf\u6743\u91cd\u76f4\u65b9\u56fe\u7edf\u8ba1\u3002\u5b83\u662f\u7528\u6765\u4f30\u8ba1\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\uff0c\u5b83\u4e0d\u64c5\u957f\u9884\u6d4b\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0c\u867d\u7136 percentile \u53ef\u4ee5\u8f93\u51fa\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u6570\u636e\uff0c\u4f46\u662f\u90fd\u662f\u4e00\u6837\u7684\u503c\u3002 \u6240\u4ee5\u5982\u679c\u4f60\u60f3\u9884\u6d4b\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0cdsp \u662f\u4e00\u4e2a\u66f4\u597d\u7684\u9009\u62e9\u3002","title":"Algorithm"},{"location":"zh/tutorials/using-time-series-prediction/#dsp-params","text":"","title":"dsp params"},{"location":"zh/tutorials/using-time-series-prediction/#percentile-params","text":"","title":"percentile params"},{"location":"zh_TW/","text":"\u4ecb\u7d39 \u00b6 Crane\u7684\u76ee\u6a19\u662f\u63d0\u4f9b\u4e00\u7ad9\u5f0f\u5c08\u6848\uff0c\u5e6b\u52a9Kubernetes\u4f7f\u7528\u8005\u901a\u904e\u8c50\u5bcc\u7684\u529f\u80fd\u7bc0\u7701\u96f2\u7aef\u8cc7\u6e90\u7684\u4f7f\u7528\u91cf\uff1a \u57fa\u65bc\u76e3\u63a7\u8cc7\u6599\u7684 \u6642\u9593\u5e8f\u5217\u9810\u6e2c \u8cc7\u6e90\u4f7f\u7528\u7387\u8207\u6210\u672c\u7684\u53ef\u8996\u5316 \u4f7f\u7528\u91cf\u53ca\u6210\u672c\u512a\u5316 \u5305\u542b\uff1a R2 \u8cc7\u6e90\u7684\u91cd\u65b0\u5206\u914d(Resource Re-allocation) R3 \u8acb\u6c42\u548c\u526f\u672c\u7684\u5efa\u8b70(Request & Replicas Recommendation) \u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u5f48\u6027\u5316 \u6210\u672c\u6700\u4f73\u5316 \u57fa\u65bcPod\u512a\u5148\u7d1a\u7684 \u589e\u5f37QoS \u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6 \u7279\u8272 \u00b6 \u6642\u9593\u5e8f\u5217\u9810\u6e2c \u00b6 \u4f7f\u7528\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u5b9a\u7fa9\u5ea6\u91cf\u898f\u7bc4\u4f86\u9810\u6e2c Kubernetes \u8cc7\u6e90\uff0c\u5982Pod\u6216Node\u3002\u9810\u6e2c\u6a21\u7d44\u662f\u5176\u4ed6Crane\u5143\u4ef6\u7684\u6838\u5fc3\u5143\u4ef6\uff0c\u4f8b\u5982\uff1a EHPA \u548c Analytics \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002 \u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u7e2e\u653e\u5668 \u00b6 \u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u7e2e\u653e\u5668\u5e6b\u52a9\u60a8\u8f15\u9b06\u7ba1\u7406\u61c9\u7528\u7a0b\u5f0f\u7684\u64f4\u5c55\u3002 \u5b83\u8207\u539f\u751f HorizontalPodAutoscaler \u517c\u5bb9\uff0c\u4f46\u64f4\u5c55\u4e86\u66f4\u591a\u529f\u80fd\uff0c\u4f8b\u5982\u9810\u6e2c\u9a45\u52d5\u7684\u81ea\u52d5\u7e2e\u653e\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002 \u5206\u6790 \u00b6 \u5206\u6790\u6a21\u7d44\u5206\u6790\u5de5\u4f5c\u8ca0\u8f09\u4e26\u63d0\u51fa\u6709\u95dc\u8cc7\u6e90\u512a\u5316\u7684\u5efa\u8b70\u3002 \u76ee\u524d\u652f\u6301\u5169\u500b\u5efa\u8b70\uff1a - ResourceRecommend : \u526f\u672c\u63a8\u85a6\u5206\u6790\u5be6\u969b\u61c9\u7528\u7a0b\u5f0f\u7684\u4f7f\u7528\u60c5\u6cc1\uff0c\u4e26\u70ba\u526f\u672c\u548c HPA \u914d\u7f6e\u63d0\u4f9b\u5efa\u8b70\u3002 - HPARecommend : \u8cc7\u6e90\u63a8\u85a6\u53ef\u4ee5\u8b93\u60a8\u7372\u53d6\u53e2\u96c6\u4e2d\u8cc7\u6e90\u7684\u63a8\u85a6\u503c\uff0c\u4e26\u4f7f\u7528\u9019\u4e9b\u63a8\u85a6\u503c\u4f86\u63d0\u9ad8\u53e2\u96c6\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002 QoS \u4fdd\u8b49 \u00b6 Kubernetes \u80fd\u5920\u5728\u540c\u4e00\u500b\u7bc0\u9ede\u4e0a\u555f\u52d5\u591a\u500b Pod\uff0c\u56e0\u6b64\u7576\u5b58\u5728\u8cc7\u6e90\uff08\u4f8b\u5982 cpu\uff09\u6d88\u8017\u7af6\u722d\u6642\uff0c\u90e8\u5206\u7528\u6236\u61c9\u7528\u7a0b\u5f0f\u53ef\u80fd\u6703\u53d7\u5230\u5f71\u97ff\u3002 \u70ba\u4e86\u7de9\u89e3\u9019\u7a2e\u60c5\u6cc1\uff0cCrane \u5141\u8a31\u4f7f\u7528\u8005\u70ba Pod \u548c QoSEnsurancePolicy \u5b9a\u7fa9\u512a\u5148\u7d1a\uff0c\u7136\u5f8c\u6aa2\u6e2c\u4e2d\u65b7\u4e26\u78ba\u4fdd\u9ad8\u512a\u5148\u7d1aPod\u4e0d\u53d7\u8cc7\u6e90\u7af6\u722d\u7684\u5f71\u97ff\u3002 \u8ff4\u907f\u63aa\u65bd\uff1a Disable Schedule \uff1a\u901a\u904e\u8a2d\u5b9a\u7bc0\u9ede\u6c61\u67d3\u548c\u689d\u4ef6\u4f86\u95dc\u9589\u8abf\u5ea6 Throttle : \u901a\u904e\u58d3\u7e2e cgroup \u8a2d\u5b9a\u4f86\u9650\u5236\u4f4e\u512a\u5148\u7d1a\u7684Pod Evict : \u95dc\u9589\u4f4e\u512a\u5148\u7d1a\u7684Pod \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002 \u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6 \u00b6 Kubernetes \u7684\u539f\u751f\u8abf\u5ea6\u5668\u53ea\u80fd\u901a\u904e\u8cc7\u6e90\u8acb\u6c42\u4f86\u8abf\u5ea6 Pod\uff0c\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8ca0\u8f09\u4e0d\u5747\u7684\u554f\u984c\u3002 \u76f8\u6bd4\u4e4b\u4e0b\uff0cCrane-scheduler \u53ef\u4ee5\u5f9e Prometheus \u7372\u53d6 kubernetes \u7bc0\u9ede\u7684\u5be6\u969b\u8ca0\u8f09\uff0c\u5be6\u73fe\u66f4\u9ad8\u6548\u7684\u8abf\u5ea6\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002 \u5132\u5b58\u5eab \u00b6 Crane \u7531\u4ee5\u4e0b\u5143\u4ef6\u7d44\u6210\uff1a craned - crane \u4e3b\u8981\u63a7\u5236\u5e73\u9762\u3002 Predictor - \u6839\u64da\u6b77\u53f2\u6578\u64da\u9810\u6e2c\u8cc7\u6e90\u6307\u6a19\u8da8\u52e2\u3002 AnalyticsController - \u5206\u6790\u8cc7\u6e90\u4e26\u7522\u751f\u76f8\u95dc\u5efa\u8b70\u3002 RecommendationController - \u63a8\u85a6 Pod \u8cc7\u6e90\u8acb\u6c42\u548c\u81ea\u52d5\u7e2e\u653e\u5668\u3002 ClusterNodePredictionController - \u70ba\u7bc0\u9ede\u5275\u5efa\u9810\u6e2c\u5668\u3002 EffectiveHPAController - \u7528\u65bc\u6c34\u5e73\u7e2e\u653e\u7684\u9ad8\u6548HPA\u3002 EffectiveVPAController - \u7528\u65bc\u5782\u76f4\u7e2e\u653e\u7684\u9ad8\u6548VPA\u3002 metric-adaptor - \u7528\u65bc\u9a45\u52d5\u64f4\u5c55\u7684\u5ea6\u91cf\u670d\u52d9\u5668\u3002 crane-agent - \u78ba\u4fdd\u57fa\u65bc\u7570\u5e38\u6aa2\u6e2c\u7684\u95dc\u9375\u5de5\u4f5c\u8ca0\u8f09SLO\u3002 gocrane/api - \u8a72\u5b58\u5132\u5eab\u70ba Crane \u5e73\u53f0\u5b9a\u7fa9\u4e86\u7d44\u4ef6\u7d1a API\u3002 gocrane/fadvisor - \u5f9e\u96f2\u7aefAPI\u6536\u96c6\u8cc7\u6e90\u50f9\u683c\u7684\u8ca1\u52d9\u9867\u554f\u3002 gocrane/crane-scheduler - \u4e00\u500b Kubernetes \u8abf\u5ea6\u5668\uff0c\u53ef\u4ee5\u6839\u64da\u5be6\u969b\u7bc0\u9ede\u8ca0\u8f09\u8abf\u5ea6pod\u3002","title":"\u4ecb\u7d39"},{"location":"zh_TW/#_1","text":"Crane\u7684\u76ee\u6a19\u662f\u63d0\u4f9b\u4e00\u7ad9\u5f0f\u5c08\u6848\uff0c\u5e6b\u52a9Kubernetes\u4f7f\u7528\u8005\u901a\u904e\u8c50\u5bcc\u7684\u529f\u80fd\u7bc0\u7701\u96f2\u7aef\u8cc7\u6e90\u7684\u4f7f\u7528\u91cf\uff1a \u57fa\u65bc\u76e3\u63a7\u8cc7\u6599\u7684 \u6642\u9593\u5e8f\u5217\u9810\u6e2c \u8cc7\u6e90\u4f7f\u7528\u7387\u8207\u6210\u672c\u7684\u53ef\u8996\u5316 \u4f7f\u7528\u91cf\u53ca\u6210\u672c\u512a\u5316 \u5305\u542b\uff1a R2 \u8cc7\u6e90\u7684\u91cd\u65b0\u5206\u914d(Resource Re-allocation) R3 \u8acb\u6c42\u548c\u526f\u672c\u7684\u5efa\u8b70(Request & Replicas Recommendation) \u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u5f48\u6027\u5316 \u6210\u672c\u6700\u4f73\u5316 \u57fa\u65bcPod\u512a\u5148\u7d1a\u7684 \u589e\u5f37QoS \u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6","title":"\u4ecb\u7d39"},{"location":"zh_TW/#_2","text":"","title":"\u7279\u8272"},{"location":"zh_TW/#_3","text":"\u4f7f\u7528\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u5b9a\u7fa9\u5ea6\u91cf\u898f\u7bc4\u4f86\u9810\u6e2c Kubernetes \u8cc7\u6e90\uff0c\u5982Pod\u6216Node\u3002\u9810\u6e2c\u6a21\u7d44\u662f\u5176\u4ed6Crane\u5143\u4ef6\u7684\u6838\u5fc3\u5143\u4ef6\uff0c\u4f8b\u5982\uff1a EHPA \u548c Analytics \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002","title":"\u6642\u9593\u5e8f\u5217\u9810\u6e2c"},{"location":"zh_TW/#pod","text":"\u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u7e2e\u653e\u5668\u5e6b\u52a9\u60a8\u8f15\u9b06\u7ba1\u7406\u61c9\u7528\u7a0b\u5f0f\u7684\u64f4\u5c55\u3002 \u5b83\u8207\u539f\u751f HorizontalPodAutoscaler \u517c\u5bb9\uff0c\u4f46\u64f4\u5c55\u4e86\u66f4\u591a\u529f\u80fd\uff0c\u4f8b\u5982\u9810\u6e2c\u9a45\u52d5\u7684\u81ea\u52d5\u7e2e\u653e\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002","title":"\u9ad8\u6548\u7387\u7684Pod\u81ea\u52d5\u7e2e\u653e\u5668"},{"location":"zh_TW/#_4","text":"\u5206\u6790\u6a21\u7d44\u5206\u6790\u5de5\u4f5c\u8ca0\u8f09\u4e26\u63d0\u51fa\u6709\u95dc\u8cc7\u6e90\u512a\u5316\u7684\u5efa\u8b70\u3002 \u76ee\u524d\u652f\u6301\u5169\u500b\u5efa\u8b70\uff1a - ResourceRecommend : \u526f\u672c\u63a8\u85a6\u5206\u6790\u5be6\u969b\u61c9\u7528\u7a0b\u5f0f\u7684\u4f7f\u7528\u60c5\u6cc1\uff0c\u4e26\u70ba\u526f\u672c\u548c HPA \u914d\u7f6e\u63d0\u4f9b\u5efa\u8b70\u3002 - HPARecommend : \u8cc7\u6e90\u63a8\u85a6\u53ef\u4ee5\u8b93\u60a8\u7372\u53d6\u53e2\u96c6\u4e2d\u8cc7\u6e90\u7684\u63a8\u85a6\u503c\uff0c\u4e26\u4f7f\u7528\u9019\u4e9b\u63a8\u85a6\u503c\u4f86\u63d0\u9ad8\u53e2\u96c6\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002","title":"\u5206\u6790"},{"location":"zh_TW/#qos","text":"Kubernetes \u80fd\u5920\u5728\u540c\u4e00\u500b\u7bc0\u9ede\u4e0a\u555f\u52d5\u591a\u500b Pod\uff0c\u56e0\u6b64\u7576\u5b58\u5728\u8cc7\u6e90\uff08\u4f8b\u5982 cpu\uff09\u6d88\u8017\u7af6\u722d\u6642\uff0c\u90e8\u5206\u7528\u6236\u61c9\u7528\u7a0b\u5f0f\u53ef\u80fd\u6703\u53d7\u5230\u5f71\u97ff\u3002 \u70ba\u4e86\u7de9\u89e3\u9019\u7a2e\u60c5\u6cc1\uff0cCrane \u5141\u8a31\u4f7f\u7528\u8005\u70ba Pod \u548c QoSEnsurancePolicy \u5b9a\u7fa9\u512a\u5148\u7d1a\uff0c\u7136\u5f8c\u6aa2\u6e2c\u4e2d\u65b7\u4e26\u78ba\u4fdd\u9ad8\u512a\u5148\u7d1aPod\u4e0d\u53d7\u8cc7\u6e90\u7af6\u722d\u7684\u5f71\u97ff\u3002 \u8ff4\u907f\u63aa\u65bd\uff1a Disable Schedule \uff1a\u901a\u904e\u8a2d\u5b9a\u7bc0\u9ede\u6c61\u67d3\u548c\u689d\u4ef6\u4f86\u95dc\u9589\u8abf\u5ea6 Throttle : \u901a\u904e\u58d3\u7e2e cgroup \u8a2d\u5b9a\u4f86\u9650\u5236\u4f4e\u512a\u5148\u7d1a\u7684Pod Evict : \u95dc\u9589\u4f4e\u512a\u5148\u7d1a\u7684Pod \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002","title":"QoS \u4fdd\u8b49"},{"location":"zh_TW/#_5","text":"Kubernetes \u7684\u539f\u751f\u8abf\u5ea6\u5668\u53ea\u80fd\u901a\u904e\u8cc7\u6e90\u8acb\u6c42\u4f86\u8abf\u5ea6 Pod\uff0c\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8ca0\u8f09\u4e0d\u5747\u7684\u554f\u984c\u3002 \u76f8\u6bd4\u4e4b\u4e0b\uff0cCrane-scheduler \u53ef\u4ee5\u5f9e Prometheus \u7372\u53d6 kubernetes \u7bc0\u9ede\u7684\u5be6\u969b\u8ca0\u8f09\uff0c\u5be6\u73fe\u66f4\u9ad8\u6548\u7684\u8abf\u5ea6\u3002 \u8acb\u53c3\u95b1 \u672c\u6587\u4ef6 \u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002","title":"\u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6"},{"location":"zh_TW/#_6","text":"Crane \u7531\u4ee5\u4e0b\u5143\u4ef6\u7d44\u6210\uff1a craned - crane \u4e3b\u8981\u63a7\u5236\u5e73\u9762\u3002 Predictor - \u6839\u64da\u6b77\u53f2\u6578\u64da\u9810\u6e2c\u8cc7\u6e90\u6307\u6a19\u8da8\u52e2\u3002 AnalyticsController - \u5206\u6790\u8cc7\u6e90\u4e26\u7522\u751f\u76f8\u95dc\u5efa\u8b70\u3002 RecommendationController - \u63a8\u85a6 Pod \u8cc7\u6e90\u8acb\u6c42\u548c\u81ea\u52d5\u7e2e\u653e\u5668\u3002 ClusterNodePredictionController - \u70ba\u7bc0\u9ede\u5275\u5efa\u9810\u6e2c\u5668\u3002 EffectiveHPAController - \u7528\u65bc\u6c34\u5e73\u7e2e\u653e\u7684\u9ad8\u6548HPA\u3002 EffectiveVPAController - \u7528\u65bc\u5782\u76f4\u7e2e\u653e\u7684\u9ad8\u6548VPA\u3002 metric-adaptor - \u7528\u65bc\u9a45\u52d5\u64f4\u5c55\u7684\u5ea6\u91cf\u670d\u52d9\u5668\u3002 crane-agent - \u78ba\u4fdd\u57fa\u65bc\u7570\u5e38\u6aa2\u6e2c\u7684\u95dc\u9375\u5de5\u4f5c\u8ca0\u8f09SLO\u3002 gocrane/api - \u8a72\u5b58\u5132\u5eab\u70ba Crane \u5e73\u53f0\u5b9a\u7fa9\u4e86\u7d44\u4ef6\u7d1a API\u3002 gocrane/fadvisor - \u5f9e\u96f2\u7aefAPI\u6536\u96c6\u8cc7\u6e90\u50f9\u683c\u7684\u8ca1\u52d9\u9867\u554f\u3002 gocrane/crane-scheduler - \u4e00\u500b Kubernetes \u8abf\u5ea6\u5668\uff0c\u53ef\u4ee5\u6839\u64da\u5be6\u969b\u7bc0\u9ede\u8ca0\u8f09\u8abf\u5ea6pod\u3002","title":"\u5132\u5b58\u5eab"},{"location":"zh_TW/CONTRIBUTING/","text":"Contributing to Crane \u00b6 Welcome to Crane! This document is a guideline about how to contribute to Crane. Become a contributor \u00b6 You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides . Report bugs \u00b6 Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug. Suggest enhancements \u00b6 If you have an idea to improve Crane, submit an feature request .","title":"\u8ca2\u737b"},{"location":"zh_TW/CONTRIBUTING/#contributing-to-crane","text":"Welcome to Crane! This document is a guideline about how to contribute to Crane.","title":"Contributing to Crane"},{"location":"zh_TW/CONTRIBUTING/#become-a-contributor","text":"You can contribute to Crane in several ways. Here are some examples: Contribute to the Crane codebase. Report bugs. Suggest enhancements. Write technical documentation and blog posts, for users and contributors. Organize meetups and user groups in your local area. Help others by answering questions about Crane. For more ways to contribute, check out the Open Source Guides .","title":"Become a contributor"},{"location":"zh_TW/CONTRIBUTING/#report-bugs","text":"Before submitting a new issue, try to make sure someone hasn't already reported the problem. Look through the existing issues for similar issues. Report a bug by submitting a bug report . Make sure that you provide as much information as possible on how to reproduce the bug.","title":"Report bugs"},{"location":"zh_TW/CONTRIBUTING/#suggest-enhancements","text":"If you have an idea to improve Crane, submit an feature request .","title":"Suggest enhancements"},{"location":"zh_TW/code-standards/","text":"Code standards \u00b6 This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project import need to be organized \u00b6 import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" ) logs standard \u00b6 logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err )) event is needed for critical reconcile loop \u00b6 event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ()) comment \u00b6 every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) } functions \u00b6 function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils variable \u00b6 variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop folder and file \u00b6 folder name should be letter with lower case and number file name should be letter and number and _ unit test \u00b6 Test-driven developing Complex function that include condition decide should add unit test for it don't forget to run make fmt before you submit code \u00b6","title":"\u4ee3\u78bc\u6a19\u6e96"},{"location":"zh_TW/code-standards/#code-standards","text":"This doc describes the code standards and suggestion for crane project, mainly for new contributor of the project","title":"Code standards"},{"location":"zh_TW/code-standards/#import-need-to-be-organized","text":"import should be categorized with blank line as system imports, community imports and crane apis and crane imports, like the following example import ( \"reflect\" \"sync\" \"time\" vpa \"k8s.io/autoscaler/vertical-pod-autoscaler/pkg/recommender/util\" \"github.com/gocrane/api/prediction/v1alpha1\" \"github.com/gocrane/crane/pkg/utils\" \"github.com/gocrane/crane/pkg/prediction/config\" )","title":"import need to be organized"},{"location":"zh_TW/code-standards/#logs-standard","text":"logs are required for troubleshooting purpose log message should always start with capital letter log message should be a complete sentence that contains enough context, for example: object key, action, parameters, status, error message by default, you don't need to set log level set 4 for debug level. set 6 for more detail debug level. set 10 for massive data log level. can use klog.KObj() to contain object key to let we know which object the message is printed for klog . Infof ( \"Failed to setup webhook %s\" , \"value\" ) klog . V ( 4 ). Infof ( \"Debug info %s\" , \"value\" ) klog . Errorf ( \"Failed to get scale, ehpa %s error %v\" , klog . KObj ( ehpa ), err ) klog . Error ( error ) klog . ErrorDepth ( 5 , fmt . Errorf ( \"failed to get ehpa %s: %v\" , klog . KObj ( ehpa ), err ))","title":"logs standard"},{"location":"zh_TW/code-standards/#event-is-needed-for-critical-reconcile-loop","text":"event is to let user know what happens on serverside, only print info we want user to know consider failure paths and success paths event do not need the object key c . Recorder . Event ( ehpa , v1 . EventTypeNormal , \"FailedGetSubstitute\" , err . Error ())","title":"event is needed for critical reconcile loop"},{"location":"zh_TW/code-standards/#comment","text":"every interface should have comments to clarify comment should be a complete sentence // Interface is a source of monitoring metric that provides metrics that can be used for // prediction, such as 'cpu usage', 'memory footprint', 'request per second (qps)', etc. type Interface interface { // GetTimeSeries returns the metric time series that meet the given // conditions from the specified time range. GetTimeSeries ( metricName string , Conditions [] common . QueryCondition , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // GetLatestTimeSeries returns the latest metric values that meet the given conditions. GetLatestTimeSeries ( metricName string , Conditions [] common . QueryCondition ) ([] * common . TimeSeries , error ) // QueryTimeSeries returns the time series based on a promql like query string. QueryTimeSeries ( queryExpr string , startTime time . Time , endTime time . Time , step time . Duration ) ([] * common . TimeSeries , error ) // QueryLatestTimeSeries returns the latest metric values that meet the given query. QueryLatestTimeSeries ( queryExpr string ) ([] * common . TimeSeries , error ) }","title":"comment"},{"location":"zh_TW/code-standards/#functions","text":"function name should clarify what do this function do, for example: verb + noun similar functions should be refactored, merge or divide them common functions should move to common folder like utils","title":"functions"},{"location":"zh_TW/code-standards/#variable","text":"variable name should clarify what do this variable does, better not use too short name and too simple name better to use more meaningful variable name for tmp variable, for example: foo loop","title":"variable"},{"location":"zh_TW/code-standards/#folder-and-file","text":"folder name should be letter with lower case and number file name should be letter and number and _","title":"folder and file"},{"location":"zh_TW/code-standards/#unit-test","text":"Test-driven developing Complex function that include condition decide should add unit test for it","title":"unit test"},{"location":"zh_TW/code-standards/#dont-forget-to-run-make-fmt-before-you-submit-code","text":"","title":"don't forget to run make fmt before you submit code"},{"location":"zh_TW/developer-guide/","text":"First, please make sure you've got a working Go environment and Docker environment . Clone crane \u00b6 Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane Building Binaries \u00b6 Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder. Building Docker Images \u00b6 You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"\u958b\u767c\u8005\u6307\u5357"},{"location":"zh_TW/developer-guide/#clone-crane","text":"Clone the repository, mkdir -p $GOPATH /src/github.com/gocrane/ cd $GOPATH /src/github.com/gocrane/ git clone https://github.com/gocrane/crane.git cd crane","title":"Clone crane"},{"location":"zh_TW/developer-guide/#building-binaries","text":"Run # build for linux/amd64 by default make all to build binaries craned , crane-agent and metric-adapter for linux/amd64 . Also you could specify other platforms when building, such as, # build only crane-agent for linux/arm64 and darwin/amd64 # use comma to separate multiple platforms PLATFORMS = linux/arm64,darwin/amd64 make crane-agent # below are all the supported platforms # PLATFORMS=darwin/amd64,darwin/arm64,linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm All the built binaries will be placed at $GOPATH/src/github.com/gocrane/crane/bin folder.","title":"Building Binaries"},{"location":"zh_TW/developer-guide/#building-docker-images","text":"You can also build docker images. Here docker buildx is used to help build multi-arch container images. If you're running MacOS, please install Docker Desktop and then check the builder, $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default * docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 If you're running Linux, please refer to docker buildx docs on the installation. Note For better docker buildx support, it is recommended to use Ubuntu Focal 20.04 (LTS), Debian Bullseye 11 and CentOS 8. And install deb/rpm package qemu-user-static as well, such as apt-get install qemu-user-static or yum install qemu-user-static # build for linux/amd64 by default # container images for craned, crane-agent, metric-adapter and dashboard make images Also you could build container images for other platforms, such as arm64 , PLATFORMS = linux/amd64,linux/arm64,linux/ppc64le make images # below are all the supported platforms # PLATFORMS=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x,linux/386,linux/arm Note For the first make image, It takes a bit of a long time, Please be patient. When we finish the make image, in the docker desktop, we can see the image we built, and the Tag is the hash value at the time of the git commit.","title":"Building Docker Images"},{"location":"zh_TW/installation/","text":"\u7522\u54c1\u90e8\u7f72\u6307\u5357 \u00b6 \u70ba\u4e86\u8b93\u60a8\u66f4\u5feb\u7684\u90e8\u7f72 Crane \uff0c\u672c\u6587\u6a94\u63d0\u4f9b\u6e05\u6670\u7684\uff1a \u90e8\u7f72\u74b0\u5883\u8981\u6c42 \u5177\u9ad4\u5b89\u88dd\u6b65\u9a5f Crane \u5b89\u88dd\u6642\u9593\u572810\u5206\u9418\u5de6\u53f3\uff0c\u5177\u9ad4\u6642\u9593\u4e5f\u4f9d\u8cf4\u96c6\u7fa4\u898f\u6a21\u4ee5\u53ca\u786c\u4ef6\u80fd\u529b\u3002\u76ee\u524d\u5b89\u88dd\u5df2\u7d93\u975e\u5e38\u6210\u719f\uff0c\u5982\u679c\u60a8\u5b89\u88dd\u4e2d\u9047\u5230\u4efb\u4f55\u554f\u984c\uff0c\u53ef\u4ee5\u63a1\u53d6\u5982\u4e0b\u5e7e\u7a2e\u65b9\u5f0f\uff1a \u8acb\u9996\u5148\u6aa2\u67e5\u5f8c\u6587\u7684 F&Q \u53ef\u4ee5\u63d0\u51fa\u4e00\u500b Issue \uff0c\u6211\u5011\u6703\u8a8d\u771f\u5c0d\u5f85\u6bcf\u4e00\u500b Issue \u90e8\u7f72\u74b0\u5883\u8981\u6c42 \u00b6 Kubernetes 1.18+ Helm 3.1.0 \u5b89\u88dd\u6d41\u7a0b \u00b6 \u5b89\u88dd Helm \u00b6 \u5efa\u8b70\u53c3\u8003 Helm \u5b98\u7db2 \u5b89\u88dd\u6587\u6a94 \u3002 \u5b89\u88dd Prometheus \u548c Grafana \u00b6 \u4f7f\u7528 Helm \u5b89\u88dd Prometheus \u548c Grafana\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u5df2\u7d93\u5728\u74b0\u5883\u4e2d\u90e8\u7f72\u4e86 Prometheus \u548c Grafana\uff0c\u53ef\u4ee5\u8df3\u904e\u8a72\u6b65\u9a5f\u3002 \u7db2\u7d61\u554f\u984c \u5982\u679c\u4f60\u7684\u7db2\u7d61\u7121\u6cd5\u8a2a\u554fGitHub\u8cc7\u6e90(GitHub Release, GitHub Raw Content raw.githubusercontent.com )\u3002 \u90a3\u9ebc\u4f60\u53ef\u4ee5\u5617\u8a66\u93e1\u50cf\u5009\u5eab\u3002\u4f46\u93e1\u50cf\u5009\u5eab\u5177\u6709\u4e00\u5b9a\u7684 \u6642\u5ef6 \u3002 \u93e1\u50cf\u5009\u5eab Crane \u4f7f\u7528 Prometheus \u6293\u53d6\u96c6\u7fa4\u5de5\u4f5c\u8ca0\u8f09\u5c0d\u8cc7\u6e90\u7684\u4f7f\u7528\u60c5\u6cc1\u3002\u5b89\u88dd Prometheus\uff1a Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/prometheus/override_values.yaml?download = false \\ --create-namespace prometheus-community/prometheus Crane \u7684 Fadvisor \u4f7f\u7528 Grafana \u5c55\u793a\u6210\u672c\u9810\u4f30\u3002\u5b89\u88dd Grafana\uff1a Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false \\ -n crane-system \\ --create-namespace grafana/grafana \u5b89\u88dd Crane \u548c Fadvisor \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor \u5b89\u88dd Crane-scheduler\uff08\u53ef\u9078\uff09 \u00b6 helm install scheduler -n crane-system --create-namespace crane/scheduler \u9a57\u8b49\u5b89\u88dd\u662f\u5426\u6210\u529f \u00b6 \u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u6aa2\u67e5\u5b89\u88dd\u7684 Deployment \u662f\u5426\u6b63\u5e38\uff1a kubectl get deploy -n crane-system \u7d50\u679c\u985e\u4f3c\u5982\u4e0b\uff1a NAME READY UP-TO-DATE AVAILABLE AGE craned 1 /1 1 1 31m fadvisor 1 /1 1 1 41m grafana 1 /1 1 1 42m metric-adapter 1 /1 1 1 31m prometheus-kube-state-metrics 1 /1 1 1 43m prometheus-server 1 /1 1 1 43m \u53ef\u4ee5\u67e5\u770b\u672c\u7bc7 \u6587\u6a94 \u7372\u53d6\u66f4\u591a\u6709\u95dc Crane Helm Chart \u7684\u4fe1\u606f\u3002 \u6210\u672c\u5c55\u793a \u00b6 \u6253\u958b Crane \u63a7\u5236\u53f0 \u00b6 \u6ce8\u610f\uff1aCrane \u7684\u63a7\u5236\u53f0\u5730\u5740\u5c31\u662f Crane \u7684 URL \u5730\u5740\uff0c\u53ef\u4ee5\u5c07\u5176\u6dfb\u52a0\u5230\u7d71\u4e00\u7684\u63a7\u5236\u53f0\u67e5\u770b\u591a\u500b\u90e8\u7f72 Crane \u7684\u96c6\u7fa4\u7684\u4fe1\u606f\u3002 \u5229\u7528 Port forwarding \u547d\u4ee4\uff0c\u53ef\u4ee5\u5728\u672c\u5730\u8a08\u7b97\u6a5f\u7684\u700f\u89bd\u5668\u6253\u958b Crane \u63a7\u5236\u53f0\uff1a kubectl port-forward -n crane-system svc/craned 9090 \u57f7\u884c\u4e0a\u8ff0\u547d\u4ee4\u5f8c\uff0c\u4e0d\u8981\u95dc\u9589\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5728\u672c\u5730\u8a08\u7b97\u6a5f\u7684\u700f\u89bd\u5668\u5730\u5740\u88e1\u8f38\u5165 localhost:9090 \u5373\u53ef\u6253\u958b Crane \u7684\u63a7\u5236\u53f0\uff1a \u6dfb\u52a0\u5b89\u88dd\u4e86 Crane \u7684\u96c6\u7fa4 \u00b6 \u60a8\u53ef\u4ee5\u9ede\u64ca\u4e0a\u5716\u4e2d\u7684\u201c\u6dfb\u52a0\u96c6\u7fa4\u201d\u7684\u85cd\u8272\u6309\u9215\uff0c\u5c07 Crane \u63a7\u5236\u53f0\u7684\u5730\u5740 http://localhost:9090 \u4f5c\u70ba Crane \u7684 URL\uff0c\u4f5c\u70ba\u7b2c\u4e00\u500b\u96c6\u7fa4\u6dfb\u52a0\u5230 Crane \u63a7\u5236\u53f0\u3002 \u82e5\u60a8\u60f3\u6dfb\u52a0\u5176\u5b83\u96c6\u7fa4\uff0c\u5be6\u73fe\u591a\u96c6\u7fa4\u7684\u8cc7\u6e90\u4f7f\u7528\u548c\u6210\u672c\u5206\u6790\u3002\u53ef\u4ee5\u5728\u5225\u7684\u96c6\u7fa4\u4e2d\u4e5f\u5b89\u88dd\u5b8c Crane \u4e4b\u5f8c\uff0c\u5c07 Crane \u7684 URL \u6dfb\u52a0\u9032\u4f86\u3002 \u81ea\u5b9a\u7fa9\u5b89\u88dd \u00b6 \u901a\u904e YAML \u5b89\u88dd Crane \u3002 Main ```bash git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION=$(curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")') git checkout $CRANE_LATEST_","title":"\u5b89\u88dd"},{"location":"zh_TW/installation/#_1","text":"\u70ba\u4e86\u8b93\u60a8\u66f4\u5feb\u7684\u90e8\u7f72 Crane \uff0c\u672c\u6587\u6a94\u63d0\u4f9b\u6e05\u6670\u7684\uff1a \u90e8\u7f72\u74b0\u5883\u8981\u6c42 \u5177\u9ad4\u5b89\u88dd\u6b65\u9a5f Crane \u5b89\u88dd\u6642\u9593\u572810\u5206\u9418\u5de6\u53f3\uff0c\u5177\u9ad4\u6642\u9593\u4e5f\u4f9d\u8cf4\u96c6\u7fa4\u898f\u6a21\u4ee5\u53ca\u786c\u4ef6\u80fd\u529b\u3002\u76ee\u524d\u5b89\u88dd\u5df2\u7d93\u975e\u5e38\u6210\u719f\uff0c\u5982\u679c\u60a8\u5b89\u88dd\u4e2d\u9047\u5230\u4efb\u4f55\u554f\u984c\uff0c\u53ef\u4ee5\u63a1\u53d6\u5982\u4e0b\u5e7e\u7a2e\u65b9\u5f0f\uff1a \u8acb\u9996\u5148\u6aa2\u67e5\u5f8c\u6587\u7684 F&Q \u53ef\u4ee5\u63d0\u51fa\u4e00\u500b Issue \uff0c\u6211\u5011\u6703\u8a8d\u771f\u5c0d\u5f85\u6bcf\u4e00\u500b Issue","title":"\u7522\u54c1\u90e8\u7f72\u6307\u5357"},{"location":"zh_TW/installation/#_2","text":"Kubernetes 1.18+ Helm 3.1.0","title":"\u90e8\u7f72\u74b0\u5883\u8981\u6c42"},{"location":"zh_TW/installation/#_3","text":"","title":"\u5b89\u88dd\u6d41\u7a0b"},{"location":"zh_TW/installation/#helm","text":"\u5efa\u8b70\u53c3\u8003 Helm \u5b98\u7db2 \u5b89\u88dd\u6587\u6a94 \u3002","title":"\u5b89\u88dd Helm"},{"location":"zh_TW/installation/#prometheus-grafana","text":"\u4f7f\u7528 Helm \u5b89\u88dd Prometheus \u548c Grafana\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u5df2\u7d93\u5728\u74b0\u5883\u4e2d\u90e8\u7f72\u4e86 Prometheus \u548c Grafana\uff0c\u53ef\u4ee5\u8df3\u904e\u8a72\u6b65\u9a5f\u3002 \u7db2\u7d61\u554f\u984c \u5982\u679c\u4f60\u7684\u7db2\u7d61\u7121\u6cd5\u8a2a\u554fGitHub\u8cc7\u6e90(GitHub Release, GitHub Raw Content raw.githubusercontent.com )\u3002 \u90a3\u9ebc\u4f60\u53ef\u4ee5\u5617\u8a66\u93e1\u50cf\u5009\u5eab\u3002\u4f46\u93e1\u50cf\u5009\u5eab\u5177\u6709\u4e00\u5b9a\u7684 \u6642\u5ef6 \u3002 \u93e1\u50cf\u5009\u5eab Crane \u4f7f\u7528 Prometheus \u6293\u53d6\u96c6\u7fa4\u5de5\u4f5c\u8ca0\u8f09\u5c0d\u8cc7\u6e90\u7684\u4f7f\u7528\u60c5\u6cc1\u3002\u5b89\u88dd Prometheus\uff1a Main Mirror helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/prometheus/override_values.yaml \\ --create-namespace prometheus-community/prometheus helm repo add prometheus-community https://finops-helm.pkg.coding.net/gocrane/prometheus-community helm install prometheus -n crane-system \\ --set pushgateway.enabled = false \\ --set alertmanager.enabled = false \\ --set server.persistentVolume.enabled = false \\ -f https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/prometheus/override_values.yaml?download = false \\ --create-namespace prometheus-community/prometheus Crane \u7684 Fadvisor \u4f7f\u7528 Grafana \u5c55\u793a\u6210\u672c\u9810\u4f30\u3002\u5b89\u88dd Grafana\uff1a Main Mirror helm repo add grafana https://grafana.github.io/helm-charts helm install grafana \\ -f https://raw.githubusercontent.com/gocrane/helm-charts/main/integration/grafana/override_values.yaml \\ -n crane-system \\ --create-namespace grafana/grafana helm repo add grafana https://finops-helm.pkg.coding.net/gocrane/grafana helm install grafana \\ -f https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false \\ -n crane-system \\ --create-namespace grafana/grafana","title":"\u5b89\u88dd Prometheus \u548c Grafana"},{"location":"zh_TW/installation/#crane-fadvisor","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install crane -n crane-system --create-namespace crane/crane helm install fadvisor -n crane-system --create-namespace crane/fadvisor","title":"\u5b89\u88dd Crane \u548c Fadvisor"},{"location":"zh_TW/installation/#crane-scheduler","text":"helm install scheduler -n crane-system --create-namespace crane/scheduler","title":"\u5b89\u88dd Crane-scheduler\uff08\u53ef\u9078\uff09"},{"location":"zh_TW/installation/#_4","text":"\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u6aa2\u67e5\u5b89\u88dd\u7684 Deployment \u662f\u5426\u6b63\u5e38\uff1a kubectl get deploy -n crane-system \u7d50\u679c\u985e\u4f3c\u5982\u4e0b\uff1a NAME READY UP-TO-DATE AVAILABLE AGE craned 1 /1 1 1 31m fadvisor 1 /1 1 1 41m grafana 1 /1 1 1 42m metric-adapter 1 /1 1 1 31m prometheus-kube-state-metrics 1 /1 1 1 43m prometheus-server 1 /1 1 1 43m \u53ef\u4ee5\u67e5\u770b\u672c\u7bc7 \u6587\u6a94 \u7372\u53d6\u66f4\u591a\u6709\u95dc Crane Helm Chart \u7684\u4fe1\u606f\u3002","title":"\u9a57\u8b49\u5b89\u88dd\u662f\u5426\u6210\u529f"},{"location":"zh_TW/installation/#_5","text":"","title":"\u6210\u672c\u5c55\u793a"},{"location":"zh_TW/installation/#crane","text":"\u6ce8\u610f\uff1aCrane \u7684\u63a7\u5236\u53f0\u5730\u5740\u5c31\u662f Crane \u7684 URL \u5730\u5740\uff0c\u53ef\u4ee5\u5c07\u5176\u6dfb\u52a0\u5230\u7d71\u4e00\u7684\u63a7\u5236\u53f0\u67e5\u770b\u591a\u500b\u90e8\u7f72 Crane \u7684\u96c6\u7fa4\u7684\u4fe1\u606f\u3002 \u5229\u7528 Port forwarding \u547d\u4ee4\uff0c\u53ef\u4ee5\u5728\u672c\u5730\u8a08\u7b97\u6a5f\u7684\u700f\u89bd\u5668\u6253\u958b Crane \u63a7\u5236\u53f0\uff1a kubectl port-forward -n crane-system svc/craned 9090 \u57f7\u884c\u4e0a\u8ff0\u547d\u4ee4\u5f8c\uff0c\u4e0d\u8981\u95dc\u9589\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5728\u672c\u5730\u8a08\u7b97\u6a5f\u7684\u700f\u89bd\u5668\u5730\u5740\u88e1\u8f38\u5165 localhost:9090 \u5373\u53ef\u6253\u958b Crane \u7684\u63a7\u5236\u53f0\uff1a","title":"\u6253\u958b Crane \u63a7\u5236\u53f0"},{"location":"zh_TW/installation/#crane_1","text":"\u60a8\u53ef\u4ee5\u9ede\u64ca\u4e0a\u5716\u4e2d\u7684\u201c\u6dfb\u52a0\u96c6\u7fa4\u201d\u7684\u85cd\u8272\u6309\u9215\uff0c\u5c07 Crane \u63a7\u5236\u53f0\u7684\u5730\u5740 http://localhost:9090 \u4f5c\u70ba Crane \u7684 URL\uff0c\u4f5c\u70ba\u7b2c\u4e00\u500b\u96c6\u7fa4\u6dfb\u52a0\u5230 Crane \u63a7\u5236\u53f0\u3002 \u82e5\u60a8\u60f3\u6dfb\u52a0\u5176\u5b83\u96c6\u7fa4\uff0c\u5be6\u73fe\u591a\u96c6\u7fa4\u7684\u8cc7\u6e90\u4f7f\u7528\u548c\u6210\u672c\u5206\u6790\u3002\u53ef\u4ee5\u5728\u5225\u7684\u96c6\u7fa4\u4e2d\u4e5f\u5b89\u88dd\u5b8c Crane \u4e4b\u5f8c\uff0c\u5c07 Crane \u7684 URL \u6dfb\u52a0\u9032\u4f86\u3002","title":"\u6dfb\u52a0\u5b89\u88dd\u4e86 Crane \u7684\u96c6\u7fa4"},{"location":"zh_TW/installation/#_6","text":"\u901a\u904e YAML \u5b89\u88dd Crane \u3002 Main ```bash git clone https://github.com/gocrane/crane.git CRANE_LATEST_VERSION=$(curl -s https://api.github.com/repos/gocrane/crane/releases/latest | grep -oP '\"tag_name\": \"\\K(.*)(?=\")') git checkout $CRANE_LATEST_","title":"\u81ea\u5b9a\u7fa9\u5b89\u88dd"},{"location":"zh_TW/mirror/","text":"\u93e1\u50cf\u8cc7\u6e90 \u00b6 \u95dc\u65bc\u93e1\u50cf\u8cc7\u6e90 \u00b6 \u56e0\u70ba\u5404\u7a2e\u7db2\u7d61\u554f\u984c\uff0c\u5c0e\u81f4\u90e8\u5206\u5730\u57df\u96e3\u4ee5\u8a2a\u554fGitHub \u8cc7\u6e90\uff0c\u5982GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com \u3002 \u70ba\u4e86\u66f4\u597d\u7684\u4f7f\u7528\u9ad4\u9a57\uff0cGoCrane \u70ba\u60a8\u984d\u5916\u63d0\u4f9b\u4e86\u591a\u500b\u93e1\u50cf\u5009\u5eab\uff0c\u4f46\u5177\u6709\u4e00\u5b9a\u7684\u6642\u5ef6\u3002 Helm Resources \u00b6 Tips \u6bcf\u516d\u5c0f\u6642\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u7684\u6700\u65b0\u7248\u672c Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public Git Resources \u00b6 Tips \u6bcf\u5929\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u5009\u5eab Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public \u7372\u53d6 Coding Git \u5009\u5eab\u6e90\u6587\u4ef6\u5167\u5bb9 \u00b6 \u5728\u9019\u88e1\u5c07\u70ba\u60a8\u4ecb\u7d39\uff0c\u5982\u4f55\u901a\u904eHTTP\u8acb\u6c42\u76f4\u63a5\u7372\u53d6 Coding Git \u5009\u5eab\u4e2d\u7684\u6e90\u6587\u4ef6\u5167\u5bb9\u3002 Coding Git \u5009\u5eab\u7684\u95dc\u9375\u53c3\u6578 \u00b6 \u8207\u5e38\u898f\u7684API\u8acb\u6c42\u985e\u4f3c\uff0cCoding Git\u5009\u5eab\u63d0\u4f9b\u4e86\u5c0d\u61c9\u7684API\u63a5\u53e3\u3002 \u4e0b\u9762\u70ba\u60a8\u4ecb\u7d39\u76f8\u95dc\u7684\u53c3\u6578\u3002 Example \u4ee5 https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml \u4f5c\u70ba\u4f8b\u5b50\u3002 \u9ede\u64ca\u8a2a\u554f \u53c3\u6578 \u8aaa\u660e \u4f8b\u5b50 team \u5718\u968a\u540d\u7a31 finops project \u9805\u76ee\u540d\u7a31 gocrane repo Git \u5009\u5eab\u540d\u7a31 helm-charts branch \u5206\u652f\u540d\u7a31 main file path \u9805\u76ee\u4e2d\u7684\u6587\u4ef6\u8def\u5f91 /integration/grafana/override_values.yaml \u69cb\u9020HTTP\u8acb\u6c42 \u00b6 \u6839\u64da\u4e0a\u9762\u6240\u63d0\u5230\u7684\u5c6c\u6027\uff0c\u6309\u7167\u4e0b\u9762\u7684URL\u69cb\u9020\u898f\u5247\u4f9d\u6b21\u586b\u5165\uff0c\u5373\u53ef\u7372\u5f97\u4e00\u500b\u53ef\u4ee5\u76f4\u63a5\u7372\u53d6\u6e90\u6587\u4ef6\u5167\u5bb9\u7684URL\u3002 https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips \u5617\u8a66\u4ee5\u4e0b\u7684\u547d\u4ee4 curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"\u93e1\u50cf\u8cc7\u6e90"},{"location":"zh_TW/mirror/#_1","text":"","title":"\u93e1\u50cf\u8cc7\u6e90"},{"location":"zh_TW/mirror/#_2","text":"\u56e0\u70ba\u5404\u7a2e\u7db2\u7d61\u554f\u984c\uff0c\u5c0e\u81f4\u90e8\u5206\u5730\u57df\u96e3\u4ee5\u8a2a\u554fGitHub \u8cc7\u6e90\uff0c\u5982GitHub Repo, GitHub Release, GitHub Raw Content raw.githubusercontent.com \u3002 \u70ba\u4e86\u66f4\u597d\u7684\u4f7f\u7528\u9ad4\u9a57\uff0cGoCrane \u70ba\u60a8\u984d\u5916\u63d0\u4f9b\u4e86\u591a\u500b\u93e1\u50cf\u5009\u5eab\uff0c\u4f46\u5177\u6709\u4e00\u5b9a\u7684\u6642\u5ef6\u3002","title":"\u95dc\u65bc\u93e1\u50cf\u8cc7\u6e90"},{"location":"zh_TW/mirror/#helm-resources","text":"Tips \u6bcf\u516d\u5c0f\u6642\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u7684\u6700\u65b0\u7248\u672c Origin Mirror Type Public https://gocrane.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/gocrane Helm Public https://prometheus-community.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/prometheus-community Helm Public https://grafana.github.io/helm-charts https://finops-helm.pkg.coding.net/gocrane/grafana Helm Public","title":"Helm Resources"},{"location":"zh_TW/mirror/#git-resources","text":"Tips \u6bcf\u5929\u540c\u6b65\u4e00\u6b21\u4e0a\u6e38\u5009\u5eab Origin Mirror Type Public https://github.com/gocrane/crane.git https://e.coding.net/finops/gocrane/crane.git Git Public https://github.com/gocrane/helm-charts.git https://e.coding.net/finops/gocrane/helm-charts.git Git Public https://github.com/gocrane/api.git https://e.coding.net/finops/gocrane/api.git Git Public https://github.com/gocrane/crane-scheduler.git https://e.coding.net/finops/gocrane/crane-scheduler.git Git Public https://github.com/gocrane/fadvisor.git https://e.coding.net/finops/gocrane/fadvisor.git Git Public","title":"Git Resources"},{"location":"zh_TW/mirror/#coding-git","text":"\u5728\u9019\u88e1\u5c07\u70ba\u60a8\u4ecb\u7d39\uff0c\u5982\u4f55\u901a\u904eHTTP\u8acb\u6c42\u76f4\u63a5\u7372\u53d6 Coding Git \u5009\u5eab\u4e2d\u7684\u6e90\u6587\u4ef6\u5167\u5bb9\u3002","title":"\u7372\u53d6 Coding Git \u5009\u5eab\u6e90\u6587\u4ef6\u5167\u5bb9"},{"location":"zh_TW/mirror/#coding-git_1","text":"\u8207\u5e38\u898f\u7684API\u8acb\u6c42\u985e\u4f3c\uff0cCoding Git\u5009\u5eab\u63d0\u4f9b\u4e86\u5c0d\u61c9\u7684API\u63a5\u53e3\u3002 \u4e0b\u9762\u70ba\u60a8\u4ecb\u7d39\u76f8\u95dc\u7684\u53c3\u6578\u3002 Example \u4ee5 https:// finops .coding.net/public/ gocrane / helm-charts /git/files /main/integration/grafana/override_values.yaml \u4f5c\u70ba\u4f8b\u5b50\u3002 \u9ede\u64ca\u8a2a\u554f \u53c3\u6578 \u8aaa\u660e \u4f8b\u5b50 team \u5718\u968a\u540d\u7a31 finops project \u9805\u76ee\u540d\u7a31 gocrane repo Git \u5009\u5eab\u540d\u7a31 helm-charts branch \u5206\u652f\u540d\u7a31 main file path \u9805\u76ee\u4e2d\u7684\u6587\u4ef6\u8def\u5f91 /integration/grafana/override_values.yaml","title":"Coding Git \u5009\u5eab\u7684\u95dc\u9375\u53c3\u6578"},{"location":"zh_TW/mirror/#http","text":"\u6839\u64da\u4e0a\u9762\u6240\u63d0\u5230\u7684\u5c6c\u6027\uff0c\u6309\u7167\u4e0b\u9762\u7684URL\u69cb\u9020\u898f\u5247\u4f9d\u6b21\u586b\u5165\uff0c\u5373\u53ef\u7372\u5f97\u4e00\u500b\u53ef\u4ee5\u76f4\u63a5\u7372\u53d6\u6e90\u6587\u4ef6\u5167\u5bb9\u7684URL\u3002 https://<team>.coding.net/p/<project>/d/<repo>/git/raw/<branch>/<file path>?download = false https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false Tips \u5617\u8a66\u4ee5\u4e0b\u7684\u547d\u4ee4 curl https://finops.coding.net/p/gocrane/d/helm-charts/git/raw/main/integration/grafana/override_values.yaml?download = false","title":"\u69cb\u9020HTTP\u8acb\u6c42"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/","text":"Advanced CPUSet Manager \u00b6 Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet. Table of Contents \u00b6 Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations Motivation \u00b6 Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service. Goals \u00b6 Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus Non-Goals/Future Work \u00b6 Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered Proposal \u00b6 Relax restrictions of cpuset allocation \u00b6 Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2 Add new annotation to describe the requirement of cpuset contorl manger \u00b6 apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use. Advanced CPU Manager component \u00b6 Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet User Stories \u00b6 Users can update pod annotaion to control cpuset policy flexibly Story 1 \u00b6 make pod from none to share without recreating pod Story 2 \u00b6 make pod from exclusive to share, so offline process can use these CPUs Risks and Mitigations \u00b6 kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Advanced CpuSet Manager"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#advanced-cpuset-manager","text":"Static CPU manager is supported by kubelet, when a guaranteed Pod is running on a node, kubelet allocate specific cpu cores to the processes exclusively, which generally keeps the cpu utilization of the node low. This proposal provides a new mechanism to manage cpusets, which allows sharing cpu cores with other processes while binds cpuset.It also allows to revise cpuset when pod is running and relaxes restrictions of binding cpus in kubelet.","title":"Advanced CPUSet Manager"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#table-of-contents","text":"Advanced CPUSet Manager Table of Contents Motivation Goals Non-Goals/Future Work Proposal Relax restrictions of cpuset allocation Add new annotation to describe the requirement of cpuset contorl manger Advanced CPU Manager component User Stories Story 1 Story 2 Risks and Mitigations","title":"Table of Contents"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#motivation","text":"Some latency-sensitive applications have lower lantency and cpu usage when running with specific cores, which results in fewer context switchs and higer cache affinity. But kubelet will always exclude assigned cores in shared cores, which may waste resources.Offline and other online pods can running on the cores actually. In our experiment, for the most part, it is barely noticeable for performance of service.","title":"Motivation"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#goals","text":"Provide a new mechanism to manage cpuset bypass Provide a new cpuset manager method \"shared\" Allow revise cpuset when pod running Relax restrictions of binding cpus","title":"Goals"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#non-goalsfuture-work","text":"Solve the conflicts with kubelet static cpuset manager, you need to set kubelet cpuset manager to \"none\" Numa manager will support in future, CCX/CCD manager also be considered","title":"Non-Goals/Future Work"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#proposal","text":"","title":"Proposal"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#relax-restrictions-of-cpuset-allocation","text":"Kubelet allocate cpus for containers should meet the conditions: requests and limits are specified for all the containers and they are equal the container's resource limit for the limit of CPU is an integer greater than or equal to one and equal to request request of CPU. In Crane, only need to meet condition No.2","title":"Relax restrictions of cpuset allocation"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#add-new-annotation-to-describe-the-requirement-of-cpuset-contorl-manger","text":"apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Provide three polices for cpuset manager: - none: containers of this pod shares a set of cpus which not allocated to exclusive containers - exclusive: containers of this pod monopolize the allocated CPUs , other containers not allowed to use. - share: containers of this pod runs in theallocated CPUs , but other containers can also use.","title":"Add new annotation to describe the  requirement of cpuset contorl manger"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#advanced-cpu-manager-component","text":"Crane-agent use podLister informs to sense the creation of pod. Crane-agent allocate cpus when pod is binded, and loop in cycle to addContainer(change cpuset) until the containers are created Update/Delete pod will handle in reconcile state. state.State referenced from kubelet and topology_cpu_assignment copied from kubelet","title":"Advanced CPU Manager component"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#user-stories","text":"Users can update pod annotaion to control cpuset policy flexibly","title":"User Stories"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#story-1","text":"make pod from none to share without recreating pod","title":"Story 1"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#story-2","text":"make pod from exclusive to share, so offline process can use these CPUs","title":"Story 2"},{"location":"zh_TW/proposals/20220228-advanced-cpuset-manger/#risks-and-mitigations","text":"kubelet cpu manger policy need to be set to none, otherwise will be conflicted with crane-agent if crane-agent can not allocate CPUs for pods, it will not refuse to start pod as kubelet","title":"Risks and Mitigations"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/","text":"Provide a policy-based abnormal detection mechanism in crane-agent \u00b6 Table of Contents \u00b6 Summary \u00b6 Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine. Motivation \u00b6 The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance. Goals \u00b6 Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code. Non-Goals \u00b6 How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope. Proposal \u00b6 User Stories \u00b6 Story 1 \u00b6 A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status. Story 2 \u00b6 The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly. Story 3 \u00b6 The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night. Functional Requirements \u00b6 Implementation Details \u00b6 API \u00b6 NodeQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 } PodQOSEnsurancePolicy \u00b6 apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future. Metrics \u00b6 Built-in metrics \u00b6 Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine. External metrics (New) \u00b6 Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node. Embedded metrics TSDB \u00b6 In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from. Policy \u00b6 The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#provide-a-policy-based-abnormal-detection-mechanism-in-crane-agent","text":"","title":"Provide a policy-based abnormal detection mechanism in crane-agent"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#summary","text":"Crane-agent is responsible for detecting abnormality on nodes and interference between running pods. Currently, such detection mechanism is fixed and quite simple. Crane-agent compares the values of some pre-defined metrics, such as node's cpu_total_usage and cpu_total_utilization , with some thresholds periodically. If the metric value is higher the threshold for some times, say the cpu_total_utilization on a node is found higher than 80% in 3 consecutive detections, crane-agent thinks the node entering into an abnormal status, and will perform some further actions, such as suppressing or evicting pods with low priorities. This proposal suggests a flexible and extensible way to detect abnormality. The criteria of abnormality can be customized by users in form of policies, and the detection process is executed in a policy decision-making way, which is offloaded to a general-purpose policy engine.","title":"Summary"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#motivation","text":"The criteria of abnormality or interference are not that always as simple as something like a metric value is higher than a threshold. Different users may have different QoS requirements on different applications in different environments. The rule of abnormality detection varies, and it is impossible to implement all of them in code in advance.","title":"Motivation"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#goals","text":"Provides an abnormality detection mechanism which can consume external metrics. Provides an abnormality detection mechanism in which the logic determining how to check the abnormality can be customized. Metrics and detection policies can be added, updated and deleted on the fly without changing the code.","title":"Goals"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#non-goals","text":"How to handle the abnormality or interference. This proposal only focuses on detection, and the subsequent action is out of scope.","title":"Non-Goals"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#proposal","text":"","title":"Proposal"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#user-stories","text":"","title":"User Stories"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#story-1","text":"A user has a critical online application which is latency sensitive running in the cluster, and he wants to use both the 99th percentile response time and the error code rate as the application QoS indicators. If either of these 2 indicators deteriorates, the application is thought of being in abnormal status.","title":"Story 1"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#story-2","text":"The SRE team finds that if the node CPU utilization is more than 60%, the QoS of some latency sensitive applications running on it are likely to decline. So they want to keep the node CPU utilization lower than 60%. If the utilization is higher than this threshold, the BE applications should be suppressed accordingly.","title":"Story 2"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#story-3","text":"The traffic of online applications is very low at night, and the offline jobs are run during this time. Comparing with online applications, offline jobs always require more CPU resource quantities but less resource qualities. In this case, the SRE team wants to set different node CPU load thresholds in the daytime and at night.","title":"Story 3"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#functional-requirements","text":"","title":"Functional Requirements"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#implementation-details","text":"","title":"Implementation Details"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#api","text":"","title":"API"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#nodeqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"xxx\" spec : nodeQualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : node_cpu_utilization query : 1 - avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=\"$nodeName\"}[5m])) variables : - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | default abnormal = false hour := time.clock([time.now_ns(), \"Local\"])[0] abnormal { input.node_cpu_utilization > 0.6 hour >= 7, hour < 21 } abnormal { input.node_cpu_utilization > 0.8 hour >= 21 } abnormal { input.node_cpu_utilization > 0.8 hour < 7 }","title":"NodeQOSEnsurancePolicy"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#podqosensurancepolicy","text":"apiVersion : ensurance.crane.io/v1alpha1 kind : PodQOSEnsurancePolicy metadata : name : \"xxx\" spec : selector : matchLabels : app : test qualityProbe : prometheus : targets : [ 'localhost:9090' ] queryInterval : 60s metrics : - name : test_app_p90_latency query : histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"$podName\", node=\"$nodeName\"}[1m])) variables : - name : podName valueFrom : fieldRef : fieldPath : metadata.name - name : nodeName valueFrom : fieldRef : fieldPath : spec.nodeName objectiveEnsurances : - name : \"ext_cpu_total_distribute\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"disablescheduling\" policy : | abnormal if test_app_p90_latency[_].value > 0.1 In addition to Prometheus , other protocols, such as Graphite , InfluxDB can also be added in the future.","title":"PodQOSEnsurancePolicy"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#metrics","text":"","title":"Metrics"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#built-in-metrics","text":"Currently, crane-agent collects a bunch of metrics(defined in pkg/ensurance/collector/types/types.go , e.g. cpu_total_usage ). These metrics are collected by nodelocal and cadvisor collectors, both of which collects metrics every 10 seconds. We call these metrics as built-in metrics. Users can use built-in metrics in the policy without explicit setting, and crane-agent will pass their values to every request to policy engine.","title":"Built-in metrics"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#external-metrics-new","text":"Crane-agent can also get external metrics by querying against prometheus servers. A new prometheus quality probe will be added to CRDs PodQOSEnsurancePolicy and NodeQOSEnsurancePolicy as shown in above 2 example yamls. In PodQOSEnsurancePolicy , .spec.nodeQualityProbe.prometheus.metrics.query is a promQL, which may includes some node variables (prefixed with $ ). In this case, crane-agent will use its node name to replace the variable $nodeName . In PodQOSEnsurancePolicy , .spec.qualityProbe.prometheus.metrics.query is a promQL, which may includes some pod related variables ( $nodeName , $podName in this example). Crane-agent will firstly get all pods that match the .spec.selector.matchLabels on its node. Say two pods are selected, and their names are pod-1 and pod-2 , and the node name is node-1 . The replaced promQL will be histogram_quantile(0.9, rate(http_request_duration_seconds_bucket{pod=~\"pod-1|pod-2\", node=\"node-1\"}[1m])) And 2 query results are expected to get returned, like: test_app_p90_latency{pod=\"pod-1\", ...} 0.01 test_app_p90_latency{pod=\"pod-2\", ...} 0.01 Simply speaking, variables in promQL help crane-agent only query metrics of its own node and the pods that running on its own node.","title":"External metrics (New)"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#embedded-metrics-tsdb","text":"In order to decouple the components that collect metrics and those which consume the metrics, and to make these components' logic simple, an embedded metrics TSDB will be imported into crane-agent. Prometheus-tsdb and vmstorage are two good candidates, both of which are easy to insert values and are compatible with promQL query grammar. Both analyzer and executor fetch metrics from the TSDB without considering where the metrics come from.","title":"Embedded metrics TSDB"},{"location":"zh_TW/proposals/20220402-policy-based-abnomal-detection/#policy","text":"The Open Policy Agent (OPA) is an open source, general-purpose policy engine that unifies policy enforcement. Crane-agent will use it to evaluate if nodes or pods are abnormal. The criteria for detecting abnormality is not pre-defined or hardcoded, instead, it is customized by users at runtime. A policy filed will be added to ObjectiveEnsurance , which is a rego rule whose result is a boolean element. crane-agent will feed both the latest built-in and external metrics as input into the OPA policy engine, and OPA make decisions based on input and policies. A sample input is as follows: { \"crane\" : { \"cpu_total_usage\" : 4680 , ... orh ter buil t - i n mer tr cs }, \"test_app_p90_latency\" : [ { \"labels\" : { \"pod\" : \"pod-1\" , \"node\" : \"node-1\" }, \"value\" : 0.1 }, { \"labels\" : { \"pod\" : \"pod-2\" , \"node\" : \"node-1\" }, \"value\" : 0.09 } ], ... }","title":"Policy"},{"location":"zh_TW/proposals/20220706-recommendation-definition/","text":"Recommendation Definition \u00b6 This proposal aims at definition for universal resource optimization. Table of Contents \u00b6 Motivation \u00b6 Proposal \u00b6 Api Definition \u00b6 RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` } Recommendation Configuration \u00b6 Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Definition"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#recommendation-definition","text":"This proposal aims at definition for universal resource optimization.","title":"Recommendation Definition"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#motivation","text":"","title":"Motivation"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#proposal","text":"","title":"Proposal"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#api-definition","text":"RecommendationRule defines which resources are required to recommend and what is the runInterval. // RecommendationRuleSpec defines resources and runInterval to recommend type RecommendationRuleSpec struct { // ResourceSelector indicates how to select resources(e.g. a set of Deployments) for an Recommendation. // +required // +kubebuilder:validation:Required ResourceSelectors [] ResourceSelector `json:\"resourceSelectors\"` // RunInterval between two recommendation RunInterval time . Duration `json:\"runInterval,omitempty\"` } // ResourceSelector describes how the resources will be selected. type ResourceSelector struct { // Kind of the resource, e.g. Deployment Kind string `json:\"kind\"` // API version of the resource, e.g. \"apps/v1\" // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Name of the resource. // +optional Name string `json:\"name,omitempty\"` // +optional LabelSelector metav1 . LabelSelector `json:\"labelSelector,omitempty\"` } namespace ? Recommendation is a content holder for recommendation result. We hope that the recommendation data can be applied directly to kubernetes cluster(Recommendation as a code) and Different type recommendation have different recommendation yaml, so the content is stored in recommendation as Data . type Recommendation struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` // +kubebuilder:pruning:PreserveUnknownFields Data runtime . RawExtension `json:\"data\"` }","title":"Api Definition"},{"location":"zh_TW/proposals/20220706-recommendation-definition/#recommendation-configuration","text":"Recommendation Configuration is centralized configuration that contains every rule for universal resource optimization. It not only includes RecommendationRules that use defines but also contains RecommendationPlugins.","title":"Recommendation Configuration"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/","text":"Universal Resource Optimization \u00b6 Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud. Table of Contents \u00b6 Motivation \u00b6 Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds. Goals \u00b6 Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud Non-Goals \u00b6 Cloud Resources that not included in kubernetes Proposal \u00b6 Recommendation Definition Recommendation Framework User Stories \u00b6 Story 1 \u00b6 As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production. Story 2 \u00b6 As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists. Story 3 \u00b6 As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Universal Resource Optimization"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#universal-resource-optimization","text":"Universal Resource Optimization provide a consistence progress to optimize variable kinds of resources in kubernetes. The progress should be Pluggable and support Multi-Cloud.","title":"Universal Resource Optimization"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#table-of-contents","text":"","title":"Table of Contents"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#motivation","text":"Currently, we use Analytics and Recommendation to provide a recommendation service for workloads in cluster. Kubernetes' users use the recommendation to optimize the resource configuration and reduce their cost. But the recommendations have some limitations now: Multiple Analytics can select some same resources, it's confused and unnecessary to have two recommendation for the same resource. We need to support more kinds of resources, for example, scan for idle load balancers. We need to make the progress Pluggable to support different user in difference clouds.","title":"Motivation"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#goals","text":"Global analytics rules Easy to know the recommendation for my resource Consistence progress for all resource recommendation Plugin mechanism to support Multi-Cloud","title":"Goals"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#non-goals","text":"Cloud Resources that not included in kubernetes","title":"Non-Goals"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#proposal","text":"Recommendation Definition Recommendation Framework","title":"Proposal"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#user-stories","text":"","title":"User Stories"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#story-1","text":"As a Serverless customer, I want to know the suitable requests and limits for my deployments, the result should be fit the existing pod model(e.g. 2c4g, 1c1g) in my cloud production.","title":"Story 1"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#story-2","text":"As an Aliyun ACK customer, I want to know whether there is a waste of LoadBalances in my cluster and delete them if exists.","title":"Story 2"},{"location":"zh_TW/proposals/20220706-universal-resource-optimization/#story-3","text":"As a container platform user, I want to integrate optimize recommendation to my platform and optimize my cluster within my CICD pipeline.","title":"Story 3"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/","text":"Recommendation Framework Internal \u00b6 Summary \u00b6 This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly. Motivation \u00b6 At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type. Goals \u00b6 Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules. Non-Goals \u00b6 Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework. Proposal \u00b6 Architecture \u00b6 Phases \u00b6 We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework. Fliter \u00b6 The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it. Prepare \u00b6 Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic. Recommend \u00b6 The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it. Observe \u00b6 Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Recommendation Framework Internal"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#recommendation-framework-internal","text":"","title":"Recommendation Framework Internal"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#summary","text":"This document describes the Crane Recommendation Framework Internal. We will propose the four major modules of Crane Recommendation in this proposal. By clearly dividing the functions of the modules and defining the interface, developers can expand the recommendation more conveniently and flexibly.","title":"Summary"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#motivation","text":"At present, crane Recommendation has been applied to kubernetes resource fields such as resource recommendation, replica recommendation, HPA recommendation, etc. The algorithm modules of crane, such as DSP, Max and Percentile algorithm modules, have been verified to be stable and effective in production practice.At the same time, the offline data source of crane supports prometheus, grpc protocol service, and the online data source supports prometheus and metricsserver. However, we have received a lot of feedback from developers, mainly focusing on the following aspects: After I have defined many different Recommendation types, I want to add some filtering or inject logic, but there seems to be no such interface. Our monitoring system is not in the default implementation, how can I implement a custom interface so that my resources can also use crane's recommended optimization capabilities? We found that the crane algorithm is not very effective for our business type, but we have explored some effective algorithms before, how to connect to the crane system? We want to be able to interface directly to the billing system after cost optimization, so we can directly quantify how much money is saved. In order to solve the above problems, we hope the whole recommendation process is more open and flexible. Therefore, we propose the crane recommendation framework, which will be divided into two types. The first is to implement recommendation flow logic in crane core code, and the second is out-of-tree, you need to implement extension point through http request or gRPC call. This documentation will focus on the first implementation type.","title":"Motivation"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#goals","text":"Define the architecture of Recommendation Framework. Define the interfaces of Recomendation Framework Internal modules.","title":"Goals"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#non-goals","text":"Define the interfaces of Recommendation Framework Extender. Provide specific implementation examples for each module of framework.","title":"Non-Goals"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#proposal","text":"","title":"Proposal"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#architecture","text":"","title":"Architecture"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#phases","text":"We divide the whole recommendation process into four actions, Fliter, Prepare, Recommend, Observe. The input of the whole system is the kubernetes resource you want to analyze, and the output is the best recommendation for the resource.Below we describe in detail the capabilities and input and output of each part of Recommendation Framework.","title":"Phases"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#fliter","text":"The input of Fliter is an analysis recommendation task queue, and the queue stores the Recommendation CR submitted by the user.In default PreFliter,we will do nothing for the queue, this queue will be a FIFO queue.If you want to follow certain rules for the queue, you can implement it yourself PreFliter via extension point or override this func.In the default fliter stage, we will first filter the non-recommended resources according to the user-defined analyzable resource type. For example, the analyzable kubernetes resource I defined is deployment,ingress,node. If you submit a recommendation cr for statefulset, it will be abort in this phase.Then, we will check whether the resource you want exists, if not, we will abort.If you wish to use different filtering logic, you can implement your own logic through the fliter extension point or override it.","title":"Fliter"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#prepare","text":"Prepare is the data preparation stage, and will pull the indicator sequence within the specified time according to your recommended tasks.In PrePrepare,by default we will check the connectivity of the metrics system. And we need generate the specified metrics information for metrics server system like prometheus or metrics server. In Prepare,we will get the indicator sequence information.In PostPrepare, we will implement a data processing module.Some data processing such as data correction for cold start application resource glitch, missing data padding, data aggregation,deduplication or noise reduction. The output of whole will be normalized to a specified data type.Of course you can also implement your own PrePrepare, Prepare, PostPrepare logic.","title":"Prepare"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#recommend","text":"The input of Recommend is a data sequence, and the output is the result of the recommendation type you specify. For example, if your recommendation type is resource, the output is the recommended size of the resource of the kubernetes workload you specified.In Recommend, we will apply crane's algorithm library to your data sequence.And in PostRecommend,We will use some strategies to regularize the results of the algorithm. For example, if a margin needs to be added when recommending resources, it will be processed at this stage.You can implement your own Recommend logic via extension points or override it.","title":"Recommend"},{"location":"zh_TW/proposals/20220712-recommendation-framework-internal/#observe","text":"Observe is to intuitively reflect the effectiveness of the recommendation results. For example, when making resource recommendations, users not only care about the recommended resource configuration, but also how much cost can be saved after modifying the resource configuration. In PreObserver, we will check the cloud api connectivity and establish link with cloud vendor's billing system. And in Observe we will turn resource optimization into cost optimization.You can implement your own Observe logic via extension points or override it.","title":"Observe"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/","text":"Pod Sorting And Precise Execution For Crane Agent \u00b6 The proposal enriches the sorting strategy of the crane agent and perfects the general sorting. In addition, a framework of precise operation (throttle/eviction) is implemented. When performing throttle, eviction and other operations, the precise operation logic of operating to the water level specified by the user, i.e. stopping, avoids excessive operation of low optimal pod; Specifically: Enriches the sorting strategy of crane agent, and perfects the general sorting and CPU dimension sorting with CPU usage as the main reference; For CPU usage, the precise operation logic that stops when operating to the water level specified by the user when throttle/eviction is implemented, which avoids the excessive operation of low optimal pod; A framework of precise operation (throttle/eviction) is implemented. By improving some column attributes and implementation of user-defined indicators, it can also have the same precise operation ability as CPU usage without caring about specific details, and has certain universality and scalability. Table of Contents \u00b6 Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal Enrich the sorting strategy of pod Definition of metric attribute How to control accurately according to the water level Precise operation of pod based on water level Analyzer phase Executor phase Non-Goals/Future Work User Stories Motivation \u00b6 Currently, in the crane agent, when the water level specified in the NodeQosEnsurancePolicy is exceeded, perform throttle, eviction and other operations to sort the low priority pods first. The current sorting is based on the prority class of the pod, and then perform throttle or eviction on the sorted pods; The existing problems are: sorting only refers to prority class, which cannot meet the sorting based on other features; At the same time, it can not meet the requirements of flexible sequencing according to the precise operation of the water level line, and can not meet the requirements of making the nodes reach the specified water level as soon as possible. For example, when we want to reduce the CPU usage of low priority services as soon as possible, we should select the pod with more CPU usage, which can reduce the CPU usage faster and ensure that high-quality services are not affected. after triggering the watermark specified in NodeQosEnsurancePolicy, all pods on the node that are lower than the specified prolityclass will be operated; For example, there are 10 pods on the current node that are lower than the specified prority class. After the water level is triggered, operations will be performed on all 10 pods. However, in fact, after the operation on the first pod is completed, it may be lower than the index value in NodeQosEnsurancePolicy. The operation on the remaining pods is excessive and can be avoided. If the index value in NodeQosEnsurancePolicy can be used as the watermark to accurately operate the pod, it is more appropriate to operate it just below the watermark, so as to avoid excessive impact on low priority services. Goals \u00b6 Enriches the sorting strategy of crane agent, including the sorting with pod CPU consumption as the main reference, the sorting with pod memory consumption as the main reference, the sorting based on runtime, and the sorting based on extended resource utilization. Implement a framework including sorting and a precise operation, support to enrich sorting rules for different indicators, and realize precise operation. To achieve a precise operation for CPU usage and memory usage, when the machine load exceeds the water level specified in NodeQosEnsurancePolicy, the low priority pods will be sorted first, and then the operation will be carried out in order until it is just below the water level. Proposal \u00b6 Enrich the sorting strategy of pod \u00b6 The proposal implements some general sorting methods (which will be improved later): classAndPriority\uff1a Compare the Qos class and class value of two pods. Compare Qos class first and then class value; Those with high priority are ranked later and have higher priority runningTime\uff1aCompare the running time of two pods. The one with a long running time is ranked later and has a higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the usage of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } Sorting of CPU usage The priority of two pods will be compared in turn. If the priority is the same, then compare the CPU usage. If the CPU usage is also the same, continue to compare the EXT CPU resource usage (this is a special point of the CPU attribute). Finally, compare the running time of the pod. When there is a difference in a certain index, the comparison result can be returned ``` go func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ) . Sort ( pods ) } ``` Sorting of ext CPU usage First, it will compare whether the extended CPU resources are used by two pods. If both are used, it will compare the ratio of the extended CPU resource usage / the extended CPU resource limit For the indicators that need to be customized, the following methods can be implemented, and the flexible and customized sorting of pods can be easily realized by freely matching the general sorting methods. The represents the customized metric indicators, and the represents the customized sorting strategy for func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } The only needs to implement the following sorting methods func ( p1 , p2 podinfo . PodContext ) int32 Definition of metric attribute \u00b6 In order to better sort and precisely control metrics configured based on NodeQosEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metrics include the following: Name indicates the name of the metric, which should be consistent with the indicator name collected in the collector module ActionPriority indicates the priority of the indicator. 0 is the lowest and 10 is the highest SortAble indicates whether the indicator can be sorted Sorting methods corresponding to SortFunc. Sorting methods can be arranged and combined with some general methods, and then combined with the sorting of indicators, which will be introduced in detail below ThrottleAble indicates whether pod can be suppressed for this indicator. For example, for the metric of CPU usage, there are corresponding suppression methods. However, for the indicator of memory usage, the pod can only be expelled, and effective suppression cannot be carried out ThrottleQuantified indicates whether the corresponding metric resources released after the suppression can be accurately calculated after a pod is restored. We call the indicators that can be accurately quantified quantifiable, otherwise, they are not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; For example, memory usage does not belong to the suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc, the specific method to execute the throttle action. If throttling is not available, the returned released is null RestoreFunc: after being throttled, the specific method to execute the recovery action. If throttling is not allowed, the returned released is null Relevant definitions of evicting actions by evictable, evictquantified, and evictfunc are similar to those of throttle actions type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } You can define your own metric. After the construction is completed, you can register it through registermetricmap() How to control accurately according to the water level \u00b6 Build multiple waterlines according to multiple nodeqosensurancepolicies and objectiveinsurances: Classified according to the actions corresponding to objectiveinsurances, the crane agent currently has three operations to guarantee node QoS, namely, evict, thtottledown (to suppress pod usage when the current usage is higher than the value in objectiveinsurances) and throttleup (to relax and recover pod usage when the current usage is lower than the value in objectiveinsurances). Therefore, there will be three waterline sets, namely, throttledownwaterline, Throttleupwaterline and evictwaterline Then classify the waterlines in the same operation category according to their metric rules (metric A and metric Z are used as schematic in the figure), and record the value of each objectiveinsurances water level line, which is recorded as waterline; The structures of throttledownwaterline, throttleupwaterline and evictwaterline are as follows: type WaterLines map[WaterLineMetric]*WaterLine Where waterlinemetric is the name field of the above metric, and waterline of value is the resource value type WaterLine resource.Quantity Finally, a data store similar to the following figure is formed: Construct the difference between real-time consumption and waterline: The following data structure is constructed by combining the difference between the real-time consumption of the indicator at the current node and the minimum value in the waterline corresponding to the indicator in waterlines, representing the difference between the current consumption and the waterline type GapToWaterLines map[WaterLineMetric]float64 Where the key value is the name field of metric, and the value is the difference between the consumption and the waterline; It should be noted that for throttleup, the minimum waterline - current usage is used as the gap value. For the other two, the minimum waterline - current usage is used as the gap value, that is, the gap value is always kept positive The following three data represent the indicators that need to perform evict, thatttledown and throttleup operations and their corresponding differences to the lowest waterline EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] Taking the metric CpuUsage as an example, the process and data structure of constructing the waterline related to node CPU usage are as follows: Precise operation of pod based on water level \u00b6 In order to realize the precise operation of pod based on the water level, the proposal will modify the analyzer and executor. The general process is as follows: In the analyzer phase, construct waterlines for different operations (eviction, throttle, etc.) and different metrics, delete the original sorting logic, and move it to the executor phase where formal operations are required, and multiple rounds of sorting may be required; In the executor stage, the corresponding sorting is carried out according to the indicators involved in the waterline, the latest consumption is obtained, gaptowaterlines is constructed, and precise operations are carried out Analyzer phase \u00b6 At this stage, the NodeQosEnsurancePolicy is converted to waterlines, and the rules of the same actionname and metricreule are merged. The details have been described above Executor phase \u00b6 Throttle: Firstly, analyze the metrics involved in the ThrottoleDownGapToWaterLines, and divide these metrics into two parts according to their quantized attribute. If there is a metric that cannot be quantized, get the metric of a throttleable (with a throttlefunc) with the highest action priority through gethighstprioritythottleablemetric to suppress all the selected pods, because if there is a metric that cannot be quantized, It is impossible to carry out a precise operation Get the latest usage of the current node and workload through getstatefunc(), Construct the gaptowaterline according to the ThrottoleDownGapToWaterLines and real-time usage (note that when constructing the gaptowaterline, it will traverse with the registered metric, so the finally constructed metric in the gaptowaterline will be the metric registered in the ThrottoleDownGapToWaterLines, avoiding the situation that the configuration error does not exist or the metric is not registered in the nodeqosensancepolicy) If there is a metric in the gaptowaterline whose real-time usage cannot be obtained (hasusagemissedmetric), obtain the metric of a throttleable (with throttlefunc) with the highest action priority through GetHighestPriorityThrottleAbleMetric to suppress all the selected pods, because if there is a metric whose real-time usage cannot be obtained, the gap with the waterline cannot be known, and precise operations cannot be performed If the situation in 3 does not exist, traverse the quantifiable metrics in the ThrottoleDownGapToWaterLines: if the metric has a sorting method, it directly uses its sortfunc to sort the pods. If not, it uses generalsorter to sort the pods, and then uses its corresponding throttlefunc to suppress the pods, and calculate the released resources of the corresponding metric, Until the gap corresponding to this metric in ThrottoleDownGapToWaterLines no longer exists metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } Eviction\uff1a The process of eviction and throttle is the same, except that it is necessary to judge whether the pod has been expelled when operating the pod; Take out a pod that has not been executed, execute the eviction operation, calculate the released metric resources, and subtract the released value from the corresponding water level until the current metric waterline requirements are met metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } } Non-Goals/Future Work \u00b6 Currently, only the precise operation of CPU usage is supported, but the framework can be reused. In the future, the framework based on precise control can achieve precise control of more dimensional indicators. In the process of precise control, only the release of metric is considered at present, and the interaction between different metrics is not considered. For example, when pressing CPU usage, memory usage will also be affected. If there are many indicators, the relationship between different indicators will be very complex, so the direct interaction of different metrics will not be considered for the time being. User Stories \u00b6 Users can use crane agent for better QoS guarantees. Support faster node load reduction to ensure that high priority services are not affected. At the same time, the throttle/eviction of low priority services is precisely controlled to avoid excessive operation. With the help of the framework of precise operation (throttle/eviction), users can easily realize the QoS function with precise operation and sorting capability based on the user-defined metric without paying attention to details by implementing the attributes and methods related to the user-defined metric.","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#pod-sorting-and-precise-execution-for-crane-agent","text":"The proposal enriches the sorting strategy of the crane agent and perfects the general sorting. In addition, a framework of precise operation (throttle/eviction) is implemented. When performing throttle, eviction and other operations, the precise operation logic of operating to the water level specified by the user, i.e. stopping, avoids excessive operation of low optimal pod; Specifically: Enriches the sorting strategy of crane agent, and perfects the general sorting and CPU dimension sorting with CPU usage as the main reference; For CPU usage, the precise operation logic that stops when operating to the water level specified by the user when throttle/eviction is implemented, which avoids the excessive operation of low optimal pod; A framework of precise operation (throttle/eviction) is implemented. By improving some column attributes and implementation of user-defined indicators, it can also have the same precise operation ability as CPU usage without caring about specific details, and has certain universality and scalability.","title":"Pod Sorting And Precise Execution For Crane Agent"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#table-of-contents","text":"Pod Sorting And Precise Execution For Crane Agent Table of Contents Motivation Goals Proposal Enrich the sorting strategy of pod Definition of metric attribute How to control accurately according to the water level Precise operation of pod based on water level Analyzer phase Executor phase Non-Goals/Future Work User Stories","title":"Table of Contents"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#motivation","text":"Currently, in the crane agent, when the water level specified in the NodeQosEnsurancePolicy is exceeded, perform throttle, eviction and other operations to sort the low priority pods first. The current sorting is based on the prority class of the pod, and then perform throttle or eviction on the sorted pods; The existing problems are: sorting only refers to prority class, which cannot meet the sorting based on other features; At the same time, it can not meet the requirements of flexible sequencing according to the precise operation of the water level line, and can not meet the requirements of making the nodes reach the specified water level as soon as possible. For example, when we want to reduce the CPU usage of low priority services as soon as possible, we should select the pod with more CPU usage, which can reduce the CPU usage faster and ensure that high-quality services are not affected. after triggering the watermark specified in NodeQosEnsurancePolicy, all pods on the node that are lower than the specified prolityclass will be operated; For example, there are 10 pods on the current node that are lower than the specified prority class. After the water level is triggered, operations will be performed on all 10 pods. However, in fact, after the operation on the first pod is completed, it may be lower than the index value in NodeQosEnsurancePolicy. The operation on the remaining pods is excessive and can be avoided. If the index value in NodeQosEnsurancePolicy can be used as the watermark to accurately operate the pod, it is more appropriate to operate it just below the watermark, so as to avoid excessive impact on low priority services.","title":"Motivation"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#goals","text":"Enriches the sorting strategy of crane agent, including the sorting with pod CPU consumption as the main reference, the sorting with pod memory consumption as the main reference, the sorting based on runtime, and the sorting based on extended resource utilization. Implement a framework including sorting and a precise operation, support to enrich sorting rules for different indicators, and realize precise operation. To achieve a precise operation for CPU usage and memory usage, when the machine load exceeds the water level specified in NodeQosEnsurancePolicy, the low priority pods will be sorted first, and then the operation will be carried out in order until it is just below the water level.","title":"Goals"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#proposal","text":"","title":"Proposal"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#enrich-the-sorting-strategy-of-pod","text":"The proposal implements some general sorting methods (which will be improved later): classAndPriority\uff1a Compare the Qos class and class value of two pods. Compare Qos class first and then class value; Those with high priority are ranked later and have higher priority runningTime\uff1aCompare the running time of two pods. The one with a long running time is ranked later and has a higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the usage of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod func GeneralSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , runningTime ). Sort ( pods ) } Sorting of CPU usage The priority of two pods will be compared in turn. If the priority is the same, then compare the CPU usage. If the CPU usage is also the same, continue to compare the EXT CPU resource usage (this is a special point of the CPU attribute). Finally, compare the running time of the pod. When there is a difference in a certain index, the comparison result can be returned ``` go func CpuUsageSorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , cpuUsage , extCpuUsage , runningTime ) . Sort ( pods ) } ``` Sorting of ext CPU usage First, it will compare whether the extended CPU resources are used by two pods. If both are used, it will compare the ratio of the extended CPU resource usage / the extended CPU resource limit For the indicators that need to be customized, the following methods can be implemented, and the flexible and customized sorting of pods can be easily realized by freely matching the general sorting methods. The represents the customized metric indicators, and the represents the customized sorting strategy for func < metric > Sorter ( pods [] podinfo . PodContext ) { orderedBy ( classAndPriority , < metric - sort - func >, runningTime ). Sort ( pods ) } The only needs to implement the following sorting methods func ( p1 , p2 podinfo . PodContext ) int32","title":"Enrich the sorting strategy of pod"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#definition-of-metric-attribute","text":"In order to better sort and precisely control metrics configured based on NodeQosEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metrics include the following: Name indicates the name of the metric, which should be consistent with the indicator name collected in the collector module ActionPriority indicates the priority of the indicator. 0 is the lowest and 10 is the highest SortAble indicates whether the indicator can be sorted Sorting methods corresponding to SortFunc. Sorting methods can be arranged and combined with some general methods, and then combined with the sorting of indicators, which will be introduced in detail below ThrottleAble indicates whether pod can be suppressed for this indicator. For example, for the metric of CPU usage, there are corresponding suppression methods. However, for the indicator of memory usage, the pod can only be expelled, and effective suppression cannot be carried out ThrottleQuantified indicates whether the corresponding metric resources released after the suppression can be accurately calculated after a pod is restored. We call the indicators that can be accurately quantified quantifiable, otherwise, they are not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; For example, memory usage does not belong to the suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc, the specific method to execute the throttle action. If throttling is not available, the returned released is null RestoreFunc: after being throttled, the specific method to execute the recovery action. If throttling is not allowed, the returned released is null Relevant definitions of evicting actions by evictable, evictquantified, and evictfunc are similar to those of throttle actions type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } You can define your own metric. After the construction is completed, you can register it through registermetricmap()","title":"Definition of metric attribute"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#how-to-control-accurately-according-to-the-water-level","text":"Build multiple waterlines according to multiple nodeqosensurancepolicies and objectiveinsurances: Classified according to the actions corresponding to objectiveinsurances, the crane agent currently has three operations to guarantee node QoS, namely, evict, thtottledown (to suppress pod usage when the current usage is higher than the value in objectiveinsurances) and throttleup (to relax and recover pod usage when the current usage is lower than the value in objectiveinsurances). Therefore, there will be three waterline sets, namely, throttledownwaterline, Throttleupwaterline and evictwaterline Then classify the waterlines in the same operation category according to their metric rules (metric A and metric Z are used as schematic in the figure), and record the value of each objectiveinsurances water level line, which is recorded as waterline; The structures of throttledownwaterline, throttleupwaterline and evictwaterline are as follows: type WaterLines map[WaterLineMetric]*WaterLine Where waterlinemetric is the name field of the above metric, and waterline of value is the resource value type WaterLine resource.Quantity Finally, a data store similar to the following figure is formed: Construct the difference between real-time consumption and waterline: The following data structure is constructed by combining the difference between the real-time consumption of the indicator at the current node and the minimum value in the waterline corresponding to the indicator in waterlines, representing the difference between the current consumption and the waterline type GapToWaterLines map[WaterLineMetric]float64 Where the key value is the name field of metric, and the value is the difference between the consumption and the waterline; It should be noted that for throttleup, the minimum waterline - current usage is used as the gap value. For the other two, the minimum waterline - current usage is used as the gap value, that is, the gap value is always kept positive The following three data represent the indicators that need to perform evict, thatttledown and throttleup operations and their corresponding differences to the lowest waterline EvictGapToWaterLines [ metrics ] ThrottoleDownGapToWaterLines [ metrics ] ThrottleUpGapWaterLine [ metrics ] Taking the metric CpuUsage as an example, the process and data structure of constructing the waterline related to node CPU usage are as follows:","title":"How to control accurately according to the water level"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#precise-operation-of-pod-based-on-water-level","text":"In order to realize the precise operation of pod based on the water level, the proposal will modify the analyzer and executor. The general process is as follows: In the analyzer phase, construct waterlines for different operations (eviction, throttle, etc.) and different metrics, delete the original sorting logic, and move it to the executor phase where formal operations are required, and multiple rounds of sorting may be required; In the executor stage, the corresponding sorting is carried out according to the indicators involved in the waterline, the latest consumption is obtained, gaptowaterlines is constructed, and precise operations are carried out","title":"Precise operation of pod based on water level"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#analyzer-phase","text":"At this stage, the NodeQosEnsurancePolicy is converted to waterlines, and the rules of the same actionname and metricreule are merged. The details have been described above","title":"Analyzer phase"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#executor-phase","text":"Throttle: Firstly, analyze the metrics involved in the ThrottoleDownGapToWaterLines, and divide these metrics into two parts according to their quantized attribute. If there is a metric that cannot be quantized, get the metric of a throttleable (with a throttlefunc) with the highest action priority through gethighstprioritythottleablemetric to suppress all the selected pods, because if there is a metric that cannot be quantized, It is impossible to carry out a precise operation Get the latest usage of the current node and workload through getstatefunc(), Construct the gaptowaterline according to the ThrottoleDownGapToWaterLines and real-time usage (note that when constructing the gaptowaterline, it will traverse with the registered metric, so the finally constructed metric in the gaptowaterline will be the metric registered in the ThrottoleDownGapToWaterLines, avoiding the situation that the configuration error does not exist or the metric is not registered in the nodeqosensancepolicy) If there is a metric in the gaptowaterline whose real-time usage cannot be obtained (hasusagemissedmetric), obtain the metric of a throttleable (with throttlefunc) with the highest action priority through GetHighestPriorityThrottleAbleMetric to suppress all the selected pods, because if there is a metric whose real-time usage cannot be obtained, the gap with the waterline cannot be known, and precise operations cannot be performed If the situation in 3 does not exist, traverse the quantifiable metrics in the ThrottoleDownGapToWaterLines: if the metric has a sorting method, it directly uses its sortfunc to sort the pods. If not, it uses generalsorter to sort the pods, and then uses its corresponding throttlefunc to suppress the pods, and calculate the released resources of the corresponding metric, Until the gap corresponding to this metric in ThrottoleDownGapToWaterLines no longer exists metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () if highestPrioriyMetric != \"\" { throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { var released ReleaseResource for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } Eviction\uff1a The process of eviction and throttle is the same, except that it is necessary to judge whether the pod has been expelled when operating the pod; Take out a pod that has not been executed, execute the eviction operation, calculate the released metric resources, and subtract the released value from the corresponding water level until the current metric waterline requirements are met metricsEvictQuantified , MetricsNotEvcitQuantified := EvictWaterLine . DivideMetricsByEvictQuantified () if len ( MetricsNotEvcitQuantified ) != 0 { highestPrioriyMetric := e . EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { EvictGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc (), ThrottleExecutor {}, * e ) if EvictGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := EvictWaterLine . GetHighestPriorityEvictAbleMetric () if highestPrioriyMetric != \"\" { e . evictPods ( ctx , & totalReleased , highestPrioriyMetric ) } } else { wg := sync . WaitGroup {} var released ReleaseResource for _ , m := range metricsEvictQuantified { if MetricMap [ m ]. SortAble { MetricMap [ m ]. SortFunc ( e . EvictPods ) } else { execsort . GeneralSorter ( e . EvictPods ) } for ! EvictGapToWaterLines . TargetGapsRemoved ( m ) { if podinfo . HasNoExecutedPod ( e . EvictPods ) { index := podinfo . GetFirstNoExecutedPod ( e . EvictPods ) released = MetricMap [ m ]. EvictFunc ( & wg , ctx , index , & totalReleased , e . EvictPods ) e . EvictPods [ index ]. HasBeenActioned = true ctx . EvictGapToWaterLines [ m ] -= released [ m ] } } } wg . Wait () } }","title":"Executor phase"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#non-goalsfuture-work","text":"Currently, only the precise operation of CPU usage is supported, but the framework can be reused. In the future, the framework based on precise control can achieve precise control of more dimensional indicators. In the process of precise control, only the release of metric is considered at present, and the interaction between different metrics is not considered. For example, when pressing CPU usage, memory usage will also be affected. If there are many indicators, the relationship between different indicators will be very complex, so the direct interaction of different metrics will not be considered for the time being.","title":"Non-Goals/Future Work"},{"location":"zh_TW/proposals/Pod-Sorting-And-Precise-Execution-For-Crane-Agent/#user-stories","text":"Users can use crane agent for better QoS guarantees. Support faster node load reduction to ensure that high priority services are not affected. At the same time, the throttle/eviction of low priority services is precisely controlled to avoid excessive operation. With the help of the framework of precise operation (throttle/eviction), users can easily realize the QoS function with precise operation and sorting capability based on the user-defined metric without paying attention to details by implementing the attributes and methods related to the user-defined metric.","title":"User Stories"},{"location":"zh_TW/roadmaps/roadmap-2022/","text":"Crane Roadmap for 2022 \u00b6 Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan. 0.1.0 [released] \u00b6 Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing 0.2.0\uff1a[released] \u00b6 Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio 0.3.0 [released] \u00b6 UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA 0.4.0 [released] \u00b6 UI to support EPA. 0.5.0 [released] \u00b6 Resource and Replicas Recommendation Load-aware Scheduler 0.6.0 [released] \u00b6 Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics 0.7.0 [July] \u00b6 Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator 0.8.0 [August] \u00b6 External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization 0.9.0 [September] \u00b6 Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard 0.10.0 [October] \u00b6 Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison 0.11.0 [November] \u00b6 Multi-cluster cost dashboard 0.12.0 [December] \u00b6 Multi-cluster cost optimization","title":2022},{"location":"zh_TW/roadmaps/roadmap-2022/#crane-roadmap-for-2022","text":"Please refer the following sections for Crane release plan of H1 2022, new release will be cut on monthly basis. Please let us know if you have urgent needs which are not presented in the plan.","title":"Crane Roadmap for 2022"},{"location":"zh_TW/roadmaps/roadmap-2022/#010-released","text":"Predictor to support Moving Windows and DSP algorithms Resource Request Recommendation and Effective Horizontal Pod Autoscaler Grafana Dashboard to view resource utilization and cost trends fadvisor to support billing","title":"0.1.0 [released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#020released","text":"Multiple Metric Adaptor support Node QoS Ensurance for CPU Operation Metrics about R3 and EPA applied ratio","title":"0.2.0\uff1a[released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#030-released","text":"UI with cost visibility and usage optimizations. Request Recommendation adapts with Virtual Kubelet Multiple Triggers for EPA Node QoS Ensurance for Mem Prediction with CPU, Memory, and Business Metrics Scalability to support 1K TSP and 1K EPA","title":"0.3.0 [released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#040-released","text":"UI to support EPA.","title":"0.4.0 [released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#050-released","text":"Resource and Replicas Recommendation Load-aware Scheduler","title":"0.5.0 [released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#060-released","text":"Scalability to support 3k TSP and 3k EPA Algorithm and QoS Documentation EHPA grafana dashboard DSP Algorithm Optimization Support remote adapter for external metric Prediction with business metrics","title":"0.6.0 [released]"},{"location":"zh_TW/roadmaps/roadmap-2022/#070-july","text":"Recommendation Framework Crane-Descheduler based on CPU/Memory metrics Offline Algorithm Evaluator","title":"0.7.0 [July]"},{"location":"zh_TW/roadmaps/roadmap-2022/#080-august","text":"External recommendation plugins Built-in CICD Pipeline integration CPU topology aware scheduler Enhanced Console with resource optimization","title":"0.8.0 [August]"},{"location":"zh_TW/roadmaps/roadmap-2022/#090-september","text":"Flexible conflict prediction and detection Builtin AI Prediction Wastes discovery and dashboard Enhanced Console with more cost visibility dashboard","title":"0.9.0 [September]"},{"location":"zh_TW/roadmaps/roadmap-2022/#0100-october","text":"Business Maturity Model Dashboard In-place Update support by EVPA Kubernetes and Elastic Kubernetes Service price comparison","title":"0.10.0 [October]"},{"location":"zh_TW/roadmaps/roadmap-2022/#0110-november","text":"Multi-cluster cost dashboard","title":"0.11.0 [November]"},{"location":"zh_TW/roadmaps/roadmap-2022/#0120-december","text":"Multi-cluster cost optimization","title":"0.12.0 [December]"},{"location":"zh_TW/tutorials/analytics-and-recommendation/","text":"\u667a\u80fd\u63a8\u85a6 \u00b6 \u667a\u80fd\u63a8\u85a6\u80fd\u5920\u5e6b\u52a9\u7528\u6236\u81ea\u52d5\u5206\u6790\u96c6\u7fa4\u4e26\u7d66\u51fa\u512a\u5316\u5efa\u8b70\u3002\u5c31\u50cf\u624b\u6a5f\u52a9\u624b\u4e00\u6a23\uff0c\u667a\u80fd\u63a8\u85a6\u6703\u5b9a\u671f\u7684\u6383\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u4e26\u7d66\u51fa\u63a8\u85a6\u5efa\u8b70\u3002\u76ee\u524d\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u5169\u7a2e\u512a\u5316\u80fd\u529b\uff1a \u8cc7\u6e90\u63a8\u85a6 : \u901a\u904e\u8cc7\u6e90\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u8cc7\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6578\u63a8\u85a6 : \u901a\u904e\u526f\u672c\u6578\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u61c9\u7528\u53ef\u4ee5\u6839\u64da\u8cc7\u6e90\u63a8\u85a6\u8abf\u6574 request \u4e5f\u53ef\u4ee5\u6839\u64da\u526f\u672c\u6578\u63a8\u85a6\u8abf\u6574\u526f\u672c\u6578\uff0c\u9019\u5169\u7a2e\u512a\u5316\u90fd\u80fd\u5e6b\u52a9\u60a8\u964d\u4f4e\u6210\u672c\uff0c\u60a8\u53ef\u4ee5\u6839\u64da\u60a8\u7684\u9700\u6c42\u9078\u64c7\u63a1\u7528\u76f8\u61c9\u7684\u512a\u5316\u5efa\u8b70\u3002 \u67b6\u69cb \u00b6 \u4e00\u6b21\u5206\u6790\u7684\u904e\u7a0b \u00b6 \u7528\u6236\u5275\u5efa Analytics \u5c0d\u8c61\uff0c\u901a\u904e ResourceSelector \u9078\u64c7\u9700\u8981\u5206\u6790\u7684\u8cc7\u6e90\uff0c\u652f\u6301\u9078\u64c7\u591a\u985e\u578b\uff08\u57fa\u65bcGroup,Kind,Version\uff09\u7684\u6279\u91cf\u9078\u64c7 \u4e26\u884c\u5206\u6790\u6bcf\u500b\u9078\u64c7\u7684\u8cc7\u6e90\uff0c\u5617\u8a66\u9032\u884c\u5206\u6790\u63a8\u85a6\uff0c\u6bcf\u6b21\u5206\u6790\u904e\u7a0b\u5206\u6210\u7be9\u9009\u548c\u63a8\u85a6\u5169\u500b\u968e\u6bb5\uff1a \u7be9\u9078\uff1a\u6392\u9664\u4e0d\u6eff\u8db3\u63a8\u85a6\u689d\u4ef6\u7684\u8cc7\u6e90\u3002\u6bd4\u5982\u5c0d\u65bc\u5f48\u6027\u63a8\u85a6\uff0c\u6392\u9664\u6c92\u6709 running pod \u7684 workload \u63a8\u85a6\uff1a\u901a\u904e\u7b97\u6cd5\u8a08\u7b97\u5206\u6790\uff0c\u7d66\u51fa\u63a8\u85a6\u7d50\u679c \u5982\u679c\u901a\u904e\u7be9\u9078\uff0c\u5275\u5efa Recommendation \u5c0d\u8c61\uff0c\u5c07\u63a8\u85a6\u7d50\u679c\u5c55\u793a\u5728 Recommendation.Status \u672a\u901a\u904e\u7be9\u9078\u7684\u539f\u56e0\u548c\u72c0\u614b\u5c55\u793a\u5728 Analytics.Status \u6839\u64da\u904b\u884c\u9593\u9694\u7b49\u5f85\u4e0b\u6b21\u5206\u6790 \u540d\u8a5e\u89e3\u91cb \u00b6 \u5206\u6790 \u00b6 \u5206\u6790\u5b9a\u7fa9\u4e86\u4e00\u500b\u6383\u63cf\u5206\u6790\u4efb\u52d9\u3002\u652f\u6301\u5169\u7a2e\u4efb\u52d9\u985e\u578b\uff1a\u8cc7\u6e90\u63a8\u85a6\u548c\u5f48\u6027\u63a8\u85a6\u3002 Crane \u5b9a\u671f\u904b\u884c\u5206\u6790\u4efb\u52d9\uff0c\u4e26\u7522\u751f\u63a8\u85a6\u7d50\u679c\u3002 \u63a8\u85a6 \u00b6 \u63a8\u85a6\u5c55\u793a\u4e86\u4e00\u500b\u512a\u5316\u63a8\u85a6\u7684\u7d50\u679c\u3002\u63a8\u85a6\u7684\u7d50\u679c\u662f\u4e00\u6bb5 YAML \u914d\u7f6e\uff0c\u6839\u64da\u7d50\u679c\u7528\u6236\u53ef\u4ee5\u9032\u884c\u76f8\u61c9\u7684\u512a\u5316\u52d5\u4f5c\uff0c\u6bd4\u5982\u8abf\u6574\u61c9\u7528\u7684\u8cc7\u6e90\u914d\u7f6e\u3002 \u53c3\u6578\u914d\u7f6e \u00b6 \u4e0d\u540c\u7684\u5206\u6790\u63a1\u7528\u4e0d\u540c\u7684\u8a08\u7b97\u6a21\u578b\uff0cCrane \u63d0\u4f9b\u4e86\u4e00\u5957\u9ed8\u8a8d\u7684\u8a08\u7b97\u6a21\u578b\u4ee5\u53ca\u4e00\u5957\u914d\u5957\u7684\u914d\u7f6e\uff0c\u7528\u6236\u53ef\u4ee5\u901a\u904e\u4fee\u6539\u914d\u7f6e\u4f86\u5b9a\u5236\u63a8\u85a6\u7684\u6548\u679c\u3002\u652f\u6301\u4fee\u6539\u5168\u5c40\u7684\u9ed8\u8a8d\u914d\u7f6e\u548c\u4fee\u6539\u55ae\u500b\u5206\u6790\u4efb\u52d9\u7684\u914d\u7f6e\u3002","title":"\u63a8\u85a6"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_1","text":"\u667a\u80fd\u63a8\u85a6\u80fd\u5920\u5e6b\u52a9\u7528\u6236\u81ea\u52d5\u5206\u6790\u96c6\u7fa4\u4e26\u7d66\u51fa\u512a\u5316\u5efa\u8b70\u3002\u5c31\u50cf\u624b\u6a5f\u52a9\u624b\u4e00\u6a23\uff0c\u667a\u80fd\u63a8\u85a6\u6703\u5b9a\u671f\u7684\u6383\u63cf\u3001\u5206\u6790\u4f60\u7684\u96c6\u7fa4\u4e26\u7d66\u51fa\u63a8\u85a6\u5efa\u8b70\u3002\u76ee\u524d\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u5169\u7a2e\u512a\u5316\u80fd\u529b\uff1a \u8cc7\u6e90\u63a8\u85a6 : \u901a\u904e\u8cc7\u6e90\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u8cc7\u6e90\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u526f\u672c\u6578\u63a8\u85a6 : \u901a\u904e\u526f\u672c\u6578\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u526f\u672c\u548c EHPA \u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u61c9\u7528\u53ef\u4ee5\u6839\u64da\u8cc7\u6e90\u63a8\u85a6\u8abf\u6574 request \u4e5f\u53ef\u4ee5\u6839\u64da\u526f\u672c\u6578\u63a8\u85a6\u8abf\u6574\u526f\u672c\u6578\uff0c\u9019\u5169\u7a2e\u512a\u5316\u90fd\u80fd\u5e6b\u52a9\u60a8\u964d\u4f4e\u6210\u672c\uff0c\u60a8\u53ef\u4ee5\u6839\u64da\u60a8\u7684\u9700\u6c42\u9078\u64c7\u63a1\u7528\u76f8\u61c9\u7684\u512a\u5316\u5efa\u8b70\u3002","title":"\u667a\u80fd\u63a8\u85a6"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_2","text":"","title":"\u67b6\u69cb"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_3","text":"\u7528\u6236\u5275\u5efa Analytics \u5c0d\u8c61\uff0c\u901a\u904e ResourceSelector \u9078\u64c7\u9700\u8981\u5206\u6790\u7684\u8cc7\u6e90\uff0c\u652f\u6301\u9078\u64c7\u591a\u985e\u578b\uff08\u57fa\u65bcGroup,Kind,Version\uff09\u7684\u6279\u91cf\u9078\u64c7 \u4e26\u884c\u5206\u6790\u6bcf\u500b\u9078\u64c7\u7684\u8cc7\u6e90\uff0c\u5617\u8a66\u9032\u884c\u5206\u6790\u63a8\u85a6\uff0c\u6bcf\u6b21\u5206\u6790\u904e\u7a0b\u5206\u6210\u7be9\u9009\u548c\u63a8\u85a6\u5169\u500b\u968e\u6bb5\uff1a \u7be9\u9078\uff1a\u6392\u9664\u4e0d\u6eff\u8db3\u63a8\u85a6\u689d\u4ef6\u7684\u8cc7\u6e90\u3002\u6bd4\u5982\u5c0d\u65bc\u5f48\u6027\u63a8\u85a6\uff0c\u6392\u9664\u6c92\u6709 running pod \u7684 workload \u63a8\u85a6\uff1a\u901a\u904e\u7b97\u6cd5\u8a08\u7b97\u5206\u6790\uff0c\u7d66\u51fa\u63a8\u85a6\u7d50\u679c \u5982\u679c\u901a\u904e\u7be9\u9078\uff0c\u5275\u5efa Recommendation \u5c0d\u8c61\uff0c\u5c07\u63a8\u85a6\u7d50\u679c\u5c55\u793a\u5728 Recommendation.Status \u672a\u901a\u904e\u7be9\u9078\u7684\u539f\u56e0\u548c\u72c0\u614b\u5c55\u793a\u5728 Analytics.Status \u6839\u64da\u904b\u884c\u9593\u9694\u7b49\u5f85\u4e0b\u6b21\u5206\u6790","title":"\u4e00\u6b21\u5206\u6790\u7684\u904e\u7a0b"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_4","text":"","title":"\u540d\u8a5e\u89e3\u91cb"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_5","text":"\u5206\u6790\u5b9a\u7fa9\u4e86\u4e00\u500b\u6383\u63cf\u5206\u6790\u4efb\u52d9\u3002\u652f\u6301\u5169\u7a2e\u4efb\u52d9\u985e\u578b\uff1a\u8cc7\u6e90\u63a8\u85a6\u548c\u5f48\u6027\u63a8\u85a6\u3002 Crane \u5b9a\u671f\u904b\u884c\u5206\u6790\u4efb\u52d9\uff0c\u4e26\u7522\u751f\u63a8\u85a6\u7d50\u679c\u3002","title":"\u5206\u6790"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_6","text":"\u63a8\u85a6\u5c55\u793a\u4e86\u4e00\u500b\u512a\u5316\u63a8\u85a6\u7684\u7d50\u679c\u3002\u63a8\u85a6\u7684\u7d50\u679c\u662f\u4e00\u6bb5 YAML \u914d\u7f6e\uff0c\u6839\u64da\u7d50\u679c\u7528\u6236\u53ef\u4ee5\u9032\u884c\u76f8\u61c9\u7684\u512a\u5316\u52d5\u4f5c\uff0c\u6bd4\u5982\u8abf\u6574\u61c9\u7528\u7684\u8cc7\u6e90\u914d\u7f6e\u3002","title":"\u63a8\u85a6"},{"location":"zh_TW/tutorials/analytics-and-recommendation/#_7","text":"\u4e0d\u540c\u7684\u5206\u6790\u63a1\u7528\u4e0d\u540c\u7684\u8a08\u7b97\u6a21\u578b\uff0cCrane \u63d0\u4f9b\u4e86\u4e00\u5957\u9ed8\u8a8d\u7684\u8a08\u7b97\u6a21\u578b\u4ee5\u53ca\u4e00\u5957\u914d\u5957\u7684\u914d\u7f6e\uff0c\u7528\u6236\u53ef\u4ee5\u901a\u904e\u4fee\u6539\u914d\u7f6e\u4f86\u5b9a\u5236\u63a8\u85a6\u7684\u6548\u679c\u3002\u652f\u6301\u4fee\u6539\u5168\u5c40\u7684\u9ed8\u8a8d\u914d\u7f6e\u548c\u4fee\u6539\u55ae\u500b\u5206\u6790\u4efb\u52d9\u7684\u914d\u7f6e\u3002","title":"\u53c3\u6578\u914d\u7f6e"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/","text":"Dynamic Scheduler\uff1a\u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6\u5668\u63d2\u4ef6 \u00b6 \u4ecb\u7d39 \u00b6 kubernetes \u7684\u539f\u751f\u8abf\u5ea6\u5668\u53ea\u80fd\u901a\u904e\u8cc7\u6e90\u8acb\u6c42\u4f86\u8abf\u5ea6 pod\uff0c\u9019\u5f88\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8ca0\u8f09\u4e0d\u5747\u7684\u554f\u984c\uff1a \u5c0d\u65bc\u67d0\u4e9b\u7bc0\u9ede\uff0c\u5be6\u969b\u8ca0\u8f09\u8207\u8cc7\u6e90\u8acb\u6c42\u76f8\u5dee\u4e0d\u5927\uff0c\u9019\u6703\u5c0e\u81f4\u5f88\u5927\u6982\u7387\u51fa\u73fe\u7a69\u5b9a\u6027\u554f\u984c\u3002 \u5c0d\u65bc\u5176\u4ed6\u7bc0\u9ede\u4f86\u8aaa\uff0c\u5be6\u969b\u8ca0\u8f09\u9060\u5c0f\u65bc\u8cc7\u6e90\u8acb\u6c42\uff0c\u9019\u5c07\u5c0e\u81f4\u8cc7\u6e90\u7684\u5de8\u5927\u6d6a\u8cbb\u3002 \u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u52d5\u614b\u8abf\u5ea6\u5668\u6839\u64da\u5be6\u969b\u7684\u7bc0\u9ede\u5229\u7528\u7387\u69cb\u5efa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u4e26\u904e\u6ffe\u6389\u90a3\u4e9b\u8ca0\u8f09\u9ad8\u7684\u7bc0\u9ede\u4f86\u5e73\u8861\u96c6\u7fa4\u3002 \u8a2d\u8a08\u7d30\u7bc0 \u00b6 \u67b6\u69cb \u00b6 \u5982\u4e0a\u5716\uff0c\u52d5\u614b\u8abf\u5ea6\u5668\u4f9d\u8cf4\u65bc Prometheus \u548c Node-exporter \u6536\u96c6\u548c\u532f\u7e3d\u6307\u6a19\u6578\u64da\uff0c\u5b83\u7531\u5169\u500b\u7d44\u4ef6\u7d44\u6210\uff1a Note Node-annotator \u76ee\u524d\u662f Crane-scheduler-controller \u7684\u4e00\u500b\u6a21\u584a. Node-annotator \u5b9a\u671f\u5f9e Prometheus \u62c9\u53d6\u6578\u64da\uff0c\u4e26\u4ee5\u8a3b\u91cb\u7684\u5f62\u5f0f\u5728\u7bc0\u9ede\u4e0a\u7528\u6642\u9593\u6233\u6a19\u8a18\u5b83\u5011\u3002 Dynamic plugin \u76f4\u63a5\u5f9e\u7bc0\u9ede\u7684\u8a3b\u91cb\u4e2d\u8b80\u53d6\u8ca0\u8f09\u6578\u64da\uff0c\u904e\u6ffe\u4e26\u57fa\u65bc\u7c21\u55ae\u7684\u7b97\u6cd5\u5c0d\u5019\u9078\u7bc0\u9ede\u9032\u884c\u8a55\u5206\u3002 \u8abf\u5ea6\u7b56\u7565 \u00b6 \u52d5\u614b\u8abf\u5ea6\u5668\u63d0\u4f9b\u4e86\u4e00\u500b\u9ed8\u8a8d\u503c \u8abf\u5ea6\u7b56\u7565 \u4e26\u652f\u6301\u7528\u6236\u81ea\u5b9a\u7fa9\u7b56\u7565\u3002\u9ed8\u8a8d\u7b56\u7565\u4f9d\u8cf4\u65bc\u4ee5\u4e0b\u6307\u6a19\uff1a cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d \u5728\u8abf\u5ea6\u7684 Filter \u968e\u6bb5\uff0c\u5982\u679c\u8a72\u7bc0\u9ede\u7684\u5be6\u969b\u4f7f\u7528\u7387\u5927\u65bc\u4e0a\u8ff0\u4efb\u4e00\u6307\u6a19\u7684\u95be\u503c\uff0c\u5247\u8a72\u7bc0\u9ede\u5c07\u88ab\u904e\u6ffe\u3002\u800c\u5728 Score \u968e\u6bb5\uff0c\u6700\u7d42\u5f97\u5206\u662f\u9019\u4e9b\u6307\u6a19\u503c\u7684\u52a0\u6b0a\u548c\u3002 Hot Value \u00b6 \u5728\u751f\u7522\u96c6\u7fa4\u4e2d\uff0c\u53ef\u80fd\u6703\u983b\u7e41\u51fa\u73fe\u8abf\u5ea6\u71b1\u9ede\uff0c\u56e0\u70ba\u5275\u5efa Pod \u5f8c\u7bc0\u9ede\u7684\u8ca0\u8f09\u4e0d\u80fd\u7acb\u5373\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5b9a\u7fa9\u4e86\u4e00\u500b\u984d\u5916\u7684\u6307\u6a19\uff0c\u540d\u70ba Hot Value \uff0c\u8868\u793a\u7bc0\u9ede\u6700\u8fd1\u5e7e\u6b21\u7684\u8abf\u5ea6\u983b\u7387\u3002\u4e26\u4e14\u7bc0\u9ede\u7684\u6700\u7d42\u512a\u5148\u7d1a\u662f\u6700\u7d42\u5f97\u5206\u6e1b\u53bb Hot Value \u3002","title":"\u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#dynamic-scheduler","text":"","title":"Dynamic Scheduler\uff1a\u8ca0\u8f09\u611f\u77e5\u8abf\u5ea6\u5668\u63d2\u4ef6"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#_1","text":"kubernetes \u7684\u539f\u751f\u8abf\u5ea6\u5668\u53ea\u80fd\u901a\u904e\u8cc7\u6e90\u8acb\u6c42\u4f86\u8abf\u5ea6 pod\uff0c\u9019\u5f88\u5bb9\u6613\u9020\u6210\u4e00\u7cfb\u5217\u8ca0\u8f09\u4e0d\u5747\u7684\u554f\u984c\uff1a \u5c0d\u65bc\u67d0\u4e9b\u7bc0\u9ede\uff0c\u5be6\u969b\u8ca0\u8f09\u8207\u8cc7\u6e90\u8acb\u6c42\u76f8\u5dee\u4e0d\u5927\uff0c\u9019\u6703\u5c0e\u81f4\u5f88\u5927\u6982\u7387\u51fa\u73fe\u7a69\u5b9a\u6027\u554f\u984c\u3002 \u5c0d\u65bc\u5176\u4ed6\u7bc0\u9ede\u4f86\u8aaa\uff0c\u5be6\u969b\u8ca0\u8f09\u9060\u5c0f\u65bc\u8cc7\u6e90\u8acb\u6c42\uff0c\u9019\u5c07\u5c0e\u81f4\u8cc7\u6e90\u7684\u5de8\u5927\u6d6a\u8cbb\u3002 \u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u52d5\u614b\u8abf\u5ea6\u5668\u6839\u64da\u5be6\u969b\u7684\u7bc0\u9ede\u5229\u7528\u7387\u69cb\u5efa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u4e26\u904e\u6ffe\u6389\u90a3\u4e9b\u8ca0\u8f09\u9ad8\u7684\u7bc0\u9ede\u4f86\u5e73\u8861\u96c6\u7fa4\u3002","title":"\u4ecb\u7d39"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#_2","text":"","title":"\u8a2d\u8a08\u7d30\u7bc0"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#_3","text":"\u5982\u4e0a\u5716\uff0c\u52d5\u614b\u8abf\u5ea6\u5668\u4f9d\u8cf4\u65bc Prometheus \u548c Node-exporter \u6536\u96c6\u548c\u532f\u7e3d\u6307\u6a19\u6578\u64da\uff0c\u5b83\u7531\u5169\u500b\u7d44\u4ef6\u7d44\u6210\uff1a Note Node-annotator \u76ee\u524d\u662f Crane-scheduler-controller \u7684\u4e00\u500b\u6a21\u584a. Node-annotator \u5b9a\u671f\u5f9e Prometheus \u62c9\u53d6\u6578\u64da\uff0c\u4e26\u4ee5\u8a3b\u91cb\u7684\u5f62\u5f0f\u5728\u7bc0\u9ede\u4e0a\u7528\u6642\u9593\u6233\u6a19\u8a18\u5b83\u5011\u3002 Dynamic plugin \u76f4\u63a5\u5f9e\u7bc0\u9ede\u7684\u8a3b\u91cb\u4e2d\u8b80\u53d6\u8ca0\u8f09\u6578\u64da\uff0c\u904e\u6ffe\u4e26\u57fa\u65bc\u7c21\u55ae\u7684\u7b97\u6cd5\u5c0d\u5019\u9078\u7bc0\u9ede\u9032\u884c\u8a55\u5206\u3002","title":"\u67b6\u69cb"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#_4","text":"\u52d5\u614b\u8abf\u5ea6\u5668\u63d0\u4f9b\u4e86\u4e00\u500b\u9ed8\u8a8d\u503c \u8abf\u5ea6\u7b56\u7565 \u4e26\u652f\u6301\u7528\u6236\u81ea\u5b9a\u7fa9\u7b56\u7565\u3002\u9ed8\u8a8d\u7b56\u7565\u4f9d\u8cf4\u65bc\u4ee5\u4e0b\u6307\u6a19\uff1a cpu_usage_avg_5m cpu_usage_max_avg_1h cpu_usage_max_avg_1d mem_usage_avg_5m mem_usage_max_avg_1h mem_usage_max_avg_1d \u5728\u8abf\u5ea6\u7684 Filter \u968e\u6bb5\uff0c\u5982\u679c\u8a72\u7bc0\u9ede\u7684\u5be6\u969b\u4f7f\u7528\u7387\u5927\u65bc\u4e0a\u8ff0\u4efb\u4e00\u6307\u6a19\u7684\u95be\u503c\uff0c\u5247\u8a72\u7bc0\u9ede\u5c07\u88ab\u904e\u6ffe\u3002\u800c\u5728 Score \u968e\u6bb5\uff0c\u6700\u7d42\u5f97\u5206\u662f\u9019\u4e9b\u6307\u6a19\u503c\u7684\u52a0\u6b0a\u548c\u3002","title":"\u8abf\u5ea6\u7b56\u7565"},{"location":"zh_TW/tutorials/dynamic-scheduler-plugin/#hot-value","text":"\u5728\u751f\u7522\u96c6\u7fa4\u4e2d\uff0c\u53ef\u80fd\u6703\u983b\u7e41\u51fa\u73fe\u8abf\u5ea6\u71b1\u9ede\uff0c\u56e0\u70ba\u5275\u5efa Pod \u5f8c\u7bc0\u9ede\u7684\u8ca0\u8f09\u4e0d\u80fd\u7acb\u5373\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5b9a\u7fa9\u4e86\u4e00\u500b\u984d\u5916\u7684\u6307\u6a19\uff0c\u540d\u70ba Hot Value \uff0c\u8868\u793a\u7bc0\u9ede\u6700\u8fd1\u5e7e\u6b21\u7684\u8abf\u5ea6\u983b\u7387\u3002\u4e26\u4e14\u7bc0\u9ede\u7684\u6700\u7d42\u512a\u5148\u7d1a\u662f\u6700\u7d42\u5f97\u5206\u6e1b\u53bb Hot Value \u3002","title":"Hot Value"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/","text":"Intelligent Autoscaling Practices Based on Effective HPA for Custom Metrics \u00b6 The Kubernetes HPA supports rich elasticity scaling capabilities, with Kubernetes platform developers deploying services to implement custom Metric services and Kubernetes users configuring multiple built-in resource metrics or custom Metric metrics to achieve custom horizontal elasticity. Effective HPA is compatible with the community's Kubernetes HPA capabilities, providing smarter autoscaling policies such as prediction-based autoscaling and Cron-cycle-based autoscaling. Prometheus is a popular open source monitoring system today, through which user-defined metrics configurations are accessible. In this article, we present an example of how to implement intelligent resilience of custom metrics based on Effective HPA. Some configurations are taken from official documentation Environment Requirements \u00b6 Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus Refer to installation documentation to install Crane in the cluster, Prometheus can be used either from the installation documentation or from the deployed Prometheus. Environment build \u00b6 Installing PrometheusAdapter \u00b6 The Crane components Metric-Adapter and PrometheusAdapter are both based on custom-metric-apiserver which implements When installing Crane, the corresponding ApiService will be installed as the Metric-Adapter of Crane, so you need to remove the ApiService before installing PrometheusAdapter to ensure that Helm is installed successfully. # View the current ApiService kubectl get apiservice Since Crane is installed, the result is as follows. NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d Remove the installed ApiService by crane kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io Install PrometheusAdapter via Helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter Then change the ApiService back to Crane's Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml Configure Metric-Adapter to enable RemoteAdapter functionality \u00b6 The installation of PrometheusAdapter did not point the ApiService to PrometheusAdapter, so in order to allow PrometheusAdapter to provide custom Metric as well, the RemoteAdapter function of Crane Metric Adapter is used to forward requests to PrometheusAdapter. Modify the Metric-Adapter configuration to configure PrometheusAdapter's Service as Crane Metric Adapter's RemoteAdapter # View the current ApiService kubectl edit deploy metric-adapter -n crane-system Make the following changes based on the PrometheusAdapter configuration. apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #Add external Adapter configuration - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443 RemoteAdapter Capabilities \u00b6 Kubernetes restricts an ApiService to configure only one backend service, so in order to use the Metric provided by Crane and the Metric provided by PrometheusAdapter within a cluster, Crane supports a RemoteAdapter to solve this problem Crane Metric-Adapter supports the configuration of a Kubernetes Service as a Remote Adapter The Crane Metric-Adapter will first check if the request is a Crane provided Local Metric, and if not, forward it to the Remote Adapter Run the example \u00b6 Preparing the application \u00b6 Deploy the following application to the cluster, which exposes the Metric to show the number of http requests received per second. sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml When the application is deployed, you can check the http_requests_total Metric with the command curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics Configure collection rules \u00b6 Configure Prometheus' ScrapeConfig to collect the application's Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server Add the following configuration - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod At this point, you can use psql to query Prometheus: sum(rate(http_requests_total[5m])) by (pod) Verify PrometheusAdapter \u00b6 The default rule configuration of PrometheusAdapter supports converting http_requests_total to a custom metric of type Pods, verified by the command kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . The result should include pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } This indicates that the HPA can now be configured via Pod Metric. Configuring autoscaling \u00b6 We can now create the Effective HPA. at this point the Effective HPA can be resilient via Pod Metric http_requests : How to define a custom metric to enable prediction \u00b6 Annotation in the Effective HPA adds the configuration according to the following rules: annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml Check the TimeSeriesPrediction status, which may be unpredictable if the app has been running for a short time: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests Looking at the HPA object created by Effective HPA, you can observe that a Metric has been created based on custom metrics predictions: crane_custom.pods_http_requests . apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app Summary \u00b6 Due to the complexity of production environments, multi-metric-based autoscaling (CPU/Memory/custom metrics) is often a common choice for production applications, so Effective HPA achieves the effectiveness of helping more businesses land horizontal autoscaling in production environments by covering multi-metric autoscaling with predictive algorithms.","title":"Custom Metric Prediction With Prometheus"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#intelligent-autoscaling-practices-based-on-effective-hpa-for-custom-metrics","text":"The Kubernetes HPA supports rich elasticity scaling capabilities, with Kubernetes platform developers deploying services to implement custom Metric services and Kubernetes users configuring multiple built-in resource metrics or custom Metric metrics to achieve custom horizontal elasticity. Effective HPA is compatible with the community's Kubernetes HPA capabilities, providing smarter autoscaling policies such as prediction-based autoscaling and Cron-cycle-based autoscaling. Prometheus is a popular open source monitoring system today, through which user-defined metrics configurations are accessible. In this article, we present an example of how to implement intelligent resilience of custom metrics based on Effective HPA. Some configurations are taken from official documentation","title":"Intelligent Autoscaling Practices Based on Effective HPA for Custom Metrics"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#environment-requirements","text":"Kubernetes 1.18+ Helm 3.1.0 Crane v0.6.0+ Prometheus Refer to installation documentation to install Crane in the cluster, Prometheus can be used either from the installation documentation or from the deployed Prometheus.","title":"Environment Requirements"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#environment-build","text":"","title":"Environment build"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#installing-prometheusadapter","text":"The Crane components Metric-Adapter and PrometheusAdapter are both based on custom-metric-apiserver which implements When installing Crane, the corresponding ApiService will be installed as the Metric-Adapter of Crane, so you need to remove the ApiService before installing PrometheusAdapter to ensure that Helm is installed successfully. # View the current ApiService kubectl get apiservice Since Crane is installed, the result is as follows. NAME SERVICE AVAILABLE AGE v1beta1.batch Local True 35d v1beta1.custom.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.discovery.k8s.io Local True 35d v1beta1.events.k8s.io Local True 35d v1beta1.external.metrics.k8s.io crane-system/metric-adapter True 18d v1beta1.flowcontrol.apiserver.k8s.io Local True 35d v1beta1.metrics.k8s.io kube-system/metrics-service True 35d Remove the installed ApiService by crane kubectl delete apiservice v1beta1.custom.metrics.k8s.io kubectl delete apiservice v1beta1.external.metrics.k8s.io Install PrometheusAdapter via Helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-adapter -n crane-system prometheus-community/prometheus-adapter Then change the ApiService back to Crane's Metric-Adapter kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/deploy/metric-adapter/apiservice.yaml","title":"Installing PrometheusAdapter"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#configure-metric-adapter-to-enable-remoteadapter-functionality","text":"The installation of PrometheusAdapter did not point the ApiService to PrometheusAdapter, so in order to allow PrometheusAdapter to provide custom Metric as well, the RemoteAdapter function of Crane Metric Adapter is used to forward requests to PrometheusAdapter. Modify the Metric-Adapter configuration to configure PrometheusAdapter's Service as Crane Metric Adapter's RemoteAdapter # View the current ApiService kubectl edit deploy metric-adapter -n crane-system Make the following changes based on the PrometheusAdapter configuration. apiVersion : apps/v1 kind : Deployment metadata : name : metric-adapter namespace : crane-system spec : template : spec : containers : - args : #Add external Adapter configuration - --remote-adapter=true - --remote-adapter-service-namespace=crane-system - --remote-adapter-service-name=prometheus-adapter - --remote-adapter-service-port=443","title":"Configure Metric-Adapter to enable RemoteAdapter functionality"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#remoteadapter-capabilities","text":"Kubernetes restricts an ApiService to configure only one backend service, so in order to use the Metric provided by Crane and the Metric provided by PrometheusAdapter within a cluster, Crane supports a RemoteAdapter to solve this problem Crane Metric-Adapter supports the configuration of a Kubernetes Service as a Remote Adapter The Crane Metric-Adapter will first check if the request is a Crane provided Local Metric, and if not, forward it to the Remote Adapter","title":"RemoteAdapter Capabilities"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#run-the-example","text":"","title":"Run the example"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#preparing-the-application","text":"Deploy the following application to the cluster, which exposes the Metric to show the number of http requests received per second. sample-app.deploy.yaml apiVersion : apps/v1 kind : Deployment metadata : name : sample-app labels : app : sample-app spec : replicas : 1 selector : matchLabels : app : sample-app template : metadata : labels : app : sample-app spec : containers : - image : luxas/autoscale-demo:v0.1.2 name : metrics-provider resources : limits : cpu : 500m requests : cpu : 200m ports : - name : http containerPort : 8080 sample-app.service.yaml apiVersion : v1 kind : Service metadata : labels : app : sample-app name : sample-app spec : ports : - name : http port : 80 protocol : TCP targetPort : 8080 selector : app : sample-app type : ClusterIP kubectl create -f sample-app.deploy.yaml kubectl create -f sample-app.service.yaml When the application is deployed, you can check the http_requests_total Metric with the command curl http:// $( kubectl get service sample-app -o jsonpath = '{ .spec.clusterIP }' ) /metrics","title":"Preparing the application"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#configure-collection-rules","text":"Configure Prometheus' ScrapeConfig to collect the application's Metric: http_requests_total kubectl edit configmap -n crane-system prometheus-server Add the following configuration - job_name : sample-app kubernetes_sd_configs : - role : pod relabel_configs : - action : keep regex : default;sample-app-(.+) source_labels : - __meta_kubernetes_namespace - __meta_kubernetes_pod_name - action : labelmap regex : __meta_kubernetes_pod_label_(.+) - action : replace source_labels : - __meta_kubernetes_namespace target_label : namespace - source_labels : [ __meta_kubernetes_pod_name ] action : replace target_label : pod At this point, you can use psql to query Prometheus: sum(rate(http_requests_total[5m])) by (pod)","title":"Configure collection rules"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#verify-prometheusadapter","text":"The default rule configuration of PrometheusAdapter supports converting http_requests_total to a custom metric of type Pods, verified by the command kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq . The result should include pods/http_requests : { \"name\" : \"pods/http_requests\" , \"singularName\" : \"\" , \"namespaced\" : true, \"kind\" : \"MetricValueList\" , \"verbs\" : [ \"get\" ] } This indicates that the HPA can now be configured via Pod Metric.","title":"Verify PrometheusAdapter"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#configuring-autoscaling","text":"We can now create the Effective HPA. at this point the Effective HPA can be resilient via Pod Metric http_requests :","title":"Configuring autoscaling"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#how-to-define-a-custom-metric-to-enable-prediction","text":"Annotation in the Effective HPA adds the configuration according to the following rules: annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" sample-app-hpa.yaml apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache annotations : # metric-query.autoscaling.crane.io \u662f\u56fa\u5b9a\u7684\u524d\u7f00\uff0c\u540e\u9762\u662f Metric \u540d\u5b57\uff0c\u9700\u8ddf spec.metrics \u4e2d\u7684 Metric.name \u76f8\u540c\uff0c\u652f\u6301 Pods \u7c7b\u578b\u548c External \u7c7b\u578b metric-query.autoscaling.crane.io/http_requests : \"sum(rate(http_requests_total[5m])) by (pod)\" spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 10 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 - type : Pods pods : metric : name : http_requests target : type : AverageValue averageValue : 500m # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"7d\" kubectl create -f sample-app-hpa.yaml Check the TimeSeriesPrediction status, which may be unpredictable if the app has been running for a short time: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : creationTimestamp : \"2022-07-11T16:10:09Z\" generation : 1 labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : predictionMetrics : - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s resourceIdentifier : crane_pod_cpu_usage resourceQuery : cpu type : ResourceQuery - algorithm : algorithmType : dsp dsp : estimators : {} historyLength : 7d sampleInterval : 60s expressionQuery : expression : sum(rate(http_requests_total[5m])) by (pod) resourceIdentifier : crane_custom.pods_http_requests type : ExpressionQuery predictionWindowSeconds : 3600 targetRef : apiVersion : apps/v1 kind : Deployment name : sample-app namespace : default status : conditions : - lastTransitionTime : \"2022-07-12T06:54:42Z\" message : not all metric predicted reason : PredictPartial status : \"False\" type : Ready predictionMetrics : - ready : false resourceIdentifier : crane_pod_cpu_usage - prediction : - labels : - name : pod value : sample-app-7cfb596f98-8h5vv samples : - timestamp : 1657608900 value : \"0.01683\" - timestamp : 1657608960 value : \"0.01683\" ...... ready : true resourceIdentifier : crane_custom.pods_http_requests Looking at the HPA object created by Effective HPA, you can observe that a Metric has been created based on custom metrics predictions: crane_custom.pods_http_requests . apiVersion : autoscaling/v2beta2 kind : HorizontalPodAutoscaler metadata : creationTimestamp : \"2022-07-11T16:10:10Z\" labels : app.kubernetes.io/managed-by : effective-hpa-controller app.kubernetes.io/name : ehpa-php-apache app.kubernetes.io/part-of : php-apache autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 name : ehpa-php-apache namespace : default spec : maxReplicas : 10 metrics : - pods : metric : name : http_requests target : averageValue : 500m type : AverageValue type : Pods - pods : metric : name : crane_custom.pods_http_requests selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : 1322c5ac-a1c6-4c71-98d6-e85d07b22da0 target : averageValue : 500m type : AverageValue type : Pods - resource : name : cpu target : averageUtilization : 50 type : Utilization type : Resource minReplicas : 1 scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : sample-app","title":"How to define a custom metric to enable prediction"},{"location":"zh_TW/tutorials/effective-hpa-with-prometheus-adapter/#summary","text":"Due to the complexity of production environments, multi-metric-based autoscaling (CPU/Memory/custom metrics) is often a common choice for production applications, so Effective HPA achieves the effectiveness of helping more businesses land horizontal autoscaling in production environments by covering multi-metric autoscaling with predictive algorithms.","title":"Summary"},{"location":"zh_TW/tutorials/replicas-recommendation/","text":"\u526f\u672c\u6578\u63a8\u85a6 \u00b6 Kubernetes \u7528\u6236\u5728\u5275\u5efa\u61c9\u7528\u8cc7\u6e90\u6642\u5e38\u5e38\u662f\u57fa\u65bc\u7d93\u9a57\u503c\u4f86\u8a2d\u7f6e\u526f\u672c\u6578\u6216\u8005 EHPA \u914d\u7f6e\u3002\u901a\u904e\u526f\u672c\u6578\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u526f\u672c\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002 \u7522\u54c1\u529f\u80fd \u00b6 \u7b97\u6cd5\uff1a\u8a08\u7b97\u526f\u672c\u6578\u7684\u7b97\u6cd5\u53c3\u8003\u4e86 HPA \u7684\u8a08\u7b97\u516c\u5f0f\uff0c\u4e26\u4e14\u652f\u6301\u81ea\u5b9a\u7fa9\u7b97\u6cd5\u7684\u95dc\u9375\u914d\u7f6e HPA \u63a8\u85a6\uff1a\u526f\u672c\u6578\u63a8\u85a6\u6703\u6383\u63cf\u51fa\u9069\u5408\u914d\u7f6e\u6c34\u5e73\u5f48\u6027\uff08EHPA\uff09\u7684\u61c9\u7528\uff0c\u4e26\u7d66\u51fa EHPA \u7684\u914d\u7f6e, EHPA \u662f Crane \u63d0\u4f9b\u4e86\u667a\u80fd\u6c34\u5e73\u5f48\u6027\u7522\u54c1 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u904e Analytics \u7684 ResourceSelector\uff0c\u7528\u6236\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u500b\u5de5\u4f5c\u8ca0\u8f09 \u5275\u5efa\u5f48\u6027\u5206\u6790 \u00b6 \u5275\u5efa\u4e00\u500b \u5f48\u6027\u5206\u6790 Analytics \uff0c\u9019\u88e1\u6211\u5011\u901a\u904e\u5be6\u4f8b deployment: nginx \u4f5c\u70ba\u4e00\u500b\u4f8b\u5b50 Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl get analytics kubectl apply -f https://finops.coding.net/p/gocrane/d/crane/git/raw/main/examples/analytics/nginx-deployment.yaml?download = false kubectl apply -f https://finops.coding.net/p/gocrane/d/crane/git/raw/main/examples/analytics/analytics-replicas.yaml?download = false kubectl get analytics analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics replicas.workload-min-replicas : \"1\" replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" \u7d50\u679c\u5982\u4e0b: NAME AGE nginx-replicas 16m \u67e5\u770b Analytics \u8a73\u60c5: kubectl get analytics nginx-replicas -o yaml \u7d50\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:06Z\" recommendations : - lastStartTime : \"2022-06-17T06:56:06Z\" message : Success name : nginx-replicas-replicas-wq6wm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db \u67e5\u770b\u5206\u6790\u7d50\u679c \u00b6 \u67e5\u770b Recommendation \u7d50\u679c\uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml \u5206\u6790\u7d50\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-17T06:56:06Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b app : nginx name : nginx-replicas-replicas-wq6wm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b resourceVersion : \"2182455668\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-wq6wm uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:07Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\" \u6279\u91cf\u63a8\u85a6 \u00b6 \u6211\u5011\u901a\u904e\u4e00\u500b\u4f8b\u5b50\u4f86\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u85a6\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u7576 namespace \u7b49\u65bc crane-system \u6642\uff0c Analytics \u9078\u64c7\u7684\u8cc7\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u7576 namespace \u4e0d\u7b49\u65bc crane-system \u6642\uff0c Analytics \u9078\u64c7 Analytics namespace \u4e0b\u7684\u8cc7\u6e90 resourceSelectors \u901a\u904e\u6578\u7d44\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8cc7\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9078\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8cc7\u6e90 \u5f48\u6027\u63a8\u85a6\u8a08\u7b97\u6a21\u578b \u00b6 \u7be9\u9078\u968e\u6bb5 \u00b6 \u4f4e\u526f\u672c\u6578\u7684\u5de5\u4f5c\u8ca0\u8f09: \u904e\u4f4e\u7684\u526f\u672c\u6578\u53ef\u80fd\u5f48\u6027\u9700\u6c42\u4e0d\u9ad8\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas \u5b58\u5728\u4e00\u5b9a\u6bd4\u4f8b\u975e Running Pod \u7684\u5de5\u4f5c\u8ca0\u8f09: \u5982\u679c\u5de5\u4f5c\u8ca0\u8f09\u7684 Pod \u5927\u591a\u4e0d\u80fd\u6b63\u5e38\u904b\u884c\uff0c\u53ef\u80fd\u4e0d\u9069\u5408\u5f48\u6027\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio \u4f4e CPU \u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8ca0\u8f09: \u904e\u4f4e\u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8ca0\u8f09\u610f\u5473\u8457\u6c92\u6709\u696d\u52d9\u58d3\u529b\uff0c\u6b64\u6642\u901a\u904e\u4f7f\u7528\u7387\u63a8\u85a6\u5f48\u6027\u4e0d\u51c6\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.min-cpu-usage-threshold CPU \u4f7f\u7528\u91cf\u7684\u6ce2\u52d5\u7387\u904e\u4f4e: \u4f7f\u7528\u91cf\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u500d\u6578\u5b9a\u7fa9\u70ba\u6ce2\u52d5\u7387\uff0c\u6ce2\u52d5\u7387\u904e\u4f4e\u7684\u5de5\u4f5c\u8ca0\u8f09\u901a\u904e\u5f48\u6027\u964d\u672c\u7684\u6536\u76ca\u4e0d\u5927\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.fluctuation-threshold \u63a8\u85a6 \u00b6 \u63a8\u85a6\u968e\u6bb5\u901a\u904e\u4ee5\u4e0b\u6a21\u578b\u63a8\u8350\u4e00\u500b EffectiveHPA \u7684 Spec\u3002\u6bcf\u500b\u5b57\u6bb5\u7684\u63a8\u85a6\u908f\u8f2f\u5982\u4e0b\uff1a \u63a8\u85a6 TargetUtilization \u539f\u7406: \u4f7f\u7528 Pod P99 \u8cc7\u6e90\u5229\u7528\u7387\u63a8\u85a6\u5f48\u6027\u7684\u76ee\u6a19\u3002\u56e0\u70ba\u5982\u679c\u61c9\u7528\u53ef\u4ee5\u5728 P99 \u6642\u9593\u5167\u63a5\u53d7\u9019\u500b\u5229\u7528\u7387\uff0c\u53ef\u4ee5\u63a8\u65b7\u51fa\u53ef\u4f5c\u70ba\u5f48\u6027\u7684\u76ee\u6a19\u3002 \u901a\u904e Percentile \u7b97\u6cd5\u5f97\u5230 Pod \u904e\u53bb\u4e03\u5929 \u7684 P99 \u4f7f\u7528\u91cf: \\(pod\\_cpu\\_usage\\_p99\\) \u5c0d\u61c9\u7684\u5229\u7528\u7387: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) \u70ba\u4e86\u9632\u6b62\u5229\u7528\u7387\u904e\u5927\u6216\u904e\u5c0f\uff0ctarget_pod_cpu_utilization \u9700\u8981\u5c0f\u65bc ehpa.min-cpu-target-utilization \u548c\u5927\u65bc ehpa.max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) \u63a8\u85a6 minReplicas \u539f\u7406: \u4f7f\u7528 workload \u904e\u53bb\u4e03\u5929\u5167\u6bcf\u5c0f\u6642\u8ca0\u8f09\u6700\u4f4e\u7684\u5229\u7528\u7387\u63a8\u85a6 minReplicas\u3002 \u8a08\u7b97\u904e\u53bb7\u5929 workload \u6bcf\u5c0f\u6642\u4f7f\u7528\u91cf\u4e2d\u4f4d\u6578\u7684\u6700\u4f4e\u503c: \\(workload\\_cpu\\_usage\\_medium\\_min\\) \u5c0d\u61c9\u7684\u6700\u4f4e\u5229\u7528\u7387\u5c0d\u61c9\u7684\u526f\u672c\u6578: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) \u70ba\u4e86\u9632\u6b62 minReplicas \u904e\u5c0f\uff0cminReplicas \u9700\u8981\u5927\u65bc\u7b49\u65bc ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) \u63a8\u85a6 maxReplicas \u539f\u7406: \u4f7f\u7528 workload \u904e\u53bb\u548c\u672a\u4f86\u4e03\u5929\u7684\u8ca0\u8f09\u63a8\u85a6\u6700\u5927\u526f\u672c\u6578\u3002 \u8a08\u7b97\u904e\u53bb\u4e03\u5929\u548c\u672a\u4f86\u4e03\u5929 workload cpu \u4f7f\u7528\u91cf\u7684 P95: \\(workload\\_cpu\\_usage\\_p95\\) \u5c0d\u61c9\u7684\u526f\u672c\u6578: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) \u70ba\u4e86\u61c9\u5c0d\u6d41\u91cf\u6d2a\u5cf0\uff0c\u653e\u5927\u4e00\u5b9a\u500d\u6578: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) \u63a8\u85a6CPU\u4ee5\u5916 MetricSpec \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7e7c\u627f\u76f8\u61c9\u9664 CpuUtilization \u4ee5\u5916\u7684\u5176\u4ed6 MetricSpec \u63a8\u85a6 Behavior \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7e7c\u627f\u76f8\u61c9\u7684 Behavior \u914d\u7f6e \u9810\u6e2c \u5617\u8a66\u9810\u6e2c\u5de5\u4f5c\u8ca0\u8f09\u672a\u4f86\u4e03\u5929\u7684 CPU \u4f7f\u7528\u91cf\uff0c\u7b97\u6cd5\u662f DSP \u5982\u679c\u9810\u6e2c\u6210\u529f\u5247\u6dfb\u52a0\u9810\u6e2c\u914d\u7f6e \u5982\u679c\u4e0d\u53ef\u9810\u6e2c\u5247\u4e0d\u6dfb\u52a0\u9810\u6e2c\u914d\u7f6e\uff0c\u9000\u5316\u6210\u4e0d\u5177\u6709\u9810\u6e2c\u529f\u80fd\u7684 EffectiveHPA \u5f48\u6027\u5206\u6790\u8a08\u7b97\u914d\u7f6e \u00b6 \u914d\u7f6e\u9805 \u9ed8\u8a8d\u503c \u63cf\u8ff0 ehpa.deployment-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.statefulset-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.workload-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.pod-min-ready-seconds 30 \u5b9a\u7fa9\u4e86 Pod \u662f\u5426 Ready \u7684\u79d2\u6578 ehpa.pod-available-ratio 0.5 Ready Pod \u6bd4\u4f8b\u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.default-min-replicas 2 \u6700\u5c0f minReplicas ehpa.max-replicas-factor 3 \u8a08\u7b97 maxReplicas \u7684\u500d\u6578 ehpa.min-cpu-usage-threshold 10 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.fluctuation-threshold 1.5 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true \u7e7c\u627f\u73fe\u6709\u7684 HPA \u914d\u7f6e","title":"\u526f\u672c\u6578\u63a8\u85a6"},{"location":"zh_TW/tutorials/replicas-recommendation/#_1","text":"Kubernetes \u7528\u6236\u5728\u5275\u5efa\u61c9\u7528\u8cc7\u6e90\u6642\u5e38\u5e38\u662f\u57fa\u65bc\u7d93\u9a57\u503c\u4f86\u8a2d\u7f6e\u526f\u672c\u6578\u6216\u8005 EHPA \u914d\u7f6e\u3002\u901a\u904e\u526f\u672c\u6578\u63a8\u85a6\u7684\u7b97\u6cd5\u5206\u6790\u61c9\u7528\u7684\u771f\u5be6\u7528\u91cf\u63a8\u85a6\u66f4\u5408\u9069\u7684\u526f\u672c\u914d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u53c3\u8003\u4e26\u63a1\u7d0d\u5b83\u63d0\u5347\u96c6\u7fa4\u7684\u8cc7\u6e90\u5229\u7528\u7387\u3002","title":"\u526f\u672c\u6578\u63a8\u85a6"},{"location":"zh_TW/tutorials/replicas-recommendation/#_2","text":"\u7b97\u6cd5\uff1a\u8a08\u7b97\u526f\u672c\u6578\u7684\u7b97\u6cd5\u53c3\u8003\u4e86 HPA \u7684\u8a08\u7b97\u516c\u5f0f\uff0c\u4e26\u4e14\u652f\u6301\u81ea\u5b9a\u7fa9\u7b97\u6cd5\u7684\u95dc\u9375\u914d\u7f6e HPA \u63a8\u85a6\uff1a\u526f\u672c\u6578\u63a8\u85a6\u6703\u6383\u63cf\u51fa\u9069\u5408\u914d\u7f6e\u6c34\u5e73\u5f48\u6027\uff08EHPA\uff09\u7684\u61c9\u7528\uff0c\u4e26\u7d66\u51fa EHPA \u7684\u914d\u7f6e, EHPA \u662f Crane \u63d0\u4f9b\u4e86\u667a\u80fd\u6c34\u5e73\u5f48\u6027\u7522\u54c1 \u652f\u6301\u6279\u91cf\u5206\u6790\uff1a\u901a\u904e Analytics \u7684 ResourceSelector\uff0c\u7528\u6236\u53ef\u4ee5\u6279\u91cf\u5206\u6790\u591a\u500b\u5de5\u4f5c\u8ca0\u8f09","title":"\u7522\u54c1\u529f\u80fd"},{"location":"zh_TW/tutorials/replicas-recommendation/#_3","text":"\u5275\u5efa\u4e00\u500b \u5f48\u6027\u5206\u6790 Analytics \uff0c\u9019\u88e1\u6211\u5011\u901a\u904e\u5be6\u4f8b deployment: nginx \u4f5c\u70ba\u4e00\u500b\u4f8b\u5b50 Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-replicas.yaml kubectl get analytics kubectl apply -f https://finops.coding.net/p/gocrane/d/crane/git/raw/main/examples/analytics/nginx-deployment.yaml?download = false kubectl apply -f https://finops.coding.net/p/gocrane/d/crane/git/raw/main/examples/analytics/analytics-replicas.yaml?download = false kubectl get analytics analytics-replicas.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 600 # analytics selected resources every 10 minutes resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment config : # defines all the configuration for this analytics replicas.workload-min-replicas : \"1\" replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" \u7d50\u679c\u5982\u4e0b: NAME AGE nginx-replicas 16m \u67e5\u770b Analytics \u8a73\u60c5: kubectl get analytics nginx-replicas -o yaml \u7d50\u679c\u5982\u4e0b: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-replicas namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 600 config : replicas.fluctuation-threshold : \"0\" replicas.min-cpu-usage-threshold : \"0\" replicas.workload-min-replicas : \"1\" resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:06Z\" recommendations : - lastStartTime : \"2022-06-17T06:56:06Z\" message : Success name : nginx-replicas-replicas-wq6wm namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db","title":"\u5275\u5efa\u5f48\u6027\u5206\u6790"},{"location":"zh_TW/tutorials/replicas-recommendation/#_4","text":"\u67e5\u770b Recommendation \u7d50\u679c\uff1a kubectl get recommend -l analysis.crane.io/analytics-name = nginx-replicas -o yaml \u5206\u6790\u7d50\u679c\u5982\u4e0b\uff1a apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-17T06:56:06Z\" generateName : nginx-replicas-replicas- generation : 2 labels : analysis.crane.io/analytics-name : nginx-replicas analysis.crane.io/analytics-type : Replicas analysis.crane.io/analytics-uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b app : nginx name : nginx-replicas-replicas-wq6wm namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-replicas uid : 795f245b-1e1f-4f7b-a02b-885d7a495e5b resourceVersion : \"2182455668\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-replicas-replicas-wq6wm uid : 59f3eb3c-f786-4b15-b37e-774e5784c2db spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Replicas status : conditions : - lastTransitionTime : \"2022-06-17T06:56:07Z\" message : Recommendation is ready reason : RecommendationReady status : \"True\" type : Ready lastUpdateTime : \"2022-06-17T06:56:07Z\" recommendedValue : | effectiveHPA: maxReplicas: 3 metrics: - resource: name: cpu target: averageUtilization: 75 type: Utilization type: Resource minReplicas: 3 replicasRecommendation: replicas: 3 kind : List metadata : resourceVersion : \"\" selfLink : \"\"","title":"\u67e5\u770b\u5206\u6790\u7d50\u679c"},{"location":"zh_TW/tutorials/replicas-recommendation/#_5","text":"\u6211\u5011\u901a\u904e\u4e00\u500b\u4f8b\u5b50\u4f86\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Analytics \u63a8\u85a6\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Deployment \u548c StatefulSet\uff1a apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-replicas namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Replicas # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 \u7576 namespace \u7b49\u65bc crane-system \u6642\uff0c Analytics \u9078\u64c7\u7684\u8cc7\u6e90\u662f\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 namespace\uff0c\u7576 namespace \u4e0d\u7b49\u65bc crane-system \u6642\uff0c Analytics \u9078\u64c7 Analytics namespace \u4e0b\u7684\u8cc7\u6e90 resourceSelectors \u901a\u904e\u6578\u7d44\u914d\u7f6e\u9700\u8981\u5206\u6790\u7684\u8cc7\u6e90\uff0ckind \u548c apiVersion \u662f\u5fc5\u586b\u5b57\u6bb5\uff0cname \u9078\u586b resourceSelectors \u652f\u6301\u914d\u7f6e\u4efb\u610f\u652f\u6301 Scale Subresource \u7684\u8cc7\u6e90","title":"\u6279\u91cf\u63a8\u85a6"},{"location":"zh_TW/tutorials/replicas-recommendation/#_6","text":"","title":"\u5f48\u6027\u63a8\u85a6\u8a08\u7b97\u6a21\u578b"},{"location":"zh_TW/tutorials/replicas-recommendation/#_7","text":"\u4f4e\u526f\u672c\u6578\u7684\u5de5\u4f5c\u8ca0\u8f09: \u904e\u4f4e\u7684\u526f\u672c\u6578\u53ef\u80fd\u5f48\u6027\u9700\u6c42\u4e0d\u9ad8\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.deployment-min-replicas | ehpa.statefulset-min-replicas | ehpa.workload-min-replicas \u5b58\u5728\u4e00\u5b9a\u6bd4\u4f8b\u975e Running Pod \u7684\u5de5\u4f5c\u8ca0\u8f09: \u5982\u679c\u5de5\u4f5c\u8ca0\u8f09\u7684 Pod \u5927\u591a\u4e0d\u80fd\u6b63\u5e38\u904b\u884c\uff0c\u53ef\u80fd\u4e0d\u9069\u5408\u5f48\u6027\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.pod-min-ready-seconds | ehpa.pod-available-ratio \u4f4e CPU \u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8ca0\u8f09: \u904e\u4f4e\u4f7f\u7528\u91cf\u7684\u5de5\u4f5c\u8ca0\u8f09\u610f\u5473\u8457\u6c92\u6709\u696d\u52d9\u58d3\u529b\uff0c\u6b64\u6642\u901a\u904e\u4f7f\u7528\u7387\u63a8\u85a6\u5f48\u6027\u4e0d\u51c6\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.min-cpu-usage-threshold CPU \u4f7f\u7528\u91cf\u7684\u6ce2\u52d5\u7387\u904e\u4f4e: \u4f7f\u7528\u91cf\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u500d\u6578\u5b9a\u7fa9\u70ba\u6ce2\u52d5\u7387\uff0c\u6ce2\u52d5\u7387\u904e\u4f4e\u7684\u5de5\u4f5c\u8ca0\u8f09\u901a\u904e\u5f48\u6027\u964d\u672c\u7684\u6536\u76ca\u4e0d\u5927\uff0c\u95dc\u806f\u914d\u7f6e: ehpa.fluctuation-threshold","title":"\u7be9\u9078\u968e\u6bb5"},{"location":"zh_TW/tutorials/replicas-recommendation/#_8","text":"\u63a8\u85a6\u968e\u6bb5\u901a\u904e\u4ee5\u4e0b\u6a21\u578b\u63a8\u8350\u4e00\u500b EffectiveHPA \u7684 Spec\u3002\u6bcf\u500b\u5b57\u6bb5\u7684\u63a8\u85a6\u908f\u8f2f\u5982\u4e0b\uff1a \u63a8\u85a6 TargetUtilization \u539f\u7406: \u4f7f\u7528 Pod P99 \u8cc7\u6e90\u5229\u7528\u7387\u63a8\u85a6\u5f48\u6027\u7684\u76ee\u6a19\u3002\u56e0\u70ba\u5982\u679c\u61c9\u7528\u53ef\u4ee5\u5728 P99 \u6642\u9593\u5167\u63a5\u53d7\u9019\u500b\u5229\u7528\u7387\uff0c\u53ef\u4ee5\u63a8\u65b7\u51fa\u53ef\u4f5c\u70ba\u5f48\u6027\u7684\u76ee\u6a19\u3002 \u901a\u904e Percentile \u7b97\u6cd5\u5f97\u5230 Pod \u904e\u53bb\u4e03\u5929 \u7684 P99 \u4f7f\u7528\u91cf: \\(pod\\_cpu\\_usage\\_p99\\) \u5c0d\u61c9\u7684\u5229\u7528\u7387: \\(target\\_pod\\_CPU\\_utilization = \\frac{pod\\_cpu\\_usage\\_p99}{pod\\_cpu\\_request}\\) \u70ba\u4e86\u9632\u6b62\u5229\u7528\u7387\u904e\u5927\u6216\u904e\u5c0f\uff0ctarget_pod_cpu_utilization \u9700\u8981\u5c0f\u65bc ehpa.min-cpu-target-utilization \u548c\u5927\u65bc ehpa.max-cpu-target-utilization \\(ehpa.max\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization < target\\_pod\\_cpu\\_utilization < ehpa.min\\mbox{-}cpu\\mbox{-}target\\mbox{-}utilization\\) \u63a8\u85a6 minReplicas \u539f\u7406: \u4f7f\u7528 workload \u904e\u53bb\u4e03\u5929\u5167\u6bcf\u5c0f\u6642\u8ca0\u8f09\u6700\u4f4e\u7684\u5229\u7528\u7387\u63a8\u85a6 minReplicas\u3002 \u8a08\u7b97\u904e\u53bb7\u5929 workload \u6bcf\u5c0f\u6642\u4f7f\u7528\u91cf\u4e2d\u4f4d\u6578\u7684\u6700\u4f4e\u503c: \\(workload\\_cpu\\_usage\\_medium\\_min\\) \u5c0d\u61c9\u7684\u6700\u4f4e\u5229\u7528\u7387\u5c0d\u61c9\u7684\u526f\u672c\u6578: \\(minReplicas = \\frac{\\mathrm{workload\\_cpu\\_usage\\_medium\\_min} }{pod\\_cpu\\_request \\times ehpa.max-cpu-target-utilization}\\) \u70ba\u4e86\u9632\u6b62 minReplicas \u904e\u5c0f\uff0cminReplicas \u9700\u8981\u5927\u65bc\u7b49\u65bc ehpa.default-min-replicas \\(minReplicas \\geq ehpa.default\\mbox{-}min\\mbox{-}replicas\\) \u63a8\u85a6 maxReplicas \u539f\u7406: \u4f7f\u7528 workload \u904e\u53bb\u548c\u672a\u4f86\u4e03\u5929\u7684\u8ca0\u8f09\u63a8\u85a6\u6700\u5927\u526f\u672c\u6578\u3002 \u8a08\u7b97\u904e\u53bb\u4e03\u5929\u548c\u672a\u4f86\u4e03\u5929 workload cpu \u4f7f\u7528\u91cf\u7684 P95: \\(workload\\_cpu\\_usage\\_p95\\) \u5c0d\u61c9\u7684\u526f\u672c\u6578: \\(max\\_replicas\\_origin = \\frac{\\mathrm{workload\\_cpu\\_usage\\_p95} }{pod\\_cpu\\_request \\times target\\_cpu\\_utilization}\\) \u70ba\u4e86\u61c9\u5c0d\u6d41\u91cf\u6d2a\u5cf0\uff0c\u653e\u5927\u4e00\u5b9a\u500d\u6578: \\(max\\_replicas = max\\_replicas\\_origin \\times ehpa.max\\mbox{-}replicas\\mbox{-}factor\\) \u63a8\u85a6CPU\u4ee5\u5916 MetricSpec \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7e7c\u627f\u76f8\u61c9\u9664 CpuUtilization \u4ee5\u5916\u7684\u5176\u4ed6 MetricSpec \u63a8\u85a6 Behavior \u5982\u679c workload \u914d\u7f6e\u4e86 HPA\uff0c\u7e7c\u627f\u76f8\u61c9\u7684 Behavior \u914d\u7f6e \u9810\u6e2c \u5617\u8a66\u9810\u6e2c\u5de5\u4f5c\u8ca0\u8f09\u672a\u4f86\u4e03\u5929\u7684 CPU \u4f7f\u7528\u91cf\uff0c\u7b97\u6cd5\u662f DSP \u5982\u679c\u9810\u6e2c\u6210\u529f\u5247\u6dfb\u52a0\u9810\u6e2c\u914d\u7f6e \u5982\u679c\u4e0d\u53ef\u9810\u6e2c\u5247\u4e0d\u6dfb\u52a0\u9810\u6e2c\u914d\u7f6e\uff0c\u9000\u5316\u6210\u4e0d\u5177\u6709\u9810\u6e2c\u529f\u80fd\u7684 EffectiveHPA","title":"\u63a8\u85a6"},{"location":"zh_TW/tutorials/replicas-recommendation/#_9","text":"\u914d\u7f6e\u9805 \u9ed8\u8a8d\u503c \u63cf\u8ff0 ehpa.deployment-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.statefulset-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.workload-min-replicas 1 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.pod-min-ready-seconds 30 \u5b9a\u7fa9\u4e86 Pod \u662f\u5426 Ready \u7684\u79d2\u6578 ehpa.pod-available-ratio 0.5 Ready Pod \u6bd4\u4f8b\u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.default-min-replicas 2 \u6700\u5c0f minReplicas ehpa.max-replicas-factor 3 \u8a08\u7b97 maxReplicas \u7684\u500d\u6578 ehpa.min-cpu-usage-threshold 10 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.fluctuation-threshold 1.5 \u5c0f\u65bc\u8a72\u503c\u7684\u5de5\u4f5c\u8ca0\u8f09\u4e0d\u505a\u5f48\u6027\u63a8\u85a6 ehpa.min-cpu-target-utilization 30 ehpa.max-cpu-target-utilization 75 ehpa.reference-hpa true \u7e7c\u627f\u73fe\u6709\u7684 HPA \u914d\u7f6e","title":"\u5f48\u6027\u5206\u6790\u8a08\u7b97\u914d\u7f6e"},{"location":"zh_TW/tutorials/resource-recommendation/","text":"Resource Recommendation \u00b6 Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster. Difference between VPA \u00b6 Resource recommendations are a lightweight implementation of VPA and are more flexible. Algorithm: The algorithm model adopts the Moving Window algorithm of VPA, and supports to customization algo args , providing higher flexibility Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads without creating VPA objects one by one More portable: It is difficult to use VPA's Auto mode in production because it will cause container reconstruction when updating container resource configuration. Resource recommendation provides suggestions to users and leaves the decision of change to users Create Resource Analytics \u00b6 Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics The created Analytics yaml is following: analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment The output is: NAME AGE nginx-resource 16m You can get view analytics status by running: kubectl get analytics nginx-resource -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e Recommendation: Analytics result \u00b6 You can get recommendations that created by above Analytics by running. kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\" The status.recommendedValue.ResourceRequest is recommended by crane's recommendation engine. Batch recommendation \u00b6 Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource Resource Recommendation Algorithm model \u00b6 Inspecting \u00b6 Workload with not pods: if the workload has no pods exist means that it's not a available workload. Advising \u00b6 VPA's Moving Window algorithm was used to calculate the CPU and Memory of each container and give the corresponding recommended values","title":"\u8cc7\u6e90\u63a8\u85a6"},{"location":"zh_TW/tutorials/resource-recommendation/#resource-recommendation","text":"Resource recommendation allows you to obtain recommended values for resources in a cluster and use them to improve the resource utilization of the cluster.","title":"Resource Recommendation"},{"location":"zh_TW/tutorials/resource-recommendation/#difference-between-vpa","text":"Resource recommendations are a lightweight implementation of VPA and are more flexible. Algorithm: The algorithm model adopts the Moving Window algorithm of VPA, and supports to customization algo args , providing higher flexibility Support batch analysis: With the ResourceSelector, users can batch analyze multiple workloads without creating VPA objects one by one More portable: It is difficult to use VPA's Auto mode in production because it will cause container reconstruction when updating container resource configuration. Resource recommendation provides suggestions to users and leaves the decision of change to users","title":"Difference between VPA"},{"location":"zh_TW/tutorials/resource-recommendation/#create-resource-analytics","text":"Create an Resource Analytics to give recommendation for deployment: nginx-deployment as a sample. Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane/main/examples/analytics/analytics-resource.yaml kubectl get analytics kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/nginx-deployment.yaml kubectl apply -f https://gitee.com/finops/crane/raw/main/examples/analytics/analytics-resource.yaml kubectl get analytics The created Analytics yaml is following: analytics-resource.yaml apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 name : nginx-deployment The output is: NAME AGE nginx-resource 16m You can get view analytics status by running: kubectl get analytics nginx-resource -o yaml The output is similar to: apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : nginx-resource namespace : default spec : completionStrategy : completionStrategyType : Periodical periodSeconds : 86400 resourceSelectors : - apiVersion : apps/v1 kind : Deployment labelSelector : {} name : nginx-deployment type : Resource status : conditions : - lastTransitionTime : \"2022-05-15T14:38:35Z\" message : Analytics is ready reason : AnalyticsReady status : \"True\" type : Ready lastUpdateTime : \"2022-05-15T14:38:35Z\" recommendations : - lastStartTime : \"2022-05-15T14:38:35Z\" message : Success name : nginx-resource-resource-w45nq namespace : default targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default uid : 750cb3bd-0b87-4f87-acbe-57e621af0a1e","title":"Create Resource Analytics"},{"location":"zh_TW/tutorials/resource-recommendation/#recommendation-analytics-result","text":"You can get recommendations that created by above Analytics by running. kubectl get recommend -l analysis.crane.io/analytics-name = nginx-resource -o yaml The output is similar to: apiVersion : v1 items : - apiVersion : analysis.crane.io/v1alpha1 kind : Recommendation metadata : creationTimestamp : \"2022-06-15T15:26:25Z\" generateName : nginx-resource-resource- generation : 1 labels : analysis.crane.io/analytics-name : nginx-resource analysis.crane.io/analytics-type : Resource analysis.crane.io/analytics-uid : 9e78964b-f8ae-40de-9740-f9a715d16280 app : nginx name : nginx-resource-resource-t4xpn namespace : default ownerReferences : - apiVersion : analysis.crane.io/v1alpha1 blockOwnerDeletion : false controller : false kind : Analytics name : nginx-resource uid : 9e78964b-f8ae-40de-9740-f9a715d16280 resourceVersion : \"2117439429\" selfLink : /apis/analysis.crane.io/v1alpha1/namespaces/default/recommendations/nginx-resource-resource-t4xpn uid : 8005e3e0-8fe9-470b-99cf-5ce9dd407529 spec : adoptionType : StatusAndAnnotation completionStrategy : completionStrategyType : Once targetRef : apiVersion : apps/v1 kind : Deployment name : nginx-deployment namespace : default type : Resource status : recommendedValue : | resourceRequest: containers: - containerName: nginx target: cpu: 100m memory: 100Mi kind : List metadata : resourceVersion : \"\" selfLink : \"\" The status.recommendedValue.ResourceRequest is recommended by crane's recommendation engine.","title":"Recommendation: Analytics result"},{"location":"zh_TW/tutorials/resource-recommendation/#batch-recommendation","text":"Use a sample to show how to recommend all Deployments and StatefulSets by one Analytics : apiVersion : analysis.crane.io/v1alpha1 kind : Analytics metadata : name : workload-resource namespace : crane-system # The Analytics in Crane-system will select all resource across all namespaces. spec : type : Resource # This can only be \"Resource\" or \"Replicas\". completionStrategy : completionStrategyType : Periodical # This can only be \"Once\" or \"Periodical\". periodSeconds : 86400 # analytics selected resources every 1 day resourceSelectors : # defines all the resources to be select with - kind : Deployment apiVersion : apps/v1 - kind : StatefulSet apiVersion : apps/v1 when using crane-system as your namespace\uff0c Analytics selected all namespaces\uff0cwhen namespace not equal crane-system \uff0c Analytics selected the resource that in Analytics namespace resourceSelectors defines the resource to analysis\uff0ckind and apiVersion is mandatory\uff0cname is optional resourceSelectors supoort any resource that are Scale Subresource","title":"Batch recommendation"},{"location":"zh_TW/tutorials/resource-recommendation/#resource-recommendation-algorithm-model","text":"","title":"Resource Recommendation Algorithm model"},{"location":"zh_TW/tutorials/resource-recommendation/#inspecting","text":"Workload with not pods: if the workload has no pods exist means that it's not a available workload.","title":"Inspecting"},{"location":"zh_TW/tutorials/resource-recommendation/#advising","text":"VPA's Moving Window algorithm was used to calculate the CPU and Memory of each container and give the corresponding recommended values","title":"Advising"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/","text":"Crane-scheduler \u00b6 Overview \u00b6 Crane-scheduler is a collection of scheduler plugins based on scheduler framework , including: Dynamic scheduler: a load-aware scheduler plugin Get Started \u00b6 Install Prometheus \u00b6 Make sure your kubernetes cluster has Prometheus installed. If not, please refer to Install Prometheus . Configure Prometheus Rules \u00b6 Configure the rules of Prometheus to get expected aggregated data: apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting The sampling interval of Prometheus must be less than 30 seconds, otherwise the above rules(such as cpu_usage_active) may not take effect. Install Crane-scheduler \u00b6 There are two options: Install Crane-scheduler as a second scheduler Replace native Kube-scheduler with Crane-scheduler Install Crane-scheduler as a second scheduler \u00b6 Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler Replace native Kube-scheduler with Crane-scheduler \u00b6 Backup /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ Modify configfile of kube-scheduler( scheduler-config.yaml ) to enable Dynamic scheduler plugin and configure plugin args: scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... Create /etc/kubernetes/policy.yaml , using as scheduler policy of Dynamic plugin: /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 Modify kube-scheduler.yaml and replace kube-scheduler image with Crane-scheduler\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... Install crane-scheduler-controller : Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml Schedule Pods With Crane-scheduler \u00b6 Test Crane-scheduler with following example: apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note Change crane-scheduler to default-scheduler if crane-scheduler is used as default. There will be the following event if the test pod is successfully scheduled: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"\u6982\u8ff0"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#crane-scheduler","text":"","title":"Crane-scheduler"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#overview","text":"Crane-scheduler is a collection of scheduler plugins based on scheduler framework , including: Dynamic scheduler: a load-aware scheduler plugin","title":"Overview"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#get-started","text":"","title":"Get Started"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#install-prometheus","text":"Make sure your kubernetes cluster has Prometheus installed. If not, please refer to Install Prometheus .","title":"Install Prometheus"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#configure-prometheus-rules","text":"Configure the rules of Prometheus to get expected aggregated data: apiVersion : monitoring.coreos.com/v1 kind : PrometheusRule metadata : name : example-record spec : groups : - name : cpu_mem_usage_active interval : 30s rules : - record : cpu_usage_active expr : 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[30s])) * 100) - record : mem_usage_active expr : 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes) - name : cpu-usage-5m interval : 5m rules : - record : cpu_usage_max_avg_1h expr : max_over_time(cpu_usage_avg_5m[1h]) - record : cpu_usage_max_avg_1d expr : max_over_time(cpu_usage_avg_5m[1d]) - name : cpu-usage-1m interval : 1m rules : - record : cpu_usage_avg_5m expr : avg_over_time(cpu_usage_active[5m]) - name : mem-usage-5m interval : 5m rules : - record : mem_usage_max_avg_1h expr : max_over_time(mem_usage_avg_5m[1h]) - record : mem_usage_max_avg_1d expr : max_over_time(mem_usage_avg_5m[1d]) - name : mem-usage-1m interval : 1m rules : - record : mem_usage_avg_5m expr : avg_over_time(mem_usage_active[5m]) \ufe0fTroubleshooting The sampling interval of Prometheus must be less than 30 seconds, otherwise the above rules(such as cpu_usage_active) may not take effect.","title":"Configure Prometheus Rules"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#install-crane-scheduler","text":"There are two options: Install Crane-scheduler as a second scheduler Replace native Kube-scheduler with Crane-scheduler","title":"Install Crane-scheduler"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#install-crane-scheduler-as-a-second-scheduler","text":"Main Mirror helm repo add crane https://gocrane.github.io/helm-charts helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler helm repo add crane https://finops-helm.pkg.coding.net/gocrane/gocrane helm install scheduler -n crane-system --create-namespace --set global.prometheusAddr = \"REPLACE_ME_WITH_PROMETHEUS_ADDR\" crane/scheduler","title":"Install Crane-scheduler as a second scheduler"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#replace-native-kube-scheduler-with-crane-scheduler","text":"Backup /etc/kubernetes/manifests/kube-scheduler.yaml cp /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/ Modify configfile of kube-scheduler( scheduler-config.yaml ) to enable Dynamic scheduler plugin and configure plugin args: scheduler-config.yaml apiVersion : kubescheduler.config.k8s.io/v1beta2 kind : KubeSchedulerConfiguration ... profiles : - schedulerName : default-scheduler plugins : filter : enabled : - name : Dynamic score : enabled : - name : Dynamic weight : 3 pluginConfig : - name : Dynamic args : policyConfigPath : /etc/kubernetes/policy.yaml ... Create /etc/kubernetes/policy.yaml , using as scheduler policy of Dynamic plugin: /etc/kubernetes/policy.yaml apiVersion : scheduler.policy.crane.io/v1alpha1 kind : DynamicSchedulerPolicy spec : syncPolicy : ##cpu usage - name : cpu_usage_avg_5m period : 3m - name : cpu_usage_max_avg_1h period : 15m - name : cpu_usage_max_avg_1d period : 3h ##memory usage - name : mem_usage_avg_5m period : 3m - name : mem_usage_max_avg_1h period : 15m - name : mem_usage_max_avg_1d period : 3h predicate : ##cpu usage - name : cpu_usage_avg_5m maxLimitPecent : 0.65 - name : cpu_usage_max_avg_1h maxLimitPecent : 0.75 ##memory usage - name : mem_usage_avg_5m maxLimitPecent : 0.65 - name : mem_usage_max_avg_1h maxLimitPecent : 0.75 priority : ##cpu usage - name : cpu_usage_avg_5m weight : 0.2 - name : cpu_usage_max_avg_1h weight : 0.3 - name : cpu_usage_max_avg_1d weight : 0.5 ##memory usage - name : mem_usage_avg_5m weight : 0.2 - name : mem_usage_max_avg_1h weight : 0.3 - name : mem_usage_max_avg_1d weight : 0.5 hotValue : - timeRange : 5m count : 5 - timeRange : 1m count : 2 Modify kube-scheduler.yaml and replace kube-scheduler image with Crane-scheduler\uff1a kube-scheduler.yaml ... image : docker.io/gocrane/crane-scheduler:0.0.23 ... Install crane-scheduler-controller : Main Mirror kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/rbac.yaml kubectl apply -f https://raw.githubusercontent.com/gocrane/crane-scheduler/main/deploy/controller/deployment.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/rbac.yaml kubectl apply -f https://gitee.com/finops/crane-scheduler/raw/main/deploy/controller/deployment.yaml","title":"Replace native Kube-scheduler with Crane-scheduler"},{"location":"zh_TW/tutorials/scheduling-pods-based-on-actual-node-load/#schedule-pods-with-crane-scheduler","text":"Test Crane-scheduler with following example: apiVersion : apps/v1 kind : Deployment metadata : name : cpu-stress spec : selector : matchLabels : app : cpu-stress replicas : 1 template : metadata : labels : app : cpu-stress spec : schedulerName : crane-scheduler hostNetwork : true tolerations : - key : node.kubernetes.io/network-unavailable operator : Exists effect : NoSchedule containers : - name : stress image : docker.io/gocrane/stress:latest command : [ \"stress\" , \"-c\" , \"1\" ] resources : requests : memory : \"1Gi\" cpu : \"1\" limits : memory : \"1Gi\" cpu : \"1\" Note Change crane-scheduler to default-scheduler if crane-scheduler is used as default. There will be the following event if the test pod is successfully scheduled: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 28s crane-scheduler Successfully assigned default/cpu-stress-7669499b57-zmrgb to vm-162-247-ubuntu","title":"Schedule Pods With Crane-scheduler"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/","text":"DSP\u9884\u6d4b\u7b97\u6cd5 \u00b6 Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09 \u6d41\u7a0b \u00b6 \u9884\u5904\u7406 \u00b6 \u586b\u5145\u7f3a\u5931\u6570\u636e \u00b6 \u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\) \u53bb\u9664\u5f02\u5e38\u70b9 \u00b6 \u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u00b6 \u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002 \u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570 \u00b6 \u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002 \u9884\u6d4b \u00b6 \u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002 \u5e94\u7528 \u00b6 Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#dsp","text":"Crane\u4f7f\u7528\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08Digital Signal Processing\uff09\u9886\u57df\u4e2d\u5e38\u7528\u7684\u7684 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 \u3001 \u81ea\u76f8\u5173\u51fd\u6570 \u7b49\u624b\u6bb5\uff0c\u8bc6\u522b\u3001\u9884\u6d4b\u5468\u671f\u6027\u7684\u65f6\u95f4\u5e8f\u5217\u3002 \u672c\u6587\u5c06\u4ecb\u7ecdDSP\u7b97\u6cd5\u7684\u5b9e\u73b0\u6d41\u7a0b\u548c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4ee5\u4fbf\u5e2e\u52a9\u5927\u5bb6\u4e86\u89e3\u7b97\u6cd5\u80cc\u540e\u7684\u539f\u7406\uff0c\u5e76\u5c06\u5b83\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u3002 \uff08\u76f8\u5173\u4ee3\u7801\u4f4d\u4e8e pkg/prediction/dsp \u76ee\u5f55\u4e0b\uff09","title":"DSP\u9884\u6d4b\u7b97\u6cd5"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_1","text":"","title":"\u6d41\u7a0b"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_2","text":"","title":"\u9884\u5904\u7406"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_3","text":"\u76d1\u63a7\u6570\u636e\u5728\u67d0\u4e9b\u65f6\u95f4\u70b9\u4e0a\u7f3a\u5931\u662f\u5f88\u5e38\u89c1\u7684\u73b0\u8c61\uff0cCrane\u4f1a\u6839\u636e\u524d\u540e\u7684\u6570\u636e\u5bf9\u7f3a\u5931\u7684\u91c7\u6837\u70b9\u8fdb\u884c\u586b\u5145\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u5047\u8bbe\u7b2c \\(m\\) \u4e2a\u4e0e\u7b2c \\(n\\) \u4e2a\u91c7\u6837\u70b9\u4e4b\u95f4\u91c7\u6837\u6570\u636e\u7f3a\u5931\uff08 \\(m+1 < n\\) \uff09,\u8bbe\u5728 \\(m\\) \u548c \\(n\\) \u70b9\u7684\u91c7\u6837\u503c\u5206\u522b\u4e3a \\(v_m\\) \u548c \\(v_n\\) \uff0c\u4ee4 \\( \\(\\Delta = {v_n-v_m \\over n-m}\\) \\) \uff0c\u5219 \\(m\\) \u548c \\(n\\) \u4e4b\u95f4\u7684\u586b\u5145\u6570\u636e\u4f9d\u6b21\u4e3a \\(v_m+\\Delta , v_m+2\\Delta , ...\\)","title":"\u586b\u5145\u7f3a\u5931\u6570\u636e"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_4","text":"\u76d1\u63a7\u6570\u636e\u4e2d\u5076\u5c14\u4f1a\u51fa\u73b0\u4e00\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u6570\u636e\u70b9\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u5f02\u5e38\u70b9\uff08outliers\uff09\u7684\u539f\u56e0\u6709\u5f88\u591a\uff0c\u4f8b\u5982\uff1a 1. \u76d1\u63a7\u7cfb\u7edf\u75280\u503c\u586b\u5145\u7f3a\u5931\u7684\u91c7\u6837\u70b9\uff1b 2. \u88ab\u76d1\u63a7\u7ec4\u4ef6\u7531\u4e8e\u81ea\u8eab\u7684bug\u4e0a\u62a5\u4e86\u9519\u8bef\u7684\u6307\u6807\u6570\u636e\uff1b 3. \u5e94\u7528\u542f\u52a8\u65f6\u4f1a\u6d88\u8017\u8fdc\u8d85\u6b63\u5e38\u8fd0\u884c\u65f6\u7684\u8d44\u6e90 \u8fd9\u4e9b\u6781\u7aef\u7684\u5f02\u5e38\u70b9\u5bf9\u4e8e\u4fe1\u53f7\u7684\u5468\u671f\u5224\u65ad\u4f1a\u9020\u6210\u5e72\u6270\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9664\u3002\u505a\u6cd5\u5982\u4e0b\uff1a \u9009\u53d6\u5b9e\u9645\u5e8f\u5217\u4e2d\u6240\u6709\u91c7\u6837\u70b9\u7684 \\(P99.9\\) \u548c \\(P0.1\\) \uff0c\u5206\u522b\u4f5c\u4e3a\u4e0a\u3001\u4e0b\u9650\u9608\u503c\uff0c\u5982\u679c\u67d0\u4e2a\u91c7\u6837\u503c\u4f4e\u4e8e\u4e0b\u9650\u6216\u8005\u9ad8\u4e8e\u4e0a\u9650\uff0c\u5c06\u91c7\u6837\u70b9\u7684\u503c\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2a\u91c7\u6837\u503c\u3002","title":"\u53bb\u9664\u5f02\u5e38\u70b9"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_5","text":"\u5bf9\u76d1\u63a7\u7684\u65f6\u95f4\u5e8f\u5217\uff08\u8bbe\u957f\u5ea6\u4e3a \\(N\\) \uff09\u505a\u5feb\u901f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u5f97\u5230\u4fe1\u53f7\u7684\u9891\u8c31\u56fe\uff08spectrogram\uff09\uff0c\u9891\u8c31\u56fe\u76f4\u89c2\u5730\u8868\u73b0\u4e3a\u5728\u5404\u4e2a\u79bb\u6563\u70b9 \\(k\\) \u5904\u7684\u300c\u51b2\u51fb\u300d\u3002 \u51b2\u51fb\u7684\u9ad8\u5ea6\u4e3a \\(k\\) \u5bf9\u5e94\u5468\u671f\u5206\u91cf\u7684\u300c\u5e45\u5ea6\u300d\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4 \\(\\(0,1,2, ... N-1\\)\\) \u3002 \\(k = 0\\) \u5bf9\u5e94\u4fe1\u53f7\u7684\u300c\u76f4\u6d41\u5206\u91cf\u300d\uff0c\u5bf9\u4e8e\u5468\u671f\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u6b64\u5ffd\u7565\u3002 \u7531\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u9891\u8c31\u5e8f\u5217\u524d\u4e00\u534a\u548c\u540e\u4e00\u534a\u662f\u5171\u8f6d\u5bf9\u79f0\u7684\uff0c\u53cd\u6620\u5230\u9891\u8c31\u56fe\u4e0a\u5c31\u662f\u5173\u4e8e\u8f74\u5bf9\u79f0\uff0c\u56e0\u6b64\u53ea\u770b\u524d\u4e00\u534a \\(N/2\\) \u5373\u53ef\u3002 \\(k\\) \u6240\u5bf9\u5e94\u7684\u5468\u671f \\( \\(T = {N \\over k} \\bullet SampleInterval\\) \\) \u8981\u89c2\u5bdf\u4e00\u4e2a\u4fe1\u53f7\u662f\u4e0d\u662f\u4ee5 \\(T\\) \u4e3a\u5468\u671f\uff0c\u81f3\u5c11\u9700\u8981\u89c2\u5bdf\u4e24\u500d\u7684 \\(T\\) \u7684\u957f\u5ea6\uff0c\u56e0\u6b64\u901a\u8fc7\u957f\u5ea6\u4e3a \\(N\\) \u7684\u5e8f\u5217\u80fd\u591f\u8bc6\u522b\u51fa\u7684\u6700\u957f\u5468\u671f\u4e3a \\(N/2\\) \u3002\u6240\u4ee5\u53ef\u4ee5\u5ffd\u7565 \\(k = 1\\) \u3002 \u81f3\u6b64\uff0c \\(k\\) \u7684\u53d6\u503c\u8303\u56f4\u4e3a \\((2, 3, ... , N/2)\\) \uff0c\u5bf9\u5e94\u7684\u5468\u671f\u4e3a \\(N/2, N/3, ...\\) \uff0c\u8fd9\u4e5f\u5c31\u662fFFT\u80fd\u591f\u63d0\u4f9b\u7684\u5468\u671f\u4fe1\u606f\u7684\u300c\u5206\u8fa8\u7387\u300d\u3002\u5982\u679c\u4e00\u4e2a\u4fe1\u53f7\u7684\u5468\u671f\u6ca1\u6709\u843d\u5230 \\(N/k\\) \u4e0a\uff0c\u5b83\u4f1a\u6563\u5e03\u5230\u6574\u4e2a\u9891\u57df\uff0c\u5bfc\u81f4\u300c\u9891\u7387\u6cc4\u6f0f\u300d\u3002 \u597d\u5728\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u5e38\u9047\u5230\u7684\u5e94\u7528\uff08\u5c24\u5176\u662f\u5728\u7ebf\u4e1a\u52a1\uff09\uff0c\u5982\u679c\u6709\u89c4\u5f8b\uff0c\u90fd\u662f\u4ee5\u300c\u5929\u300d\u4e3a\u5468\u671f\u7684\uff0c\u67d0\u4e9b\u4e1a\u52a1\u53ef\u80fd\u4f1a\u6709\u6240\u8c13\u7684\u300c\u5468\u672b\u300d\u6548\u5e94\uff0c\u5373\u5468\u672b\u548c\u5de5\u4f5c\u65e5\u4e0d\u592a\u4e00\u6837\uff0c\u5982\u679c\u6269\u5927\u5230\u300c\u5468\u300d\u7684\u7c92\u5ea6\u53bb\u89c2\u5bdf\uff0c\u5b83\u4eec\u540c\u6837\u5177\u6709\u826f\u597d\u7684\u5468\u671f\u6027\u3002 Crane\u6ca1\u6709\u5c1d\u8bd5\u53d1\u73b0\u4efb\u610f\u957f\u5ea6\u7684\u5468\u671f\uff0c\u800c\u662f\u6307\u5b9a\u51e0\u4e2a\u56fa\u5b9a\u7684\u5468\u671f\u957f\u5ea6\uff08 \\(1d\u30017d\\) \uff09\u53bb\u5224\u65ad\u3002\u5e76\u901a\u8fc7\u622a\u53d6\u3001\u586b\u5145\u7684\u65b9\u5f0f\uff0c\u4fdd\u8bc1\u5e8f\u5217\u7684\u957f\u5ea6 \\(N\\) \u4e3a\u5f85\u68c0\u6d4b\u5468\u671f \\(T\\) \u7684\u6574\u500d\u6570\uff0c\u4f8b\u5982\uff1a \\(T=1d\uff0cN=3d\uff1bT=7d\uff0cN=14d\\) \u3002 \u6211\u4eec\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u6293\u53d6\u4e86\u4e00\u4e9b\u5e94\u7528\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u5b58\u4e3acsv\u683c\u5f0f\uff0c\u653e\u5230 pkg/prediction/dsp/test_data \u76ee\u5f55\u4e0b\u3002 \u4f8b\u5982\uff0c input0.csv \u6587\u4ef6\u5305\u62ec\u4e86\u4e00\u4e2a\u5e94\u7528\u8fde\u7eed8\u5929\u7684CPU\u76d1\u63a7\u6570\u636e\uff0c\u5bf9\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u5982\u4e0b\u56fe\uff1a \u6211\u4eec\u770b\u5230\uff0c\u5c3d\u7ba1\u6bcf\u5929\u7684\u6570\u636e\u4e0d\u5c3d\u76f8\u540c\uff0c\u4f46\u5927\u4f53\u300c\u6a21\u5f0f\u300d\u8fd8\u662f\u57fa\u672c\u4e00\u81f4\u7684\u3002 \u5bf9\u5b83\u505aFFT\uff0c\u4f1a\u5f97\u5230\u4e0b\u9762\u7684\u9891\u8c31\u56fe\uff1a \u6211\u4eec\u53d1\u73b0\u5728\u51e0\u4e2a\u70b9\u4e0a\u7684\u300c\u5e45\u503c\u300d\u660e\u663e\u9ad8\u4e8e\u5176\u5b83\u70b9\uff0c\u8fd9\u4e9b\u70b9\u4fbf\u53ef\u4ee5\u4f5c\u4e3a\u6211\u4eec\u7684\u300c\u5019\u9009\u5468\u671f\u300d\uff0c\u5f85\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u3002 \u4e0a\u9762\u662f\u6211\u4eec\u901a\u8fc7\u76f4\u89c9\u5224\u65ad\u7684\uff0cCrane\u662f\u5982\u4f55\u6311\u9009\u300c\u5019\u9009\u5468\u671f\u300d\u7684\u5462\uff1f \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u8fdb\u884c\u4e00\u4e2a\u968f\u673a\u6392\u5217\u540e\u5f97\u5230\u5e8f\u5217 \\(\\vec x'(n)\\) \uff0c\u518d\u5bf9 \\(\\vec x'(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X'(k)\\) \uff0c\u4ee4 \\(P_{max} = argmax\\|\\vec X'(k)\\|\\) \u3002 \u91cd\u590d100\u6b21\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u5f97\u5230100\u4e2a \\(P_{max}\\) \uff0c\u53d6 \\(P99\\) \u4f5c\u4e3a\u9608\u503c \\(P_{threshold}\\) \u3002 \u5bf9\u539f\u59cb\u5e8f\u5217 \\(\\vec x(n)\\) \u505aFFT\u5f97\u5230 \\(\\vec X(f)\\) \uff0c\u904d\u5386 \\(k = 2, 3, ...\\) \uff0c\u5982\u679c \\(P_k = \\|X(k)\\| > P_{threshold}\\) \uff0c\u5219\u5c06 \\(k\\) \u52a0\u5165\u5019\u9009\u5468\u671f\u3002","title":"\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_6","text":"\u81ea\u76f8\u5173\u51fd\u6570\uff08Auto Correlation Function\uff0cACF\uff09\u662f\u4e00\u4e2a\u4fe1\u53f7\u4e8e\u5176\u81ea\u8eab\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u4e92\u76f8\u5173\u3002\u901a\u4fd7\u7684\u8bb2\uff0c\u5b83\u5c31\u662f\u4e24\u6b21\u89c2\u5bdf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u65f6\u95f4\u5dee\u7684\u51fd\u6570\u3002 Crane\u4f7f\u7528\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570\uff08Circular ACF\uff09\uff0c\u5148\u5bf9\u957f\u5ea6\u4e3a \\(N\\) \u7684\u65f6\u95f4\u5e8f\u5217\u4ee5 \\(N\\) \u4e3a\u5468\u671f\u505a\u6269\u5c55\uff0c\u4e5f\u5c31\u662f\u5728 \\(..., [-N, -1], [N, 2N-1], ...\\) \u533a\u95f4\u4e0a\u590d\u5236 \\(\\vec x(n)\\) \uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217 \\(\\vec x'(n)\\) \u3002 \u518d\u4f9d\u6b21\u8ba1\u7b97\u5c06 \\(\\vec x'(n)\\) \u4f9d\u6b21\u5e73\u79fb \\(k=1,2,3,...N/2\\) \u540e\u7684 \\(\\vec x'(n+k)\\) \u4e0e \\(\\vec x'(n)\\) \u7684\u76f8\u5173\u7cfb\u6570 \\[r_k={\\displaystyle\\sum_{i=-k}^{N-k-1} (x_i-\\mu)(x_{i+k}-\\mu) \\over \\displaystyle\\sum_{i=0}^{N-1} (x_i-\\mu)^2}\\ \\ \\ \\mu: mean\\] Crane\u6ca1\u6709\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u5b9a\u4e49\u53bb\u8ba1\u7b97ACF\uff0c\u800c\u662f\u6839\u636e\u4e0b\u9762\u7684\u516c\u5f0f\uff0c\u901a\u8fc7\u4e24\u6b21 \\((I)FFT\\) \uff0c\u4ece\u800c\u80fd\u591f\u5728 \\(O(nlogn)\\) \u7684\u65f6\u95f4\u5185\u5b8c\u6210ACF\u7684\u8ba1\u7b97\u3002 \\( \\(\\vec r = IFFT(|FFT({\\vec x - \\mu \\over \\sigma})|^2)\\ \\ \\ \\mu: mean,\\ \\sigma: standard\\ deviation\\) \\) ACF\u7684\u56fe\u50cf\u5982\u4e0b\u6240\u793a\uff0c\u6a2a\u8f74\u4ee3\u8868\u4fe1\u53f7\u5e73\u79fb\u7684\u65f6\u95f4\u957f\u5ea6 \\(k\\) \uff1b\u7eb5\u8f74\u4ee3\u8868\u81ea\u76f8\u5173\u7cfb\u6570 \\(r_k\\) \uff0c\u53cd\u5e94\u4e86\u5e73\u79fb\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u7684\u300c\u76f8\u4f3c\u300d\u7a0b\u5ea6\u3002 Crane\u4f1a\u4f9d\u6b21\u9a8c\u8bc1\u6bcf\u4e00\u4e2a\u5019\u9009\u5468\u671f\u5bf9\u5e94\u7684\u81ea\u76f8\u5173\u7cfb\u6570\u662f\u5426\u4f4d\u4e8e\u300c\u5c71\u9876\u300d\u4e0a\uff1b\u5e76\u4e14\u9009\u62e9\u5bf9\u5e94\u300c\u6700\u9ad8\u5cf0\u300d\u7684\u90a3\u4e2a\u5019\u9009\u5468\u671f\u4e3a\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u4e3b\u5468\u671f\uff08\u57fa\u6ce2\u5468\u671f\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c\u9884\u6d4b\u3002 \u5982\u4f55\u5224\u65ad\u300c\u5c71\u9876\u300d\uff1f Crane\u5728\u4e24\u4fa7\u4e2a\u5404\u9009\u53d6\u4e00\u6bb5\u66f2\u7ebf\uff0c\u5206\u522b\u505a\u7ebf\u6027\u56de\u5f52\uff0c\u5f53\u56de\u5f52\u540e\u5de6\u3001\u53f3\u7684\u76f4\u7ebf\u659c\u7387\u5206\u522b\u5927\u4e8e\u3001\u5c0f\u4e8e\u96f6\u65f6\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e2a\u70b9\u662f\u5728\u4e00\u4e2a\u300c\u5c71\u9876\u300d\u4e0a\u3002","title":"\u5faa\u73af\u81ea\u76f8\u5173\u51fd\u6570"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_7","text":"\u6839\u636e\u4e0a\u4e00\u6b65\u5f97\u5230\u7684\u4e3b\u5468\u671f\uff0cCrane\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b9\u5f0f\u53bb\u62df\u5408\uff08\u9884\u6d4b\uff09\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u65f6\u5e8f\u6570\u636e maxValue \u9009\u53d6\u8fc7\u53bb\u51e0\u4e2a\u5468\u671f\u4e2d\u76f8\u540c\u65f6\u523b \\(t\\) \uff08\u4f8b\u5982\uff1a\u4e0b\u53486:00\uff09\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f \\(t\\) \u65f6\u523b\u7684\u9884\u6d4b\u503c\u3002 fft \u5bf9\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u505aFFT\u5f97\u5230\u9891\u8c31\u5e8f\u5217\uff0c\u53bb\u9664\u300c\u9ad8\u9891\u566a\u58f0\u300d\u540e\uff0c\u518d\u505aIFFT\uff08\u9006\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0c\u5c06\u5f97\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u9884\u6d4b\u7ed3\u679c\u3002","title":"\u9884\u6d4b"},{"location":"zh_TW/tutorials/timeseriees-forecasting-by-dsp/#_8","text":"Crane\u63d0\u4f9b\u4e86 TimeSeriesPrediction \uff0c\u901a\u8fc7\u8fd9\u4e2aCRD\uff0c\u7528\u6237\u53ef\u4ee5\u5bf9\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u4f8b\u5982\u5de5\u4f5c\u8d1f\u8d23\u7684CPU\u5229\u7528\u7387\u3001\u5e94\u7528\u7684QPS\u7b49\u7b49\u3002 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : tsp-workload-dsp namespace : default spec : targetRef : apiVersion : apps/v1 kind : Deployment name : test namespace : default predictionWindowSeconds : 7200 # \u63d0\u4f9b\u672a\u67657200\u79d2\uff082\u5c0f\u65f6\uff09\u7684\u9884\u6d4b\u6570\u636e\u3002Crane\u4f1a\u628a\u9884\u6d4b\u6570\u636e\u5199\u5230status\u4e2d\u3002 predictionMetrics : - resourceIdentifier : workload-cpu type : ExpressionQuery expressionQuery : expression : 'sum (irate (container_cpu_usage_seconds_total{container!=\"\",image!=\"\",container!=\"POD\",pod=~\"^test-.*$\"}[1m]))' # \u83b7\u53d6\u5386\u53f2\u76d1\u63a7\u6570\u636e\u7684\u67e5\u8be2\u8bed\u53e5 algorithm : algorithmType : \"dsp\" # \u6307\u5b9adsp\u4e3a\u9884\u6d4b\u7b97\u6cd5 dsp : sampleInterval : \"60s\" # \u76d1\u63a7\u6570\u636e\u7684\u91c7\u6837\u95f4\u9694\u4e3a1\u5206\u949f historyLength : \"15d\" # \u62c9\u53d6\u8fc7\u53bb15\u5929\u7684\u76d1\u63a7\u6307\u6807\u4f5c\u4e3a\u9884\u6d4b\u7684\u4f9d\u636e estimators : # \u6307\u5b9a\u9884\u6d4b\u65b9\u5f0f\uff0c\u5305\u62ec'maxValue'\u548c'fft'\uff0c\u6bcf\u4e00\u7c7b\u53ef\u4ee5\u6307\u5b9a\u591a\u4e2aestimator\uff0c\u914d\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\uff0ccrane\u4f1a\u9009\u53d6\u4e00\u4e2a\u62df\u5408\u5ea6\u6700\u9ad8\u7684\u53bb\u4ea7\u751f\u9884\u6d4b\u7ed3\u679c\u3002\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u4f7f\u7528'fft'\u3002 # maxValue: # - marginFraction: \"0.1\" fft : - marginFraction : \"0.2\" lowAmplitudeThreshold : \"1.0\" highFrequencyThreshold : \"0.05\" minNumOfSpectrumItems : 10 maxNumOfSpectrumItems : 20 \u4e0a\u9762\u793a\u4f8b\u4e2d\u7684\u4e00\u4e9bdsp\u53c2\u6570\u542b\u4e49\u5982\u4e0b\uff1a maxValue marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 fft marginFraction : \u62df\u5408\u51fa\u4e0b\u4e00\u4e2a\u5468\u671f\u7684\u5e8f\u5217\u540e\uff0c\u5c06\u6bcf\u4e00\u4e2a\u9884\u6d4b\u503c\u4e58\u4ee5 1 + marginFraction \uff0c\u4f8b\u5982 marginFraction = 0.1 ,\u5c31\u662f\u4e58\u4ee51.1\u3002 marginFraction \u7684\u4f5c\u7528\u662f\u5c06\u9884\u6d4b\u6570\u636e\u8fdb\u884c\u4e00\u5b9a\u6bd4\u4f8b\u7684\u653e\u5927\uff08\u6216\u7f29\u5c0f\uff09\u3002 lowAmplitudeThreshold : \u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\uff0c\u6240\u6709\u5e45\u5ea6\u4f4e\u4e8e\u8fd9\u4e2a\u4e0b\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002 highFrequencyThreshold : \u9891\u7387\u4e0a\u9650\uff0c\u6240\u6709\u9891\u7387\u9ad8\u4e8e\u8fd9\u4e2a\u4e0a\u9650\u7684\u9891\u7387\u5206\u91cf\u5c06\u88ab\u6ee4\u9664\u3002\u5355\u4f4dHz\uff0c\u4f8b\u5982\u5982\u679c\u60f3\u5ffd\u7565\u957f\u5ea6\u5c0f\u4e8e1\u5c0f\u65f6\u7684\u5468\u671f\u5206\u91cf\uff0c\u8bbe\u7f6e highFrequencyThreshold = 1/3600 \u3002 minNumOfSpectrumItems : \u81f3\u5c11\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 maxNumOfSpectrumItems \uff1a\u81f3\u591a\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u4e2a\u6570\u3002 \u7b80\u5355\u6765\u8bf4\uff0c\u4fdd\u7559\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u8d8a\u5c11\u3001\u9891\u7387\u4e0a\u9650\u8d8a\u4f4e\u3001\u9891\u8c31\u5e45\u5ea6\u4e0b\u9650\u8d8a\u9ad8\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5149\u6ed1\uff0c\u4f46\u4f1a\u4e22\u5931\u4e00\u4e9b\u7ec6\u8282\uff1b\u53cd\u4e4b\uff0c\u66f2\u7ebf\u6bdb\u523a\u8d8a\u591a\uff0c\u4fdd\u7559\u66f4\u591a\u7ec6\u8282\u3002 \u4e0b\u9762\u662f\u5bf9\u540c\u4e00\u65f6\u6bb5\u9884\u6d4b\u7684\u4e24\u6761\u66f2\u7ebf\uff0c\u84dd\u8272\u3001\u7eff\u8272\u7684 highFrequencyThreshold \u5206\u522b\u4e3a \\(0.01\\) \u548c \\(0.001\\) \uff0c\u84dd\u8272\u66f2\u7ebf\u8fc7\u6ee4\u6389\u4e86\u66f4\u591a\u7684\u9ad8\u9891\u5206\u91cf\uff0c\u56e0\u6b64\u66f4\u4e3a\u5e73\u6ed1\u3002 \u5e76\u6ca1\u6709\u4e00\u5957\u53c2\u6570\u914d\u7f6e\u9002\u5408\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u6839\u636e\u5e94\u7528\u6307\u6807\u7684\u7279\u70b9\uff0c\u53bb\u8c03\u6574\u7b97\u6cd5\u53c2\u6570\uff0c\u4ee5\u671f\u83b7\u5f97\u6700\u4f73\u7684\u9884\u6d4b\u6548\u679c\u3002 Crane\u63d0\u4f9b\u4e86\u4e00\u4e2aweb\u63a5\u53e3\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u8c03\u6574\u53c2\u6570\u540e\uff0c\u76f4\u89c2\u7684\u770b\u5230\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u6b65\u9aa4\u5982\u4e0b\uff1a \u4fee\u6539 TimeSeriesPrediction \u4e2d\u7684 estimators \u7684\u53c2\u6570\u3002 \u8bbf\u95eecraned http server\u7684 api/prediction/debug/<namespace>/<timeseries prediction name> \uff0c\u67e5\u770b\u53c2\u6570\u6548\u679c\uff08\u5982\u4e0b\u56fe\uff09\u3002 \u4e0a\u8ff0\u6b65\u9aa4\u53ef\u591a\u6b21\u6267\u884c\uff0c\u76f4\u5230\u5f97\u5230\u6ee1\u610f\u7684\u9884\u6d4b\u6548\u679c\u3002 \u901a\u8fc7port-forward\u8fdb\u884c\u672c\u5730\u8c03\u8bd5 craned http server\u7684\u7aef\u53e3\u901a\u8fc7craned\u542f\u52a8\u53c2\u6570 --server-bind-port \u8bbe\u7f6e\uff0c\u9ed8\u8ba4\u4e3a 8082 \u3002 \u6253\u5f00\u7ec8\u7aef\uff0c $kubectl -n crane-system port-forward service/craned 8082:8082 Forwarding from 127.0.0.1:8082 -> 8082 Forwarding from [::1]:8082 -> 8082 \u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee http://localhost:8082/api/prediction/debug/<namespace>/<timeseries prediction name>","title":"\u5e94\u7528"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/","text":"EffectiveHorizontalPodAutoscaler \u00b6 EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with HorizontalPodAutoscaler but extends more features. EffectiveHorizontalPodAutoscaler supports prediction-driven autoscaling. With this capability, user can forecast the incoming peak flow and scale up their application ahead, also user can know when the peak flow will end and scale down their application gracefully. Besides that, EffectiveHorizontalPodAutoscaler also defines several scale strategies to support different scaling scenarios. Features \u00b6 A EffectiveHorizontalPodAutoscaler sample yaml looks like below: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef is the reference to the workload that should be scaled. MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. ScaleStrategy indicates the strategy to scaling target, value can be \"Auto\" and \"Preview\". Metrics contains the specifications for which to use to calculate the desired replica count. Prediction defines configurations for predict resources.If unspecified, defaults don't enable prediction. PredictionWindowSeconds is the time window to predict metrics in the future. Prediction-driven autoscaling \u00b6 Most of online applications follow regular pattern. We can predict future trend of hours or days. DSP is a time series prediction algorithm that applicable for application metrics prediction. The following shows a sample EffectiveHorizontalPodAutoscaler yaml with prediction enabled. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" Metric conversion \u00b6 When user defines spec.metrics in EffectiveHorizontalPodAutoscaler and prediction configuration is enabled, EffectiveHPAController will convert it to a new metric and configure the background HorizontalPodAutoscaler. This is a source EffectiveHorizontalPodAutoscaler yaml for metric definition. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 It's converted to underlying HorizontalPodAutoscaler metrics yaml. apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource In this sample, the resource metric defined by user is converted into two metrics: prediction metric and origin metric. prediction metric is custom metrics that provided by component MetricAdapter. Since custom metric doesn't support targetAverageUtilization , it's converted to targetAverageValue based on target pod cpu request. origin metric is equivalent to user defined metrics in EffectiveHorizontalPodAutoscaler, to fall back to baseline user defined in case of some unexpected situation e.g. business traffic sudden growth. HorizontalPodAutoscaler will calculate on each metric, and propose new replicas based on that. The largest one will be picked as the new scale. Horizontal scaling process \u00b6 There are six steps of prediction and scaling process: EffectiveHPAController create HorizontalPodAutoscaler and TimeSeriesPrediction instance PredictionCore get historic metric from prometheus and persist into TimeSeriesPrediction HPAController read metrics from KubeApiServer KubeApiServer forward requests to MetricAdapter and MetricServer HPAController calculate all metric results and propose a new scale replicas for target HPAController scale target with Scale Api Below is the process flow. Use case \u00b6 Let's take one use case that using EffectiveHorizontalPodAutoscaler in production cluster. We did a profiling on the load history of one application in production and replayed it in staging environment. With the same application, we leverage both EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler to manage the scale and compare the result. From the red line in below chart, we can see its actual total cpu usage is high at ~8am, ~12pm, ~8pm and low in midnight. The green line shows the prediction cpu usage trend. Below is the comparison result between EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler. The red line is the replica number generated by HorizontalPodAutoscaler and the green line is the result from EffectiveHorizontalPodAutoscaler. We can see significant improvement with EffectiveHorizontalPodAutoscaler: Scale up in advance before peek flow Scale down gracefully after peek flow Fewer replicas changes than HorizontalPodAutoscaler ScaleStrategy \u00b6 EffectiveHorizontalPodAutoscaler provides two strategies for scaling: Auto and Preview . User can change the strategy at runtime, and it will take effect on the fly. Auto \u00b6 Auto strategy achieves automatic scaling based on metrics. It is the default strategy. With this strategy, EffectiveHorizontalPodAutoscaler will create and control a HorizontalPodAutoscaler instance in backend. We don't recommend explicit configuration on the underlying HorizontalPodAutoscaler because it will be overridden by EffectiveHPAController. If user delete EffectiveHorizontalPodAutoscaler, HorizontalPodAutoscaler will be cleaned up too. Preview \u00b6 Preview strategy means EffectiveHorizontalPodAutoscaler won't change target's replicas automatically, so you can preview the calculated replicas and control target's replicas by themselves. User can switch from default strategy to this one by applying spec.scaleStrategy to Preview . It will take effect immediately, During the switch, EffectiveHPAController will disable HorizontalPodAutoscaler if exists and scale the target to the value spec.specificReplicas , if user not set spec.specificReplicas , when ScaleStrategy is change to Preview, it will just stop scaling. A sample preview configuration looks like following: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target HorizontalPodAutoscaler compatible \u00b6 EffectiveHorizontalPodAutoscaler is designed to be compatible with k8s native HorizontalPodAutoscaler, because we don't reinvent the autoscaling part but take advantage of the extension from HorizontalPodAutoscaler and build a high level autoscaling CRD. EffectiveHorizontalPodAutoscaler support all abilities from HorizontalPodAutoscaler like metricSpec and behavior. EffectiveHorizontalPodAutoscaler will continue support incoming new feature from HorizontalPodAutoscaler. EffectiveHorizontalPodAutoscaler status \u00b6 This is a yaml from EffectiveHorizontalPodAutoscaler.Status apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0 Cron-based autoscaling \u00b6 EffectiveHorizontalPodAutoscaler supports cron based autoscaling. Besides based on monitoring metrics, sometimes there are differences between holiday and weekdays in workload traffic, and a simple prediction algorithm may not work relatively well. Then you can make up for the lack of prediction by setting the weekend cron to have a larger number of replicas. For some non-web traffic applications, for example, some applications do not need to work on weekends, and then want to reduce the workload replicas to 1, you can also configure cron to reduce the cost for your service. Following are cron main fields in the ehpa spec: CronSpec: You can set multiple cron autoscaling configurations, cron cycle can set the start time and end time of the cycle, and the number of replicas of the workload can be continuously guaranteed to the set target value within the time range. Name: cron identifier TargetReplicas: the target number of replicas of the workload in this cron time range. Start: The start time of the cron, in the standard linux crontab format End: the end time of the cron, in the standard linux crontab format Current cron autoscaling capabilities from some manufacturers and communities have some shortcomings. The cron capability is provided separately, has no global view of autoscaling, poor compatibility with HPA, and conflicts with other scale trigger. The semantics and behavior of cron do not match very well, and are even very difficult to understand when used, which can easily mislead users and lead to autoscaling failures. The following figure shows the comparison between the current EHPA cron autoscaling implementation and other cron capabilities. To address the above issues, the cron autoscaling implemented by EHPA is designed on the basis of compatibility with HPA, and cron, as an indicator of HPA, acts on the workload object together with other indicators. In addition, the setting of cron is also very simple. When cron is configured separately, the default scaling of the workload will not be performed when it is not in the active time range. Cron working without other metrics \u00b6 You can just configure cron itself to work, assume you have no other metrics configured. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Better to setting cron to fill the one complete time period such as one day, one week # Below is one day cron scheduling, it #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Local timezone means you use the server's(or maybe is a container's) timezone which the craned running in. for example, if your craned started as utc timezone, then it is utc. if it started as Asia/Shanghai, then it is Asia/Shanghai. crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec has following fields. name defines the name of the cron, cron name must be unique in the same ehpa description defines the details description of the cron. it can be empty. timezone defines the timezone of the cron which the crane to schedule in. If unspecified, default use UTC timezone. you can set it to Local which means you use timezone of the container of crane service running in. Also, America/Los_Angeles is ok. start defines the cron start time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron end defines the cron end time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron targetReplicas defines the target replicas the workload to scale when the cron is active, which means current time is between start and end. Above means each day, the workload needs to keep the replicas hourly. #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Remember not to set start time is after end . For example, when you set following: crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 Above is not valid because the start will be always later than end. The hpa controller will always get the workload's desired replica to scale, which means keep the original replicas. Horizontal scaling process \u00b6 There are six steps of cron-driven and scaling process: EffectiveHPAController creates HorizontalPodAutoscaler which is injected to external cron metrics in spec. HPAController reads cron external metrics from KubeApiServer KubeApiServer forwards requests to MetricAdapter and MetricServer The MetricAdapter finds the cron scaler for target hpa, and detect if the cron scaler is active, which means the current time is between the cron start and end schedule time. It will return the TargetReplicas specified in the CronSpec . HPAController calculates all metric results and propose a new scale replicas for target by selecting the largest one. HPAController scales target with Scale Api When use ehpa, users can configure only cron metric, let the ehpa to be used as cron hpa. Multiple crons of one ehpa will be transformed to one external metric. HPA will fetch this external cron metric and calculates target replicas when reconcile. HPA will select the largest proposal replicas to scale the workload from multiple metrics. Cron working with other metrics together \u00b6 EffectiveHorizontalPodAutoscaler is compatible with HorizontalPodAutoscaler(Which is kubernetes built in). So if you configured metrics for HPA such as cpu or memory, then the HPA will scale by the real time metric it observed. With EHPA, users can configure CronMetric\u3001PredictionMetric\u3001OriginalMetric at the same time. We highly recomend you configure metrics of all dimensions. They are represtenting the cron replicas, prior predicted replicas, posterior observed replicas. This is a powerful feature. Because HPA always pick the largest replicas calculated by all dimensional metrics to scale. Which will gurantee your workload's QoS, when you configure three types of autoscaling at the same time, the replicas caculated by real metric observed is largest, then it will use the max one. Although the replicas caculated by prediction metric is smaller for some unexpected reason. So you don't be worried about the QoS. Mechanism \u00b6 When metrics adapter deal with the external cron metric requests, metrics adapter will do following steps. graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; No active cron now, there are two cases: no other hpa metrics work with cron together, then return current workload replicas to keep the original desired replicas other hpa metrics work with cron together, then return min value to remove the cron impact for other metrics. when cron is working with other metrics together, it should not return workload's original desired replicas, because there maybe other metrics want to trigger the workload to scale in. hpa controller select max replicas computed by all metrics(this is hpa default policy in hard code), cron will impact the hpa. so we should remove the cron effect when cron is not active, it should return min value. Has active ones. we use the largest targetReplicas specified in cron spec. Basically, there should not be more then one active cron at the same time period, it is not a best practice. HPA will get the cron external metric value, then it will compute the replicas by itself. Use Case \u00b6 When you need to keep the workload replicas to minimum at midnight, you configured cron. And you need the HPA to get the real metric observed by metrics server to do scale based on real time observed metric. At last you configure a prediction-driven metric to do scale up early and scale down lately by predicting way. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100 FAQ \u00b6 error: unable to get metric crane_pod_cpu_usage \u00b6 When checking the status for EffectiveHorizontalPodAutoscaler, you may see this error: - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive reason: Not all workload's cpu metric are predictable, if predict your workload failed, it will show above errors. solution: Just waiting. the Prediction algorithm need more time, you can see DSP section to know more about this algorithm. EffectiveHorizontalPodAutoscaler have a protection mechanism when prediction failed, it will use the actual cpu utilization to do autoscaling.","title":"\u9ad8\u6548\u6c34\u5e73\u5f48\u6027"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler","text":"EffectiveHorizontalPodAutoscaler helps you manage application scaling in an easy way. It is compatible with HorizontalPodAutoscaler but extends more features. EffectiveHorizontalPodAutoscaler supports prediction-driven autoscaling. With this capability, user can forecast the incoming peak flow and scale up their application ahead, also user can know when the peak flow will end and scale down their application gracefully. Besides that, EffectiveHorizontalPodAutoscaler also defines several scale strategies to support different scaling scenarios.","title":"EffectiveHorizontalPodAutoscaler"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#features","text":"A EffectiveHorizontalPodAutoscaler sample yaml looks like below: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache spec : scaleTargetRef : #(1) apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 #(2) maxReplicas : 10 #(3) scaleStrategy : Auto #(4) metrics : #(5) - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 prediction : #(6) predictionWindowSeconds : 3600 #(7) predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" ScaleTargetRef is the reference to the workload that should be scaled. MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. ScaleStrategy indicates the strategy to scaling target, value can be \"Auto\" and \"Preview\". Metrics contains the specifications for which to use to calculate the desired replica count. Prediction defines configurations for predict resources.If unspecified, defaults don't enable prediction. PredictionWindowSeconds is the time window to predict metrics in the future.","title":"Features"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#prediction-driven-autoscaling","text":"Most of online applications follow regular pattern. We can predict future trend of hours or days. DSP is a time series prediction algorithm that applicable for application metrics prediction. The following shows a sample EffectiveHorizontalPodAutoscaler yaml with prediction enabled. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : prediction : predictionWindowSeconds : 3600 predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\"","title":"Prediction-driven autoscaling"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#metric-conversion","text":"When user defines spec.metrics in EffectiveHorizontalPodAutoscaler and prediction configuration is enabled, EffectiveHPAController will convert it to a new metric and configure the background HorizontalPodAutoscaler. This is a source EffectiveHorizontalPodAutoscaler yaml for metric definition. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 It's converted to underlying HorizontalPodAutoscaler metrics yaml. apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler spec : metrics : - pods : metric : name : crane_pod_cpu_usage selector : matchLabels : autoscaling.crane.io/effective-hpa-uid : f9b92249-eab9-4671-afe0-17925e5987b8 target : type : AverageValue averageValue : 100m type : Pods - resource : name : cpu target : type : Utilization averageUtilization : 50 type : Resource In this sample, the resource metric defined by user is converted into two metrics: prediction metric and origin metric. prediction metric is custom metrics that provided by component MetricAdapter. Since custom metric doesn't support targetAverageUtilization , it's converted to targetAverageValue based on target pod cpu request. origin metric is equivalent to user defined metrics in EffectiveHorizontalPodAutoscaler, to fall back to baseline user defined in case of some unexpected situation e.g. business traffic sudden growth. HorizontalPodAutoscaler will calculate on each metric, and propose new replicas based on that. The largest one will be picked as the new scale.","title":"Metric conversion"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontal-scaling-process","text":"There are six steps of prediction and scaling process: EffectiveHPAController create HorizontalPodAutoscaler and TimeSeriesPrediction instance PredictionCore get historic metric from prometheus and persist into TimeSeriesPrediction HPAController read metrics from KubeApiServer KubeApiServer forward requests to MetricAdapter and MetricServer HPAController calculate all metric results and propose a new scale replicas for target HPAController scale target with Scale Api Below is the process flow.","title":"Horizontal scaling process"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#use-case","text":"Let's take one use case that using EffectiveHorizontalPodAutoscaler in production cluster. We did a profiling on the load history of one application in production and replayed it in staging environment. With the same application, we leverage both EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler to manage the scale and compare the result. From the red line in below chart, we can see its actual total cpu usage is high at ~8am, ~12pm, ~8pm and low in midnight. The green line shows the prediction cpu usage trend. Below is the comparison result between EffectiveHorizontalPodAutoscaler and HorizontalPodAutoscaler. The red line is the replica number generated by HorizontalPodAutoscaler and the green line is the result from EffectiveHorizontalPodAutoscaler. We can see significant improvement with EffectiveHorizontalPodAutoscaler: Scale up in advance before peek flow Scale down gracefully after peek flow Fewer replicas changes than HorizontalPodAutoscaler","title":"Use case"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#scalestrategy","text":"EffectiveHorizontalPodAutoscaler provides two strategies for scaling: Auto and Preview . User can change the strategy at runtime, and it will take effect on the fly.","title":"ScaleStrategy"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#auto","text":"Auto strategy achieves automatic scaling based on metrics. It is the default strategy. With this strategy, EffectiveHorizontalPodAutoscaler will create and control a HorizontalPodAutoscaler instance in backend. We don't recommend explicit configuration on the underlying HorizontalPodAutoscaler because it will be overridden by EffectiveHPAController. If user delete EffectiveHorizontalPodAutoscaler, HorizontalPodAutoscaler will be cleaned up too.","title":"Auto"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#preview","text":"Preview strategy means EffectiveHorizontalPodAutoscaler won't change target's replicas automatically, so you can preview the calculated replicas and control target's replicas by themselves. User can switch from default strategy to this one by applying spec.scaleStrategy to Preview . It will take effect immediately, During the switch, EffectiveHPAController will disable HorizontalPodAutoscaler if exists and scale the target to the value spec.specificReplicas , if user not set spec.specificReplicas , when ScaleStrategy is change to Preview, it will just stop scaling. A sample preview configuration looks like following: apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler spec : scaleStrategy : Preview # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Preview\". specificReplicas : 5 # SpecificReplicas specify the target replicas. status : expectReplicas : 4 # expectReplicas is the calculated replicas that based on prediction metrics or spec.specificReplicas. currentReplicas : 4 # currentReplicas is actual replicas from target","title":"Preview"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontalpodautoscaler-compatible","text":"EffectiveHorizontalPodAutoscaler is designed to be compatible with k8s native HorizontalPodAutoscaler, because we don't reinvent the autoscaling part but take advantage of the extension from HorizontalPodAutoscaler and build a high level autoscaling CRD. EffectiveHorizontalPodAutoscaler support all abilities from HorizontalPodAutoscaler like metricSpec and behavior. EffectiveHorizontalPodAutoscaler will continue support incoming new feature from HorizontalPodAutoscaler.","title":"HorizontalPodAutoscaler compatible"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#effectivehorizontalpodautoscaler-status","text":"This is a yaml from EffectiveHorizontalPodAutoscaler.Status apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler status : conditions : - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : the HPA controller was able to get the target's current scale reason : SucceededGetScale status : \"True\" type : AbleToScale - lastTransitionTime : \"2021-11-30T08:18:59Z\" message : Effective HPA is ready reason : EffectiveHorizontalPodAutoscalerReady status : \"True\" type : Ready currentReplicas : 1 expectReplicas : 0","title":"EffectiveHorizontalPodAutoscaler status"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-based-autoscaling","text":"EffectiveHorizontalPodAutoscaler supports cron based autoscaling. Besides based on monitoring metrics, sometimes there are differences between holiday and weekdays in workload traffic, and a simple prediction algorithm may not work relatively well. Then you can make up for the lack of prediction by setting the weekend cron to have a larger number of replicas. For some non-web traffic applications, for example, some applications do not need to work on weekends, and then want to reduce the workload replicas to 1, you can also configure cron to reduce the cost for your service. Following are cron main fields in the ehpa spec: CronSpec: You can set multiple cron autoscaling configurations, cron cycle can set the start time and end time of the cycle, and the number of replicas of the workload can be continuously guaranteed to the set target value within the time range. Name: cron identifier TargetReplicas: the target number of replicas of the workload in this cron time range. Start: The start time of the cron, in the standard linux crontab format End: the end time of the cron, in the standard linux crontab format Current cron autoscaling capabilities from some manufacturers and communities have some shortcomings. The cron capability is provided separately, has no global view of autoscaling, poor compatibility with HPA, and conflicts with other scale trigger. The semantics and behavior of cron do not match very well, and are even very difficult to understand when used, which can easily mislead users and lead to autoscaling failures. The following figure shows the comparison between the current EHPA cron autoscaling implementation and other cron capabilities. To address the above issues, the cron autoscaling implemented by EHPA is designed on the basis of compatibility with HPA, and cron, as an indicator of HPA, acts on the workload object together with other indicators. In addition, the setting of cron is also very simple. When cron is configured separately, the default scaling of the workload will not be performed when it is not in the active time range.","title":"Cron-based autoscaling"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-without-other-metrics","text":"You can just configure cron itself to work, assume you have no other metrics configured. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-local spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Better to setting cron to fill the one complete time period such as one day, one week # Below is one day cron scheduling, it #(targetReplicas) #80 -------- --------- ---------- # | | | | | | #10 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Local timezone means you use the server's(or maybe is a container's) timezone which the craned running in. for example, if your craned started as utc timezone, then it is utc. if it started as Asia/Shanghai, then it is Asia/Shanghai. crons : - name : \"cron1\" timezone : \"Local\" description : \"scale down\" start : \"0 0 ? * *\" end : \"0 6 ? * *\" targetReplicas : 10 - name : \"cron2\" timezone : \"Local\" description : \"scale up\" start : \"0 6 ? * *\" end : \"0 9 ? * *\" targetReplicas : 80 - name : \"cron3\" timezone : \"Local\" description : \"scale down\" start : \"00 9 ? * *\" end : \"00 11 ? * *\" targetReplicas : 10 - name : \"cron4\" timezone : \"Local\" description : \"scale up\" start : \"00 11 ? * *\" end : \"00 14 ? * *\" targetReplicas : 80 - name : \"cron5\" timezone : \"Local\" description : \"scale down\" start : \"00 14 ? * *\" end : \"00 17 ? * *\" targetReplicas : 10 - name : \"cron6\" timezone : \"Local\" description : \"scale up\" start : \"00 17 ? * *\" end : \"00 20 ? * *\" targetReplicas : 80 - name : \"cron7\" timezone : \"Local\" description : \"scale down\" start : \"00 20 ? * *\" end : \"00 00 ? * *\" targetReplicas : 10 CronSpec has following fields. name defines the name of the cron, cron name must be unique in the same ehpa description defines the details description of the cron. it can be empty. timezone defines the timezone of the cron which the crane to schedule in. If unspecified, default use UTC timezone. you can set it to Local which means you use timezone of the container of crane service running in. Also, America/Los_Angeles is ok. start defines the cron start time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron end defines the cron end time schedule, which is crontab format. see https://en.wikipedia.org/wiki/Cron targetReplicas defines the target replicas the workload to scale when the cron is active, which means current time is between start and end. Above means each day, the workload needs to keep the replicas hourly. #80 -------- --------- ---------- # | | | | | | #1 ------------ ----- -------- ---------- #(time) 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Remember not to set start time is after end . For example, when you set following: crons: - name: \"cron2\" timezone: \"Local\" description: \"scale up\" start: \"0 9 ? * *\" end: \"0 6 ? * *\" targetReplicas: 80 Above is not valid because the start will be always later than end. The hpa controller will always get the workload's desired replica to scale, which means keep the original replicas.","title":"Cron working without other metrics"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#horizontal-scaling-process_1","text":"There are six steps of cron-driven and scaling process: EffectiveHPAController creates HorizontalPodAutoscaler which is injected to external cron metrics in spec. HPAController reads cron external metrics from KubeApiServer KubeApiServer forwards requests to MetricAdapter and MetricServer The MetricAdapter finds the cron scaler for target hpa, and detect if the cron scaler is active, which means the current time is between the cron start and end schedule time. It will return the TargetReplicas specified in the CronSpec . HPAController calculates all metric results and propose a new scale replicas for target by selecting the largest one. HPAController scales target with Scale Api When use ehpa, users can configure only cron metric, let the ehpa to be used as cron hpa. Multiple crons of one ehpa will be transformed to one external metric. HPA will fetch this external cron metric and calculates target replicas when reconcile. HPA will select the largest proposal replicas to scale the workload from multiple metrics.","title":"Horizontal scaling process"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#cron-working-with-other-metrics-together","text":"EffectiveHorizontalPodAutoscaler is compatible with HorizontalPodAutoscaler(Which is kubernetes built in). So if you configured metrics for HPA such as cpu or memory, then the HPA will scale by the real time metric it observed. With EHPA, users can configure CronMetric\u3001PredictionMetric\u3001OriginalMetric at the same time. We highly recomend you configure metrics of all dimensions. They are represtenting the cron replicas, prior predicted replicas, posterior observed replicas. This is a powerful feature. Because HPA always pick the largest replicas calculated by all dimensional metrics to scale. Which will gurantee your workload's QoS, when you configure three types of autoscaling at the same time, the replicas caculated by real metric observed is largest, then it will use the max one. Although the replicas caculated by prediction metric is smaller for some unexpected reason. So you don't be worried about the QoS.","title":"Cron working with other metrics together"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#mechanism","text":"When metrics adapter deal with the external cron metric requests, metrics adapter will do following steps. graph LR A[Start] --> B{Active Cron?}; B -->|Yes| C(largest targetReplicas) --> F; B -->|No| D{Work together with other metrics?}; D -->|Yes| G(minimum replicas) --> F; D -->|No| H(current replicas) --> F; F[Result workload replicas]; No active cron now, there are two cases: no other hpa metrics work with cron together, then return current workload replicas to keep the original desired replicas other hpa metrics work with cron together, then return min value to remove the cron impact for other metrics. when cron is working with other metrics together, it should not return workload's original desired replicas, because there maybe other metrics want to trigger the workload to scale in. hpa controller select max replicas computed by all metrics(this is hpa default policy in hard code), cron will impact the hpa. so we should remove the cron effect when cron is not active, it should return min value. Has active ones. we use the largest targetReplicas specified in cron spec. Basically, there should not be more then one active cron at the same time period, it is not a best practice. HPA will get the cron external metric value, then it will compute the replicas by itself.","title":"Mechanism"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#use-case_1","text":"When you need to keep the workload replicas to minimum at midnight, you configured cron. And you need the HPA to get the real metric observed by metrics server to do scale based on real time observed metric. At last you configure a prediction-driven metric to do scale up early and scale down lately by predicting way. apiVersion : autoscaling.crane.io/v1alpha1 kind : EffectiveHorizontalPodAutoscaler metadata : name : php-apache-multi-dimensions spec : # ScaleTargetRef is the reference to the workload that should be scaled. scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : php-apache minReplicas : 1 # MinReplicas is the lower limit replicas to the scale target which the autoscaler can scale down to. maxReplicas : 100 # MaxReplicas is the upper limit replicas to the scale target which the autoscaler can scale up to. scaleStrategy : Auto # ScaleStrategy indicate the strategy to scaling target, value can be \"Auto\" and \"Manual\". # Metrics contains the specifications for which to use to calculate the desired replica count. metrics : - type : Resource resource : name : cpu target : type : Utilization averageUtilization : 50 # Prediction defines configurations for predict resources. # If unspecified, defaults don't enable prediction. prediction : predictionWindowSeconds : 3600 # PredictionWindowSeconds is the time window to predict metrics in the future. predictionAlgorithm : algorithmType : dsp dsp : sampleInterval : \"60s\" historyLength : \"3d\" crons : - name : \"cron1\" description : \"scale up\" start : \"0 0 ? * 6\" end : \"00 23 ? * 0\" targetReplicas : 100","title":"Use Case"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#faq","text":"","title":"FAQ"},{"location":"zh_TW/tutorials/using-effective-hpa-to-scaling-with-effectiveness/#error-unable-to-get-metric-crane_pod_cpu_usage","text":"When checking the status for EffectiveHorizontalPodAutoscaler, you may see this error: - lastTransitionTime : \"2022-05-15T14:05:43Z\" message : 'the HPA was unable to compute the replica count: unable to get metric crane_pod_cpu_usage: unable to fetch metrics from custom metrics API: TimeSeriesPrediction is not ready. ' reason : FailedGetPodsMetric status : \"False\" type : ScalingActive reason: Not all workload's cpu metric are predictable, if predict your workload failed, it will show above errors. solution: Just waiting. the Prediction algorithm need more time, you can see DSP section to know more about this algorithm. EffectiveHorizontalPodAutoscaler have a protection mechanism when prediction failed, it will use the actual cpu utilization to do autoscaling.","title":"error: unable to get metric crane_pod_cpu_usage"},{"location":"zh_TW/tutorials/using-qos-ensurance/","text":"Qos Ensurance \u00b6 QoS ensurance guarantees the stability of the pods running on Kubernetes. It has the ability of interference detection and active avoidance. When pod with higher priority is affected by resource competition, disable schedule, throttle and evict will be applied to pod with lower priority to support interference detection and user-defined operation of user-defined indicators; At the same time, it has enhanced bypass cpuset management capability to improve resource utilization efficiency while binding cores. It has the dynamic resource oversold ability enhanced by the prediction algorithm, and reuses the idle resources. At the same time, it combines the prediction ability of the crane to better reuse the idle resources. At the same time, it has the elastic resource limitation function to limit the workload of reusing idle resources. Qos Ensurance Architecture \u00b6 Qos ensurance's architecture is shown as below. It contains three modules. state collector: collect metrics periodically anomaly analyzer: analyze the node triggered anomaly used collected metrics action executor: execute avoidance actions, include disable scheduling, throttle and eviction. The main process: State collector synchronizes policies from kube-apiserver. If the policies are changed, the state collector updates the collectors. State collector collects metrics periodically. State collector transmits metrics to anomaly analyzer. Anomaly analyzer ranges all rules to analyze the avoidance threshold or the restored threshold reached. Anomaly analyzer merges the analyzed results and notices the avoidance actions. Action executor executes actions based on the analyzed results. Interference Detection and Active Avoidance \u00b6 Disable Scheduling \u00b6 The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, disable schedule action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 # The minimum wait time of the node from scheduling disable status to normal status apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) We consider the rule is triggered, when the threshold reached continued so many times We consider the rule is restored, when the threshold not reached continued so many times Name of AvoidanceAction which be associated Strategy for the action, you can set it \"Preview\" to not perform actually Name of metric Threshold of metric Please check the video to learn more about the scheduling disable actions. Throttle \u00b6 The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, throttle action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" The minimal ratio of the CPU quota, if the pod is throttled lower than this ratio, it will be set to this. The step for throttle action. It will reduce this percentage of CPU quota in each avoidance triggered.It will increase this percentage of CPU quota in each restored. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000 Eviction \u00b6 The following YAML is another case, low priority pods on the node will be evicted, when the node CPU usage trigger the threshold. apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" Duration in seconds the pod needs to terminate gracefully. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 Strategy for the action, \"Preview\" to not perform actually Supported Metrics \u00b6 Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization Accurately Perform Avoidance Actions \u00b6 Through the following two points, the excessive operation of low-quality pod can be avoided, and the gap between the metrics and the specified waterline can be reduced faster, so as to ensure that the high-priority service is not affected 1. Sort pod Crane implements some general sorting methods (which will be improved later): ClassAndPriority: compare the QOSClass and class value of two pods, compare QOSClass first, and then class value; Those with high priority are ranked later and have higher priority runningTime: compare the running time of two pods. The one with long running time is ranked later and has higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the consumption of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod Taking the ranking of CPU usage metric as an example, it also extends some ranking strategies related to its own metric, such as the ranking of CPU usage, which will compare the priority of two pods in turn. If the priority is the same, then compare the CPU consumption. If the CPU consumption is also the same, continue to compare the extended CPU resource consumption, and finally compare the running time of pod, when there is a difference in an indicator, the comparison result can be returned: orderedby (classandpriority, CpuUsage, extcpuusage, runningtime) Sort(pods) Refer to the waterline and pod usage to perform avoidance action //Divide all the metrics that trigger the waterline threshold into two parts according to their quantified attribute metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // If there is a metric that cannot be quantified, obtain the metric of a throttleable with the highest actionpriority to operate on all selected pods if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //Get the latest usage, get the gap to waterline ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //If the real-time consumption of metric in the trigger waterline threshold cannot be obtained, chose the metric which is throttleable with the highest actionpriority to suppress all selected pods if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //Traverse the quantifiable metrics in the metrics that trigger the waterline: if the metric has a sorting method, use its sortfunc to sort the pod directly, //otherwise use generalsorter to sort; Then use its corresponding operation method to operate the pod, and calculate the amount of resources released from the corresponding metric until the gap between the corresponding metric and the waterline no longer exists for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } About extending user-defined metrics and sorting, it is introduced in \"User-defined metrics interference detection avoidance and user-defined sorting\". Enhanced bypass cpuset management capability \u00b6 Kubelet supports the static CPU manager strategy. When the guaranteed pod runs on the node, kebelet will allocate the specified dedicated CPU for the pod, which cannot be occupied by other processes. This ensures the CPU monopoly of the guaranteed pod, but also causes the low utilization of CPU and nodes, resulting in a certain waste. Crane agent provides a new strategy for cpuset management, allowing pod and other pod to share CPU. When it specifies CPU binding core, it can make use of the advantages of less context switching and higher cache affinity of binding core, and also allow other workload to deploy and share, so as to improve resource utilization. Three types of pod cpuset are provided: Exclusive: after binding the core, other containers can no longer use the CPU and monopolize the CPU Share: other containers can use the CPU after binding the core None: select the CPU that is not occupied by the container of exclusive pod, can use the binding core of share type Share type binding strategy can make use of the advantages of less context switching and higher cache affinity, and can also be shared by other workload deployments to improve resource utilization Relax the restrictions on binding cores in kubelet Originally, it was required that the CPU limit of all containers be equal to the CPU request. Here, it is only required that the CPU limit of any container be greater than or equal to 1 and equal to the CPU request to set the binding core for the container Support modifying the cpuset policy of pod during the running of pod, which will take effect immediately The CPU manager policy of pod is converted from none to share and from exclusive to share without restart How to use: 1. Set the cpuset manager of kubelet to \"None\" 2. Set CPU manager policy through pod annotation qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share Dynamic resource oversold enhanced by prediction algorithm \u00b6 In order to improve the stability, users usually set the request value higher than the actual usage when deploying applications, resulting in a waste of resources. In order to improve the resource utilization of nodes, users will deploy some besteffort applications in combination, using idle resources to realize oversold; However, due to the lack of resource limit and request constraints and related information in these applications, scheduler may still schedule these pods to nodes with high load, which is inconsistent with our original intention, so it is best to schedule based on the free resources of nodes. Crane collects the idle resources of nodes in the following two ways, and takes them as the idle resources of nodes after synthesis, which enhances the accuracy of resource evaluation: CPU usage information collected locally nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal ExclusiveCPUIdle refers to the idle amount of CPU occupied by the pod whose CPU manager policy is exclusive. Although this part of resources is idle, it cannot be reused because of monopoly, so it is counted as used ExtResContainerCpuUsageTotal refers to the CPU consumption used as dynamic resources, which needs to be subtracted to avoid secondary calculation Create a TSP of node CPU usage, which is automatically created by default, and will predict node CPU usage based on history apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default Combine the prediction algorithm with the current actual consumption to calculate the remaining available resources of the node, and give it to the node as an extended resource. Pod can indicate that the extended resource is used as an offline job to use the idle resources, so as to improve the resource utilization rate of the node; How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> , as follows spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\" Elastic resource restriction function \u00b6 The native besteffort application lacks a fair guarantee of resource usage. Crane guarantees that the CPU usage of the besteffort pod using dynamic resources is limited within the reasonable range of its allowable use. The agent guarantees that the actual consumption of the pod using extended resources will not exceed its stated limit. At the same time, when the CPU competes, it can also compete fairly according to its stated amount; At the same time, pod using elastic resources will also be managed by the waterline function. How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> User-defined metrics interference detection avoidance and user-defined sorting \u00b6 The use of user-defined metrics interference detection avoidance and user-defined sorting is the same as the process described in the \"Accurately Perform Avoidance Actions\". Here is how to customize your own metrics to participate in the interference detection avoidance process In order to better sort and accurately control metrics configured based on NodeQoSEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metric include the following, and these fields can be realized by customized indicators: Name Indicates the name of metric, which should be consistent with the metric name collected in the collector module ActionPriority Indicates the priority of the metric. 0 is the lowest and 10 is the highest SortAble Indicates whether the metric can be sorted. If it is true, the corresponding SortFunc needs to be implemented SortFunc The corresponding sorting method. The sorting method can be arranged and combined with some general methods, and then combined with the sorting of the metric itself, which will be introduced in detail below ThrottleAble Indicates whether pod can be suppressed for this metric. For example, for the metric of CPU usage, there are corresponding suppression methods, but for the metric of memory usage, pod can only be evicted, and effective suppression cannot be carried out ThrottleQuantified Indicates whether the amount of resources corresponding to metric released after suppressing (restoring) a pod can be accurately calculated. We call the metric that can be accurately quantified as quantifiable, otherwise it is not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; Memory usage does not belong to suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc The specific method of executing throttle action. If throttle is not available, the returned released is null RestoreFunc After being throttled, the specific method of performing the recovery action. If restore is not allowed, the returned released is null Evictable, EvictQuantified and EvictFunc The relevant definitions of evict action are similar to those of throttle action type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } After the construction is completed, register the metric through registerMetricMap() For the metrics that need to be customized, you can easily realize the flexible customized sorting of pod by combining the following methods with general sorting methods to represent the customized metric indicators, represents the customized sorting strategy func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } Among them, the following sorting method <metric-sort-func> needs to be implemented func (p1, p2 podinfo.PodContext) int32","title":"Qos Ensurance"},{"location":"zh_TW/tutorials/using-qos-ensurance/#qos-ensurance","text":"QoS ensurance guarantees the stability of the pods running on Kubernetes. It has the ability of interference detection and active avoidance. When pod with higher priority is affected by resource competition, disable schedule, throttle and evict will be applied to pod with lower priority to support interference detection and user-defined operation of user-defined indicators; At the same time, it has enhanced bypass cpuset management capability to improve resource utilization efficiency while binding cores. It has the dynamic resource oversold ability enhanced by the prediction algorithm, and reuses the idle resources. At the same time, it combines the prediction ability of the crane to better reuse the idle resources. At the same time, it has the elastic resource limitation function to limit the workload of reusing idle resources.","title":"Qos Ensurance"},{"location":"zh_TW/tutorials/using-qos-ensurance/#qos-ensurance-architecture","text":"Qos ensurance's architecture is shown as below. It contains three modules. state collector: collect metrics periodically anomaly analyzer: analyze the node triggered anomaly used collected metrics action executor: execute avoidance actions, include disable scheduling, throttle and eviction. The main process: State collector synchronizes policies from kube-apiserver. If the policies are changed, the state collector updates the collectors. State collector collects metrics periodically. State collector transmits metrics to anomaly analyzer. Anomaly analyzer ranges all rules to analyze the avoidance threshold or the restored threshold reached. Anomaly analyzer merges the analyzed results and notices the avoidance actions. Action executor executes actions based on the analyzed results.","title":"Qos Ensurance Architecture"},{"location":"zh_TW/tutorials/using-qos-ensurance/#interference-detection-and-active-avoidance","text":"","title":"Interference Detection and Active Avoidance"},{"location":"zh_TW/tutorials/using-qos-ensurance/#disable-scheduling","text":"The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, disable schedule action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : labels : app : system name : disablescheduling spec : description : disable schedule new pods to the node coolDownSeconds : 300 # The minimum wait time of the node from scheduling disable status to normal status apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline1\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 #(1) restoreThreshold : 2 #(2) actionName : \"disablescheduling\" #(3) strategy : \"None\" #(4) metricRule : name : \"cpu_total_usage\" #(5) value : 4000 #(6) We consider the rule is triggered, when the threshold reached continued so many times We consider the rule is restored, when the threshold not reached continued so many times Name of AvoidanceAction which be associated Strategy for the action, you can set it \"Preview\" to not perform actually Name of metric Threshold of metric Please check the video to learn more about the scheduling disable actions.","title":"Disable Scheduling"},{"location":"zh_TW/tutorials/using-qos-ensurance/#throttle","text":"The following AvoidanceAction and NodeQOSEnsurancePolicy can be defined. As a result, when the node CPU usage triggers the threshold, throttle action for the node will be executed. The sample YAML looks like below: apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : throttle labels : app : system spec : coolDownSeconds : 300 throttle : cpuThrottle : minCPURatio : 10 #(1) stepCPURatio : 10 #(2) description : \"throttle low priority pods\" The minimal ratio of the CPU quota, if the pod is throttled lower than this ratio, it will be set to this. The step for throttle action. It will reduce this percentage of CPU quota in each avoidance triggered.It will increase this percentage of CPU quota in each restored. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline2\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoredThreshold : 2 actionName : \"throttle\" strategy : \"None\" metricRule : name : \"cpu_total_usage\" value : 6000","title":"Throttle"},{"location":"zh_TW/tutorials/using-qos-ensurance/#eviction","text":"The following YAML is another case, low priority pods on the node will be evicted, when the node CPU usage trigger the threshold. apiVersion : ensurance.crane.io/v1alpha1 kind : AvoidanceAction metadata : name : eviction labels : app : system spec : coolDownSeconds : 300 eviction : terminationGracePeriodSeconds : 30 #(1) description : \"evict low priority pods\" Duration in seconds the pod needs to terminate gracefully. apiVersion : ensurance.crane.io/v1alpha1 kind : NodeQOSEnsurancePolicy metadata : name : \"waterline3\" labels : app : \"system\" spec : nodeQualityProbe : timeoutSeconds : 10 nodeLocalGet : localCacheTTLSeconds : 60 objectiveEnsurances : - name : \"cpu-usage\" avoidanceThreshold : 2 restoreThreshold : 2 actionName : \"eviction\" strategy : \"Preview\" #(1) metricRule : name : \"cpu_total_usage\" value : 6000 Strategy for the action, \"Preview\" to not perform actually","title":"Eviction"},{"location":"zh_TW/tutorials/using-qos-ensurance/#supported-metrics","text":"Name Description cpu_total_usage node cpu usage cpu_total_utilization node cpu utilization","title":"Supported Metrics"},{"location":"zh_TW/tutorials/using-qos-ensurance/#accurately-perform-avoidance-actions","text":"Through the following two points, the excessive operation of low-quality pod can be avoided, and the gap between the metrics and the specified waterline can be reduced faster, so as to ensure that the high-priority service is not affected 1. Sort pod Crane implements some general sorting methods (which will be improved later): ClassAndPriority: compare the QOSClass and class value of two pods, compare QOSClass first, and then class value; Those with high priority are ranked later and have higher priority runningTime: compare the running time of two pods. The one with long running time is ranked later and has higher priority If you only need to use these two sorting strategies, you can use the default sorting method: you will first compare the priority of the pod, then compare the consumption of the corresponding indicators of the pod, and then compare the running time of the pod. There is a dimension that can compare the results, that is, the sorting results of the pod Taking the ranking of CPU usage metric as an example, it also extends some ranking strategies related to its own metric, such as the ranking of CPU usage, which will compare the priority of two pods in turn. If the priority is the same, then compare the CPU consumption. If the CPU consumption is also the same, continue to compare the extended CPU resource consumption, and finally compare the running time of pod, when there is a difference in an indicator, the comparison result can be returned: orderedby (classandpriority, CpuUsage, extcpuusage, runningtime) Sort(pods) Refer to the waterline and pod usage to perform avoidance action //Divide all the metrics that trigger the waterline threshold into two parts according to their quantified attribute metricsQuantified , MetricsNotQuantified := ThrottleDownWaterLine . DivideMetricsByQuantified () // If there is a metric that cannot be quantified, obtain the metric of a throttleable with the highest actionpriority to operate on all selected pods if len ( MetricsNotThrottleQuantified ) != 0 { highestPrioriyMetric := GetHighestPriorityThrottleAbleMetric () t . throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { //Get the latest usage, get the gap to waterline ThrottoleDownGapToWaterLines = buildGapToWaterLine ( ctx . getStateFunc ()) //If the real-time consumption of metric in the trigger waterline threshold cannot be obtained, chose the metric which is throttleable with the highest actionpriority to suppress all selected pods if ThrottoleDownGapToWaterLines . HasUsageMissedMetric () { highestPrioriyMetric := ThrottleDownWaterLine . GetHighestPriorityThrottleAbleMetric () errPodKeys = throttlePods ( ctx , & totalReleased , highestPrioriyMetric ) } else { var released ReleaseResource //Traverse the quantifiable metrics in the metrics that trigger the waterline: if the metric has a sorting method, use its sortfunc to sort the pod directly, //otherwise use generalsorter to sort; Then use its corresponding operation method to operate the pod, and calculate the amount of resources released from the corresponding metric until the gap between the corresponding metric and the waterline no longer exists for _ , m := range metricsQuantified { if m . SortAble { m . SortFunc ( ThrottleDownPods ) } else { GeneralSorter ( ThrottleDownPods ) } for ! ThrottoleDownGapToWaterLines . TargetGapsRemoved ( m ) { for index , _ := range ThrottleDownPods { released = m . ThrottleFunc ( ctx , index , ThrottleDownPods , & totalReleased ) ThrottoleDownGapToWaterLines [ m ] -= released [ m ] } } } } } About extending user-defined metrics and sorting, it is introduced in \"User-defined metrics interference detection avoidance and user-defined sorting\".","title":"Accurately Perform Avoidance Actions"},{"location":"zh_TW/tutorials/using-qos-ensurance/#enhanced-bypass-cpuset-management-capability","text":"Kubelet supports the static CPU manager strategy. When the guaranteed pod runs on the node, kebelet will allocate the specified dedicated CPU for the pod, which cannot be occupied by other processes. This ensures the CPU monopoly of the guaranteed pod, but also causes the low utilization of CPU and nodes, resulting in a certain waste. Crane agent provides a new strategy for cpuset management, allowing pod and other pod to share CPU. When it specifies CPU binding core, it can make use of the advantages of less context switching and higher cache affinity of binding core, and also allow other workload to deploy and share, so as to improve resource utilization. Three types of pod cpuset are provided: Exclusive: after binding the core, other containers can no longer use the CPU and monopolize the CPU Share: other containers can use the CPU after binding the core None: select the CPU that is not occupied by the container of exclusive pod, can use the binding core of share type Share type binding strategy can make use of the advantages of less context switching and higher cache affinity, and can also be shared by other workload deployments to improve resource utilization Relax the restrictions on binding cores in kubelet Originally, it was required that the CPU limit of all containers be equal to the CPU request. Here, it is only required that the CPU limit of any container be greater than or equal to 1 and equal to the CPU request to set the binding core for the container Support modifying the cpuset policy of pod during the running of pod, which will take effect immediately The CPU manager policy of pod is converted from none to share and from exclusive to share without restart How to use: 1. Set the cpuset manager of kubelet to \"None\" 2. Set CPU manager policy through pod annotation qos.gocrane.io/cpu-manager: none/exclusive/share apiVersion : v1 kind : Pod metadata : annotations : qos.gocrane.io/cpu-manager : none/exclusive/share","title":"Enhanced bypass cpuset management capability"},{"location":"zh_TW/tutorials/using-qos-ensurance/#dynamic-resource-oversold-enhanced-by-prediction-algorithm","text":"In order to improve the stability, users usually set the request value higher than the actual usage when deploying applications, resulting in a waste of resources. In order to improve the resource utilization of nodes, users will deploy some besteffort applications in combination, using idle resources to realize oversold; However, due to the lack of resource limit and request constraints and related information in these applications, scheduler may still schedule these pods to nodes with high load, which is inconsistent with our original intention, so it is best to schedule based on the free resources of nodes. Crane collects the idle resources of nodes in the following two ways, and takes them as the idle resources of nodes after synthesis, which enhances the accuracy of resource evaluation: CPU usage information collected locally nodeCpuCannotBeReclaimed := nodeCpuUsageTotal + exclusiveCPUIdle - extResContainerCpuUsageTotal ExclusiveCPUIdle refers to the idle amount of CPU occupied by the pod whose CPU manager policy is exclusive. Although this part of resources is idle, it cannot be reused because of monopoly, so it is counted as used ExtResContainerCpuUsageTotal refers to the CPU consumption used as dynamic resources, which needs to be subtracted to avoid secondary calculation Create a TSP of node CPU usage, which is automatically created by default, and will predict node CPU usage based on history apiVersion : v1 data : spec : | predictionMetrics: - algorithm: algorithmType: dsp dsp: estimators: fft: - highFrequencyThreshold: \"0.05\" lowAmplitudeThreshold: \"1.0\" marginFraction: \"0.2\" maxNumOfSpectrumItems: 20 minNumOfSpectrumItems: 10 historyLength: 3d sampleInterval: 60s resourceIdentifier: cpu type: ExpressionQuery expressionQuery: expression: 'sum(count(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}) by (mode, cpu)) - sum(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"({{.metadata.name}})(:\\\\d+)?\"}[5m]))' predictionWindowSeconds: 3600 kind : ConfigMap metadata : name : noderesource-tsp-template namespace : default Combine the prediction algorithm with the current actual consumption to calculate the remaining available resources of the node, and give it to the node as an extended resource. Pod can indicate that the extended resource is used as an offline job to use the idle resources, so as to improve the resource utilization rate of the node; How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value> , as follows spec : containers : - image : nginx imagePullPolicy : Always name : extended-resource-demo-ctr resources : limits : gocrane.io/cpu : \"2\" requests : gocrane.io/cpu : \"2\"","title":"Dynamic resource oversold enhanced by prediction algorithm"},{"location":"zh_TW/tutorials/using-qos-ensurance/#elastic-resource-restriction-function","text":"The native besteffort application lacks a fair guarantee of resource usage. Crane guarantees that the CPU usage of the besteffort pod using dynamic resources is limited within the reasonable range of its allowable use. The agent guarantees that the actual consumption of the pod using extended resources will not exceed its stated limit. At the same time, when the CPU competes, it can also compete fairly according to its stated amount; At the same time, pod using elastic resources will also be managed by the waterline function. How to use: When deploying pod, limit and request use gocrane.io/<$resourcename>:<$value>","title":"Elastic resource restriction function"},{"location":"zh_TW/tutorials/using-qos-ensurance/#user-defined-metrics-interference-detection-avoidance-and-user-defined-sorting","text":"The use of user-defined metrics interference detection avoidance and user-defined sorting is the same as the process described in the \"Accurately Perform Avoidance Actions\". Here is how to customize your own metrics to participate in the interference detection avoidance process In order to better sort and accurately control metrics configured based on NodeQoSEnsurancePolicy, the concept of attributes is introduced into metrics. The attributes of metric include the following, and these fields can be realized by customized indicators: Name Indicates the name of metric, which should be consistent with the metric name collected in the collector module ActionPriority Indicates the priority of the metric. 0 is the lowest and 10 is the highest SortAble Indicates whether the metric can be sorted. If it is true, the corresponding SortFunc needs to be implemented SortFunc The corresponding sorting method. The sorting method can be arranged and combined with some general methods, and then combined with the sorting of the metric itself, which will be introduced in detail below ThrottleAble Indicates whether pod can be suppressed for this metric. For example, for the metric of CPU usage, there are corresponding suppression methods, but for the metric of memory usage, pod can only be evicted, and effective suppression cannot be carried out ThrottleQuantified Indicates whether the amount of resources corresponding to metric released after suppressing (restoring) a pod can be accurately calculated. We call the metric that can be accurately quantified as quantifiable, otherwise it is not quantifiable; For example, the CPU usage can be suppressed by limiting the CGroup usage, and the CPU usage released after suppression can be calculated by the current running value and the value after suppression; Memory usage does not belong to suppression quantifiable metric, because memory has no corresponding throttle implementation, so it is impossible to accurately measure the specific amount of memory resources released after suppressing a pod; ThrottleFunc The specific method of executing throttle action. If throttle is not available, the returned released is null RestoreFunc After being throttled, the specific method of performing the recovery action. If restore is not allowed, the returned released is null Evictable, EvictQuantified and EvictFunc The relevant definitions of evict action are similar to those of throttle action type metric struct { Name WaterLineMetric ActionPriority int SortAble bool SortFunc func ( pods [] podinfo . PodContext ) ThrottleAble bool ThrottleQuantified bool ThrottleFunc func ( ctx * ExecuteContext , index int , ThrottleDownPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) RestoreFunc func ( ctx * ExecuteContext , index int , ThrottleUpPods ThrottlePods , totalReleasedResource * ReleaseResource ) ( errPodKeys [] string , released ReleaseResource ) EvictAble bool EvictQuantified bool EvictFunc func ( wg * sync . WaitGroup , ctx * ExecuteContext , index int , totalReleasedResource * ReleaseResource , EvictPods EvictPods ) ( errPodKeys [] string , released ReleaseResource ) } After the construction is completed, register the metric through registerMetricMap() For the metrics that need to be customized, you can easily realize the flexible customized sorting of pod by combining the following methods with general sorting methods to represent the customized metric indicators, represents the customized sorting strategy func <metric>Sorter(pods []podinfo.PodContext) { orderedBy(classAndPriority, <metric-sort-func>, runningTime).Sort(pods) } Among them, the following sorting method <metric-sort-func> needs to be implemented func (p1, p2 podinfo.PodContext) int32","title":"User-defined metrics interference detection avoidance and user-defined sorting"},{"location":"zh_TW/tutorials/using-time-series-prediction/","text":"TimeSeriesPrediction \u00b6 Knowing the future makes things easier for us. Many businesses are naturally cyclical in time series, especially for those that directly or indirectly serve \"people\". This periodicity is determined by the regularity of people\u2019s daily activities. For example, people are accustomed to ordering take-out at noon and in the evenings; there are always traffic peaks in the morning and evening; even for services that don't have such obvious patterns, such as searching, the amount of requests at night is much lower than that during business hours. For applications related to this kind of business, it is a natural idea to infer the next day's metrics from the historical data of the past few days, or to infer the coming Monday's access traffic from the data of last Monday. With predicted metrics or traffic patterns in the next 24 hours, we can better manage our application instances, stabilize our system, and meanwhile, reduce the cost. TimeSeriesPrediction is used to forecast the kubernetes object metric. It is based on PredictionCore to do forecast. Features \u00b6 A TimeSeriesPrediction sample yaml looks like below: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef defines the reference to the kubernetes object including Node or other workload such as Deployment. spec.predictionMetrics defines the metrics about the spec.targetRef. spec.predictionWindowSeconds is a prediction time series duration. the TimeSeriesPredictionController will rotate the predicted data in spec.Status for consumer to consume the predicted time series data. PredictionMetrics \u00b6 apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" MetricType \u00b6 There are three types of the metric query: ResourceQuery is a kubernetes built-in resource metric such as cpu or memory. crane supports only cpu and memory now. RawQuery is a query by DSL, such as prometheus query language. now support prometheus. ExpressionQuery is a query by Expression selector. Now we only support prometheus as data source. We define the MetricType to orthogonal with the datasource. but now maybe some datasources do not support the metricType. Algorithm \u00b6 Algorithm define the algorithm type and params to do predict for the metric. Now there are two kinds of algorithms: dsp is an algorithm to forcasting a time series, it is based on FFT(Fast Fourier Transform), it is good at predicting some time series with seasonality and periods. percentile is an algorithm to estimate a time series, and find a recommended value to represent the past time series, it is based on exponentially-decaying weights historgram statistics. it is used to estimate a time series, it is not good at to predict a time sequences, although the percentile can output a time series predicted data, but it is all the same value. so if you want to predict a time sequences, dsp is a better choice. dsp params \u00b6 percentile params \u00b6","title":"Time Series Prediction"},{"location":"zh_TW/tutorials/using-time-series-prediction/#timeseriesprediction","text":"Knowing the future makes things easier for us. Many businesses are naturally cyclical in time series, especially for those that directly or indirectly serve \"people\". This periodicity is determined by the regularity of people\u2019s daily activities. For example, people are accustomed to ordering take-out at noon and in the evenings; there are always traffic peaks in the morning and evening; even for services that don't have such obvious patterns, such as searching, the amount of requests at night is much lower than that during business hours. For applications related to this kind of business, it is a natural idea to infer the next day's metrics from the historical data of the past few days, or to infer the coming Monday's access traffic from the data of last Monday. With predicted metrics or traffic patterns in the next 24 hours, we can better manage our application instances, stabilize our system, and meanwhile, reduce the cost. TimeSeriesPrediction is used to forecast the kubernetes object metric. It is based on PredictionCore to do forecast.","title":"TimeSeriesPrediction"},{"location":"zh_TW/tutorials/using-time-series-prediction/#features","text":"A TimeSeriesPrediction sample yaml looks like below: apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : targetRef : kind : Node name : 192.168.56.166 predictionWindowSeconds : 600 predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" - resourceIdentifier : node-mem type : ResourceQuery resourceQuery : memory algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"1000000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\" spec.targetRef defines the reference to the kubernetes object including Node or other workload such as Deployment. spec.predictionMetrics defines the metrics about the spec.targetRef. spec.predictionWindowSeconds is a prediction time series duration. the TimeSeriesPredictionController will rotate the predicted data in spec.Status for consumer to consume the predicted time series data.","title":"Features"},{"location":"zh_TW/tutorials/using-time-series-prediction/#predictionmetrics","text":"apiVersion : prediction.crane.io/v1alpha1 kind : TimeSeriesPrediction metadata : name : node-resource-percentile namespace : default spec : predictionMetrics : - resourceIdentifier : node-cpu type : ResourceQuery resourceQuery : cpu algorithm : algorithmType : \"percentile\" percentile : sampleInterval : \"1m\" minSampleWeight : \"1.0\" histogram : maxValue : \"10000.0\" epsilon : \"1e-10\" halfLife : \"12h\" bucketSize : \"10\" firstBucketSize : \"40\" bucketSizeGrowthRatio : \"1.5\"","title":"PredictionMetrics"},{"location":"zh_TW/tutorials/using-time-series-prediction/#metrictype","text":"There are three types of the metric query: ResourceQuery is a kubernetes built-in resource metric such as cpu or memory. crane supports only cpu and memory now. RawQuery is a query by DSL, such as prometheus query language. now support prometheus. ExpressionQuery is a query by Expression selector. Now we only support prometheus as data source. We define the MetricType to orthogonal with the datasource. but now maybe some datasources do not support the metricType.","title":"MetricType"},{"location":"zh_TW/tutorials/using-time-series-prediction/#algorithm","text":"Algorithm define the algorithm type and params to do predict for the metric. Now there are two kinds of algorithms: dsp is an algorithm to forcasting a time series, it is based on FFT(Fast Fourier Transform), it is good at predicting some time series with seasonality and periods. percentile is an algorithm to estimate a time series, and find a recommended value to represent the past time series, it is based on exponentially-decaying weights historgram statistics. it is used to estimate a time series, it is not good at to predict a time sequences, although the percentile can output a time series predicted data, but it is all the same value. so if you want to predict a time sequences, dsp is a better choice.","title":"Algorithm"},{"location":"zh_TW/tutorials/using-time-series-prediction/#dsp-params","text":"","title":"dsp params"},{"location":"zh_TW/tutorials/using-time-series-prediction/#percentile-params","text":"","title":"percentile params"}]}